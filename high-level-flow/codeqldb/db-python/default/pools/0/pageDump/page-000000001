#                        keyword-only defaults #16967)#     Python 3.4a1  3260 (add LOAD_CLASSDEREF; allow locals of class to override#                        free vars #17853)#     Python 3.4a1  3270 (various tweaks to the __class__ closure #12370)#     Python 3.4a1  3280 (remove implicit class argument)#     Python 3.4a4  3290 (changes to __qualname__ computation #19301)#     Python 3.4a4  3300 (more changes to __qualname__ computation #19301)#     Python 3.4rc2 3310 (alter __qualname__ computation #20625)#     Python 3.5a1  3320 (PEP 465: Matrix multiplication operator #21176)#     Python 3.5b1  3330 (PEP 448: Additional Unpacking Generalizations #2292)#     Python 3.5b2  3340 (fix dictionary display evaluation order #11205)#     Python 3.5b3  3350 (add GET_YIELD_FROM_ITER opcode #24400)#     Python 3.5.2  3351 (fix BUILD_MAP_UNPACK_WITH_CALL opcode #27286)#     Python 3.6a0  3360 (add FORMAT_VALUE opcode #25483)#     Python 3.6a1  3361 (lineno delta of code.co_lnotab becomes signed #26107)#     Python 3.6a2  3370 (16 bit wordcode #26647)#     Python 3.6a2  3371 (add BUILD_CONST_KEY_MAP opcode #27140)#     Python 3.6a2  3372 (MAKE_FUNCTION simplification, remove MAKE_CLOSURE#                         #27095)#     Python 3.6b1  3373 (add BUILD_STRING opcode #27078)#     Python 3.6b1  3375 (add SETUP_ANNOTATIONS and STORE_ANNOTATION opcodes#                         #27985)#     Python 3.6b1  3376 (simplify CALL_FUNCTIONs & BUILD_MAP_UNPACK_WITH_CALL#27213)#     Python 3.6b1  3377 (set __class__ cell from type.__new__ #23722)#     Python 3.6b2  3378 (add BUILD_TUPLE_UNPACK_WITH_CALL #28257)#     Python 3.6rc1 3379 (more thorough __class__ validation #23722)#     Python 3.7a1  3390 (add LOAD_METHOD and CALL_METHOD opcodes #26110)#     Python 3.7a2  3391 (update GET_AITER #31709)#     Python 3.7a4  3392 (PEP 552: Deterministic pycs #31650)#     Python 3.7b1  3393 (remove STORE_ANNOTATION opcode #32550)#     Python 3.7b5  3394 (restored docstring as the first stmt in the body;#                         this might affected the first line number #32911)#     Python 3.8a1  3400 (move frame block handling to compiler #17611)#     Python 3.8a1  3401 (add END_ASYNC_FOR #33041)#     Python 3.8a1  3410 (PEP570 Python Positional-Only Parameters #36540)#     Python 3.8b2  3411 (Reverse evaluation order of key: value in dict#                         comprehensions #35224)#     Python 3.8b2  3412 (Swap the position of positional args and positional#                         only args in ast.arguments #37593)#     Python 3.8b4  3413 (Fix "break" and "continue" in "finally" #37830)#     Python 3.9a0  3420 (add LOAD_ASSERTION_ERROR #34880)#     Python 3.9a0  3421 (simplified bytecode for with blocks #32949)#     Python 3.9a0  3422 (remove BEGIN_FINALLY, END_FINALLY, CALL_FINALLY, POP_FINALLY bytecodes #33387)#     Python 3.9a2  3423 (add IS_OP, CONTAINS_OP and JUMP_IF_NOT_EXC_MATCH bytecodes #39156)#     Python 3.9a2  3424 (simplify bytecodes for *value unpacking)#     Python 3.9a2  3425 (simplify bytecodes for **value unpacking)#     Python 3.10a1 3430 (Make 'annotations' future by default)#     Python 3.10a1 3431 (New line number table format -- PEP 626)#     Python 3.10a2 3432 (Function annotation for MAKE_FUNCTION is changed from dict to tuple bpo-42202)#     Python 3.10a2 3433 (RERAISE restores f_lasti if oparg != 0)#     Python 3.10a6 3434 (PEP 634: Structural Pattern Matching)#     Python 3.10a7 3435 Use instruction offsets (as opposed to byte offsets).#     Python 3.10b1 3436 (Add GEN_START bytecode #43683)#     Python 3.10b1 3437 (Undo making 'annotations' future by default - We like to dance among core devs!)#     Python 3.10b1 3438 Safer line number table handling.#     Python 3.10b1 3439 (Add ROT_N)# MAGIC must change whenever the bytecode emitted by the compiler may no# longer be understood by older implementations of the eval loop (usually# due to the addition of new opcodes).# Whenever MAGIC_NUMBER is changed, the ranges in the magic_values array# in PC/launcher.c must also be updated.# For import.c# Deprecated.# We need an absolute path to the py file to avoid the possibility of# collisions within sys.pycache_prefix, if someone has two different# `foo/bar.py` on their system and they import both of them using the# same sys.pycache_prefix. Let's say sys.pycache_prefix is# `C:\Bytecode`; the idea here is that if we get `Foo\Bar`, we first# make it absolute (`C:\Somewhere\Foo\Bar`), then make it root-relative# (`Somewhere\Foo\Bar`), so we end up placing the bytecode file in an# unambiguous `C:\Bytecode\Somewhere\Foo\Bar\`.# Strip initial drive from a Windows path. We know we have an absolute# path here, so the second part of the check rules out a POSIX path that# happens to contain a colon at the second character.# Strip initial path separator from `head` to complete the conversion# back to a root-relative path before joining.# We always ensure write access so we can update cached files# later even when the source files are read-only on Windows (#6074)# FIXME: @_check_name is used to define class methods before the# _bootstrap module is set by _set_bootstrap_module().# Call find_loader(). If it returns a string (indicating this# is a namespace package portion), generate a warning and# return None.# Only the first two flags are defined.# To avoid bootstrap issues.# The caller may simply want a partially populated location-# oriented spec.  So we set the location to a bogus value and# fill in as much as we can.# ExecutionLoader# If the location is on the filesystem, but doesn't actually exist,# we could return None here, indicating that the location is not# valid.  However, we don't have a good way of testing since an# indirect location (e.g. a zip file or URL) will look like a# non-existent file relative to the filesystem.# Pick a loader if one wasn't provided.# Set submodule_search_paths appropriately.# Check the loader.# For backwards compatibility, we delegate to set_data()# The only reason for this method is for the name check.# Issue #14857: Avoid the zero-argument form of super so the implementation# of that form can be updated without breaking the frozen module.# Adapt between the two APIs# Figure out what directories are missing.# Create needed directories.# Probably another Python process already created the dir.# Could be a permission error, read-only filesystem: just forget# about writing the data.# Same as above: just don't write the bytecode.# Call _classify_pyc to do basic validation of the pyc but ignore the# result. There's no source to check against.# When invalidate_caches() is called, this epoch is incremented# https://bugs.python.org/issue45703# This is a top-level module. sys.path contains the parent path.# Not a top-level module. parent-module.__path__ contains the#  parent path.# If the parent's path has changed, recalculate _path# Make a copy# Note that no changes are made if a loader is returned, but we#  do remember the new parent path# Save the copy# We use this exclusively in module_from_spec() for backward-compatibility.# The import system never calls this method.# Finders ###################################################################### Also invalidate the caches of _NamespacePaths# Don't cache the failure as the cwd can easily change to# a valid directory later on.# This would be a good place for a DeprecationWarning if# we ended up going that route.# If this ends up being a namespace package, namespace_path is#  the list of paths that will become its __path__# This is possibly part of a namespace package.#  Remember these path entries (if any) for when we#  create a namespace package, and continue iterating#  on path.# We found at least one namespace path.  Return a spec which# can create the namespace package.# Base (directory) path# tail_module keeps the original casing, for __file__ and friends# Check if the module is the name of a directory (and thus a package).# If a namespace package, return the path if we don't#  find a module in the next section.# Check for a file w/ a proper suffix exists.# Directory has either been removed, turned into a file, or made# unreadable.# We store two cached versions, to handle runtime changes of the# PYTHONCASEOK environment variable.# Windows users can import modules with case-insensitive file# suffixes (for legacy reasons). Make the suffix lowercase here# so it's done once instead of for every import. This is safe as# the specified suffixes to check against are always specified in a# case-sensitive manner.# Import setup ################################################################ This function is used by PyImport_ExecCodeModuleObject().# Not important enough to report.b'Core implementation of path-based import.

This module is NOT meant to be directly imported! It has been designed such
that it can be bootstrapped into Python as the implementation of import. As
such it requires the injection of specific modules and attributes in order to
work. One should use importlib as the public-facing version of this module.

'u'Core implementation of path-based import.

This module is NOT meant to be directly imported! It has been designed such
that it can be bootstrapped into Python as the implementation of import. As
such it requires the injection of specific modules and attributes in order to
work. One should use importlib as the public-facing version of this module.

'b'PYTHONCASEOK'u'PYTHONCASEOK'b'True if filenames must be checked case-insensitively and ignore environment flags are not set.'u'True if filenames must be checked case-insensitively and ignore environment flags are not set.'b'True if filenames must be checked case-insensitively.'u'True if filenames must be checked case-insensitively.'b'Convert a 32-bit integer to little-endian.'u'Convert a 32-bit integer to little-endian.'b'little'b'Convert 4 bytes in little-endian to an integer.'u'Convert 4 bytes in little-endian to an integer.'b'Convert 2 bytes in little-endian to an integer.'u'Convert 2 bytes in little-endian to an integer.'b'Replacement for os.path.join().'u'Replacement for os.path.join().'b'Replacement for os.path.split().'u'Replacement for os.path.split().'b'Stat the path.

    Made a separate function to make it easier to override in experiments
    (e.g. cache stat results).

    'u'Stat the path.

    Made a separate function to make it easier to override in experiments
    (e.g. cache stat results).

    'b'Test whether the path is the specified mode type.'u'Test whether the path is the specified mode type.'b'Replacement for os.path.isfile.'u'Replacement for os.path.isfile.'b'Replacement for os.path.isdir.'u'Replacement for os.path.isdir.'b'Replacement for os.path.isabs.'u'Replacement for os.path.isabs.'b'\\'u'\\'b'Best-effort function to write data to a path atomically.
    Be prepared to handle a FileExistsError if concurrent writing of the
    temporary file is attempted.'u'Best-effort function to write data to a path atomically.
    Be prepared to handle a FileExistsError if concurrent writing of the
    temporary file is attempted.'b'
'b'__pycache__'u'__pycache__'b'opt-'u'opt-'b'.pyw'u'.pyw'b'Given the path to a .py file, return the path to its .pyc file.

    The .py file does not need to exist; this simply returns the path to the
    .pyc file calculated as if the .py file were imported.

    The 'optimization' parameter controls the presumed optimization level of
    the bytecode file. If 'optimization' is not None, the string representation
    of the argument is taken and verified to be alphanumeric (else ValueError
    is raised).

    The debug_override parameter is deprecated. If debug_override is not None,
    a True value is the same as setting 'optimization' to the empty string
    while a False value is equivalent to setting 'optimization' to '1'.

    If sys.implementation.cache_tag is None then NotImplementedError is raised.

    'u'Given the path to a .py file, return the path to its .pyc file.

    The .py file does not need to exist; this simply returns the path to the
    .pyc file calculated as if the .py file were imported.

    The 'optimization' parameter controls the presumed optimization level of
    the bytecode file. If 'optimization' is not None, the string representation
    of the argument is taken and verified to be alphanumeric (else ValueError
    is raised).

    The debug_override parameter is deprecated. If debug_override is not None,
    a True value is the same as setting 'optimization' to the empty string
    while a False value is equivalent to setting 'optimization' to '1'.

    If sys.implementation.cache_tag is None then NotImplementedError is raised.

    'b'the debug_override parameter is deprecated; use 'optimization' instead'u'the debug_override parameter is deprecated; use 'optimization' instead'b'debug_override or optimization must be set to None'u'debug_override or optimization must be set to None'b'sys.implementation.cache_tag is None'u'sys.implementation.cache_tag is None'b'{!r} is not alphanumeric'u'{!r} is not alphanumeric'b'{}.{}{}'u'{}.{}{}'b'Given the path to a .pyc. file, return the path to its .py file.

    The .pyc file does not need to exist; this simply returns the path to
    the .py file calculated to correspond to the .pyc file.  If path does
    not conform to PEP 3147/488 format, ValueError will be raised. If
    sys.implementation.cache_tag is None then NotImplementedError is raised.

    'u'Given the path to a .pyc. file, return the path to its .py file.

    The .pyc file does not need to exist; this simply returns the path to
    the .py file calculated to correspond to the .pyc file.  If path does
    not conform to PEP 3147/488 format, ValueError will be raised. If
    sys.implementation.cache_tag is None then NotImplementedError is raised.

    'b' not bottom-level directory in 'u' not bottom-level directory in 'b'expected only 2 or 3 dots in 'u'expected only 2 or 3 dots in 'b'optimization portion of filename does not start with 'u'optimization portion of filename does not start with 'b'optimization level 'u'optimization level 'b' is not an alphanumeric value'u' is not an alphanumeric value'b'Convert a bytecode file path to a source path (if possible).

    This function exists purely for backwards-compatibility for
    PyImport_ExecCodeModuleWithFilenames() in the C API.

    'u'Convert a bytecode file path to a source path (if possible).

    This function exists purely for backwards-compatibility for
    PyImport_ExecCodeModuleWithFilenames() in the C API.

    'b'py'u'py'b'Calculate the mode permissions for a bytecode file.'u'Calculate the mode permissions for a bytecode file.'b'Decorator to verify that the module being requested matches the one the
    loader can handle.

    The first argument (self) must define _name which the second argument is
    compared against. If the comparison fails then ImportError is raised.

    'u'Decorator to verify that the module being requested matches the one the
    loader can handle.

    The first argument (self) must define _name which the second argument is
    compared against. If the comparison fails then ImportError is raised.

    'b'loader for %s cannot handle %s'u'loader for %s cannot handle %s'b'Try to find a loader for the specified module by delegating to
    self.find_loader().

    This method is deprecated in favor of finder.find_spec().

    'u'Try to find a loader for the specified module by delegating to
    self.find_loader().

    This method is deprecated in favor of finder.find_spec().

    'b'find_module() is deprecated and slated for removal in Python 3.12; use find_spec() instead'u'find_module() is deprecated and slated for removal in Python 3.12; use find_spec() instead'b'Not importing directory {}: missing __init__'u'Not importing directory {}: missing __init__'b'Perform basic validity checking of a pyc header and return the flags field,
    which determines how the pyc should be further validated against the source.

    *data* is the contents of the pyc file. (Only the first 16 bytes are
    required, though.)

    *name* is the name of the module being imported. It is used for logging.

    *exc_details* is a dictionary passed to ImportError if it raised for
    improved debugging.

    ImportError is raised when the magic number is incorrect or when the flags
    field is invalid. EOFError is raised when the data is found to be truncated.

    'u'Perform basic validity checking of a pyc header and return the flags field,
    which determines how the pyc should be further validated against the source.

    *data* is the contents of the pyc file. (Only the first 16 bytes are
    required, though.)

    *name* is the name of the module being imported. It is used for logging.

    *exc_details* is a dictionary passed to ImportError if it raised for
    improved debugging.

    ImportError is raised when the magic number is incorrect or when the flags
    field is invalid. EOFError is raised when the data is found to be truncated.

    'b'bad magic number in 'u'bad magic number in 'b': 'u': 'b'reached EOF while reading pyc header of 'u'reached EOF while reading pyc header of 'b'invalid flags 'u'invalid flags 'b' in 'u' in 'b'Validate a pyc against the source last-modified time.

    *data* is the contents of the pyc file. (Only the first 16 bytes are
    required.)

    *source_mtime* is the last modified timestamp of the source file.

    *source_size* is None or the size of the source file in bytes.

    *name* is the name of the module being imported. It is used for logging.

    *exc_details* is a dictionary passed to ImportError if it raised for
    improved debugging.

    An ImportError is raised if the bytecode is stale.

    'u'Validate a pyc against the source last-modified time.

    *data* is the contents of the pyc file. (Only the first 16 bytes are
    required.)

    *source_mtime* is the last modified timestamp of the source file.

    *source_size* is None or the size of the source file in bytes.

    *name* is the name of the module being imported. It is used for logging.

    *exc_details* is a dictionary passed to ImportError if it raised for
    improved debugging.

    An ImportError is raised if the bytecode is stale.

    'b'bytecode is stale for 'u'bytecode is stale for 'b'Validate a hash-based pyc by checking the real source hash against the one in
    the pyc header.

    *data* is the contents of the pyc file. (Only the first 16 bytes are
    required.)

    *source_hash* is the importlib.util.source_hash() of the source file.

    *name* is the name of the module being imported. It is used for logging.

    *exc_details* is a dictionary passed to ImportError if it raised for
    improved debugging.

    An ImportError is raised if the bytecode is stale.

    'u'Validate a hash-based pyc by checking the real source hash against the one in
    the pyc header.

    *data* is the contents of the pyc file. (Only the first 16 bytes are
    required.)

    *source_hash* is the importlib.util.source_hash() of the source file.

    *name* is the name of the module being imported. It is used for logging.

    *exc_details* is a dictionary passed to ImportError if it raised for
    improved debugging.

    An ImportError is raised if the bytecode is stale.

    'b'hash in bytecode doesn't match hash of source 'u'hash in bytecode doesn't match hash of source 'b'Compile bytecode as found in a pyc.'u'Compile bytecode as found in a pyc.'b'code object from {!r}'u'code object from {!r}'b'Non-code object in {!r}'u'Non-code object in {!r}'b'Produce the data for a timestamp-based pyc.'u'Produce the data for a timestamp-based pyc.'b'Produce the data for a hash-based pyc.'u'Produce the data for a hash-based pyc.'b'Decode bytes representing source code and return the string.

    Universal newline support is used in the decoding.
    'u'Decode bytes representing source code and return the string.

    Universal newline support is used in the decoding.
    'b'Return a module spec based on a file location.

    To indicate that the module is a package, set
    submodule_search_locations to a list of directory paths.  An
    empty list is sufficient, though its not otherwise useful to the
    import system.

    The loader must take a spec as its only __init__() arg.

    'u'Return a module spec based on a file location.

    To indicate that the module is a package, set
    submodule_search_locations to a list of directory paths.  An
    empty list is sufficient, though its not otherwise useful to the
    import system.

    The loader must take a spec as its only __init__() arg.

    'b'<unknown>'u'<unknown>'b'Meta path finder for modules declared in the Windows registry.'u'Meta path finder for modules declared in the Windows registry.'b'Software\Python\PythonCore\{sys_version}\Modules\{fullname}'u'Software\Python\PythonCore\{sys_version}\Modules\{fullname}'b'Software\Python\PythonCore\{sys_version}\Modules\{fullname}\Debug'u'Software\Python\PythonCore\{sys_version}\Modules\{fullname}\Debug'b'_d.pyd'u'_d.pyd'b'%d.%d'u'%d.%d'b'Find module named in the registry.

        This method is deprecated.  Use find_spec() instead.

        'u'Find module named in the registry.

        This method is deprecated.  Use find_spec() instead.

        'b'WindowsRegistryFinder.find_module() is deprecated and slated for removal in Python 3.12; use find_spec() instead'u'WindowsRegistryFinder.find_module() is deprecated and slated for removal in Python 3.12; use find_spec() instead'b'Base class of common code needed by both SourceLoader and
    SourcelessFileLoader.'b'Concrete implementation of InspectLoader.is_package by checking if
        the path returned by get_filename has a filename of '__init__.py'.'u'Concrete implementation of InspectLoader.is_package by checking if
        the path returned by get_filename has a filename of '__init__.py'.'b'__init__'b'Execute the module.'u'Execute the module.'b'cannot load module {!r} when get_code() returns None'u'cannot load module {!r} when get_code() returns None'b'This method is deprecated.'u'This method is deprecated.'b'Optional method that returns the modification time (an int) for the
        specified path (a str).

        Raises OSError when the path cannot be handled.
        'u'Optional method that returns the modification time (an int) for the
        specified path (a str).

        Raises OSError when the path cannot be handled.
        'b'Optional method returning a metadata dict for the specified
        path (a str).

        Possible keys:
        - 'mtime' (mandatory) is the numeric timestamp of last source
          code modification;
        - 'size' (optional) is the size in bytes of the source code.

        Implementing this method allows the loader to read bytecode files.
        Raises OSError when the path cannot be handled.
        'u'Optional method returning a metadata dict for the specified
        path (a str).

        Possible keys:
        - 'mtime' (mandatory) is the numeric timestamp of last source
          code modification;
        - 'size' (optional) is the size in bytes of the source code.

        Implementing this method allows the loader to read bytecode files.
        Raises OSError when the path cannot be handled.
        'b'mtime'u'mtime'b'Optional method which writes data (bytes) to a file path (a str).

        Implementing this method allows for the writing of bytecode files.

        The source path is needed in order to correctly transfer permissions
        'u'Optional method which writes data (bytes) to a file path (a str).

        Implementing this method allows for the writing of bytecode files.

        The source path is needed in order to correctly transfer permissions
        'b'Optional method which writes data (bytes) to a file path (a str).

        Implementing this method allows for the writing of bytecode files.
        'u'Optional method which writes data (bytes) to a file path (a str).

        Implementing this method allows for the writing of bytecode files.
        'b'Concrete implementation of InspectLoader.get_source.'u'Concrete implementation of InspectLoader.get_source.'b'source not available through get_data()'u'source not available through get_data()'b'Return the code object compiled from source.

        The 'data' argument can be any object type that compile() supports.
        'u'Return the code object compiled from source.

        The 'data' argument can be any object type that compile() supports.
        'b'Concrete implementation of InspectLoader.get_code.

        Reading of bytecode requires path_stats to be implemented. To write
        bytecode, set_data must also be implemented.

        'u'Concrete implementation of InspectLoader.get_code.

        Reading of bytecode requires path_stats to be implemented. To write
        bytecode, set_data must also be implemented.

        'b'path'u'path'b'never'u'never'b'{} matches {}'u'{} matches {}'b'code object from {}'u'code object from {}'b'Base file loader class which implements the loader protocol methods that
    require file system usage.'b'Cache the module name and the path to the file found by the
        finder.'u'Cache the module name and the path to the file found by the
        finder.'b'Load a module from a file.

        This method is deprecated.  Use exec_module() instead.

        'u'Load a module from a file.

        This method is deprecated.  Use exec_module() instead.

        'b'Return the path to the source file as found by the finder.'u'Return the path to the source file as found by the finder.'b'Return the data from path as raw bytes.'u'Return the data from path as raw bytes.'b'Concrete implementation of SourceLoader using the file system.'u'Concrete implementation of SourceLoader using the file system.'b'Return the metadata for the path.'u'Return the metadata for the path.'b'Write bytes data to a file.'u'Write bytes data to a file.'b'could not create {!r}: {!r}'u'could not create {!r}: {!r}'b'created {!r}'u'created {!r}'b'Loader which handles sourceless file imports.'u'Loader which handles sourceless file imports.'b'Return None as there is no source code.'u'Return None as there is no source code.'b'Loader for extension modules.

    The constructor is designed to work with FileFinder.

    'b'Create an unitialized extension module'u'Create an unitialized extension module'b'extension module {!r} loaded from {!r}'u'extension module {!r} loaded from {!r}'b'Initialize an extension module'u'Initialize an extension module'b'extension module {!r} executed from {!r}'u'extension module {!r} executed from {!r}'b'Return True if the extension module is a package.'u'Return True if the extension module is a package.'b'Return None as an extension module cannot create a code object.'u'Return None as an extension module cannot create a code object.'b'Return None as extension modules have no source code.'u'Return None as extension modules have no source code.'b'Represents a namespace package's path.  It uses the module name
    to find its parent module, and from there it looks up the parent's
    __path__.  When this changes, the module's own path is recomputed,
    using path_finder.  For top-level modules, the parent module's path
    is sys.path.'u'Represents a namespace package's path.  It uses the module name
    to find its parent module, and from there it looks up the parent's
    __path__.  When this changes, the module's own path is recomputed,
    using path_finder.  For top-level modules, the parent module's path
    is sys.path.'b'Returns a tuple of (parent-module-name, parent-path-attr-name)'u'Returns a tuple of (parent-module-name, parent-path-attr-name)'b'sys'b'_NamespacePath({!r})'u'_NamespacePath({!r})'b'_NamespaceLoader.module_repr() is deprecated and slated for removal in Python 3.12'u'_NamespaceLoader.module_repr() is deprecated and slated for removal in Python 3.12'b'<module {!r} (namespace)>'u'<module {!r} (namespace)>'b'Load a namespace module.

        This method is deprecated.  Use exec_module() instead.

        'u'Load a namespace module.

        This method is deprecated.  Use exec_module() instead.

        'b'namespace module loaded with path {!r}'u'namespace module loaded with path {!r}'b'Meta path finder for sys.path and package __path__ attributes.'b'Call the invalidate_caches() method on all path entry finders
        stored in sys.path_importer_caches (where implemented).'u'Call the invalidate_caches() method on all path entry finders
        stored in sys.path_importer_caches (where implemented).'b'Search sys.path_hooks for a finder for 'path'.'u'Search sys.path_hooks for a finder for 'path'.'b'sys.path_hooks is empty'u'sys.path_hooks is empty'b'Get the finder for the path entry from sys.path_importer_cache.

        If the path entry is not in the cache, find the appropriate finder
        and cache it. If no finder is available, store None.

        'u'Get the finder for the path entry from sys.path_importer_cache.

        If the path entry is not in the cache, find the appropriate finder
        and cache it. If no finder is available, store None.

        'b'find_loader'u'find_loader'b'.find_spec() not found; falling back to find_loader()'u'.find_spec() not found; falling back to find_loader()'b'Find the loader or namespace_path for this module/package name.'u'Find the loader or namespace_path for this module/package name.'b'find_spec'u'find_spec'b'spec missing loader'u'spec missing loader'b'Try to find a spec for 'fullname' on sys.path or 'path'.

        The search is based on sys.path_hooks and sys.path_importer_cache.
        'u'Try to find a spec for 'fullname' on sys.path or 'path'.

        The search is based on sys.path_hooks and sys.path_importer_cache.
        'b'find the module on sys.path or 'path' based on sys.path_hooks and
        sys.path_importer_cache.

        This method is deprecated.  Use find_spec() instead.

        'u'find the module on sys.path or 'path' based on sys.path_hooks and
        sys.path_importer_cache.

        This method is deprecated.  Use find_spec() instead.

        'b'PathFinder.find_module() is deprecated and slated for removal in Python 3.12; use find_spec() instead'u'PathFinder.find_module() is deprecated and slated for removal in Python 3.12; use find_spec() instead'b'
        Find distributions.

        Return an iterable of all Distribution instances capable of
        loading the metadata for packages matching ``context.name``
        (or all names if ``None`` indicated) along the paths in the list
        of directories ``context.path``.
        'u'
        Find distributions.

        Return an iterable of all Distribution instances capable of
        loading the metadata for packages matching ``context.name``
        (or all names if ``None`` indicated) along the paths in the list
        of directories ``context.path``.
        'b'File-based finder.

    Interactions with the file system are cached for performance, being
    refreshed when the directory the finder is handling has been modified.

    'u'File-based finder.

    Interactions with the file system are cached for performance, being
    refreshed when the directory the finder is handling has been modified.

    'b'Initialize with the path to search on and a variable number of
        2-tuples containing the loader and the file suffixes the loader
        recognizes.'u'Initialize with the path to search on and a variable number of
        2-tuples containing the loader and the file suffixes the loader
        recognizes.'b'Invalidate the directory mtime.'u'Invalidate the directory mtime.'b'Try to find a loader for the specified module, or the namespace
        package portions. Returns (loader, list-of-portions).

        This method is deprecated.  Use find_spec() instead.

        'u'Try to find a loader for the specified module, or the namespace
        package portions. Returns (loader, list-of-portions).

        This method is deprecated.  Use find_spec() instead.

        'b'FileFinder.find_loader() is deprecated and slated for removal in Python 3.12; use find_spec() instead'u'FileFinder.find_loader() is deprecated and slated for removal in Python 3.12; use find_spec() instead'b'Try to find a spec for the specified module.

        Returns the matching spec, or None if not found.
        'u'Try to find a spec for the specified module.

        Returns the matching spec, or None if not found.
        'b'trying {}'u'trying {}'b'possible namespace for {}'u'possible namespace for {}'b'Fill the cache of potential modules and packages for this directory.'u'Fill the cache of potential modules and packages for this directory.'b'A class method which returns a closure to use on sys.path_hook
        which will return an instance using the specified loaders and the path
        called on the closure.

        If the path called on the closure is not a directory, ImportError is
        raised.

        'u'A class method which returns a closure to use on sys.path_hook
        which will return an instance using the specified loaders and the path
        called on the closure.

        If the path called on the closure is not a directory, ImportError is
        raised.

        'b'Path hook for importlib.machinery.FileFinder.'u'Path hook for importlib.machinery.FileFinder.'b'only directories are supported'u'only directories are supported'b'FileFinder({!r})'u'FileFinder({!r})'b'Returns a list of file-based module loaders.

    Each item is a tuple (loader, suffixes).
    'u'Returns a list of file-based module loaders.

    Each item is a tuple (loader, suffixes).
    'b'Install the path-based import components.'u'Install the path-based import components.'u'_bootstrap_external'
Basic subprocess implementation for POSIX which only uses os functions. Only
implement features required by setup.py to build C extension modules when
subprocess is unavailable. setup.py is not used on Windows.
_cmdexecveexecv_check_cmdsafe_chars./-check_strsunsupported command: check_output.tmptmp_filename >Command  returned non-zero exit status " returned non-zero ""exit status "# distutils.spawn used by distutils.command.build_ext# calls subprocess.Popen().wait()# Child process# Use regex [a-zA-Z0-9./-]+: reject empty string, space, etc.# reject empty string# _aix_support used by distutil.util calls subprocess.check_output()# system() spawns a shellb'
Basic subprocess implementation for POSIX which only uses os functions. Only
implement features required by setup.py to build C extension modules when
subprocess is unavailable. setup.py is not used on Windows.
'u'
Basic subprocess implementation for POSIX which only uses os functions. Only
implement features required by setup.py to build C extension modules when
subprocess is unavailable. setup.py is not used on Windows.
'b'A'u'A'b'./-'u'./-'b'unsupported command: 'u'unsupported command: 'b'check_output.tmp'u'check_output.tmp'b' >'u' >'b'Command 'u'Command 'b' returned non-zero exit status 'u' returned non-zero exit status 'u'_bootsubprocess'u'Create a compressor object for compressing data incrementally.

  compresslevel
    Compression level, as a number between 1 and 9.

For one-shot compression, use the compress() function instead.'u'_bz2'compress_bz2.BZ2CompressorBZ2Compressoru'Create a decompressor object for decompressing data incrementally.

For one-shot decompression, use the decompress() function instead.'decompresseofneeds_inputunused_data_bz2.BZ2DecompressorBZ2Decompressoru'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_bz2.cpython-310-darwin.so'_bz2ascii_decodeascii_encodecharmap_buildcharmap_decodecharmap_encodeescape_decodeescape_encodelatin_1_decodelatin_1_encodelookuplookup_errorraw_unicode_escape_decoderaw_unicode_escape_encodereadbuffer_encoderegister_errorunicode_escape_decodeunicode_escape_encodeunregisterutf_16_be_decodeutf_16_be_encodeutf_16_decodeutf_16_encodeutf_16_ex_decodeutf_16_le_decodeutf_16_le_encodeutf_32_be_decodeutf_32_be_encodeutf_32_decodeutf_32_encodeutf_32_ex_decodeutf_32_le_decodeutf_32_le_encodeutf_7_decodeutf_7_encodeutf_8_decodeutf_8_encode_codecsu'OrderedDict.__dict__'collections.OrderedDictu'High performance data structures.
- deque:        ordered collection accessible from endpoints only
- defaultdict:  dict subclass with a default value factory
'_collections._deque_iterator_deque_iterator_collections._deque_reverse_iterator_deque_reverse_iterator_collections._tuplegetteru'defaultdict(default_factory=None, /, [...]) --> dict with default factory

The default factory is called without arguments to produce
a new value when a key is not present, in __getitem__ only.
A defaultdict compares equal to a dict with the same items.
All remaining arguments are treated the same as if they were
passed to the dict constructor, including keyword arguments.
'default_factorycollections.defaultdictu'deque([iterable[, maxlen]]) --> deque object

A list-like sequence optimized for data accesses near its endpoints.'appendleftextendleftu'maximum size of a deque or None if unbounded'u'deque.maxlen'maxlenrotatecollections.dequeInvalidHeaderpackages.sixHTTPHeaderDict_Null
    Provides a thread-safe dict-like container which maintains up to
    ``maxsize`` keys while throwing away the least-recently-used keys beyond
    ``maxsize``.

    :param maxsize:
        Maximum number of recent elements to retain.

    :param dispose_func:
        Every time an item is evicted from the container,
        ``dispose_func(value)`` is called.  Callback which will get called
    ContainerCls_maxsize_containerevicted_value_keyIteration over this class is unlikely to be threadsafe.
    :param headers:
        An iterable of field-value pairs. Must not contain multiple field names
        when compared case-insensitively.

    :param kwargs:
        Additional field-value pairs to pass in to ``dict.update``.

    A ``dict`` like container for storing HTTP Headers.

    Field names are stored and compared case-insensitively in compliance with
    RFC 7230. Iteration provides the first case-sensitive key seen for each
    case-insensitive pair.

    Using ``__setitem__`` syntax overwrites fields that compare equal
    case-insensitively in order to maintain ``dict``'s api. For fields that
    compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``
    in a loop.

    If multiple fields that are equal case-insensitively are passed to the
    constructor or ``.update``, the behavior is undefined and some will be
    lost.

    >>> headers = HTTPHeaderDict()
    >>> headers.add('Set-Cookie', 'foo=bar')
    >>> headers.add('set-cookie', 'baz=quxx')
    >>> headers['content-length'] = '7'
    >>> headers['SET-cookie']
    'foo=bar, baz=quxx'
    >>> headers['Content-Length']
    '7'
    _copy_fromitermergedvalsD.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised.
        Adds a (name, value) pair, doesn't overwrite the value if it already
        exists.

        >>> headers = HTTPHeaderDict(foo='bar')
        >>> headers.add('Foo', 'baz')
        >>> headers['foo']
        'bar, baz'
        key_lowernew_valsGeneric import function for any type of header-like object.
        Adapted version of MutableMapping.update in order to insert items
        with self.add instead of self.__setitem__
        extend() takes at most 1 positional arguments ({0} given)"extend() takes at most 1 positional ""arguments ({0} given)"getlistReturns a list of all the values for the named field. Returns an
        empty list if the key doesn't exist.getheadersgetallmatchingheadersigetget_allIterate over all header lines, including duplicate ones.Iterate over all headers, merging duplicate ones together.from_httplibRead headers from a Python 2 httplib message object.obs_fold_continued_leadersHeader continuation with no previous header: %s# Platform-specific: No threads available# Re-insert the item, moving it to the end of the eviction line.# Possibly evict the existing value of 'key'# If we didn't evict an existing value, we might have to evict the# least recently used item from the beginning of the container.# Copy pointers to all values, then wipe the mapping# Python 2# Only provide the originally cased names# Using the MutableMapping function directly fails due to the private marker.# Using ordinary dict.pop would expose the internal structures.# So let's reinvent the wheel.# Keep the common case aka no item present as fast as possible# Backwards compatibility for httplib# Backwards compatibility for http.cookiejar# Don't need to convert tuples# python2.7 does not expose a proper API for exporting multiheaders# efficiently. This function re-reads raw lines from the message# object and extracts the multiheaders properly.# We received a header line that starts with OWS as described# in RFC-7230 S3.2.4. This indicates a multiline header, but# there exists no previous header to which we can attach it.b'RecentlyUsedContainer'u'RecentlyUsedContainer'b'HTTPHeaderDict'u'HTTPHeaderDict'b'
    Provides a thread-safe dict-like container which maintains up to
    ``maxsize`` keys while throwing away the least-recently-used keys beyond
    ``maxsize``.

    :param maxsize:
        Maximum number of recent elements to retain.

    :param dispose_func:
        Every time an item is evicted from the container,
        ``dispose_func(value)`` is called.  Callback which will get called
    'u'
    Provides a thread-safe dict-like container which maintains up to
    ``maxsize`` keys while throwing away the least-recently-used keys beyond
    ``maxsize``.

    :param maxsize:
        Maximum number of recent elements to retain.

    :param dispose_func:
        Every time an item is evicted from the container,
        ``dispose_func(value)`` is called.  Callback which will get called
    'b'Iteration over this class is unlikely to be threadsafe.'u'Iteration over this class is unlikely to be threadsafe.'b'
    :param headers:
        An iterable of field-value pairs. Must not contain multiple field names
        when compared case-insensitively.

    :param kwargs:
        Additional field-value pairs to pass in to ``dict.update``.

    A ``dict`` like container for storing HTTP Headers.

    Field names are stored and compared case-insensitively in compliance with
    RFC 7230. Iteration provides the first case-sensitive key seen for each
    case-insensitive pair.

    Using ``__setitem__`` syntax overwrites fields that compare equal
    case-insensitively in order to maintain ``dict``'s api. For fields that
    compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``
    in a loop.

    If multiple fields that are equal case-insensitively are passed to the
    constructor or ``.update``, the behavior is undefined and some will be
    lost.

    >>> headers = HTTPHeaderDict()
    >>> headers.add('Set-Cookie', 'foo=bar')
    >>> headers.add('set-cookie', 'baz=quxx')
    >>> headers['content-length'] = '7'
    >>> headers['SET-cookie']
    'foo=bar, baz=quxx'
    >>> headers['Content-Length']
    '7'
    'u'
    :param headers:
        An iterable of field-value pairs. Must not contain multiple field names
        when compared case-insensitively.

    :param kwargs:
        Additional field-value pairs to pass in to ``dict.update``.

    A ``dict`` like container for storing HTTP Headers.

    Field names are stored and compared case-insensitively in compliance with
    RFC 7230. Iteration provides the first case-sensitive key seen for each
    case-insensitive pair.

    Using ``__setitem__`` syntax overwrites fields that compare equal
    case-insensitively in order to maintain ``dict``'s api. For fields that
    compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``
    in a loop.

    If multiple fields that are equal case-insensitively are passed to the
    constructor or ``.update``, the behavior is undefined and some will be
    lost.

    >>> headers = HTTPHeaderDict()
    >>> headers.add('Set-Cookie', 'foo=bar')
    >>> headers.add('set-cookie', 'baz=quxx')
    >>> headers['content-length'] = '7'
    >>> headers['SET-cookie']
    'foo=bar, baz=quxx'
    >>> headers['Content-Length']
    '7'
    'b'D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised.
        'u'D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised.
        'b'Adds a (name, value) pair, doesn't overwrite the value if it already
        exists.

        >>> headers = HTTPHeaderDict(foo='bar')
        >>> headers.add('Foo', 'baz')
        >>> headers['foo']
        'bar, baz'
        'u'Adds a (name, value) pair, doesn't overwrite the value if it already
        exists.

        >>> headers = HTTPHeaderDict(foo='bar')
        >>> headers.add('Foo', 'baz')
        >>> headers['foo']
        'bar, baz'
        'b'Generic import function for any type of header-like object.
        Adapted version of MutableMapping.update in order to insert items
        with self.add instead of self.__setitem__
        'u'Generic import function for any type of header-like object.
        Adapted version of MutableMapping.update in order to insert items
        with self.add instead of self.__setitem__
        'b'extend() takes at most 1 positional arguments ({0} given)'u'extend() takes at most 1 positional arguments ({0} given)'b'Returns a list of all the values for the named field. Returns an
        empty list if the key doesn't exist.'u'Returns a list of all the values for the named field. Returns an
        empty list if the key doesn't exist.'b'Iterate over all header lines, including duplicate ones.'u'Iterate over all header lines, including duplicate ones.'b'Iterate over all headers, merging duplicate ones together.'u'Iterate over all headers, merging duplicate ones together.'b'Read headers from a Python 2 httplib message object.'u'Read headers from a Python 2 httplib message object.'b'Header continuation with no previous header: %s'u'Header continuation with no previous header: %s'u'urllib3._collections'Abstract Base Classes (ABCs) for collections, according to PEP 3119.

Unit tests are in test_collections.
abstractmethodEllipsisType_fAwaitableCoroutineAsyncIterableAsyncIteratorAsyncGeneratorHashableIterableGeneratorReversibleSizedContainerCallableCollectionMutableSetMappingViewByteStringbytes_iteratorbytearray_iteratordict_keyiteratordict_valueiteratordict_itemiteratorlist_iteratorlist_reverseiteratorrange_iteratorlongrange_iteratorset_iteratorstr_iteratortuple_iteratorzip_iteratordict_keysdict_valuesdict_itemsmappingproxycoroutine_agasync_generator_check_methodsCmethodsSend a value into the coroutine.
        Return next yielded value or raise StopIteration.
        Raise an exception in the coroutine.
        Return next yielded value or raise StopIteration.
        Raise GeneratorExit inside coroutine.
        coroutine ignored GeneratorExit__aiter____anext__Return the next item or raise StopAsyncIteration when exhausted.Return the next item from the asynchronous generator.
        When exhausted, raise StopAsyncIteration.
        asendSend a value into the asynchronous generator.
        Return next yielded value or raise StopAsyncIteration.
        athrowRaise an exception in the asynchronous generator.
        Return next yielded value or raise StopAsyncIteration.
        acloseasynchronous generator ignored GeneratorExitReturn the next item from the iterator. When exhausted, raise StopIterationReturn the next item from the generator.
        When exhausted, raise StopIteration.
        Send a value into the generator.
        Return next yielded value or raise StopIteration.
        Raise an exception in the generator.
        Return next yielded value or raise StopIteration.
        Raise GeneratorExit inside generator.
        generator ignored GeneratorExit_CallableGenericAlias Represent `Callable[argtypes, resulttype]`.

    This sets ``__args__`` to a tuple containing the flattened ``argtypes``
    followed by ``resulttype``.

    Example: ``Callable[[int, str], float]`` sets ``__args__`` to
    ``(int, str, float)``.
    Callable must be used as Callable[[arg, ...], result].t_argst_result_is_param_exprExpected a list of types, an ellipsis, ParamSpec, or Concatenate. Got "Expected a list of types, an ellipsis, ""ParamSpec, or Concatenate. Got "__parameters__params__args___is_typevarlikecollections.abc.Callable[['collections.abc.Callable''[['_type_repr], '], 'param_len is not a generic classitem_lenToo manyfew arguments for ' arguments for '; actual ';'' actual ', expected new_argssubparamssubargsParamSpecTypeVarChecks if obj matches either a list of types, ``...``, ``ParamSpec`` or
    ``_ConcatenateGenericAlias`` from typing.py
    _ConcatenateGenericAliasReturn the repr() of an object, special-casing types (internal helper).

    Copied from :mod:`typing` since collections.abc
    shouldn't depend on that module.
    ...A set is a finite, iterable container.

    This class provides concrete generic implementations of all
    methods except for __contains__, __iter__ and __len__.

    To override the comparisons (presumably for speed, as the
    semantics are fixed), redefine __le__ and __ge__,
    then the other operations will automatically follow suit.
    _from_iterableConstruct an instance of the class from any iterable input.

        Must override this method if the class constructor signature
        does not accept an iterable for an input.
        Return True if two sets have a null intersection._hashCompute the hash value of a set.

        Note that we don't define __hash__: not all sets are hashable.
        But if you define a hashable set type, its __hash__ should
        call this function.

        This must be compatible __eq__.

        All sets ought to compare equal if they contain the same
        elements, regardless of how they are implemented, and
        regardless of the order of the elements; so there's not much
        freedom for __eq__ or __hash__.  We match the algorithm used
        by the built-in frozenset type.
        MAXMASK1927868237hx89869747364479816769069907133923590923713A mutable set is a finite, iterable container.

    This class provides concrete generic implementations of all
    methods except for __contains__, __iter__, __len__,
    add(), and discard().

    To override the comparisons (presumably for speed, as the
    semantics are fixed), all you have to do is redefine __le__ and
    then the other operations will automatically follow suit.
    Add an element.Remove an element.  Do not raise an exception if absent.Remove an element. If not a member, raise a KeyError.Return the popped value.  Raise KeyError if empty.This is slow (creates N new iterators!) but effective.A Mapping is a generic container for associating key/value
    pairs.

    This class provides concrete generic implementations of all
    methods except for __getitem__, __iter__, and __len__.
    __abc_tpflags__D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.{0.__class__.__name__}({0._mapping!r})A MutableMapping is a generic container for associating
    key/value pairs.

    This class provides concrete generic implementations of all
    methods except for __getitem__, __setitem__, __delitem__,
    __iter__, and __len__.
    D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
          If key is not found, d is returned if given, otherwise KeyError is raised.
        D.popitem() -> (k, v), remove and return some (key, value) pair
           as a 2-tuple; but raise KeyError if D is empty.
        D.clear() -> None.  Remove all items from D. D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
            If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
            If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
            In either case, this is followed by: for k, v in F.items(): D[k] = v
        D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in DAll the operations on a read-only sequence.

    Concrete subclasses must override __new__ or __init__,
    __getitem__, and __len__.
    S.index(value, [start, [stop]]) -> integer -- return first index of value.
           Raises ValueError if the value is not present.

           Supporting start and stop arguments is optional, but
           recommended.
        S.count(value) -> integer -- return number of occurrences of valueThis unifies bytes and bytearray.

    XXX Should add all their methods.
    All the operations on a read-write sequence.

    Concrete subclasses must provide __new__ or __init__,
    __getitem__, __setitem__, __delitem__, __len__, and insert().
    S.insert(index, value) -- insert value before indexS.append(value) -- append value to the end of the sequenceS.clear() -> None -- remove all items from SS.reverse() -- reverse *IN PLACE*S.extend(iterable) -- extend sequence by appending elements from the iterableS.pop([index]) -> item -- remove and return item at index (default last).
           Raise IndexError if list is empty or index is out of range.
        S.remove(value) -- remove first occurrence of value.
           Raise ValueError if the value is not present.
        # Copyright 2007 Google, Inc. All Rights Reserved.# This module has been renamed from collections.abc to _collections_abc to# speed up interpreter startup. Some of the types such as MutableMapping are# required early but collections module imports a lot of other modules.# See issue #19218# Private list of types that we want to register with the various ABCs# so that they will pass tests like:#       it = iter(somebytearray)#       assert isinstance(it, Iterable)# Note:  in other implementations, these types might not be distinct# and they may have their own implementation specific types that# are not included on this list.#callable_iterator = ???## views #### misc #### coroutine ### Prevent ResourceWarning## asynchronous generator ##### ONE-TRICK PONIES ####Iterator.register(callable_iterator)# Looks like a genericalias# Called during TypeVar substitution, returns the custom subclass# rather than the default types.GenericAlias object.  Most of the# code is copied from typing's _GenericAlias and the builtin# types.GenericAlias.# A special case in PEP 612 where if X = Callable[P, int],# then X[int, str] == X[[int, str]].# Looks like a GenericAlias# args[0] occurs due to things like Z[[int, str, bool]] from PEP 612# looks like a TypeVar/ParamSpec### SETS ###### MAPPINGS #### Tell ABCMeta.__new__ that this class should have TPFLAGS_MAPPING set.# Py_TPFLAGS_MAPPING### SEQUENCES #### Tell ABCMeta.__new__ that this class should have TPFLAGS_SEQUENCE set.# Py_TPFLAGS_SEQUENCE# Multiply inheriting, see ByteStringb'Abstract Base Classes (ABCs) for collections, according to PEP 3119.

Unit tests are in test_collections.
'u'Abstract Base Classes (ABCs) for collections, according to PEP 3119.

Unit tests are in test_collections.
'b'Awaitable'u'Awaitable'b'Coroutine'u'Coroutine'b'AsyncIterable'u'AsyncIterable'b'AsyncIterator'u'AsyncIterator'b'AsyncGenerator'u'AsyncGenerator'b'Hashable'u'Hashable'b'Iterable'u'Iterable'b'Iterator'u'Iterator'b'Generator'u'Generator'b'Reversible'u'Reversible'b'Sized'u'Sized'b'Container'u'Container'b'Callable'u'Callable'b'Collection'u'Collection'b'Set'u'Set'b'MutableSet'u'MutableSet'b'Mapping'u'Mapping'b'MutableMapping'u'MutableMapping'b'MappingView'u'MappingView'b'KeysView'u'KeysView'b'ItemsView'u'ItemsView'b'ValuesView'u'ValuesView'b'Sequence'u'Sequence'b'MutableSequence'u'MutableSequence'b'ByteString'u'ByteString'b'collections.abc'u'collections.abc'b'__hash__'u'__hash__'b'__await__'u'__await__'b'Send a value into the coroutine.
        Return next yielded value or raise StopIteration.
        'u'Send a value into the coroutine.
        Return next yielded value or raise StopIteration.
        'b'Raise an exception in the coroutine.
        Return next yielded value or raise StopIteration.
        'u'Raise an exception in the coroutine.
        Return next yielded value or raise StopIteration.
        'b'Raise GeneratorExit inside coroutine.
        'u'Raise GeneratorExit inside coroutine.
        'b'coroutine ignored GeneratorExit'u'coroutine ignored GeneratorExit'b'throw'u'throw'b'__aiter__'u'__aiter__'b'Return the next item or raise StopAsyncIteration when exhausted.'u'Return the next item or raise StopAsyncIteration when exhausted.'b'__anext__'u'__anext__'b'Return the next item from the asynchronous generator.
        When exhausted, raise StopAsyncIteration.
        'u'Return the next item from the asynchronous generator.
        When exhausted, raise StopAsyncIteration.
        'b'Send a value into the asynchronous generator.
        Return next yielded value or raise StopAsyncIteration.
        'u'Send a value into the asynchronous generator.
        Return next yielded value or raise StopAsyncIteration.
        'b'Raise an exception in the asynchronous generator.
        Return next yielded value or raise StopAsyncIteration.
        'u'Raise an exception in the asynchronous generator.
        Return next yielded value or raise StopAsyncIteration.
        'b'asynchronous generator ignored GeneratorExit'u'asynchronous generator ignored GeneratorExit'b'asend'u'asend'b'athrow'u'athrow'b'aclose'u'aclose'b'__iter__'u'__iter__'b'Return the next item from the iterator. When exhausted, raise StopIteration'u'Return the next item from the iterator. When exhausted, raise StopIteration'b'__next__'u'__next__'b'__reversed__'u'__reversed__'b'Return the next item from the generator.
        When exhausted, raise StopIteration.
        'u'Return the next item from the generator.
        When exhausted, raise StopIteration.
        'b'Send a value into the generator.
        Return next yielded value or raise StopIteration.
        'u'Send a value into the generator.
        Return next yielded value or raise StopIteration.
        'b'Raise an exception in the generator.
        Return next yielded value or raise StopIteration.
        'u'Raise an exception in the generator.
        Return next yielded value or raise StopIteration.
        'b'Raise GeneratorExit inside generator.
        'u'Raise GeneratorExit inside generator.
        'b'generator ignored GeneratorExit'u'generator ignored GeneratorExit'b'__len__'u'__len__'b'__contains__'u'__contains__'b' Represent `Callable[argtypes, resulttype]`.

    This sets ``__args__`` to a tuple containing the flattened ``argtypes``
    followed by ``resulttype``.

    Example: ``Callable[[int, str], float]`` sets ``__args__`` to
    ``(int, str, float)``.
    'u' Represent `Callable[argtypes, resulttype]`.

    This sets ``__args__`` to a tuple containing the flattened ``argtypes``
    followed by ``resulttype``.

    Example: ``Callable[[int, str], float]`` sets ``__args__`` to
    ``(int, str, float)``.
    'b'Callable must be used as Callable[[arg, ...], result].'u'Callable must be used as Callable[[arg, ...], result].'b'Expected a list of types, an ellipsis, ParamSpec, or Concatenate. Got 'u'Expected a list of types, an ellipsis, ParamSpec, or Concatenate. Got 'b'__parameters__'u'__parameters__'b'collections.abc.Callable[['u'collections.abc.Callable[['b'], 'u'], 'b' is not a generic class'u' is not a generic class'b'Too 'u'Too 'b'many'u'many'b'few'u'few'b' arguments for 'u' arguments for 'b'; actual 'u'; actual 'b', expected 'u', expected 'b'typing'u'typing'b'ParamSpec'u'ParamSpec'b'TypeVar'u'TypeVar'b'Checks if obj matches either a list of types, ``...``, ``ParamSpec`` or
    ``_ConcatenateGenericAlias`` from typing.py
    'u'Checks if obj matches either a list of types, ``...``, ``ParamSpec`` or
    ``_ConcatenateGenericAlias`` from typing.py
    'b'_ConcatenateGenericAlias'u'_ConcatenateGenericAlias'b'Return the repr() of an object, special-casing types (internal helper).

    Copied from :mod:`typing` since collections.abc
    shouldn't depend on that module.
    'u'Return the repr() of an object, special-casing types (internal helper).

    Copied from :mod:`typing` since collections.abc
    shouldn't depend on that module.
    'b'...'u'...'b'A set is a finite, iterable container.

    This class provides concrete generic implementations of all
    methods except for __contains__, __iter__ and __len__.

    To override the comparisons (presumably for speed, as the
    semantics are fixed), redefine __le__ and __ge__,
    then the other operations will automatically follow suit.
    'u'A set is a finite, iterable container.

    This class provides concrete generic implementations of all
    methods except for __contains__, __iter__ and __len__.

    To override the comparisons (presumably for speed, as the
    semantics are fixed), redefine __le__ and __ge__,
    then the other operations will automatically follow suit.
    'b'Construct an instance of the class from any iterable input.

        Must override this method if the class constructor signature
        does not accept an iterable for an input.
        'u'Construct an instance of the class from any iterable input.

        Must override this method if the class constructor signature
        does not accept an iterable for an input.
        'b'Return True if two sets have a null intersection.'u'Return True if two sets have a null intersection.'b'Compute the hash value of a set.

        Note that we don't define __hash__: not all sets are hashable.
        But if you define a hashable set type, its __hash__ should
        call this function.

        This must be compatible __eq__.

        All sets ought to compare equal if they contain the same
        elements, regardless of how they are implemented, and
        regardless of the order of the elements; so there's not much
        freedom for __eq__ or __hash__.  We match the algorithm used
        by the built-in frozenset type.
        'u'Compute the hash value of a set.

        Note that we don't define __hash__: not all sets are hashable.
        But if you define a hashable set type, its __hash__ should
        call this function.

        This must be compatible __eq__.

        All sets ought to compare equal if they contain the same
        elements, regardless of how they are implemented, and
        regardless of the order of the elements; so there's not much
        freedom for __eq__ or __hash__.  We match the algorithm used
        by the built-in frozenset type.
        'b'A mutable set is a finite, iterable container.

    This class provides concrete generic implementations of all
    methods except for __contains__, __iter__, __len__,
    add(), and discard().

    To override the comparisons (presumably for speed, as the
    semantics are fixed), all you have to do is redefine __le__ and
    then the other operations will automatically follow suit.
    'u'A mutable set is a finite, iterable container.

    This class provides concrete generic implementations of all
    methods except for __contains__, __iter__, __len__,
    add(), and discard().

    To override the comparisons (presumably for speed, as the
    semantics are fixed), all you have to do is redefine __le__ and
    then the other operations will automatically follow suit.
    'b'Add an element.'u'Add an element.'b'Remove an element.  Do not raise an exception if absent.'u'Remove an element.  Do not raise an exception if absent.'b'Remove an element. If not a member, raise a KeyError.'u'Remove an element. If not a member, raise a KeyError.'b'Return the popped value.  Raise KeyError if empty.'u'Return the popped value.  Raise KeyError if empty.'b'This is slow (creates N new iterators!) but effective.'u'This is slow (creates N new iterators!) but effective.'b'A Mapping is a generic container for associating key/value
    pairs.

    This class provides concrete generic implementations of all
    methods except for __getitem__, __iter__, and __len__.
    'u'A Mapping is a generic container for associating key/value
    pairs.

    This class provides concrete generic implementations of all
    methods except for __getitem__, __iter__, and __len__.
    'b'D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.'u'D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.'b'_mapping'u'_mapping'b'{0.__class__.__name__}({0._mapping!r})'u'{0.__class__.__name__}({0._mapping!r})'b'A MutableMapping is a generic container for associating
    key/value pairs.

    This class provides concrete generic implementations of all
    methods except for __getitem__, __setitem__, __delitem__,
    __iter__, and __len__.
    'u'A MutableMapping is a generic container for associating
    key/value pairs.

    This class provides concrete generic implementations of all
    methods except for __getitem__, __setitem__, __delitem__,
    __iter__, and __len__.
    'b'D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
          If key is not found, d is returned if given, otherwise KeyError is raised.
        'u'D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
          If key is not found, d is returned if given, otherwise KeyError is raised.
        'b'D.popitem() -> (k, v), remove and return some (key, value) pair
           as a 2-tuple; but raise KeyError if D is empty.
        'u'D.popitem() -> (k, v), remove and return some (key, value) pair
           as a 2-tuple; but raise KeyError if D is empty.
        'b'D.clear() -> None.  Remove all items from D.'u'D.clear() -> None.  Remove all items from D.'b' D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
            If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
            If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
            In either case, this is followed by: for k, v in F.items(): D[k] = v
        'u' D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
            If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
            If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
            In either case, this is followed by: for k, v in F.items(): D[k] = v
        'b'D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D'u'D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D'b'All the operations on a read-only sequence.

    Concrete subclasses must override __new__ or __init__,
    __getitem__, and __len__.
    'u'All the operations on a read-only sequence.

    Concrete subclasses must override __new__ or __init__,
    __getitem__, and __len__.
    'b'S.index(value, [start, [stop]]) -> integer -- return first index of value.
           Raises ValueError if the value is not present.

           Supporting start and stop arguments is optional, but
           recommended.
        'u'S.index(value, [start, [stop]]) -> integer -- return first index of value.
           Raises ValueError if the value is not present.

           Supporting start and stop arguments is optional, but
           recommended.
        'b'S.count(value) -> integer -- return number of occurrences of value'u'S.count(value) -> integer -- return number of occurrences of value'b'This unifies bytes and bytearray.

    XXX Should add all their methods.
    'u'This unifies bytes and bytearray.

    XXX Should add all their methods.
    'b'All the operations on a read-write sequence.

    Concrete subclasses must provide __new__ or __init__,
    __getitem__, __setitem__, __delitem__, __len__, and insert().
    'u'All the operations on a read-write sequence.

    Concrete subclasses must provide __new__ or __init__,
    __getitem__, __setitem__, __delitem__, __len__, and insert().
    'b'S.insert(index, value) -- insert value before index'u'S.insert(index, value) -- insert value before index'b'S.append(value) -- append value to the end of the sequence'u'S.append(value) -- append value to the end of the sequence'b'S.clear() -> None -- remove all items from S'u'S.clear() -> None -- remove all items from S'b'S.reverse() -- reverse *IN PLACE*'u'S.reverse() -- reverse *IN PLACE*'b'S.extend(iterable) -- extend sequence by appending elements from the iterable'u'S.extend(iterable) -- extend sequence by appending elements from the iterable'b'S.pop([index]) -> item -- remove and return item at index (default last).
           Raise IndexError if list is empty or index is out of range.
        'u'S.pop([index]) -> item -- remove and return item at index (default last).
           Raise IndexError if list is empty or index is out of range.
        'b'S.remove(value) -- remove first occurrence of value.
           Raise ValueError if the value is not present.
        'u'S.remove(value) -- remove first occurrence of value.
           Raise ValueError if the value is not present.
        'u'_collections_abc'
Common code used in multiple modules.
weekdayMOTUWETHFRSASU%s(%+d)# vim:ts=4:sw=4:etb'
Common code used in multiple modules.
'u'
Common code used in multiple modules.
'b'weekday'u'weekday'b'MO'u'MO'b'TU'u'TU'b'WE'u'WE'b'TH'u'TH'b'FR'u'FR'b'SA'u'SA'b'SU'u'SU'b'%s(%+d)'u'%s(%+d)'u'dateutil._common'u'_common'pathlibtempfileAnyOptionalResourceReader_adaptersPackage
    Get a Traversable resource from a package
    from_packageget_packagenormalize_pathNormalize a path by ensuring it is a string.

    If the resulting string contains path separators, an exception is raised.
    str_path must be only a file name
    Return the package's loader if it's a ResourceReader.
    resolvecandTake a package name or module object and return the module.

    Raise an exception if the resolved module is not a package.
    resolved is not a package
    Return a Traversable object for the given package.

    _tempfile_os_removemkstempraw_pathsingledispatchas_file
    Given a Traversable object, return that object as a
    path on the local file system in a context manager.
    read_bytes
    Degenerate behavior for pathlib.Path objects.
    # type: (Package) -> Traversable# type: (Any) -> str# type: (types.ModuleType) -> Optional[ResourceReader]# We can't use# a issubclass() check here because apparently abc.'s __subclasscheck__()# hook wants to create a weak reference to the object, but# zipimport.zipimporter does not support weak references, resulting in a# TypeError.  That seems terrible.# type: (Package) -> types.ModuleType# gh-93353: Keep a reference to call os.remove() in late Python# Not using tempfile.NamedTemporaryFile as it leads to deeper 'try'# blocks due to the need to close the temporary file to work on Windows# properly.b'
    Get a Traversable resource from a package
    'u'
    Get a Traversable resource from a package
    'b'Normalize a path by ensuring it is a string.

    If the resulting string contains path separators, an exception is raised.
    'u'Normalize a path by ensuring it is a string.

    If the resulting string contains path separators, an exception is raised.
    'b' must be only a file name'u' must be only a file name'b'
    Return the package's loader if it's a ResourceReader.
    'u'
    Return the package's loader if it's a ResourceReader.
    'b'get_resource_reader'u'get_resource_reader'b'Take a package name or module object and return the module.

    Raise an exception if the resolved module is not a package.
    'u'Take a package name or module object and return the module.

    Raise an exception if the resolved module is not a package.
    'b' is not a package'u' is not a package'b'
    Return a Traversable object for the given package.

    'u'
    Return a Traversable object for the given package.

    'b'
    Given a Traversable object, return that object as a
    path on the local file system in a context manager.
    'u'
    Given a Traversable object, return that object as a
    path on the local file system in a context manager.
    'b'
    Degenerate behavior for pathlib.Path objects.
    'u'
    Degenerate behavior for pathlib.Path objects.
    'u'importlib._common'datetimetimedeltatzinfoZEROtzname_in_python2namefuncChange unicode output into bytestrings in Python 2

    tzname() API changed in Python 3. It used to return bytes, but was changed
    to unicode strings
    adjust_encodingfold
        Provides a unified interface for assigning the ``fold`` attribute to
        datetimes both before and after the implementation of PEP-495.

        :param fold:
            The value for the ``fold`` attribute in the returned datetime. This
            should be either 0 or 1.

        :return:
            Returns an object for which ``getattr(dt, 'fold', 0)`` returns
            ``fold`` for all versions of Python. In versions prior to
            Python 3.6, this is a ``_DatetimeWithFold`` object, which is a
            subclass of :py:class:`datetime.datetime` with the ``fold``
            attribute added, if ``fold`` is 1.

        .. versionadded:: 2.6.0
        _DatetimeWithFold
        This is a class designed to provide a PEP 495-compliant interface for
        Python versions before 3.6. It is used only for dates in a fold, so
        the ``fold`` attribute is fixed at ``1``.

        .. versionadded:: 2.6.0
        
            Return a datetime with the same attributes, except for those
            attributes given new values by whichever keyword arguments are
            specified. Note that tzinfo=None can be specified to create a naive
            datetime from an aware datetime with no conversion of date and time
            data.

            This is reimplemented in ``_DatetimeWithFold`` because pypy3 will
            return a ``datetime.datetime`` even if ``fold`` is unchanged.
            yearmonthdayhourminutesecondmicrosecondargnamesargnameDuplicate argument: {}dt_classtimetuple_validate_fromutc_inputs
    The CPython version of ``fromutc`` checks that the input is a ``datetime``
    object and that ``self`` is attached as its ``tzinfo``.
    fromutcfromutc() requires a datetime argumentdt.tzinfo is not self_tzinfo
    Base class for all ``dateutil`` ``tzinfo`` objects.
    is_ambiguous
        Whether or not the "wall time" of a given datetime is ambiguous in this
        zone.

        :param dt:
            A :py:class:`datetime.datetime`, naive or time zone aware.


        :return:
            Returns ``True`` if ambiguous, ``False`` otherwise.

        .. versionadded:: 2.6.0
        wall_0wall_1utcoffsetsame_offsetsame_dt_fold_statusdt_utcdt_wall
        Determine the fold status of a "wall" datetime, given a representation
        of the same datetime as a (naive) UTC datetime. This is calculated based
        on the assumption that ``dt.utcoffset() - dt.dst()`` is constant for all
        datetimes, and that this offset is the actual number of hours separating
        ``dt_utc`` and ``dt_wall``.

        :param dt_utc:
            Representation of the datetime as UTC

        :param dt_wall:
            Representation of the datetime as "wall time". This parameter must
            either have a `fold` attribute or have a fold-naive
            :class:`datetime.tzinfo` attached, otherwise the calculation may
            fail.
        delta_walldst_fold_fromutc
        Given a timezone-aware datetime in a given timezone, calculates a
        timezone-aware datetime in a new timezone.

        Since this is the one time that we *know* we have an unambiguous
        datetime object, we take this opportunity to determine whether the
        datetime is ambiguous and in a "fold" state (e.g. if it's the first
        occurrence, chronologically, of the ambiguous datetime).

        :param dt:
            A timezone-aware :class:`datetime.datetime` object.
        dtofffromutc() requires a non-None utcoffset() result"fromutc() requires a non-None utcoffset() ""result"dtdstfromutc() requires a non-None dst() resultfromutc(): dt.dst gave inconsistent results; cannot convert"fromutc(): dt.dst gave inconsistent ""results; cannot convert"tzrangebase
    This is an abstract base class for time zones represented by an annual
    transition into and out of DST. Child classes should implement the following
    methods:

        * ``__init__(self, *args, **kwargs)``
        * ``transitions(self, year)`` - this is expected to return a tuple of
          datetimes representing the DST on and off transitions in standard
          time.

    A fully initialized ``tzrangebase`` subclass should also provide the
    following attributes:
        * ``hasdst``: Boolean whether or not the zone uses DST.
        * ``_dst_offset`` / ``_std_offset``: :class:`datetime.timedelta` objects
          representing the respective UTC offsets.
        * ``_dst_abbr`` / ``_std_abbr``: Strings representing the timezone short
          abbreviations in DST and STD, respectively.
        * ``_hasdst``: Whether or not the zone has DST.

    .. versionadded:: 2.6.0
    tzrangebase is an abstract base class_isdstisdst_dst_offset_std_offset_dst_base_offsettzname_dst_abbr_std_abbr Given a datetime in UTC, return local time transitionsdstondstoffutc_transitions_naive_isdsthasdst%s(...)# The following is adapted from Alexander Belopolsky's tz library# https://github.com/abalkin/tz# This is the pre-python 3.6 fold situation# Re-implement the algorithm from Python's datetime.py# The original datetime.py code assumes that `dst()` defaults to# zero during ambiguous times. PEP 495 inverts this presumption, so# for pre-PEP 495 versions of python, we need to tweak the algorithm.# Set fold=1 so we can default to being in the fold for# ambiguous dates.# Calculate the fold status given the two datetimes.# Set the default fold value for ambiguous dates# Get transitions - if there are none, fixed offset# Get the transition times in UTC# Handle ambiguous datesb'tzname_in_python2'u'tzname_in_python2'b'Change unicode output into bytestrings in Python 2

    tzname() API changed in Python 3. It used to return bytes, but was changed
    to unicode strings
    'u'Change unicode output into bytestrings in Python 2

    tzname() API changed in Python 3. It used to return bytes, but was changed
    to unicode strings
    'b'fold'u'fold'b'
        Provides a unified interface for assigning the ``fold`` attribute to
        datetimes both before and after the implementation of PEP-495.

        :param fold:
            The value for the ``fold`` attribute in the returned datetime. This
            should be either 0 or 1.

        :return:
            Returns an object for which ``getattr(dt, 'fold', 0)`` returns
            ``fold`` for all versions of Python. In versions prior to
            Python 3.6, this is a ``_DatetimeWithFold`` object, which is a
            subclass of :py:class:`datetime.datetime` with the ``fold``
            attribute added, if ``fold`` is 1.

        .. versionadded:: 2.6.0
        'u'
        Provides a unified interface for assigning the ``fold`` attribute to
        datetimes both before and after the implementation of PEP-495.

        :param fold:
            The value for the ``fold`` attribute in the returned datetime. This
            should be either 0 or 1.

        :return:
            Returns an object for which ``getattr(dt, 'fold', 0)`` returns
            ``fold`` for all versions of Python. In versions prior to
            Python 3.6, this is a ``_DatetimeWithFold`` object, which is a
            subclass of :py:class:`datetime.datetime` with the ``fold``
            attribute added, if ``fold`` is 1.

        .. versionadded:: 2.6.0
        'b'
        This is a class designed to provide a PEP 495-compliant interface for
        Python versions before 3.6. It is used only for dates in a fold, so
        the ``fold`` attribute is fixed at ``1``.

        .. versionadded:: 2.6.0
        'u'
        This is a class designed to provide a PEP 495-compliant interface for
        Python versions before 3.6. It is used only for dates in a fold, so
        the ``fold`` attribute is fixed at ``1``.

        .. versionadded:: 2.6.0
        'b'
            Return a datetime with the same attributes, except for those
            attributes given new values by whichever keyword arguments are
            specified. Note that tzinfo=None can be specified to create a naive
            datetime from an aware datetime with no conversion of date and time
            data.

            This is reimplemented in ``_DatetimeWithFold`` because pypy3 will
            return a ``datetime.datetime`` even if ``fold`` is unchanged.
            'u'
            Return a datetime with the same attributes, except for those
            attributes given new values by whichever keyword arguments are
            specified. Note that tzinfo=None can be specified to create a naive
            datetime from an aware datetime with no conversion of date and time
            data.

            This is reimplemented in ``_DatetimeWithFold`` because pypy3 will
            return a ``datetime.datetime`` even if ``fold`` is unchanged.
            'b'year'u'year'b'month'u'month'b'day'u'day'b'hour'u'hour'b'minute'u'minute'b'second'u'second'b'microsecond'u'microsecond'b'tzinfo'u'tzinfo'b'Duplicate argument: {}'u'Duplicate argument: {}'b'
    The CPython version of ``fromutc`` checks that the input is a ``datetime``
    object and that ``self`` is attached as its ``tzinfo``.
    'u'
    The CPython version of ``fromutc`` checks that the input is a ``datetime``
    object and that ``self`` is attached as its ``tzinfo``.
    'b'fromutc() requires a datetime argument'u'fromutc() requires a datetime argument'b'dt.tzinfo is not self'u'dt.tzinfo is not self'b'
    Base class for all ``dateutil`` ``tzinfo`` objects.
    'u'
    Base class for all ``dateutil`` ``tzinfo`` objects.
    'b'
        Whether or not the "wall time" of a given datetime is ambiguous in this
        zone.

        :param dt:
            A :py:class:`datetime.datetime`, naive or time zone aware.


        :return:
            Returns ``True`` if ambiguous, ``False`` otherwise.

        .. versionadded:: 2.6.0
        'u'
        Whether or not the "wall time" of a given datetime is ambiguous in this
        zone.

        :param dt:
            A :py:class:`datetime.datetime`, naive or time zone aware.


        :return:
            Returns ``True`` if ambiguous, ``False`` otherwise.

        .. versionadded:: 2.6.0
        'b'
        Determine the fold status of a "wall" datetime, given a representation
        of the same datetime as a (naive) UTC datetime. This is calculated based
        on the assumption that ``dt.utcoffset() - dt.dst()`` is constant for all
        datetimes, and that this offset is the actual number of hours separating
        ``dt_utc`` and ``dt_wall``.

        :param dt_utc:
            Representation of the datetime as UTC

        :param dt_wall:
            Representation of the datetime as "wall time". This parameter must
            either have a `fold` attribute or have a fold-naive
            :class:`datetime.tzinfo` attached, otherwise the calculation may
            fail.
        'u'
        Determine the fold status of a "wall" datetime, given a representation
        of the same datetime as a (naive) UTC datetime. This is calculated based
        on the assumption that ``dt.utcoffset() - dt.dst()`` is constant for all
        datetimes, and that this offset is the actual number of hours separating
        ``dt_utc`` and ``dt_wall``.

        :param dt_utc:
            Representation of the datetime as UTC

        :param dt_wall:
            Representation of the datetime as "wall time". This parameter must
            either have a `fold` attribute or have a fold-naive
            :class:`datetime.tzinfo` attached, otherwise the calculation may
            fail.
        'b'
        Given a timezone-aware datetime in a given timezone, calculates a
        timezone-aware datetime in a new timezone.

        Since this is the one time that we *know* we have an unambiguous
        datetime object, we take this opportunity to determine whether the
        datetime is ambiguous and in a "fold" state (e.g. if it's the first
        occurrence, chronologically, of the ambiguous datetime).

        :param dt:
            A timezone-aware :class:`datetime.datetime` object.
        'u'
        Given a timezone-aware datetime in a given timezone, calculates a
        timezone-aware datetime in a new timezone.

        Since this is the one time that we *know* we have an unambiguous
        datetime object, we take this opportunity to determine whether the
        datetime is ambiguous and in a "fold" state (e.g. if it's the first
        occurrence, chronologically, of the ambiguous datetime).

        :param dt:
            A timezone-aware :class:`datetime.datetime` object.
        'b'fromutc() requires a non-None utcoffset() result'u'fromutc() requires a non-None utcoffset() result'b'fromutc() requires a non-None dst() result'u'fromutc() requires a non-None dst() result'b'fromutc(): dt.dst gave inconsistent results; cannot convert'u'fromutc(): dt.dst gave inconsistent results; cannot convert'b'
    This is an abstract base class for time zones represented by an annual
    transition into and out of DST. Child classes should implement the following
    methods:

        * ``__init__(self, *args, **kwargs)``
        * ``transitions(self, year)`` - this is expected to return a tuple of
          datetimes representing the DST on and off transitions in standard
          time.

    A fully initialized ``tzrangebase`` subclass should also provide the
    following attributes:
        * ``hasdst``: Boolean whether or not the zone uses DST.
        * ``_dst_offset`` / ``_std_offset``: :class:`datetime.timedelta` objects
          representing the respective UTC offsets.
        * ``_dst_abbr`` / ``_std_abbr``: Strings representing the timezone short
          abbreviations in DST and STD, respectively.
        * ``_hasdst``: Whether or not the zone has DST.

    .. versionadded:: 2.6.0
    'u'
    This is an abstract base class for time zones represented by an annual
    transition into and out of DST. Child classes should implement the following
    methods:

        * ``__init__(self, *args, **kwargs)``
        * ``transitions(self, year)`` - this is expected to return a tuple of
          datetimes representing the DST on and off transitions in standard
          time.

    A fully initialized ``tzrangebase`` subclass should also provide the
    following attributes:
        * ``hasdst``: Boolean whether or not the zone uses DST.
        * ``_dst_offset`` / ``_std_offset``: :class:`datetime.timedelta` objects
          representing the respective UTC offsets.
        * ``_dst_abbr`` / ``_std_abbr``: Strings representing the timezone short
          abbreviations in DST and STD, respectively.
        * ``_hasdst``: Whether or not the zone has DST.

    .. versionadded:: 2.6.0
    'b'tzrangebase is an abstract base class'u'tzrangebase is an abstract base class'b' Given a datetime in UTC, return local time 'u' Given a datetime in UTC, return local time 'b'%s(...)'u'%s(...)'u'dateutil.tz._common'u'tz._common'_markupbasemarkupbasedbm.bsddbhashdumbdbmtest.test_supporturllib.robotparserurllib2anydbm_abcollIMPORT_MAPPINGizipimapifilterifilterfalseizip_longestIterableUserDictfromfd_socketmultiprocessing.connectionConnectionmultiprocessing.contextProcessmultiprocessing.processmultiprocessing.popen_forkmultiprocessing.forkingurllib.errorContentTooShortErrorgetproxiespathname2urlquote_plusunquote_plusunquoteurl2pathnameurlcleanupurlencodeurlretrieveURLErrorNAME_MAPPINGPYTHON2_EXCEPTIONSWindowsErrorexcnameAuthenticationErrorBufferTooShortProcessErrorMULTIPROCESSING_EXCEPTIONSREVERSE_IMPORT_MAPPINGREVERSE_NAME_MAPPINGxml.etree.ElementTreeDocXMLRPCServer_dbm_functools_gdbm_pickleStandardErrorSocketType_socketobjectLoadFileDialogSaveFileDialogServerHTMLDocXMLRPCDocGeneratorDocXMLRPCRequestHandlerDocCGIXMLRPCRequestHandlerSimpleHTTPRequestHandlerCGIHTTPRequestHandlerPYTHON3_OSERROR_EXCEPTIONSPYTHON3_IMPORTERROR_EXCEPTIONS# This module is used to map the old Python 2 names to the new names used in# Python 3 for the pickle module.  This needed to make pickle streams# generated with Python 2 loadable by Python 3.# This is a copy of lib2to3.fixes.fix_imports.MAPPING.  We cannot import# lib2to3 and use the mapping defined there, because lib2to3 uses pickle.# Thus, this could cause the module to be imported recursively.# This contains rename rules that are easy to handle.  We ignore the more# complex stuff (e.g. mapping the names in the urllib and types modules).# These rules should be run before import names are fixed.# StandardError is gone in Python 3, so we map it to Exception# Same, but for 3.x to 2.x# Non-mutual mappings.# For compatibility with broken pickles saved in old Python 3 versionsb'__builtin__'u'__builtin__'b'copyreg'u'copyreg'b'copy_reg'u'copy_reg'b'queue'u'queue'b'socketserver'u'socketserver'b'SocketServer'b'configparser'u'configparser'b'reprlib'u'reprlib'b'repr'u'repr'b'tkinter.filedialog'u'tkinter.filedialog'b'tkFileDialog'u'tkFileDialog'b'tkinter.simpledialog'u'tkinter.simpledialog'b'tkSimpleDialog'u'tkSimpleDialog'b'tkinter.colorchooser'u'tkinter.colorchooser'b'tkColorChooser'u'tkColorChooser'b'tkinter.commondialog'u'tkinter.commondialog'b'tkCommonDialog'u'tkCommonDialog'b'tkinter.dialog'u'tkinter.dialog'b'Dialog'u'Dialog'b'tkinter.dnd'u'tkinter.dnd'b'Tkdnd'u'Tkdnd'b'tkinter.font'u'tkinter.font'b'tkFont'u'tkFont'b'tkinter.messagebox'u'tkinter.messagebox'b'tkMessageBox'u'tkMessageBox'b'tkinter.scrolledtext'u'tkinter.scrolledtext'b'ScrolledText'u'ScrolledText'b'tkinter.constants'u'tkinter.constants'b'Tkconstants'u'Tkconstants'b'tkinter.tix'u'tkinter.tix'b'Tix'u'Tix'b'tkinter.ttk'u'tkinter.ttk'b'ttk'u'ttk'b'tkinter'b'Tkinter'b'_markupbase'u'_markupbase'b'markupbase'u'markupbase'b'winreg'u'winreg'b'_winreg'u'_winreg'b'thread'u'thread'b'_dummy_thread'u'_dummy_thread'b'dummy_thread'u'dummy_thread'b'dbm.bsd'u'dbm.bsd'b'dbhash'u'dbhash'b'dumbdbm'u'dumbdbm'b'dbm'b'gdbm'u'gdbm'b'xmlrpc.client'u'xmlrpc.client'b'xmlrpclib'u'xmlrpclib'b'xmlrpc.server'u'xmlrpc.server'b'SimpleXMLRPCServer'u'SimpleXMLRPCServer'b'http.client'u'http.client'b'httplib'u'httplib'b'html.entities'u'html.entities'b'htmlentitydefs'u'htmlentitydefs'b'html.parser'u'html.parser'b'HTMLParser'u'HTMLParser'b'http.cookies'u'http.cookies'b'Cookie'u'Cookie'b'http.cookiejar'u'http.cookiejar'b'cookielib'u'cookielib'b'http.server'u'http.server'b'BaseHTTPServer'u'BaseHTTPServer'b'test.test_support'u'test.test_support'b'subprocess'u'subprocess'b'commands'u'commands'b'urllib.parse'u'urllib.parse'b'urlparse'u'urlparse'b'urllib.robotparser'u'urllib.robotparser'b'robotparser'u'robotparser'b'urllib.request'u'urllib.request'b'urllib2'u'urllib2'b'anydbm'u'anydbm'b'_abcoll'u'_abcoll'b'xrange'u'xrange'b'functools'u'functools'b'reduce'u'reduce'b'intern'u'intern'b'chr'u'chr'b'unichr'u'unichr'b'str'u'str'b'int'u'int'b'long'u'long'b'zip'u'zip'b'itertools'b'izip'u'izip'b'map'u'map'b'imap'u'imap'b'ifilter'u'ifilter'b'filterfalse'u'filterfalse'b'ifilterfalse'u'ifilterfalse'b'zip_longest'u'zip_longest'b'izip_longest'u'izip_longest'b'collections'b'IterableUserDict'u'IterableUserDict'b'socket'u'socket'b'fromfd'u'fromfd'b'_socket'u'_socket'b'multiprocessing.connection'u'multiprocessing.connection'b'Connection'u'Connection'b'multiprocessing.context'u'multiprocessing.context'b'Process'u'Process'b'multiprocessing.process'u'multiprocessing.process'b'multiprocessing.popen_fork'u'multiprocessing.popen_fork'b'Popen'u'Popen'b'multiprocessing.forking'u'multiprocessing.forking'b'urllib.error'u'urllib.error'b'ContentTooShortError'u'ContentTooShortError'b'urllib'b'getproxies'u'getproxies'b'pathname2url'u'pathname2url'b'quote_plus'u'quote_plus'b'quote'u'quote'b'unquote_plus'u'unquote_plus'b'unquote'u'unquote'b'url2pathname'u'url2pathname'b'urlcleanup'u'urlcleanup'b'urlencode'u'urlencode'b'urlopen'u'urlopen'b'urlretrieve'u'urlretrieve'b'HTTPError'u'HTTPError'b'URLError'u'URLError'b'ArithmeticError'u'ArithmeticError'b'AssertionError'u'AssertionError'b'AttributeError'u'AttributeError'b'BaseException'u'BaseException'b'BufferError'u'BufferError'b'BytesWarning'u'BytesWarning'b'DeprecationWarning'u'DeprecationWarning'b'EOFError'u'EOFError'b'EnvironmentError'u'EnvironmentError'b'Exception'u'Exception'b'FloatingPointError'u'FloatingPointError'b'FutureWarning'u'FutureWarning'b'GeneratorExit'u'GeneratorExit'b'IOError'u'IOError'b'ImportError'u'ImportError'b'ImportWarning'u'ImportWarning'b'IndentationError'u'IndentationError'b'IndexError'u'IndexError'b'KeyError'u'KeyError'b'KeyboardInterrupt'u'KeyboardInterrupt'b'LookupError'u'LookupError'b'MemoryError'u'MemoryError'b'NameError'u'NameError'b'NotImplementedError'u'NotImplementedError'b'OSError'u'OSError'b'OverflowError'u'OverflowError'b'PendingDeprecationWarning'u'PendingDeprecationWarning'b'ReferenceError'u'ReferenceError'b'RuntimeError'u'RuntimeError'b'RuntimeWarning'u'RuntimeWarning'b'StopIteration'u'StopIteration'b'SyntaxError'u'SyntaxError'b'SyntaxWarning'u'SyntaxWarning'b'SystemError'u'SystemError'b'SystemExit'u'SystemExit'b'TabError'u'TabError'b'TypeError'u'TypeError'b'UnboundLocalError'u'UnboundLocalError'b'UnicodeDecodeError'u'UnicodeDecodeError'b'UnicodeEncodeError'u'UnicodeEncodeError'b'UnicodeError'u'UnicodeError'b'UnicodeTranslateError'u'UnicodeTranslateError'b'UnicodeWarning'u'UnicodeWarning'b'UserWarning'u'UserWarning'b'ValueError'u'ValueError'b'Warning'u'Warning'b'ZeroDivisionError'u'ZeroDivisionError'b'WindowsError'u'WindowsError'b'exceptions'u'exceptions'b'AuthenticationError'u'AuthenticationError'b'BufferTooShort'u'BufferTooShort'b'ProcessError'u'ProcessError'b'pickle'u'pickle'b'cPickle'u'cPickle'b'xml.etree.ElementTree'b'_elementtree'u'_elementtree'b'FileDialog'u'FileDialog'b'SimpleDialog'u'SimpleDialog'b'DocXMLRPCServer'u'DocXMLRPCServer'b'SimpleHTTPServer'u'SimpleHTTPServer'b'CGIHTTPServer'u'CGIHTTPServer'b'io'u'io'b'StringIO'u'StringIO'b'cStringIO'u'cStringIO'b'bz2'u'bz2'b'_bz2'b'_dbm'u'_dbm'b'_functools'b'_gdbm'u'_gdbm'b'_pickle'u'_pickle'b'basestring'u'basestring'b'StandardError'u'StandardError'b'SocketType'u'SocketType'b'_socketobject'u'_socketobject'b'LoadFileDialog'u'LoadFileDialog'b'SaveFileDialog'u'SaveFileDialog'b'ServerHTMLDoc'u'ServerHTMLDoc'b'XMLRPCDocGenerator'u'XMLRPCDocGenerator'b'DocXMLRPCRequestHandler'u'DocXMLRPCRequestHandler'b'DocCGIXMLRPCRequestHandler'u'DocCGIXMLRPCRequestHandler'b'SimpleHTTPRequestHandler'u'SimpleHTTPRequestHandler'b'CGIHTTPRequestHandler'u'CGIHTTPRequestHandler'b'BrokenPipeError'u'BrokenPipeError'b'ChildProcessError'u'ChildProcessError'b'ConnectionAbortedError'u'ConnectionAbortedError'b'ConnectionError'u'ConnectionError'b'ConnectionRefusedError'u'ConnectionRefusedError'b'ConnectionResetError'u'ConnectionResetError'b'FileExistsError'u'FileExistsError'b'FileNotFoundError'u'FileNotFoundError'b'InterruptedError'u'InterruptedError'b'IsADirectoryError'u'IsADirectoryError'b'NotADirectoryError'u'NotADirectoryError'b'PermissionError'u'PermissionError'b'ProcessLookupError'u'ProcessLookupError'b'ModuleNotFoundError'u'ModuleNotFoundError'u'_compat_pickle'Internal classes used by the gzip, lzma and bz2 modulesDEFAULT_BUFFER_SIZEBUFFER_SIZEBaseStreamMode-checking helper functions._check_not_closedI/O operation on closed file_check_can_readUnsupportedOperationFile not open for reading_check_can_writeFile not open for writing_check_can_seekSeeking is only supported on files open for reading"Seeking is only supported ""on files open for reading"The underlying file object does not support seeking"The underlying file object ""does not support seeking"DecompressReaderAdapts the decompressor API to a RawIOBase reader APIdecomp_factorytrailing_errordecomp_args_fp_eof_pos_size_decomp_factory_decomp_args_decompressor_trailing_errorreadintobyte_viewreadallrawblockCompressed file ended before the end-of-stream marker was reached"Compressed file ended before the ""end-of-stream marker was reached"chunks_rewindSEEK_SETwhenceSEEK_CURSEEK_ENDInvalid value for whence: {}Return the current file position.# Compressed data read chunk size# Current offset in decompressed stream# Set to size of decompressed stream once it is known, for SEEK_END# Save the decompressor factory and arguments.# If the file contains multiple compressed streams, each# stream will need a separate decompressor object. A new decompressor# object is also needed when implementing a backwards seek().# Exception class to catch from decompressor signifying invalid# trailing data to ignore# Default if EOF is encountered# Depending on the input data, our call to the decompressor may not# return any data. In this case, try again after reading another block.# Continue to next stream.# Trailing data isn't a valid compressed stream; ignore it.# sys.maxsize means the max length of output buffer is unlimited,# so that the whole input buffer can be decompressed within one# .decompress() call.# Rewind the file to the beginning of the data stream.# Recalculate offset as an absolute file position.# Seeking relative to EOF - we need to know the file's size.# Make it so that offset is the number of bytes to skip forward.# Read and discard data until we reach the desired position.b'Internal classes used by the gzip, lzma and bz2 modules'u'Internal classes used by the gzip, lzma and bz2 modules'b'Mode-checking helper functions.'u'Mode-checking helper functions.'b'I/O operation on closed file'u'I/O operation on closed file'b'File not open for reading'u'File not open for reading'b'File not open for writing'u'File not open for writing'b'Seeking is only supported on files open for reading'u'Seeking is only supported on files open for reading'b'The underlying file object does not support seeking'u'The underlying file object does not support seeking'b'Adapts the decompressor API to a RawIOBase reader API'u'Adapts the decompressor API to a RawIOBase reader API'b'Compressed file ended before the end-of-stream marker was reached'u'Compressed file ended before the end-of-stream marker was reached'b'Invalid value for whence: {}'u'Invalid value for whence: {}'b'Return the current file position.'u'Return the current file position.'u'_compression'_contextvars.ContextContext_contextvars.ContextVarContextVarToken.MISSINGMISSINGu'Token.old_value'u'Token.var'_contextvars.TokenTokenu'Context Variables'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_contextvars.cpython-310-darwin.so'u'_contextvars'copy_context_contextvarsu'ArgumentError.__weakref__'ctypes.ArgumentErroru'metatype for the Array Objects'from_addressfrom_buffer_copyin_dll_ctypes.PyCArrayTypeu'XXX to be provided'__ctypes_from_outparam___b_base__b_needsfree__objects_ctypes._CData_ctypes.Arrayu'metatype for C function pointers'_ctypes.PyCFuncPtrTypeu'Function Pointer'u'specify the argument types'u'CFuncPtr.argtypes'u'a function to check for errors'u'CFuncPtr.errcheck'errchecku'specify the result type'u'CFuncPtr.restype'_ctypes.CFuncPtrPyObj_FromPtrPy_DECREFPy_INCREFu'metatype for the CData Objects'_ctypes.PyCStructTypeu'Structure base class'_ctypes.Structure_ctypes.UnionTypeu'Union base class'_ctypes.Unionu'metatype for the Pointer Objects'_ctypes.PyCPointerTypeu'the object this pointer points to (read-write)'u'_Pointer.contents'_ctypes._Pointeru'metatype for the PyCSimpleType Objects'_ctypes.PyCSimpleTypeu'current value'u'_SimpleCData.value'_ctypes._SimpleCDatau'Create and manipulate C compatible data types in Python.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_ctypes.cpython-310-darwin.so'u'_ctypes'4399720972_dyld_shared_cache_contains_path651940009665193993764399720852_unpickle4399721416buffer_infocall_cdeclfunctioncall_functiondlclosedlsym9999MAXYEARMINYEARu'Fast implementation of the datetime type.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_datetime.cpython-310-darwin.so'u'_datetime'u'date(year, month, day) --> date object'ctimeu'date.day'fromisocalendarfromisoformatfromordinalfromtimestampisocalendarisoformatisoweekdayu'date.month'u'Difference between two datetime values.

timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)

All arguments are optional and default to 0.
Arguments may be integers or floats, and may be positive or negative.'daysmicrosecondsresolutionsecondstotal_secondsdatetime.timedeltatodaytoordinalu'date.year'datetime.datedateu'datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])

The year, month and day arguments are required. tzinfo may be None, or an
instance of a tzinfo subclass. The remaining arguments may be ints.
'astimezonecombineu'datetime.fold'u'datetime.hour'u'datetime.microsecond'u'datetime.minute'nowu'datetime.second'strptimetimetzu'datetime.tzinfo'utcfromtimestamputcnowutctimetupledatetime.datetimeu'Capsule objects let you wrap a C "void *" pointer in a Python
object.  They're a way of passing data through the Python interpreter
without creating your own custom type.

Capsules are used for communication between extension modules.
They provide a way for an extension module to export a C interface
to other extension modules, so that extension modules can use the
Python import mechanism to link to one another.
'PyCapsuledatetime_CAPIu'time([hour[, minute[, second[, microsecond[, tzinfo]]]]]) --> a time object

All arguments are optional. tzinfo may be None, or an instance of
a tzinfo subclass. The remaining arguments may be ints.
'u'time.fold'u'time.hour'u'time.microsecond'u'time.minute'u'time.second'u'time.tzinfo'datetime.timeu'Fixed offset from UTC implementation of tzinfo.'__getinitargs__utcu'Abstract base class for time zone info objects.'datetime.tzinfodatetime.timezonetimezone_datetimeu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_dbm.cpython-310-darwin.so'u'error.__weakref__'_dbm.erroru'GNU gdbm'libraryu'Context.Emax'Emaxu'Context.Emin'EminEtinyEtopu'The context affects almost all operations and controls rounding,
Over/Underflow, raising of exceptions and much more.  A new context
can be constructed as follows:

    >>> c = Context(prec=28, Emin=-425000000, Emax=425000000,
    ...             rounding=ROUND_HALF_EVEN, capitals=1, clamp=1,
    ...             traps=[InvalidOperation, DivisionByZero, Overflow],
    ...             flags=[])
    >>>


'u'decimal'_applycanonicalu'Context.capitals'capitalsu'Context.clamp'clampclear_flagsclear_trapscompare_signalcompare_totalcompare_total_magcopy_abscopy_decimalcopy_negatecopy_signcreate_decimalcreate_decimal_from_floatdividedivide_intexpfmais_canonicalis_finiteis_infiniteis_nanis_normalis_qnanis_signedis_snanis_subnormalis_zerolnlog10logblogical_andlogical_invertlogical_orlogical_xormax_magmin_magminusmultiplynext_minusnext_plusnext_towardnormalizenumber_classpluspoweru'Context.prec'quantizeremainderremainder_nearu'Context.rounding'roundingsame_quantumscalebshiftto_eng_stringto_integralto_integral_exactto_integral_valueto_sci_stringdecimal.ContextBasicContextu'DecimalException.__weakref__'decimal.DecimalExceptiondecimal.ClampedClampeddecimal.InvalidOperationdecimal.ConversionSyntaxConversionSyntaxu'Construct a new Decimal object. 'value' can be an integer, string, tuple,
or another Decimal object. If no value is given, return Decimal('0'). The
context does not affect the conversion and is only passed to determine if
the InvalidOperation trap is active.

'adjustedas_tupleu'Decimal.imag'u'Decimal.real'decimal.DecimalDecimalExceptionu'DecimalTuple(sign, digits, exponent)'u'sign'u'digits'u'exponent'digitsexponentsigndecimal.DecimalTupleDecimalTupleDefaultContextdecimal.DivisionByZeroDivisionByZerodecimal.DivisionImpossibleDivisionImpossibledecimal.DivisionUndefinedDivisionUndefinedExtendedContextdecimal.FloatOperationFloatOperationHAVE_CONTEXTVARHAVE_THREADSdecimal.InexactInexactdecimal.InvalidContextInvalidContextInvalidOperation999999999999999999MAX_EMAXMAX_PREC-999999999999999999MIN_EMIN-1999999999999999997MIN_ETINYdecimal.OverflowOverflowu'ROUND_05UP'ROUND_05UPu'ROUND_CEILING'ROUND_CEILINGu'ROUND_DOWN'ROUND_DOWNu'ROUND_FLOOR'ROUND_FLOORu'ROUND_HALF_DOWN'ROUND_HALF_DOWNu'ROUND_HALF_EVEN'ROUND_HALF_EVENu'ROUND_HALF_UP'ROUND_HALF_UPu'ROUND_UP'ROUND_UPdecimal.RoundedRoundeddecimal.SubnormalSubnormaldecimal.UnderflowUnderflowu'C decimal arithmetic module'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_decimal.cpython-310-darwin.so'u'2.5.1'__libmpdec_version__u'1.70'getcontextsetcontext__getstate__u'A dictionary containing the element's attributes'u'Element.attrib'u'A string identifying what kind of data this element represents'u'Element.tag'u'A string of text directly after the end tag, or None'u'Element.tail'u'A string of text directly after the start tag, or None'u'Element.text'xml.etree.ElementTree.Elementu'ParseError.__weakref__'xml.etree.ElementTree.ParseErrorxml.etree.ElementTree.TreeBuilderu'XMLParser.version'xml.etree.ElementTree.XMLParseru'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_elementtree.cpython-310-darwin.so' Routines for manipulating RFC2047 encoded words.

This is currently a package-private API, but will be considered for promotion
to a public API if there is demand.

base64binasciiascii_lettersemaildecode_qencode_qdecode_bencode_blen_qlen_b=([a-fA-F0-9]{2})br'_q_byte_subberencoded_QByteMap-!*+/safe={:02X}_q_byte_mapbstringpad_err===missing_paddingb64decodeInvalidBase64PaddingDefectInvalidBase64CharactersDefect==InvalidBase64LengthDefectb64encodegroups_of_3leftover_cte_decodersewDecode encoded word and return (string, charset, lang, defects) tuple.

    An RFC 2047/2243 encoded word has the form:

        =?charset*lang?cte?encoded_string?=

    where '*lang' may be omitted but the other parts may not be.

    This function expects exactly such a string (that is, it does not check the
    syntax and may raise errors if the string is not well formed), and returns
    the encoded_string decoded first from its Content Transfer Encoding and
    then from the resulting bytes into unicode using the specified charset.  If
    the cte-decoded string does not successfully decode using the specified
    character set, a defect is added to the defects list and the unknown octets
    are replaced by the unicode 'unknown' character \uFDFF.

    The specified charset and language are returned.  The default for language,
    which is rarely if ever encountered, is the empty string.

    ctecte_stringlangsurrogateescapedefectsUndecodableBytesDefectEncoded word contains bytes not decodable using "Encoded word ""contains bytes not decodable using " charsetunknown-8bitCharsetErrorUnknown charset  in encoded word; decoded as unknown bytes" ""in encoded word; decoded as unknown bytes"_cte_encoders_cte_encode_lengthEncode string using the CTE encoding that produces the shorter result.

    Produces an RFC 2047/2243 encoded word of the form:

        =?charset*lang?cte?encoded_string?=

    where '*lang' is omitted unless the 'lang' parameter is given a value.
    Optional argument charset (defaults to utf-8) specifies the charset to use
    to encode the string to binary before CTE encoding it.  Optional argument
    'encoding' is the cte specifier for the encoding that should be used ('q'
    or 'b'); if it is None (the default) the encoding which produces the
    shortest encoded sequence is used, except that 'q' is preferred if it is up
    to five characters longer.  Optional argument 'lang' (default '') gives the
    RFC 2243 language string to specify in the encoded word.

    qlenblen=?{}{}?{}?{}?=# An ecoded word looks like this:#        =?charset[*lang]?cte?encoded_string?=# for more information about charset see the charset module.  Here it is one# of the preferred MIME charset names (hopefully; you never know when parsing).# cte (Content Transfer Encoding) is either 'q' or 'b' (ignoring case).  In# theory other letters could be used for other encodings, but in practice this# (almost?) never happens.  There could be a public API for adding entries# to the CTE tables, but YAGNI for now.  'q' is Quoted Printable, 'b' is# Base64.  The meaning of encoded_string should be obvious.  'lang' is optional# as indicated by the brackets (they are not part of the syntax) but is almost# never encountered in practice.# The general interface for a CTE decoder is that it takes the encoded_string# as its argument, and returns a tuple (cte_decoded_string, defects).  The# cte_decoded_string is the original binary that was encoded using the# specified cte.  'defects' is a list of MessageDefect instances indicating any# problems encountered during conversion.  'charset' and 'lang' are the# corresponding strings extracted from the EW, case preserved.# The general interface for a CTE encoder is that it takes a binary sequence# as input and returns the cte_encoded_string, which is an ascii-only string.# Each decoder must also supply a length function that takes the binary# sequence as its argument and returns the length of the resulting encoded# string.# The main API functions for the module are decode, which calls the decoder# referenced by the cte specifier, and encode, which adds the appropriate# RFC 2047 "chrome" to the encoded string, and can optionally automatically# select the shortest possible encoding.  See their docstrings below for# details.# Quoted Printable# regex based decoder.# dict mapping bytes to their encoded form# In headers spaces are mapped to '_'.# Base64# First try encoding with validate=True, fixing the padding if needed.# This will succeed only if encoded includes no invalid characters.# Since we had correct padding, this is likely an invalid char error.# The non-alphabet characters are ignored as far as padding# goes, but we don't know how many there are.  So try without adding# padding to see if it works.# Add as much padding as could possibly be necessary (extra padding# is ignored).# This only happens when the encoded string's length is 1 more# than a multiple of 4, which is invalid.# bpo-27397: Just return the encoded string since there's no# way to decode.# 4 bytes out for each 3 bytes (or nonzero fraction thereof) in.# Recover the original bytes and do CTE decoding.# Turn the CTE decoded bytes into unicode.# Bias toward q.  5 is arbitrary.b' Routines for manipulating RFC2047 encoded words.

This is currently a package-private API, but will be considered for promotion
to a public API if there is demand.

'u' Routines for manipulating RFC2047 encoded words.

This is currently a package-private API, but will be considered for promotion
to a public API if there is demand.

'b'decode_q'u'decode_q'b'encode_q'u'encode_q'b'decode_b'u'decode_b'b'encode_b'u'encode_b'b'len_q'u'len_q'b'len_b'u'len_b'b'=([a-fA-F0-9]{2})'b'-!*+/'b'={:02X}'u'={:02X}'b'==='b'=='b'Decode encoded word and return (string, charset, lang, defects) tuple.

    An RFC 2047/2243 encoded word has the form:

        =?charset*lang?cte?encoded_string?=

    where '*lang' may be omitted but the other parts may not be.

    This function expects exactly such a string (that is, it does not check the
    syntax and may raise errors if the string is not well formed), and returns
    the encoded_string decoded first from its Content Transfer Encoding and
    then from the resulting bytes into unicode using the specified charset.  If
    the cte-decoded string does not successfully decode using the specified
    character set, a defect is added to the defects list and the unknown octets
    are replaced by the unicode 'unknown' character \uFDFF.

    The specified charset and language are returned.  The default for language,
    which is rarely if ever encountered, is the empty string.

    'u'Decode encoded word and return (string, charset, lang, defects) tuple.

    An RFC 2047/2243 encoded word has the form:

        =?charset*lang?cte?encoded_string?=

    where '*lang' may be omitted but the other parts may not be.

    This function expects exactly such a string (that is, it does not check the
    syntax and may raise errors if the string is not well formed), and returns
    the encoded_string decoded first from its Content Transfer Encoding and
    then from the resulting bytes into unicode using the specified charset.  If
    the cte-decoded string does not successfully decode using the specified
    character set, a defect is added to the defects list and the unknown octets
    are replaced by the unicode 'unknown' character \uFDFF.

    The specified charset and language are returned.  The default for language,
    which is rarely if ever encountered, is the empty string.

    'b'surrogateescape'u'surrogateescape'b'Encoded word contains bytes not decodable using 'u'Encoded word contains bytes not decodable using 'b' charset'u' charset'b'unknown-8bit'u'unknown-8bit'b'Unknown charset 'u'Unknown charset 'b' in encoded word; decoded as unknown bytes'u' in encoded word; decoded as unknown bytes'b'Encode string using the CTE encoding that produces the shorter result.

    Produces an RFC 2047/2243 encoded word of the form:

        =?charset*lang?cte?encoded_string?=

    where '*lang' is omitted unless the 'lang' parameter is given a value.
    Optional argument charset (defaults to utf-8) specifies the charset to use
    to encode the string to binary before CTE encoding it.  Optional argument
    'encoding' is the cte specifier for the encoding that should be used ('q'
    or 'b'); if it is None (the default) the encoding which produces the
    shortest encoded sequence is used, except that 'q' is preferred if it is up
    to five characters longer.  Optional argument 'lang' (default '') gives the
    RFC 2243 language string to specify in the encoded word.

    'u'Encode string using the CTE encoding that produces the shorter result.

    Produces an RFC 2047/2243 encoded word of the form:

        =?charset*lang?cte?encoded_string?=

    where '*lang' is omitted unless the 'lang' parameter is given a value.
    Optional argument charset (defaults to utf-8) specifies the charset to use
    to encode the string to binary before CTE encoding it.  Optional argument
    'encoding' is the cte specifier for the encoding that should be used ('q'
    or 'b'); if it is None (the default) the encoding which produces the
    shortest encoded sequence is used, except that 'q' is preferred if it is up
    to five characters longer.  Optional argument 'lang' (default '') gives the
    RFC 2243 language string to specify in the encoded word.

    'b'=?{}{}?{}?{}?='u'=?{}{}?{}?{}?='u'email._encoded_words'u'_encoded_words'_array_type_other_endianReturn the type with the 'other' byte order.  Simple types like
    c_int and so on already have __ctype_be__ and __ctype_le__
    attributes which contain the types, for more complicated types
    arrays and structures are supported.
    _OTHER_ENDIAN_length_This type does not support other endian: %s_swapped_metaattrnamedescStructure with big endian byte order_swappedbytes_bigStructure with little endian byte orderInvalid byteorder# check _OTHER_ENDIAN attribute (present if typ is primitive type)# if typ is array# if typ is structure# Note: The Structure metaclass checks for the *presence* (not the# value!) of a _swapped_bytes_ attribute to determine the bit order in# structures containing bit fields.b'Return the type with the 'other' byte order.  Simple types like
    c_int and so on already have __ctype_be__ and __ctype_le__
    attributes which contain the types, for more complicated types
    arrays and structures are supported.
    'u'Return the type with the 'other' byte order.  Simple types like
    c_int and so on already have __ctype_be__ and __ctype_le__
    attributes which contain the types, for more complicated types
    arrays and structures are supported.
    'b'This type does not support other endian: %s'u'This type does not support other endian: %s'b'_fields_'u'_fields_'b'__ctype_be__'u'__ctype_be__'b'Structure with big endian byte order'u'Structure with big endian byte order'b'big'u'big'b'__ctype_le__'u'__ctype_le__'b'Structure with little endian byte order'u'Structure with little endian byte order'b'Invalid byteorder'u'Invalid byteorder'u'ctypes._endian'u'_endian'_TzSingleton__instance_TzFactoryAlternate constructor that returns a fresh instance_TzOffsetFactory__instances__strong_cache__strong_cache_size_cache_lock_TzStrFactory__cache_lockposix_offset# This lock may not be necessary in Python 3. See GH issue #901# Remove an item if the strong cache is overpopulatedb'Alternate constructor that returns a fresh instance'u'Alternate constructor that returns a fresh instance'u'dateutil.tz._factories'u'tz._factories'u'_factories'u'Tools that operate on functions.'u'_lru_cache_wrapper.__dict__'u'Create a cached callable that wraps another function.

user_function:      the function being cached

maxsize:  0         for no caching
          None      for unlimited cache size
          n         for a bounded cache

typed:    False     cache f(3) and f(3.0) as identical calls
          True      cache f(3) and f(3.0) as distinct calls

cache_info_type:    namedtuple class with the fields:
                        hits misses currsize maxsize
'cache_clearcache_infofunctools._lru_cache_wrapper_lru_cache_wrappercmp_to_keyu'partial.__dict__'u'partial(func, *args, **keywords) - new function with partial application
    of the given arguments and keywords.
'__vectorcalloffset__keywordsfunctools.partial_GDBM_VERSIONu'This module provides an interface to the GNU DBM (GDBM) library.

This module is quite similar to the dbm module, but uses GDBM instead to
provide some additional functionality.  Please note that the file formats
created by GDBM and dbm are incompatible.

GDBM objects behave like mappings (dictionaries), except that keys and
values are always immutable bytes-like objects or strings.  Printing
a GDBM object doesn't print the keys and values, and the items() and
values() methods are not supported.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_gdbm.cpython-310-darwin.so'_gdbm.erroru'rwcnfsu'open_flagsu'A hash is an object used to calculate a checksum of a string of information.

Methods:

update() -- updates the current digest with an additional string
digest() -- return the current digest value
hexdigest() -- return the current digest as a string of hexadecimal digits
copy() -- return a copy of the current hash object

Attributes:

name -- the hash algorithm being used by this object
digest_size -- number of bytes in this hashes output'u'_hashlib'u'HASH.block_size'u'HASH.digest_size'u'HASH.name'_hashlib.HASHHASHu'A hash is an object used to calculate a checksum of a string of information.

Methods:

update() -- updates the current digest with an additional string
digest(length) -- return the current digest value
hexdigest(length) -- return the current digest as a string of hexadecimal digits
copy() -- return a copy of the current hash object

Attributes:

name -- the hash algorithm being used by this object
digest_size -- number of bytes in this hashes output'u'HASHXOF.digest_size'_hashlib.HASHXOFHASHXOFu'The object used to calculate HMAC of a message.

Methods:

update() -- updates the current digest with an additional string
digest() -- return the current digest value
hexdigest() -- return the current digest as a string of hexadecimal digits
copy() -- return a copy of the current hash object

Attributes:

name -- the name, including the hash algorithm used by this object
digest_size -- number of bytes in digest() output
'u'HMAC.block_size'u'HMAC.digest_size'u'HMAC.name'_hashlib.HMACHMACu'UnsupportedDigestmodError.__weakref__'_hashlib.UnsupportedDigestmodErrorUnsupportedDigestmodErroru'OpenSSL interface for hashlib module'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_hashlib.cpython-310-darwin.so'_constructorscompare_digestget_fips_modehmac_digesthmac_newopenssl_md5openssl_md_meth_namesopenssl_sha1openssl_sha224openssl_sha256openssl_sha384openssl_sha3_224openssl_sha3_256openssl_sha3_384openssl_sha3_512openssl_sha512openssl_shake_128openssl_shake_256pbkdf2_hmacscrypt_hashlibHeader value parser implementing various email-related RFC parsing rules.

The parsing methods defined in this module implement various email related
parsing rules.  Principal among them is RFC 5322, which is the followon
to RFC 2822 and primarily a clarification of the former.  It also implements
RFC 2047 encoded word decoding.

RFC 5322 goes to considerable trouble to maintain backward compatibility with
RFC 822 in the parse phase, while cleaning up the structure on the generation
phase.  This parser supports correct RFC 5322 generation by tagging white space
as folding white space only when folding is allowed in the non-obsolete rule
sets.  Actually, the parser is even more generous when accepting input than RFC
5322 mandates, following the spirit of Postel's Law, which RFC 5322 encourages.
Where possible deviations from the standard are annotated on the 'defects'
attribute of tokens that deviate.

The general structure of the parser follows RFC 5322, and uses its terminology
where there is a direct correspondence.  Where the implementation requires a
somewhat different structure than that used by the formal grammar, new terms
that mimic the closest existing terms are used.  Thus, it really helps to have
a copy of RFC 5322 handy when studying this code.

Input to the parser is a string that has already been unfolded according to
RFC 5322 rules.  According to the RFC this unfolding is the very first step, and
this parser leaves the unfolding step to a higher level message parser, which
will have already detected the line breaks that need unfolding while
determining the beginning and end of each header.

The output of the parser is a TokenList object, which is a list subclass.  A
TokenList is a recursive data structure.  The terminal nodes of the structure
are Terminal objects, which are subclasses of str.  These do not correspond
directly to terminal objects in the formal grammar, but are instead more
practical higher level combinations of true terminals.

All TokenList and Terminal objects have a 'value' attribute, which produces the
semantically meaningful value of that part of the parse subtree.  The value of
all whitespace tokens (no matter how many sub-tokens they may contain) is a
single space, as per the RFC rules.  This includes 'CFWS', which is herein
included in the general class of whitespace tokens.  There is one exception to
the rule that whitespace tokens are collapsed into single spaces in values: in
the value of a 'bare-quoted-string' (a quoted-string with no leading or
trailing whitespace), any whitespace that appeared between the quotation marks
is preserved in the returned value.  Note that in all Terminal strings quoted
pairs are turned into their unquoted values.

All TokenList and Terminal objects also have a string value, which attempts to
be a "canonical" representation of the RFC-compliant form of the substring that
produced the parsed subtree, including minimal use of quoted pair quoting.
Whitespace runs are not collapsed.

Comment tokens also have a 'content' attribute providing the string found
between the parens (including any nested comments) with whitespace preserved.

All TokenList and Terminal objects have a 'defects' attribute which is a
possibly empty list all of the defects found while creating the token.  Defects
may appear on any token in the tree, and a composite list of all defects in the
subtree is available through the 'all_defects' attribute of any node.  (For
Terminal notes x.defects == x.all_defects.)

Each object in a parse tree is called a 'token', and each has a 'token_type'
attribute that gives the name from the RFC 5322 grammar that it represents.
Not all RFC 5322 nodes are produced, and there is one non-RFC 5322 node that
may be produced: 'ptext'.  A 'ptext' is a string of printable ascii characters.
It is returned in place of lists of (ctext/quoted-pair) and
(qtext/quoted-pair).

XXX: provide complete list of token types.
hexdigits_encoded_words_ew 	WSPCFWS_LEADER()<>@,:;.\"[]SPECIALSATOM_ENDSDOT_ATOM_ENDS."(PHRASE_ENDS/?=TSPECIALSTOKEN_ENDS*'%ASPECIALSATTRIBUTE_ENDSEXTENDED_ATTRIBUTE_ENDSquote_string\"
   =\?            # literal =?
   [^?]*          # charset
   \?             # literal ?
   [qQbB]         # literal 'q' or 'b', case insensitive
   \?             # literal ?
  .*?             # encoded word
  \?=             # literal ?=
r'''MULTILINErfc2047_matcherTokenListtoken_typesyntactic_breakew_combine_allowedall_defectsstartswith_fwsas_ew_allowedTrue if all top level tokens of this part may be RFC2047 encoded.commentspolicy_refold_parse_treepprintppstr_pp{}{}/{}(    !! invalid element in token list: {!r}'    !! invalid element in token ''list: {!r}'     Defects: {}{}){}WhiteSpaceTokenListcontentUnstructuredTokenListunstructuredPhraseWordwordCFWSListcfwsAtomencode_as_ewEncodedWordencoded-wordQuotedStringquoted-stringbare-quoted-stringquoted_valuestripped_valueBareQuotedString\(\)AddressListaddress-listaddressesmailboxesall_mailboxesAddressdisplay_namemailboxinvalid-mailboxMailboxListmailbox-listGroupListgroup-listGroupNameAddrname-addrlocal_partdomainrouteaddr_specAngleAddrangle-addraddr-specobs-routedomains<>ObsRouteMailboxInvalidMailboxDomainDotAtomdot-atomDotAtomTextdot-atom-textNoFoldLiteralno-fold-literalAddrSpecnamesetlpObsLocalPartobs-local-partDisplayNamedisplay-namepreLocalPartlocal-partDOTlast_is_tltokis_tlDomainLiteraldomain-literalipptextMIMEVersionmime-versionParameterparametersectionedextendedsection_numberparam_valueInvalidParameterinvalid-parameterattrtextSectionValueextended-attributeMimeParametersmime-parametersfirst_paramInvalidHeaderDefectduplicate parameter name; duplicate(s) ignoredvalue_partsduplicate parameter name; duplicate ignoredinconsistent RFC2231 parameter numberingunquote_to_bytes_has_surrogateslatin-1{}={}; ParameterizedHeaderValueContentTypecontent-typemaintypeplainsubtypeContentDispositioncontent-dispositioncontent_dispositionContentTransferEncodingcontent-transfer-encoding7bitHeaderLabelheader-labelMsgIDmsg-idlinesepMessageIDmessage-idInvalidMessageIDinvalid-message-idHeaderTerminal{}{}/{}({}){} {}pop_trailing_wsWhiteSpaceTerminalValueTerminalEWWhiteSpaceTerminal_InvalidEwErrorHeaderParseErrorInvalid encoded word found while parsing headers.list-separatorListSeparatorroute-component-markerRouteComponentMarker([{}]+)_wsp_splitter[^{}]+_non_atom_end_matcher[\x00-\x20\x7F]_non_printable_finder_non_token_end_matcher_non_attribute_end_matcher_non_extended_attribute_end_matcher_validate_xtextxtextIf input token contains ASCII non-printables, register a defect.non_printablesNonPrintableDefectNon-ASCII characters found in header token_get_ptext_to_endcharsendcharsScan printables/quoted-pairs until endchars and return unquoted ptext.

    This function turns a run of qcontent, ccontent-without-comments, or
    dtext-with-quoted-printables into a single string by unquoting any
    quoted printables.  It returns the string, the remaining value, and
    a flag that is True iff there were any quoted printables decoded.

    fragmentvcharshad_qpposget_fwsFWS = 1*WSP

    This isn't the RFC definition.  We're using fws to represent tokens where
    folding can be done, but when we are parsing the *un*folding has already
    been done so we don't need to watch out for CRLF.

    newvaluefwsget_encoded_word encoded-word = "=?" charset "?" encoding "?" encoded-text "?="

    =?expected encoded word but found {}?=remstrwhitespace inside encoded wordencoded word format invalid: '{}'vtextmissing trailing whitespace after encoded-wordget_unstructuredunstructured = (*([FWS] vchar) *WSP) / obs-unstruct
       obs-unstruct = *((*LF *CR *(obs-utext) *LF *CR)) / FWS)
       obs-utext = %d0 / obs-NO-WS-CTL / LF / CR

       obs-NO-WS-CTL is control characters except WSP/CR/LF.

    So, basically, we have printable runs, plus control characters or nulls in
    the obsolete syntax, separated by whitespace.  Since RFC 2047 uses the
    obsolete syntax in its specification, but requires whitespace on either
    side of the encoded words, I can see no reason to need to separate the
    non-printable-non-whitespace from the printable runs if they occur, so we
    parse this into xtext tokens separated by WSP tokens.

    Because an 'unstructured' value must by definition constitute the entire
    value, this 'get' routine does not return a remaining value, only the
    parsed TokenList.

    valid_ewhave_wsmissing whitespace before encoded wordget_qp_ctextctext = <printable ascii except \ ( )>

    This is not the RFC ctext, since we are handling nested comments in comment
    and unquoting quoted-pairs here.  We allow anything except the '()'
    characters, but if we find any ASCII other than the RFC defined printable
    ASCII, a NonPrintableDefect is added to the token's defects list.  Since
    quoted pairs are converted to their unquoted values, what is returned is
    a 'ptext' token.  In this case it is a WhiteSpaceTerminal, so it's value
    is ' '.

    get_qcontentqcontent = qtext / quoted-pair

    We allow anything except the DQUOTE character, but if we find any ASCII
    other than the RFC defined printable ASCII, a NonPrintableDefect is
    added to the token's defects list.  Any quoted pairs are converted to their
    unquoted values, so what is returned is a 'ptext' token.  In this case it
    is a ValueTerminal.

    get_atextatext = <matches _atext_matcher>

    We allow any non-ATOM_ENDS in atext, but add an InvalidATextDefect to
    the token's defects list if we find non-atext characters.
    expected atext but found '{}'atextget_bare_quoted_stringbare-quoted-string = DQUOTE *([FWS] qcontent) [FWS] DQUOTE

    A quoted-string without the leading or trailing white space.  Its
    value is the text between the quote marks, with whitespace
    preserved and quoted pairs decoded.
    expected '"' but found '{}'bare_quoted_stringencoded word inside quoted stringend of header inside quoted stringget_commentcomment = "(" *([FWS] ccontent) [FWS] ")"
       ccontent = ctext / quoted-pair / comment

    We handle nested comments here, and quoted-pair in our qp-ctext routine.
    expected '(' but found '{}'end of header inside commentget_cfwsCFWS = (1*([FWS] comment) [FWS]) / FWS

    get_quoted_stringquoted-string = [CFWS] <bare-quoted-string> [CFWS]

    'bare-quoted-string' is an intermediate class defined by this
    parser and not by the RFC grammar.  It is the quoted string
    without any attached CFWS.
    quoted_stringget_atomatom = [CFWS] 1*atext [CFWS]

    An atom could be an rfc2047 encoded word.
    expected atom but found '{}'get_dot_atom_text dot-text = 1*atext *("." 1*atext)

    dot_atom_textexpected atom at a start of dot-atom-text but found '{}'"expected atom at a start of ""dot-atom-text but found '{}'"expected atom at end of dot-atom-text but found '{}'"expected atom at end of dot-atom-text ""but found '{}'"get_dot_atom dot-atom = [CFWS] dot-atom-text [CFWS]

    Any place we can have a dot atom, we could instead have an rfc2047 encoded
    word.
    dot_atomget_wordword = atom / quoted-string

    Either atom or quoted-string may start with CFWS.  We have to peel off this
    CFWS first to determine which type of word to parse.  Afterward we splice
    the leading CFWS, if any, into the parsed sub-token.

    If neither an atom or a quoted-string is found before the next special, a
    HeaderParseError is raised.

    The token returned is either an Atom or a QuotedString, as appropriate.
    This means the 'word' level of the formal grammar is not represented in the
    parse tree; this is because having that extra layer when manipulating the
    parse tree is more confusing than it is helpful.

    leaderExpected 'atom' or 'quoted-string' but found nothing.Expected 'atom' or 'quoted-string' but found '{}'"Expected 'atom' or 'quoted-string' "get_phrase phrase = 1*word / obs-phrase
        obs-phrase = word *(word / "." / CFWS)

    This means a phrase can be a sequence of words, periods, and CFWS in any
    order as long as it starts with at least one word.  If anything other than
    words is detected, an ObsoleteHeaderDefect is added to the token's defect
    list.  We also accept a phrase that starts with CFWS followed by a dot;
    this is registered as an InvalidHeaderDefect, since it is not supported by
    even the obsolete grammar.

    phrase does not start with wordObsoleteHeaderDefectperiod in 'phrase'comment found without atomget_local_part local-part = dot-atom / quoted-string / obs-local-part

    expected local-part but found '{}'get_obs_local_partobs_local_partinvalid-obs-local-partlocal-part is not dot-atom, quoted-string, or obs-local-partlocal-part is not a dot-atom (contains CFWS)NonASCIILocalPartDefectlocal-part contains non-ASCII characters) obs-local-part = word *("." word)
    last_non_ws_was_dotinvalid repeated '.'misplaced-special'\' character outside of quoted-string/ccontentmissing '.' between wordsInvalid leading '.' in local partInvalid trailing '.' in local partget_dtext dtext = <printable ascii except \ [ ]> / obs-dtext
        obs-dtext = obs-NO-WS-CTL / quoted-pair

    We allow anything except the excluded characters, but if we find any
    ASCII other than the RFC defined printable ASCII, a NonPrintableDefect is
    added to the token's defects list.  Quoted pairs are converted to their
    unquoted values, so what is returned is a ptext token, in this case a
    ValueTerminal.  If there were quoted-printables, an ObsoleteHeaderDefect is
    added to the returned token's defect list.

    []quoted printable found in domain-literal_check_for_early_dl_enddomain_literalend of input inside domain-literaldomain-literal-endget_domain_literal domain-literal = [CFWS] "[" *([FWS] dtext) [FWS] "]" [CFWS]

    expected domain-literalexpected '[' at start of domain-literal but found '{}'"expected '[' at start of domain-literal "domain-literal-startexpected ']' at end of domain-literal but found '{}'"expected ']' at end of domain-literal "get_domain domain = dot-atom / domain-literal / obs-domain
        obs-domain = atom *("." atom))

    expected domain but found '{}'Invalid Domaindomain is not a dot-atom (contains CFWS)get_addr_spec addr-spec = local-part "@" domain

    addr-spec local part with no domainaddress-at-symbolget_obs_route obs-route = obs-domain-list ":"
        obs-domain-list = *(CFWS / ",") "@" domain *("," [CFWS] ["@" domain])

        Returns an obs-route token with the appropriate sub-tokens (that is,
        there is no obs-domain-list in the parse tree).
    obs_routeexpected obs-route domain but found '{}'end of header while parsing obs-routeexpected ':' marking end of obs-route but found '{}'"expected ':' marking end of ""obs-route but found '{}'"end-of-obs-route-markerget_angle_addr angle-addr = [CFWS] "<" addr-spec ">" [CFWS] / obs-angle-addr
        obs-angle-addr = [CFWS] "<" obs-route addr-spec ">" [CFWS]

    angle_addrexpected angle-addr but found '{}'angle-addr-startangle-addr-endnull addr-spec in angle-addrobsolete route specification in angle-addrexpected addr-spec or obs-route but found '{}'missing trailing '>' on angle-addrget_display_name display-name = phrase

    Because this is simply a name-rule, we don't return a display-name
    token containing a phrase, but rather a display-name token with
    the content of the phrase.

    get_name_addr name-addr = [display-name] angle-addr

    name_addrexpected name-addr but found '{}'get_mailbox mailbox = name-addr / addr-spec

    expected mailbox but found '{}'get_invalid_mailbox Read everything up to one of the chars in endchars.

    This is outside the formal grammar.  The InvalidMailbox TokenList that is
    returned acts like a Mailbox, but the data attributes are None.

    invalid_mailboxget_mailbox_list mailbox-list = (mailbox *("," mailbox)) / obs-mbox-list
        obs-mbox-list = *([CFWS] ",") mailbox *("," [mailbox / CFWS])

    For this routine we go outside the formal grammar in order to improve error
    handling.  We recognize the end of the mailbox list only at the end of the
    value or at a ';' (the group terminator).  This is so that we can turn
    invalid mailboxes into InvalidMailbox tokens and continue parsing any
    remaining valid mailboxes.  We also allow all mailbox entries to be null,
    and this condition is handled appropriately at a higher level.

    mailbox_list,;empty element in mailbox-listinvalid mailbox in mailbox-listget_group_list group-list = mailbox-list / CFWS / obs-group-list
        obs-group-list = 1*([CFWS] ",") [CFWS]

    group_listend of header before group-listend of header in group-listgroup-list with empty entriesget_group group = display-name ":" [group-list] ";" [CFWS]

    expected ':' at end of group display name but found '{}'"expected ':' at end of group ""display name but found '{}'"group-display-name-terminatorgroup-terminatorend of header in groupexpected ';' at end of group but found {}get_address address = mailbox / group

    Note that counter-intuitively, an address can be either a single address or
    a list of addresses (a group).  This is why the returned Address object has
    a 'mailboxes' attribute which treats a single address as a list of length
    one.  When you need to differentiate between to two cases, extract the single
    element, which is either a mailbox or a group token.

    expected address but found '{}'get_address_list address_list = (address *("," address)) / obs-addr-list
        obs-addr-list = *([CFWS] ",") address *("," [address / CFWS])

    We depart from the formal grammar here by continuing to parse until the end
    of the input, assuming the input to be entirely composed of an
    address-list.  This is always true in email parsing, and allows us
    to skip invalid addresses to parse additional valid ones.

    address_listaddress-list entry with no contentinvalid address in address-listempty element in address-listget_no_fold_literal no-fold-literal = "[" *dtext "]"
    no_fold_literalexpected no-fold-literal but found '{}'expected '[' at the start of no-fold-literal but found '{}'"expected '[' at the start of no-fold-literal "no-fold-literal-startexpected ']' at the end of no-fold-literal but found '{}'"expected ']' at the end of no-fold-literal "no-fold-literal-endget_msg_idmsg-id = [CFWS] "<" id-left '@' id-right  ">" [CFWS]
       id-left = dot-atom-text / obs-id-left
       id-right = dot-atom-text / no-fold-literal / obs-id-right
       no-fold-literal = "[" *dtext "]"
    msg_idexpected msg-id but found '{}'msg-id-startobsolete id-left in msg-idexpected dot-atom-text or obs-id-left but found '{}'"expected dot-atom-text or obs-id-left"" but found '{}'"msg-id with no id-rightmsg-id-endobsolete id-right in msg-idexpected dot-atom-text, no-fold-literal or obs-id-right but found '{}'"expected dot-atom-text, no-fold-literal or obs-id-right"missing trailing '>' on msg-idparse_message_idmessage-id      =   "Message-ID:" msg-id CRLF
    message_idUnexpected {!r}Invalid msg-id: {!r}parse_mime_version mime-version = [CFWS] 1*digit [CFWS] "." [CFWS] 1*digit [CFWS]

    mime_versionHeaderMissingRequiredValueMissing MIME version number (eg: 1.0)Expected MIME version number but found only CFWSExpected MIME major version number but found {!r}Incomplete MIME version; found only major numberversion-separatorExpected MIME minor version number but found {!r}Excess non-CFWS text after MIME versionget_invalid_parameter Read everything up to the next ';'.

    This is outside the formal grammar.  The InvalidParameter TokenList that is
    returned acts like a Parameter, but the data attributes are None.

    invalid_parameterget_ttextttext = <matches _ttext_matcher>

    We allow any non-TOKEN_ENDS in ttext, but add defects to the token's
    defects list if we find non-ttext characters.  We also register defects for
    *any* non-printables even though the RFC doesn't exclude all of them,
    because we follow the spirit of RFC 5322.

    expected ttext but found '{}'ttextget_tokentoken = [CFWS] 1*ttext [CFWS]

    The RFC equivalent of ttext is any US-ASCII chars except space, ctls, or
    tspecials.  We also exclude tabs even though the RFC doesn't.

    The RFC implies the CFWS but is not explicit about it in the BNF.

    mtokenexpected token but found '{}'get_attrtextattrtext = 1*(any non-ATTRIBUTE_ENDS character)

    We allow any non-ATTRIBUTE_ENDS in attrtext, but add defects to the
    token's defects list if we find non-attrtext characters.  We also register
    defects for *any* non-printables even though the RFC doesn't exclude all of
    them, because we follow the spirit of RFC 5322.

    expected attrtext but found {!r} [CFWS] 1*attrtext [CFWS]

    This version of the BNF makes the CFWS explicit, and as usual we use a
    value terminal for the actual run of characters.  The RFC equivalent of
    attrtext is the token characters, with the subtraction of '*', "'", and '%'.
    We include tab in the excluded set just as we do for token.

    get_extended_attrtextattrtext = 1*(any non-ATTRIBUTE_ENDS character plus '%')

    This is a special parsing routine so that we get a value that
    includes % escapes as a single string (which we decode as a single
    string later).

    expected extended attrtext but found {!r}extended-attrtextget_extended_attribute [CFWS] 1*extended_attrtext [CFWS]

    This is like the non-extended version except we allow % characters, so that
    we can pick up an encoded value as a single string.

    get_section '*' digits

    The formal BNF is more complicated because leading 0s are not allowed.  We
    check for that and add a defect.  We also assume no CFWS is allowed between
    the '*' and the digits, though the RFC is not crystal clear on that.
    The caller should already have dealt with leading CFWS.

    Expected section but found {}section-markerExpected section number but found {}"Expected section number but ""found {}"section number has an invalid leading 0get_value quoted-string / attribute

    Expected value but found end of stringExpected value but found only {}"Expected value but found ""only {}"get_parameter attribute [section] ["*"] [CFWS] "=" value

    The CFWS is implied by the RFC but not made explicit in the BNF.  This
    simplified form of the BNF from the RFC is made to conform with the RFC BNF
    through some extra checks.  We do it this way because it makes both error
    recovery and working with the resulting parse tree easier.
    Parameter contains name ({}) but no value"Parameter contains ""name ({}) but no value"Incomplete parameterextended-parameter-markerParameter not followed by '='parameter-separatorappendtoqstringinner_valuesemi_validQuoted string value for extended parameter is invalidParameter marked as extended but appears to have a quoted string value that is non-encoded"Parameter marked as extended but appears to have a ""quoted string value that is non-encoded"Apparent initial-extended-value but attribute was not marked as extended or was not initial section"Apparent initial-extended-value but attribute ""was not marked as extended or was not initial section"Missing required charset/lang delimitersExpected RFC2231 char/lang encoding delimiter, but found {!r}"Expected RFC2231 char/lang encoding ""delimiter, but found {!r}"RFC2231-delimiterExpected RFC2231 char/lang encoding delimiter, but found {}"delimiter, but found {}"DQUOTEparse_mime_parameters parameter *( ";" parameter )

    That BNF is meant to indicate this routine should only be called after
    finding and handling the leading ';'.  There is no corresponding rule in
    the formal RFC grammar, but it is more convenient for us for the set of
    parameters to be treated as its own TokenList.

    This is 'parse' routine because it consumes the remaining value, but it
    would never be called to parse a full header.  Instead it is called to
    parse everything after the non-parameter value of a specific MIME header.

    mime_parametersparameter entry with no contentinvalid parameter {!r}parameter with invalid trailing text {!r}_find_mime_parameterstokenlistDo our best to find the parameters in an invalid MIME header

    parse_content_type_header maintype "/" subtype *( ";" parameter )

    The maintype and substype are tokens.  Theoretically they could
    be checked against the official IANA list + x-token, but we
    don't do that.
    ctyperecoverMissing content type specificationExpected content maintype but found {!r}Invalid content typecontent-type-separatorExpected content subtype but found {!r}Only parameters are valid after content type, but found {!r}"Only parameters are valid after content type, but ""found {!r}"parse_content_disposition_header disposition-type *( ";" parameter )

    disp_headerMissing content dispositionExpected content disposition but found {!r}Only parameters are valid after content disposition, but found {!r}"Only parameters are valid after content disposition, but "parse_content_transfer_encoding_header mechanism

    cte_headerMissing content transfer encodingExpected content transfer encoding but found {!r}Extra text after content transfer encoding_steal_trailing_WSP_if_existswspparse_treeReturn string of contents of parse_tree folded according to RFC rules.

    max_line_lengthutf8last_ewwrap_as_ew_blockedwant_encodingend_ew_not_allowedtstr_fold_mime_parametersencoded_part_fold_as_ewnewpartsto_encodeFold string to_encode into lines as encoded word, combining if allowed.
    Return the new value for last_ew, or None if ew_combine_allowed is False.

    If there is already an encoded word in the last line of lines (indicated by
    a non-None value for last_ew) and ew_combine_allowed is true, decode the
    existing ew, combine it with to_encode, and re-encode.  Otherwise, encode
    to_encode.  In either case, split to_encode as necessary so that the
    encoded segments fit within maxlen.

    leading_wsptrailing_wspnew_last_ewencode_aschrome_lenmax_line_length is too small to fit an encoded wordremaining_spacetext_spaceto_encode_wordencoded_wordexcessFold TokenList 'part' into the 'lines' list as mime parameters.

    Using the decoded list of parameters and values, format them according to
    the RFC rules, including using RFC2231 encoding if the value cannot be
    expressed in 'encoding' and/or the parameter+value is too long to fit
    within 'maxlen'.

    error_handlerencoding_requiredencoded_value{}*={}''{}extra_chrome78splitpointmaxchars {}*{}*={}{}# For urllib.parse.unquote# Useful constants and functions# '.', '"', and '(' do not end phrases in order to support obs-phrase# Match a RFC 2047 word, looks like =?utf-8?q?someword?=# TokenList and its subclasses# Strip whitespace from front, back, and around dots.# Because the first token, the attribute (name) eats CFWS, the second# token is always the section if there is one.# This is part of the "handle quoted extended parameters" hack.# The RFC specifically states that the ordering of parameters is not# guaranteed and may be reordered by the transport layer.  So we have# to assume the RFC 2231 pieces can come in any order.  However, we# output them in the order that we first see a given name, which gives# us a stable __str__.# Using order preserving dict from Python 3.7+# Our arbitrary error recovery is to ignore duplicate parameters,# to use appearance order if there are duplicate rfc 2231 parts,# and to ignore gaps.  This mimics the error recovery of get_param.# Else assume the *0* was missing...note that this is different# from get_param, but we registered a defect for this earlier.# We could get fancier here and look for a complete# duplicate extended parameter and ignore the second one# seen.  But we're not doing that.  The old code didn't.# source had surrogate escaped bytes.  What we do now# is a bit of an open question.  I'm not sure this is# the best choice, but it is what the old algorithm did# XXX: there should really be a custom defect for# unknown character set to make it easy to find,# because otherwise unknown charset is a silent# failure.# Set this false so that the value doesn't wind up on a new line even# if it and the parameters would fit there but not on the first line.# message-id tokens may not be folded.# Terminal classes and instances# This terminates the recursion.# XXX these need to become classes and used as instances so# that a program can't change them in a parse tree and screw# up other parse trees.  Maybe should have  tests for that, too.# Parser# Parse strings according to RFC822/2047/2822/5322 rules.# This is a stateless parser.  Each get_XXX function accepts a string and# returns either a Terminal or a TokenList representing the RFC object named# by the method and a string containing the remaining unparsed characters# from the input.  Thus a parser method consumes the next syntactic construct# of a given type and returns a token representing the construct plus the# unparsed remainder of the input string.# For example, if the first element of a structured header is a 'phrase',# then:#     phrase, value = get_phrase(value)# returns the complete phrase from the start of the string value, plus any# characters left in the string after the phrase is removed.# The ? after the CTE was followed by an encoded word escape (=XX).# Encoded words should be followed by a WS# XXX: but what about bare CR and LF?  They might signal the start or# end of an encoded word.  YAGNI for now, since our current parsers# will never send us strings with bare CR or LF.# XXX: Need to figure out how to register defects when# appropriate here.# Split in the middle of an atom if there is a rfc2047 encoded word# which does not have WSP on both sides. The defect will be registered# the next time through the loop.# This needs to only be performed when the encoded word is valid;# otherwise, performing it on an invalid encoded word can cause# the parser to go in an infinite loop.# Collapse the whitespace between two encoded words that occur in a# bare-quoted-string.# XXX: need to figure out how to register defects when# Although it is not legal per RFC5322, SMTP uses '<>' in certain# circumstances.# Both the optional display name and the angle-addr can start with cfws.# The only way to figure out if we are dealing with a name-addr or an# addr-spec is to try parsing each one.# Crap after mailbox; treat it as an invalid mailbox.# The mailbox info will still be available.# This should never happen in email parsing, since CFWS-only is a# legal alternative to group-list in a group, which is the only# place group-list appears.# The formal grammar isn't very helpful when parsing an address.  mailbox# and group, especially when allowing for obsolete forms, start off very# similarly.  It is only when you reach one of @, <, or : that you know# what you've got.  So, we try each one in turn, starting with the more# likely of the two.  We could perhaps make this more efficient by looking# for a phrase and then branching based on the next character, but that# would be a premature optimization.# Crap after address; treat it as an invalid mailbox.# Must be a , at this point.# Parse id-left.# obs-id-left is same as local-part of add-spec.# Even though there is no id-right, if the local part# ends with `>` let's just parse it too and return# along with the defect.# Parse id-right.# Value after parsing a valid msg_id should be None.# XXX: As I begin to add additional header parsers, I'm realizing we probably# have two level of parser routines: the get_XXX methods that get a token in# the grammar, and parse_XXX methods that parse an entire field value.  So# get_address_list above should really be a parse_ method, as probably should# be get_unstructured.# The [CFWS] is implicit in the RFC 2045 BNF.# XXX: This routine is a bit verbose, should factor out a get_int method.# XXX: should we have an ExtendedAttribute TokenList?# It is possible CFWS would also be implicitly allowed between the section# and the 'extended-attribute' marker (the '*') , but we've never seen that# in the wild and we will therefore ignore the possibility.# Now for some serious hackery to handle the common invalid case of# double quotes around an extended value.  We also accept (with defect)# a value marked as encoded that isn't really.# Assume the charset/lang is missing and the token is the value.# Treat the rest of value as bare quoted string content.# Junk after the otherwise valid parameter.  Mark it as# invalid, but it will have a value.# Must be a ';' at this point.# XXX: If we really want to follow the formal grammar we should make# mantype and subtype specialized TokenLists here.  Probably not worth it.# The RFC requires that a syntactically invalid content-type be treated# as text/plain.  Perhaps we should postel this, but we should probably# only do that if we were checking the subtype value against IANA.# We should probably validate the values, since the list is fixed.# Header folding# Header folding is complex, with lots of rules and corner cases.  The# following code does its best to obey the rules and handle the corner# cases, but you can be sure there are few bugs:)# This folder generally canonicalizes as it goes, preferring the stringified# version of each token.  The tokens contain information that supports the# folder, including which tokens can be encoded in which ways.# Folded text is accumulated in a simple list of strings ('lines'), each# one of which should be less than policy.max_line_length ('maxlen').# max_line_length 0/None means no limit, ie: infinitely long.# Encode if tstr contains special characters.# If policy.utf8 is false this should really be taken from a# 'charset' property on the policy.# Mime parameter folding (using RFC2231) is extra special.# It fits on a single line# But not on this one, so start a new one.# XXX what if encoded_part has no leading FWS?# Either this is not a major syntactic break, so we don't# want it on a line by itself even if it fits, or it# doesn't fit on a line by itself.  Either way, fall through# to unpacking the subparts and wrapping them.# It's not a Terminal, do each piece individually.# It's a terminal, wrap it as an encoded word, possibly# combining it with previously encoded words if allowed.# This part is too long to fit.  The RFC wants us to break at# "major syntactic breaks", so unless we don't consider this# to be one, check if it will fit on the next line by itself.# It's not a terminal, try folding the subparts.# It doesn't need CTE encoding, but encode it anyway so we can# wrap it.# We can't figure out how to wrap, it, so give up.# We can't fold it onto the next line either...# We're joining this to non-encoded text, so don't encode# the leading blank.# Likewise for the trailing space.# The RFC2047 chrome takes up 7 characters plus the length# of the charset name.# Since the chunk to encode is guaranteed to fit into less than 100 characters,# shrinking it by one at a time shouldn't take long.# Special case for RFC2231 encoding: start from decoded values and use# RFC2231 encoding iff needed.# Note that the 1 and 2s being added to the length calculations are# accounting for the possibly-needed spaces and semicolons we'll be adding.# XXX What if this ';' puts us over maxlen the first time through the# loop?  We should split the header value onto a newline in that case,# but to do that we need to recognize the need earlier or reparse the# header, so I'm going to ignore that bug for now.  It'll only put us# one character over.# We need multiple sections.  We are allowed to mix encoded and# non-encoded sections, but we aren't going to.  We'll encode them all.# We need room for the leading blank, the trailing semicolon,# and at least one character of the value.  If we don't# have that, we'd be stuck, so in that case fall back to# the RFC standard width.b'Header value parser implementing various email-related RFC parsing rules.

The parsing methods defined in this module implement various email related
parsing rules.  Principal among them is RFC 5322, which is the followon
to RFC 2822 and primarily a clarification of the former.  It also implements
RFC 2047 encoded word decoding.

RFC 5322 goes to considerable trouble to maintain backward compatibility with
RFC 822 in the parse phase, while cleaning up the structure on the generation
phase.  This parser supports correct RFC 5322 generation by tagging white space
as folding white space only when folding is allowed in the non-obsolete rule
sets.  Actually, the parser is even more generous when accepting input than RFC
5322 mandates, following the spirit of Postel's Law, which RFC 5322 encourages.
Where possible deviations from the standard are annotated on the 'defects'
attribute of tokens that deviate.

The general structure of the parser follows RFC 5322, and uses its terminology
where there is a direct correspondence.  Where the implementation requires a
somewhat different structure than that used by the formal grammar, new terms
that mimic the closest existing terms are used.  Thus, it really helps to have
a copy of RFC 5322 handy when studying this code.

Input to the parser is a string that has already been unfolded according to
RFC 5322 rules.  According to the RFC this unfolding is the very first step, and
this parser leaves the unfolding step to a higher level message parser, which
will have already detected the line breaks that need unfolding while
determining the beginning and end of each header.

The output of the parser is a TokenList object, which is a list subclass.  A
TokenList is a recursive data structure.  The terminal nodes of the structure
are Terminal objects, which are subclasses of str.  These do not correspond
directly to terminal objects in the formal grammar, but are instead more
practical higher level combinations of true terminals.

All TokenList and Terminal objects have a 'value' attribute, which produces the
semantically meaningful value of that part of the parse subtree.  The value of
all whitespace tokens (no matter how many sub-tokens they may contain) is a
single space, as per the RFC rules.  This includes 'CFWS', which is herein
included in the general class of whitespace tokens.  There is one exception to
the rule that whitespace tokens are collapsed into single spaces in values: in
the value of a 'bare-quoted-string' (a quoted-string with no leading or
trailing whitespace), any whitespace that appeared between the quotation marks
is preserved in the returned value.  Note that in all Terminal strings quoted
pairs are turned into their unquoted values.

All TokenList and Terminal objects also have a string value, which attempts to
be a "canonical" representation of the RFC-compliant form of the substring that
produced the parsed subtree, including minimal use of quoted pair quoting.
Whitespace runs are not collapsed.

Comment tokens also have a 'content' attribute providing the string found
between the parens (including any nested comments) with whitespace preserved.

All TokenList and Terminal objects have a 'defects' attribute which is a
possibly empty list all of the defects found while creating the token.  Defects
may appear on any token in the tree, and a composite list of all defects in the
subtree is available through the 'all_defects' attribute of any node.  (For
Terminal notes x.defects == x.all_defects.)

Each object in a parse tree is called a 'token', and each has a 'token_type'
attribute that gives the name from the RFC 5322 grammar that it represents.
Not all RFC 5322 nodes are produced, and there is one non-RFC 5322 node that
may be produced: 'ptext'.  A 'ptext' is a string of printable ascii characters.
It is returned in place of lists of (ctext/quoted-pair) and
(qtext/quoted-pair).

XXX: provide complete list of token types.
'u'Header value parser implementing various email-related RFC parsing rules.

The parsing methods defined in this module implement various email related
parsing rules.  Principal among them is RFC 5322, which is the followon
to RFC 2822 and primarily a clarification of the former.  It also implements
RFC 2047 encoded word decoding.

RFC 5322 goes to considerable trouble to maintain backward compatibility with
RFC 822 in the parse phase, while cleaning up the structure on the generation
phase.  This parser supports correct RFC 5322 generation by tagging white space
as folding white space only when folding is allowed in the non-obsolete rule
sets.  Actually, the parser is even more generous when accepting input than RFC
5322 mandates, following the spirit of Postel's Law, which RFC 5322 encourages.
Where possible deviations from the standard are annotated on the 'defects'
attribute of tokens that deviate.

The general structure of the parser follows RFC 5322, and uses its terminology
where there is a direct correspondence.  Where the implementation requires a
somewhat different structure than that used by the formal grammar, new terms
that mimic the closest existing terms are used.  Thus, it really helps to have
a copy of RFC 5322 handy when studying this code.

Input to the parser is a string that has already been unfolded according to
RFC 5322 rules.  According to the RFC this unfolding is the very first step, and
this parser leaves the unfolding step to a higher level message parser, which
will have already detected the line breaks that need unfolding while
determining the beginning and end of each header.

The output of the parser is a TokenList object, which is a list subclass.  A
TokenList is a recursive data structure.  The terminal nodes of the structure
are Terminal objects, which are subclasses of str.  These do not correspond
directly to terminal objects in the formal grammar, but are instead more
practical higher level combinations of true terminals.

All TokenList and Terminal objects have a 'value' attribute, which produces the
semantically meaningful value of that part of the parse subtree.  The value of
all whitespace tokens (no matter how many sub-tokens they may contain) is a
single space, as per the RFC rules.  This includes 'CFWS', which is herein
included in the general class of whitespace tokens.  There is one exception to
the rule that whitespace tokens are collapsed into single spaces in values: in
the value of a 'bare-quoted-string' (a quoted-string with no leading or
trailing whitespace), any whitespace that appeared between the quotation marks
is preserved in the returned value.  Note that in all Terminal strings quoted
pairs are turned into their unquoted values.

All TokenList and Terminal objects also have a string value, which attempts to
be a "canonical" representation of the RFC-compliant form of the substring that
produced the parsed subtree, including minimal use of quoted pair quoting.
Whitespace runs are not collapsed.

Comment tokens also have a 'content' attribute providing the string found
between the parens (including any nested comments) with whitespace preserved.

All TokenList and Terminal objects have a 'defects' attribute which is a
possibly empty list all of the defects found while creating the token.  Defects
may appear on any token in the tree, and a composite list of all defects in the
subtree is available through the 'all_defects' attribute of any node.  (For
Terminal notes x.defects == x.all_defects.)

Each object in a parse tree is called a 'token', and each has a 'token_type'
attribute that gives the name from the RFC 5322 grammar that it represents.
Not all RFC 5322 nodes are produced, and there is one non-RFC 5322 node that
may be produced: 'ptext'.  A 'ptext' is a string of printable ascii characters.
It is returned in place of lists of (ctext/quoted-pair) and
(qtext/quoted-pair).

XXX: provide complete list of token types.
'b' 	'u' 	'b'()<>@,:;.\"[]'u'()<>@,:;.\"[]'b'."('u'."('b'/?='u'/?='b'*'%'u'*'%'b'\"'u'\"'b'
   =\?            # literal =?
   [^?]*          # charset
   \?             # literal ?
   [qQbB]         # literal 'q' or 'b', case insensitive
   \?             # literal ?
  .*?             # encoded word
  \?=             # literal ?=
'u'
   =\?            # literal =?
   [^?]*          # charset
   \?             # literal ?
   [qQbB]         # literal 'q' or 'b', case insensitive
   \?             # literal ?
  .*?             # encoded word
  \?=             # literal ?=
'b'True if all top level tokens of this part may be RFC2047 encoded.'u'True if all top level tokens of this part may be RFC2047 encoded.'b'{}{}/{}('u'{}{}/{}('b'_pp'u'_pp'b'    !! invalid element in token list: {!r}'u'    !! invalid element in token list: {!r}'b'    'u'    'b' Defects: {}'u' Defects: {}'b'{}){}'u'{}){}'b'unstructured'u'unstructured'b'phrase'u'phrase'b'word'u'word'b'cfws'u'cfws'b'token'u'token'b'encoded-word'u'encoded-word'b'quoted-string'u'quoted-string'b'bare-quoted-string'u'bare-quoted-string'b'\('u'\('b'\)'u'\)'b'address-list'u'address-list'b'address'u'address'b'mailbox'u'mailbox'b'invalid-mailbox'u'invalid-mailbox'b'mailbox-list'u'mailbox-list'b'group-list'u'group-list'b'name-addr'u'name-addr'b'angle-addr'u'angle-addr'b'addr-spec'u'addr-spec'b'obs-route'u'obs-route'b'<>'u'<>'b'domain'u'domain'b'dot-atom'u'dot-atom'b'dot-atom-text'u'dot-atom-text'b'no-fold-literal'u'no-fold-literal'b'obs-local-part'u'obs-local-part'b'display-name'u'display-name'b'local-part'u'local-part'b'dot'u'dot'b'domain-literal'u'domain-literal'b'ptext'u'ptext'b'mime-version'u'mime-version'b'parameter'u'parameter'b'invalid-parameter'u'invalid-parameter'b'attribute'u'attribute'b'attrtext'u'attrtext'b'section'u'section'b'extended-attribute'u'extended-attribute'b'mime-parameters'u'mime-parameters'b'duplicate parameter name; duplicate(s) ignored'u'duplicate parameter name; duplicate(s) ignored'b'duplicate parameter name; duplicate ignored'u'duplicate parameter name; duplicate ignored'b'inconsistent RFC2231 parameter numbering'u'inconsistent RFC2231 parameter numbering'b'latin-1'u'latin-1'b'{}={}'u'{}={}'b'; 'u'; 'b'content-type'u'content-type'b'plain'u'plain'b'content-disposition'u'content-disposition'b'content-transfer-encoding'u'content-transfer-encoding'b'7bit'u'7bit'b'header-label'u'header-label'b'msg-id'u'msg-id'b'message-id'u'message-id'b'invalid-message-id'u'invalid-message-id'b'{}{}/{}({}){}'u'{}{}/{}({}){}'b' {}'u' {}'b'Invalid encoded word found while parsing headers.'u'Invalid encoded word found while parsing headers.'b'list-separator'u'list-separator'b'route-component-marker'u'route-component-marker'b'([{}]+)'u'([{}]+)'b'[^{}]+'u'[^{}]+'b'[\x00-\x20\x7F]'u'[\x00-\x20\x7F]'b'If input token contains ASCII non-printables, register a defect.'u'If input token contains ASCII non-printables, register a defect.'b'Non-ASCII characters found in header token'u'Non-ASCII characters found in header token'b'Scan printables/quoted-pairs until endchars and return unquoted ptext.

    This function turns a run of qcontent, ccontent-without-comments, or
    dtext-with-quoted-printables into a single string by unquoting any
    quoted printables.  It returns the string, the remaining value, and
    a flag that is True iff there were any quoted printables decoded.

    'u'Scan printables/quoted-pairs until endchars and return unquoted ptext.

    This function turns a run of qcontent, ccontent-without-comments, or
    dtext-with-quoted-printables into a single string by unquoting any
    quoted printables.  It returns the string, the remaining value, and
    a flag that is True iff there were any quoted printables decoded.

    'b'FWS = 1*WSP

    This isn't the RFC definition.  We're using fws to represent tokens where
    folding can be done, but when we are parsing the *un*folding has already
    been done so we don't need to watch out for CRLF.

    'u'FWS = 1*WSP

    This isn't the RFC definition.  We're using fws to represent tokens where
    folding can be done, but when we are parsing the *un*folding has already
    been done so we don't need to watch out for CRLF.

    'b'fws'u'fws'b' encoded-word = "=?" charset "?" encoding "?" encoded-text "?="

    'u' encoded-word = "=?" charset "?" encoding "?" encoded-text "?="

    'b'=?'u'=?'b'expected encoded word but found {}'u'expected encoded word but found {}'b'?='u'?='b'whitespace inside encoded word'u'whitespace inside encoded word'b'encoded word format invalid: '{}''u'encoded word format invalid: '{}''b'vtext'u'vtext'b'missing trailing whitespace after encoded-word'u'missing trailing whitespace after encoded-word'b'unstructured = (*([FWS] vchar) *WSP) / obs-unstruct
       obs-unstruct = *((*LF *CR *(obs-utext) *LF *CR)) / FWS)
       obs-utext = %d0 / obs-NO-WS-CTL / LF / CR

       obs-NO-WS-CTL is control characters except WSP/CR/LF.

    So, basically, we have printable runs, plus control characters or nulls in
    the obsolete syntax, separated by whitespace.  Since RFC 2047 uses the
    obsolete syntax in its specification, but requires whitespace on either
    side of the encoded words, I can see no reason to need to separate the
    non-printable-non-whitespace from the printable runs if they occur, so we
    parse this into xtext tokens separated by WSP tokens.

    Because an 'unstructured' value must by definition constitute the entire
    value, this 'get' routine does not return a remaining value, only the
    parsed TokenList.

    'u'unstructured = (*([FWS] vchar) *WSP) / obs-unstruct
       obs-unstruct = *((*LF *CR *(obs-utext) *LF *CR)) / FWS)
       obs-utext = %d0 / obs-NO-WS-CTL / LF / CR

       obs-NO-WS-CTL is control characters except WSP/CR/LF.

    So, basically, we have printable runs, plus control characters or nulls in
    the obsolete syntax, separated by whitespace.  Since RFC 2047 uses the
    obsolete syntax in its specification, but requires whitespace on either
    side of the encoded words, I can see no reason to need to separate the
    non-printable-non-whitespace from the printable runs if they occur, so we
    parse this into xtext tokens separated by WSP tokens.

    Because an 'unstructured' value must by definition constitute the entire
    value, this 'get' routine does not return a remaining value, only the
    parsed TokenList.

    'b'missing whitespace before encoded word'u'missing whitespace before encoded word'b'ctext = <printable ascii except \ ( )>

    This is not the RFC ctext, since we are handling nested comments in comment
    and unquoting quoted-pairs here.  We allow anything except the '()'
    characters, but if we find any ASCII other than the RFC defined printable
    ASCII, a NonPrintableDefect is added to the token's defects list.  Since
    quoted pairs are converted to their unquoted values, what is returned is
    a 'ptext' token.  In this case it is a WhiteSpaceTerminal, so it's value
    is ' '.

    'u'ctext = <printable ascii except \ ( )>

    This is not the RFC ctext, since we are handling nested comments in comment
    and unquoting quoted-pairs here.  We allow anything except the '()'
    characters, but if we find any ASCII other than the RFC defined printable
    ASCII, a NonPrintableDefect is added to the token's defects list.  Since
    quoted pairs are converted to their unquoted values, what is returned is
    a 'ptext' token.  In this case it is a WhiteSpaceTerminal, so it's value
    is ' '.

    'b'qcontent = qtext / quoted-pair

    We allow anything except the DQUOTE character, but if we find any ASCII
    other than the RFC defined printable ASCII, a NonPrintableDefect is
    added to the token's defects list.  Any quoted pairs are converted to their
    unquoted values, so what is returned is a 'ptext' token.  In this case it
    is a ValueTerminal.

    'u'qcontent = qtext / quoted-pair

    We allow anything except the DQUOTE character, but if we find any ASCII
    other than the RFC defined printable ASCII, a NonPrintableDefect is
    added to the token's defects list.  Any quoted pairs are converted to their
    unquoted values, so what is returned is a 'ptext' token.  In this case it
    is a ValueTerminal.

    'b'atext = <matches _atext_matcher>

    We allow any non-ATOM_ENDS in atext, but add an InvalidATextDefect to
    the token's defects list if we find non-atext characters.
    'u'atext = <matches _atext_matcher>

    We allow any non-ATOM_ENDS in atext, but add an InvalidATextDefect to
    the token's defects list if we find non-atext characters.
    'b'expected atext but found '{}''u'expected atext but found '{}''b'atext'u'atext'b'bare-quoted-string = DQUOTE *([FWS] qcontent) [FWS] DQUOTE

    A quoted-string without the leading or trailing white space.  Its
    value is the text between the quote marks, with whitespace
    preserved and quoted pairs decoded.
    'u'bare-quoted-string = DQUOTE *([FWS] qcontent) [FWS] DQUOTE

    A quoted-string without the leading or trailing white space.  Its
    value is the text between the quote marks, with whitespace
    preserved and quoted pairs decoded.
    'b'expected '"' but found '{}''u'expected '"' but found '{}''b'encoded word inside quoted string'u'encoded word inside quoted string'b'end of header inside quoted string'u'end of header inside quoted string'b'comment = "(" *([FWS] ccontent) [FWS] ")"
       ccontent = ctext / quoted-pair / comment

    We handle nested comments here, and quoted-pair in our qp-ctext routine.
    'u'comment = "(" *([FWS] ccontent) [FWS] ")"
       ccontent = ctext / quoted-pair / comment

    We handle nested comments here, and quoted-pair in our qp-ctext routine.
    'b'expected '(' but found '{}''u'expected '(' but found '{}''b'end of header inside comment'u'end of header inside comment'b'CFWS = (1*([FWS] comment) [FWS]) / FWS

    'u'CFWS = (1*([FWS] comment) [FWS]) / FWS

    'b'quoted-string = [CFWS] <bare-quoted-string> [CFWS]

    'bare-quoted-string' is an intermediate class defined by this
    parser and not by the RFC grammar.  It is the quoted string
    without any attached CFWS.
    'u'quoted-string = [CFWS] <bare-quoted-string> [CFWS]

    'bare-quoted-string' is an intermediate class defined by this
    parser and not by the RFC grammar.  It is the quoted string
    without any attached CFWS.
    'b'atom = [CFWS] 1*atext [CFWS]

    An atom could be an rfc2047 encoded word.
    'u'atom = [CFWS] 1*atext [CFWS]

    An atom could be an rfc2047 encoded word.
    'b'expected atom but found '{}''u'expected atom but found '{}''b' dot-text = 1*atext *("." 1*atext)

    'u' dot-text = 1*atext *("." 1*atext)

    'b'expected atom at a start of dot-atom-text but found '{}''u'expected atom at a start of dot-atom-text but found '{}''b'expected atom at end of dot-atom-text but found '{}''u'expected atom at end of dot-atom-text but found '{}''b' dot-atom = [CFWS] dot-atom-text [CFWS]

    Any place we can have a dot atom, we could instead have an rfc2047 encoded
    word.
    'u' dot-atom = [CFWS] dot-atom-text [CFWS]

    Any place we can have a dot atom, we could instead have an rfc2047 encoded
    word.
    'b'word = atom / quoted-string

    Either atom or quoted-string may start with CFWS.  We have to peel off this
    CFWS first to determine which type of word to parse.  Afterward we splice
    the leading CFWS, if any, into the parsed sub-token.

    If neither an atom or a quoted-string is found before the next special, a
    HeaderParseError is raised.

    The token returned is either an Atom or a QuotedString, as appropriate.
    This means the 'word' level of the formal grammar is not represented in the
    parse tree; this is because having that extra layer when manipulating the
    parse tree is more confusing than it is helpful.

    'u'word = atom / quoted-string

    Either atom or quoted-string may start with CFWS.  We have to peel off this
    CFWS first to determine which type of word to parse.  Afterward we splice
    the leading CFWS, if any, into the parsed sub-token.

    If neither an atom or a quoted-string is found before the next special, a
    HeaderParseError is raised.

    The token returned is either an Atom or a QuotedString, as appropriate.
    This means the 'word' level of the formal grammar is not represented in the
    parse tree; this is because having that extra layer when manipulating the
    parse tree is more confusing than it is helpful.

    'b'Expected 'atom' or 'quoted-string' but found nothing.'u'Expected 'atom' or 'quoted-string' but found nothing.'b'Expected 'atom' or 'quoted-string' but found '{}''u'Expected 'atom' or 'quoted-string' but found '{}''b' phrase = 1*word / obs-phrase
        obs-phrase = word *(word / "." / CFWS)

    This means a phrase can be a sequence of words, periods, and CFWS in any
    order as long as it starts with at least one word.  If anything other than
    words is detected, an ObsoleteHeaderDefect is added to the token's defect
    list.  We also accept a phrase that starts with CFWS followed by a dot;
    this is registered as an InvalidHeaderDefect, since it is not supported by
    even the obsolete grammar.

    'u' phrase = 1*word / obs-phrase
        obs-phrase = word *(word / "." / CFWS)

    This means a phrase can be a sequence of words, periods, and CFWS in any
    order as long as it starts with at least one word.  If anything other than
    words is detected, an ObsoleteHeaderDefect is added to the token's defect
    list.  We also accept a phrase that starts with CFWS followed by a dot;
    this is registered as an InvalidHeaderDefect, since it is not supported by
    even the obsolete grammar.

    'b'phrase does not start with word'u'phrase does not start with word'b'period in 'phrase''u'period in 'phrase''b'comment found without atom'u'comment found without atom'b' local-part = dot-atom / quoted-string / obs-local-part

    'u' local-part = dot-atom / quoted-string / obs-local-part

    'b'expected local-part but found '{}''u'expected local-part but found '{}''b'invalid-obs-local-part'u'invalid-obs-local-part'b'local-part is not dot-atom, quoted-string, or obs-local-part'u'local-part is not dot-atom, quoted-string, or obs-local-part'b'local-part is not a dot-atom (contains CFWS)'u'local-part is not a dot-atom (contains CFWS)'b'local-part contains non-ASCII characters)'u'local-part contains non-ASCII characters)'b' obs-local-part = word *("." word)
    'u' obs-local-part = word *("." word)
    'b'invalid repeated '.''u'invalid repeated '.''b'misplaced-special'u'misplaced-special'b''\' character outside of quoted-string/ccontent'u''\' character outside of quoted-string/ccontent'b'missing '.' between words'u'missing '.' between words'b'Invalid leading '.' in local part'u'Invalid leading '.' in local part'b'Invalid trailing '.' in local part'u'Invalid trailing '.' in local part'b' dtext = <printable ascii except \ [ ]> / obs-dtext
        obs-dtext = obs-NO-WS-CTL / quoted-pair

    We allow anything except the excluded characters, but if we find any
    ASCII other than the RFC defined printable ASCII, a NonPrintableDefect is
    added to the token's defects list.  Quoted pairs are converted to their
    unquoted values, so what is returned is a ptext token, in this case a
    ValueTerminal.  If there were quoted-printables, an ObsoleteHeaderDefect is
    added to the returned token's defect list.

    'u' dtext = <printable ascii except \ [ ]> / obs-dtext
        obs-dtext = obs-NO-WS-CTL / quoted-pair

    We allow anything except the excluded characters, but if we find any
    ASCII other than the RFC defined printable ASCII, a NonPrintableDefect is
    added to the token's defects list.  Quoted pairs are converted to their
    unquoted values, so what is returned is a ptext token, in this case a
    ValueTerminal.  If there were quoted-printables, an ObsoleteHeaderDefect is
    added to the returned token's defect list.

    'b'[]'u'[]'b'quoted printable found in domain-literal'u'quoted printable found in domain-literal'b'end of input inside domain-literal'u'end of input inside domain-literal'b'domain-literal-end'u'domain-literal-end'b' domain-literal = [CFWS] "[" *([FWS] dtext) [FWS] "]" [CFWS]

    'u' domain-literal = [CFWS] "[" *([FWS] dtext) [FWS] "]" [CFWS]

    'b'expected domain-literal'u'expected domain-literal'b'expected '[' at start of domain-literal but found '{}''u'expected '[' at start of domain-literal but found '{}''b'domain-literal-start'u'domain-literal-start'b'expected ']' at end of domain-literal but found '{}''u'expected ']' at end of domain-literal but found '{}''b' domain = dot-atom / domain-literal / obs-domain
        obs-domain = atom *("." atom))

    'u' domain = dot-atom / domain-literal / obs-domain
        obs-domain = atom *("." atom))

    'b'expected domain but found '{}''u'expected domain but found '{}''b'Invalid Domain'u'Invalid Domain'b'domain is not a dot-atom (contains CFWS)'u'domain is not a dot-atom (contains CFWS)'b' addr-spec = local-part "@" domain

    'u' addr-spec = local-part "@" domain

    'b'addr-spec local part with no domain'u'addr-spec local part with no domain'b'address-at-symbol'u'address-at-symbol'b' obs-route = obs-domain-list ":"
        obs-domain-list = *(CFWS / ",") "@" domain *("," [CFWS] ["@" domain])

        Returns an obs-route token with the appropriate sub-tokens (that is,
        there is no obs-domain-list in the parse tree).
    'u' obs-route = obs-domain-list ":"
        obs-domain-list = *(CFWS / ",") "@" domain *("," [CFWS] ["@" domain])

        Returns an obs-route token with the appropriate sub-tokens (that is,
        there is no obs-domain-list in the parse tree).
    'b'expected obs-route domain but found '{}''u'expected obs-route domain but found '{}''b'end of header while parsing obs-route'u'end of header while parsing obs-route'b'expected ':' marking end of obs-route but found '{}''u'expected ':' marking end of obs-route but found '{}''b'end-of-obs-route-marker'u'end-of-obs-route-marker'b' angle-addr = [CFWS] "<" addr-spec ">" [CFWS] / obs-angle-addr
        obs-angle-addr = [CFWS] "<" obs-route addr-spec ">" [CFWS]

    'u' angle-addr = [CFWS] "<" addr-spec ">" [CFWS] / obs-angle-addr
        obs-angle-addr = [CFWS] "<" obs-route addr-spec ">" [CFWS]

    'b'expected angle-addr but found '{}''u'expected angle-addr but found '{}''b'angle-addr-start'u'angle-addr-start'b'angle-addr-end'u'angle-addr-end'b'null addr-spec in angle-addr'u'null addr-spec in angle-addr'b'obsolete route specification in angle-addr'u'obsolete route specification in angle-addr'b'expected addr-spec or obs-route but found '{}''u'expected addr-spec or obs-route but found '{}''b'missing trailing '>' on angle-addr'u'missing trailing '>' on angle-addr'b' display-name = phrase

    Because this is simply a name-rule, we don't return a display-name
    token containing a phrase, but rather a display-name token with
    the content of the phrase.

    'u' display-name = phrase

    Because this is simply a name-rule, we don't return a display-name
    token containing a phrase, but rather a display-name token with
    the content of the phrase.

    'b' name-addr = [display-name] angle-addr

    'u' name-addr = [display-name] angle-addr

    'b'expected name-addr but found '{}''u'expected name-addr but found '{}''b' mailbox = name-addr / addr-spec

    'u' mailbox = name-addr / addr-spec

    'b'expected mailbox but found '{}''u'expected mailbox but found '{}''b' Read everything up to one of the chars in endchars.

    This is outside the formal grammar.  The InvalidMailbox TokenList that is
    returned acts like a Mailbox, but the data attributes are None.

    'u' Read everything up to one of the chars in endchars.

    This is outside the formal grammar.  The InvalidMailbox TokenList that is
    returned acts like a Mailbox, but the data attributes are None.

    'b' mailbox-list = (mailbox *("," mailbox)) / obs-mbox-list
        obs-mbox-list = *([CFWS] ",") mailbox *("," [mailbox / CFWS])

    For this routine we go outside the formal grammar in order to improve error
    handling.  We recognize the end of the mailbox list only at the end of the
    value or at a ';' (the group terminator).  This is so that we can turn
    invalid mailboxes into InvalidMailbox tokens and continue parsing any
    remaining valid mailboxes.  We also allow all mailbox entries to be null,
    and this condition is handled appropriately at a higher level.

    'u' mailbox-list = (mailbox *("," mailbox)) / obs-mbox-list
        obs-mbox-list = *([CFWS] ",") mailbox *("," [mailbox / CFWS])

    For this routine we go outside the formal grammar in order to improve error
    handling.  We recognize the end of the mailbox list only at the end of the
    value or at a ';' (the group terminator).  This is so that we can turn
    invalid mailboxes into InvalidMailbox tokens and continue parsing any
    remaining valid mailboxes.  We also allow all mailbox entries to be null,
    and this condition is handled appropriately at a higher level.

    'b',;'u',;'b'empty element in mailbox-list'u'empty element in mailbox-list'b'invalid mailbox in mailbox-list'u'invalid mailbox in mailbox-list'b' group-list = mailbox-list / CFWS / obs-group-list
        obs-group-list = 1*([CFWS] ",") [CFWS]

    'u' group-list = mailbox-list / CFWS / obs-group-list
        obs-group-list = 1*([CFWS] ",") [CFWS]

    'b'end of header before group-list'u'end of header before group-list'b'end of header in group-list'u'end of header in group-list'b'group-list with empty entries'u'group-list with empty entries'b' group = display-name ":" [group-list] ";" [CFWS]

    'u' group = display-name ":" [group-list] ";" [CFWS]

    'b'expected ':' at end of group display name but found '{}''u'expected ':' at end of group display name but found '{}''b'group-display-name-terminator'u'group-display-name-terminator'b'group-terminator'u'group-terminator'b'end of header in group'u'end of header in group'b'expected ';' at end of group but found {}'u'expected ';' at end of group but found {}'b' address = mailbox / group

    Note that counter-intuitively, an address can be either a single address or
    a list of addresses (a group).  This is why the returned Address object has
    a 'mailboxes' attribute which treats a single address as a list of length
    one.  When you need to differentiate between to two cases, extract the single
    element, which is either a mailbox or a group token.

    'u' address = mailbox / group

    Note that counter-intuitively, an address can be either a single address or
    a list of addresses (a group).  This is why the returned Address object has
    a 'mailboxes' attribute which treats a single address as a list of length
    one.  When you need to differentiate between to two cases, extract the single
    element, which is either a mailbox or a group token.

    'b'expected address but found '{}''u'expected address but found '{}''b' address_list = (address *("," address)) / obs-addr-list
        obs-addr-list = *([CFWS] ",") address *("," [address / CFWS])

    We depart from the formal grammar here by continuing to parse until the end
    of the input, assuming the input to be entirely composed of an
    address-list.  This is always true in email parsing, and allows us
    to skip invalid addresses to parse additional valid ones.

    'u' address_list = (address *("," address)) / obs-addr-list
        obs-addr-list = *([CFWS] ",") address *("," [address / CFWS])

    We depart from the formal grammar here by continuing to parse until the end
    of the input, assuming the input to be entirely composed of an
    address-list.  This is always true in email parsing, and allows us
    to skip invalid addresses to parse additional valid ones.

    'b'address-list entry with no content'u'address-list entry with no content'b'invalid address in address-list'u'invalid address in address-list'b'empty element in address-list'u'empty element in address-list'b' no-fold-literal = "[" *dtext "]"
    'u' no-fold-literal = "[" *dtext "]"
    'b'expected no-fold-literal but found '{}''u'expected no-fold-literal but found '{}''b'expected '[' at the start of no-fold-literal but found '{}''u'expected '[' at the start of no-fold-literal but found '{}''b'no-fold-literal-start'u'no-fold-literal-start'b'expected ']' at the end of no-fold-literal but found '{}''u'expected ']' at the end of no-fold-literal but found '{}''b'no-fold-literal-end'u'no-fold-literal-end'b'msg-id = [CFWS] "<" id-left '@' id-right  ">" [CFWS]
       id-left = dot-atom-text / obs-id-left
       id-right = dot-atom-text / no-fold-literal / obs-id-right
       no-fold-literal = "[" *dtext "]"
    'u'msg-id = [CFWS] "<" id-left '@' id-right  ">" [CFWS]
       id-left = dot-atom-text / obs-id-left
       id-right = dot-atom-text / no-fold-literal / obs-id-right
       no-fold-literal = "[" *dtext "]"
    'b'expected msg-id but found '{}''u'expected msg-id but found '{}''b'msg-id-start'u'msg-id-start'b'obsolete id-left in msg-id'u'obsolete id-left in msg-id'b'expected dot-atom-text or obs-id-left but found '{}''u'expected dot-atom-text or obs-id-left but found '{}''b'msg-id with no id-right'u'msg-id with no id-right'b'msg-id-end'u'msg-id-end'b'obsolete id-right in msg-id'u'obsolete id-right in msg-id'b'expected dot-atom-text, no-fold-literal or obs-id-right but found '{}''u'expected dot-atom-text, no-fold-literal or obs-id-right but found '{}''b'missing trailing '>' on msg-id'u'missing trailing '>' on msg-id'b'message-id      =   "Message-ID:" msg-id CRLF
    'u'message-id      =   "Message-ID:" msg-id CRLF
    'b'Unexpected {!r}'u'Unexpected {!r}'b'Invalid msg-id: {!r}'u'Invalid msg-id: {!r}'b' mime-version = [CFWS] 1*digit [CFWS] "." [CFWS] 1*digit [CFWS]

    'u' mime-version = [CFWS] 1*digit [CFWS] "." [CFWS] 1*digit [CFWS]

    'b'Missing MIME version number (eg: 1.0)'u'Missing MIME version number (eg: 1.0)'b'Expected MIME version number but found only CFWS'u'Expected MIME version number but found only CFWS'b'Expected MIME major version number but found {!r}'u'Expected MIME major version number but found {!r}'b'xtext'u'xtext'b'digits'b'Incomplete MIME version; found only major number'u'Incomplete MIME version; found only major number'b'version-separator'u'version-separator'b'Expected MIME minor version number but found {!r}'u'Expected MIME minor version number but found {!r}'b'Excess non-CFWS text after MIME version'u'Excess non-CFWS text after MIME version'b' Read everything up to the next ';'.

    This is outside the formal grammar.  The InvalidParameter TokenList that is
    returned acts like a Parameter, but the data attributes are None.

    'u' Read everything up to the next ';'.

    This is outside the formal grammar.  The InvalidParameter TokenList that is
    returned acts like a Parameter, but the data attributes are None.

    'b'ttext = <matches _ttext_matcher>

    We allow any non-TOKEN_ENDS in ttext, but add defects to the token's
    defects list if we find non-ttext characters.  We also register defects for
    *any* non-printables even though the RFC doesn't exclude all of them,
    because we follow the spirit of RFC 5322.

    'u'ttext = <matches _ttext_matcher>

    We allow any non-TOKEN_ENDS in ttext, but add defects to the token's
    defects list if we find non-ttext characters.  We also register defects for
    *any* non-printables even though the RFC doesn't exclude all of them,
    because we follow the spirit of RFC 5322.

    'b'expected ttext but found '{}''u'expected ttext but found '{}''b'ttext'u'ttext'b'token = [CFWS] 1*ttext [CFWS]

    The RFC equivalent of ttext is any US-ASCII chars except space, ctls, or
    tspecials.  We also exclude tabs even though the RFC doesn't.

    The RFC implies the CFWS but is not explicit about it in the BNF.

    'u'token = [CFWS] 1*ttext [CFWS]

    The RFC equivalent of ttext is any US-ASCII chars except space, ctls, or
    tspecials.  We also exclude tabs even though the RFC doesn't.

    The RFC implies the CFWS but is not explicit about it in the BNF.

    'b'expected token but found '{}''u'expected token but found '{}''b'attrtext = 1*(any non-ATTRIBUTE_ENDS character)

    We allow any non-ATTRIBUTE_ENDS in attrtext, but add defects to the
    token's defects list if we find non-attrtext characters.  We also register
    defects for *any* non-printables even though the RFC doesn't exclude all of
    them, because we follow the spirit of RFC 5322.

    'u'attrtext = 1*(any non-ATTRIBUTE_ENDS character)

    We allow any non-ATTRIBUTE_ENDS in attrtext, but add defects to the
    token's defects list if we find non-attrtext characters.  We also register
    defects for *any* non-printables even though the RFC doesn't exclude all of
    them, because we follow the spirit of RFC 5322.

    'b'expected attrtext but found {!r}'u'expected attrtext but found {!r}'b' [CFWS] 1*attrtext [CFWS]

    This version of the BNF makes the CFWS explicit, and as usual we use a
    value terminal for the actual run of characters.  The RFC equivalent of
    attrtext is the token characters, with the subtraction of '*', "'", and '%'.
    We include tab in the excluded set just as we do for token.

    'u' [CFWS] 1*attrtext [CFWS]

    This version of the BNF makes the CFWS explicit, and as usual we use a
    value terminal for the actual run of characters.  The RFC equivalent of
    attrtext is the token characters, with the subtraction of '*', "'", and '%'.
    We include tab in the excluded set just as we do for token.

    'b'attrtext = 1*(any non-ATTRIBUTE_ENDS character plus '%')

    This is a special parsing routine so that we get a value that
    includes % escapes as a single string (which we decode as a single
    string later).

    'u'attrtext = 1*(any non-ATTRIBUTE_ENDS character plus '%')

    This is a special parsing routine so that we get a value that
    includes % escapes as a single string (which we decode as a single
    string later).

    'b'expected extended attrtext but found {!r}'u'expected extended attrtext but found {!r}'b'extended-attrtext'u'extended-attrtext'b' [CFWS] 1*extended_attrtext [CFWS]

    This is like the non-extended version except we allow % characters, so that
    we can pick up an encoded value as a single string.

    'u' [CFWS] 1*extended_attrtext [CFWS]

    This is like the non-extended version except we allow % characters, so that
    we can pick up an encoded value as a single string.

    'b' '*' digits

    The formal BNF is more complicated because leading 0s are not allowed.  We
    check for that and add a defect.  We also assume no CFWS is allowed between
    the '*' and the digits, though the RFC is not crystal clear on that.
    The caller should already have dealt with leading CFWS.

    'u' '*' digits

    The formal BNF is more complicated because leading 0s are not allowed.  We
    check for that and add a defect.  We also assume no CFWS is allowed between
    the '*' and the digits, though the RFC is not crystal clear on that.
    The caller should already have dealt with leading CFWS.

    'b'Expected section but found {}'u'Expected section but found {}'b'section-marker'u'section-marker'b'Expected section number but found {}'u'Expected section number but found {}'b'section number has an invalid leading 0'u'section number has an invalid leading 0'b' quoted-string / attribute

    'u' quoted-string / attribute

    'b'Expected value but found end of string'u'Expected value but found end of string'b'Expected value but found only {}'u'Expected value but found only {}'b' attribute [section] ["*"] [CFWS] "=" value

    The CFWS is implied by the RFC but not made explicit in the BNF.  This
    simplified form of the BNF from the RFC is made to conform with the RFC BNF
    through some extra checks.  We do it this way because it makes both error
    recovery and working with the resulting parse tree easier.
    'u' attribute [section] ["*"] [CFWS] "=" value

    The CFWS is implied by the RFC but not made explicit in the BNF.  This
    simplified form of the BNF from the RFC is made to conform with the RFC BNF
    through some extra checks.  We do it this way because it makes both error
    recovery and working with the resulting parse tree easier.
    'b'Parameter contains name ({}) but no value'u'Parameter contains name ({}) but no value'b'Incomplete parameter'u'Incomplete parameter'b'extended-parameter-marker'u'extended-parameter-marker'b'Parameter not followed by '=''u'Parameter not followed by '=''b'parameter-separator'u'parameter-separator'b'Quoted string value for extended parameter is invalid'u'Quoted string value for extended parameter is invalid'b'Parameter marked as extended but appears to have a quoted string value that is non-encoded'u'Parameter marked as extended but appears to have a quoted string value that is non-encoded'b'Apparent initial-extended-value but attribute was not marked as extended or was not initial section'u'Apparent initial-extended-value but attribute was not marked as extended or was not initial section'b'Missing required charset/lang delimiters'u'Missing required charset/lang delimiters'b'Expected RFC2231 char/lang encoding delimiter, but found {!r}'u'Expected RFC2231 char/lang encoding delimiter, but found {!r}'b'RFC2231-delimiter'u'RFC2231-delimiter'b'Expected RFC2231 char/lang encoding delimiter, but found {}'u'Expected RFC2231 char/lang encoding delimiter, but found {}'b'DQUOTE'u'DQUOTE'b' parameter *( ";" parameter )

    That BNF is meant to indicate this routine should only be called after
    finding and handling the leading ';'.  There is no corresponding rule in
    the formal RFC grammar, but it is more convenient for us for the set of
    parameters to be treated as its own TokenList.

    This is 'parse' routine because it consumes the remaining value, but it
    would never be called to parse a full header.  Instead it is called to
    parse everything after the non-parameter value of a specific MIME header.

    'u' parameter *( ";" parameter )

    That BNF is meant to indicate this routine should only be called after
    finding and handling the leading ';'.  There is no corresponding rule in
    the formal RFC grammar, but it is more convenient for us for the set of
    parameters to be treated as its own TokenList.

    This is 'parse' routine because it consumes the remaining value, but it
    would never be called to parse a full header.  Instead it is called to
    parse everything after the non-parameter value of a specific MIME header.

    'b'parameter entry with no content'u'parameter entry with no content'b'invalid parameter {!r}'u'invalid parameter {!r}'b'parameter with invalid trailing text {!r}'u'parameter with invalid trailing text {!r}'b'Do our best to find the parameters in an invalid MIME header

    'u'Do our best to find the parameters in an invalid MIME header

    'b' maintype "/" subtype *( ";" parameter )

    The maintype and substype are tokens.  Theoretically they could
    be checked against the official IANA list + x-token, but we
    don't do that.
    'u' maintype "/" subtype *( ";" parameter )

    The maintype and substype are tokens.  Theoretically they could
    be checked against the official IANA list + x-token, but we
    don't do that.
    'b'Missing content type specification'u'Missing content type specification'b'Expected content maintype but found {!r}'u'Expected content maintype but found {!r}'b'Invalid content type'u'Invalid content type'b'content-type-separator'u'content-type-separator'b'Expected content subtype but found {!r}'u'Expected content subtype but found {!r}'b'Only parameters are valid after content type, but found {!r}'u'Only parameters are valid after content type, but found {!r}'b' disposition-type *( ";" parameter )

    'u' disposition-type *( ";" parameter )

    'b'Missing content disposition'u'Missing content disposition'b'Expected content disposition but found {!r}'u'Expected content disposition but found {!r}'b'Only parameters are valid after content disposition, but found {!r}'u'Only parameters are valid after content disposition, but found {!r}'b' mechanism

    'u' mechanism

    'b'Missing content transfer encoding'u'Missing content transfer encoding'b'Expected content transfer encoding but found {!r}'u'Expected content transfer encoding but found {!r}'b'Extra text after content transfer encoding'u'Extra text after content transfer encoding'b'Return string of contents of parse_tree folded according to RFC rules.

    'u'Return string of contents of parse_tree folded according to RFC rules.

    'b'wrap_as_ew_blocked'u'wrap_as_ew_blocked'b'Fold string to_encode into lines as encoded word, combining if allowed.
    Return the new value for last_ew, or None if ew_combine_allowed is False.

    If there is already an encoded word in the last line of lines (indicated by
    a non-None value for last_ew) and ew_combine_allowed is true, decode the
    existing ew, combine it with to_encode, and re-encode.  Otherwise, encode
    to_encode.  In either case, split to_encode as necessary so that the
    encoded segments fit within maxlen.

    'u'Fold string to_encode into lines as encoded word, combining if allowed.
    Return the new value for last_ew, or None if ew_combine_allowed is False.

    If there is already an encoded word in the last line of lines (indicated by
    a non-None value for last_ew) and ew_combine_allowed is true, decode the
    existing ew, combine it with to_encode, and re-encode.  Otherwise, encode
    to_encode.  In either case, split to_encode as necessary so that the
    encoded segments fit within maxlen.

    'b'max_line_length is too small to fit an encoded word'u'max_line_length is too small to fit an encoded word'b'Fold TokenList 'part' into the 'lines' list as mime parameters.

    Using the decoded list of parameters and values, format them according to
    the RFC rules, including using RFC2231 encoding if the value cannot be
    expressed in 'encoding' and/or the parameter+value is too long to fit
    within 'maxlen'.

    'u'Fold TokenList 'part' into the 'lines' list as mime parameters.

    Using the decoded list of parameters and values, format them according to
    the RFC rules, including using RFC2231 encoding if the value cannot be
    expressed in 'encoding' and/or the parameter+value is too long to fit
    within 'maxlen'.

    'b'{}*={}''{}'u'{}*={}''{}'b''''u''''b' {}*{}*={}{}'u' {}*{}*={}{}'u'email._header_value_parser'u'_header_value_parser'u'Heap queues

[explanation by Franois Pinard]

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for
all k, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that a[0] is always its smallest element.

The strange invariant above is meant to be an efficient memory
representation for a tournament.  The numbers below are `k', not a[k]:

                                   0

                  1                                 2

          3               4                5               6

      7       8       9       10      11      12      13      14

    15 16   17 18   19 20   21 22   23 24   25 26   27 28   29 30


In the tree above, each cell `k' is topping `2*k+1' and `2*k+2'.  In
a usual binary tournament we see in sports, each cell is the winner
over the two cells it tops, and we can trace the winner down the tree
to see all opponents s/he had.  However, in many computer applications
of such tournaments, we do not need to trace the history of a winner.
To be more memory efficient, when a winner is promoted, we try to
replace it by something else at a lower level, and the rule becomes
that a cell and the two cells it tops contain three different items,
but the top cell "wins" over the two topped cells.

If this heap invariant is protected at all time, index 0 is clearly
the overall winner.  The simplest algorithmic way to remove it and
find the "next" winner is to move some loser (let's say cell 30 in the
diagram above) into the 0 position, and then percolate this new 0 down
the tree, exchanging values, until the invariant is re-established.
This is clearly logarithmic on the total number of items in the tree.
By iterating over all items, you get an O(n ln n) sort.

A nice feature of this sort is that you can efficiently insert new
items while the sort is going on, provided that the inserted items are
not "better" than the last 0'th element you extracted.  This is
especially useful in simulation contexts, where the tree holds all
incoming events, and the "win" condition means the smallest scheduled
time.  When an event schedule other events for execution, they are
scheduled into the future, so they can easily go into the heap.  So, a
heap is a good structure for implementing schedulers (this is what I
used for my MIDI sequencer :-).

Various structures for implementing schedulers have been extensively
studied, and heaps are good for this, as they are reasonably speedy,
the speed is almost constant, and the worst case is not much different
than the average case.  However, there are other representations which
are more efficient overall, yet the worst cases might be terrible.

Heaps are also very useful in big disk sorts.  You most probably all
know that a big sort implies producing "runs" (which are pre-sorted
sequences, which size is usually related to the amount of CPU memory),
followed by a merging passes for these runs, which merging is often
very cleverly organised[1].  It is very important that the initial
sort produces the longest runs possible.  Tournaments are a good way
to that.  If, using all the memory available to hold a tournament, you
replace and percolate items that happen to fit the current run, you'll
produce runs which are twice the size of the memory for random input,
and much better for input fuzzily ordered.

Moreover, if you output the 0'th item on disk and get an input which
may not fit in the current tournament (because the value "wins" over
the last output value), it cannot fit in the heap, so the size of the
heap decreases.  The freed memory could be cleverly reused immediately
for progressively building a second heap, which grows at exactly the
same rate the first heap is melting.  When the first heap completely
vanishes, you switch heaps and start a new run.  Clever and quite
effective!

In a word, heaps are useful memory structures to know.  I use them in
a few applications, and I think it is good to keep a `heap' module
around. :-)

--------------------
[1] The disk balancing algorithms which are current, nowadays, are
more annoying than clever, and this is a consequence of the seeking
capabilities of the disks.  On devices which cannot seek, like big
tape drives, the story was quite different, and one had to be very
clever to ensure (far in advance) that each tape movement will be the
most effective possible (that is, will best participate at
"progressing" the merge).  Some tapes were even able to read
backwards, and this was also used to avoid the rewinding time.
Believe me, real good tape sorts were quite spectacular to watch!
From all times, sorting has always been a Great Art! :-)
'__about__u'Heap queue algorithm (a.k.a. priority queue).

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for
all k, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that a[0] is always its smallest element.

Usage:

heap = []            # creates an empty heap
heappush(heap, item) # pushes a new item on the heap
item = heappop(heap) # pops the smallest item from the heap
item = heap[0]       # smallest item on the heap without popping it
heapify(x)           # transforms list into a heap, in-place, in linear time
item = heapreplace(heap, item) # pops and returns smallest item, and adds
                               # new item; the heap size is unchanged

Our API differs from textbook heap algorithms as follows:

- We use 0-based indexing.  This makes the relationship between the
  index for a node and the indexes for its children slightly less
  obvious, but is more suitable since Python uses 0-based indexing.

- Our heappop() method returns the smallest item, not the largest.

These two make it possible to view the heap as a regular Python list
without surprises: heap[0] is the smallest item, and heap.sort()
maintains the heap invariant!
'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_heapq.cpython-310-darwin.so'u'_heapq'_heapify_max_heappop_max_heapreplace_maxheapifyheappushpopheapreplace_heapqu'(Extremely) low-level import machinery bits as used by importlib and imp.'init_frozenlock_held
requests._internal_utils
~~~~~~~~~~~~~~

Provides utility functions that are consumed internally by Requests
which depend on extremely few external helpers (such as compat)
compatbuiltin_str^[^:\s][^:\r\n]*$rb"_VALID_HEADER_NAME_RE_BYTE_VALID_HEADER_NAME_RE_STR^\S[^\r\n]*$|^$_VALID_HEADER_VALUE_RE_BYTE_VALID_HEADER_VALUE_RE_STRHEADER_VALIDATORSto_native_stringGiven a string object, regardless of type, returns a representation of
    that string in the native string type, encoding and decoding where
    necessary. This assumes ASCII unless told otherwise.
    unicode_is_asciiu_stringDetermine if unicode string only contains ASCII characters.

    :param str u_string: unicode string to check. Must be unicode
        and not Python 2 `str`.
    :rtype: bool
    b'
requests._internal_utils
~~~~~~~~~~~~~~

Provides utility functions that are consumed internally by Requests
which depend on extremely few external helpers (such as compat)
'u'
requests._internal_utils
~~~~~~~~~~~~~~

Provides utility functions that are consumed internally by Requests
which depend on extremely few external helpers (such as compat)
'b'^[^:\s][^:\r\n]*$'u'^[^:\s][^:\r\n]*$'b'^\S[^\r\n]*$|^$'u'^\S[^\r\n]*$|^$'b'Given a string object, regardless of type, returns a representation of
    that string in the native string type, encoding and decoding where
    necessary. This assumes ASCII unless told otherwise.
    'u'Given a string object, regardless of type, returns a representation of
    that string in the native string type, encoding and decoding where
    necessary. This assumes ASCII unless told otherwise.
    'b'Determine if unicode string only contains ASCII characters.

    :param str u_string: unicode string to check. Must be unicode
        and not Python 2 `str`.
    :rtype: bool
    'u'Determine if unicode string only contains ASCII characters.

    :param str u_string: unicode string to check. Must be unicode
        and not Python 2 `str`.
    :rtype: bool
    'u'requests._internal_utils'u'_internal_utils'u'A buffered reader and writer object together.

A buffered reader object and buffered writer object put together to
form a sequential IO object that can read and write. This is typically
used with a socket or two-way pipe.

reader and writer are RawIOBase objects that are readable and
writeable respectively. If the buffer_size is omitted it defaults to
DEFAULT_BUFFER_SIZE.'u'BufferedRWPair.closed'peekread1readinto1u'Base class for buffered IO objects.

The main difference with RawIOBase is that the read() method
supports omitting the size argument, and does not have a default
implementation that defers to readinto().

In addition, read(), readinto() and write() may raise
BlockingIOError if the underlying raw stream is in non-blocking
mode and not ready; unlike their raw counterparts, they will never
return None.

A typical implementation should not inherit from a RawIOBase
implementation, but wrap one.
'_io._BufferedIOBase_io.BufferedRWPairBufferedRWPairu'A buffered interface to random access streams.

The constructor creates a reader and writer for a seekable stream,
raw, given in the first argument. If the buffer_size is omitted it
defaults to DEFAULT_BUFFER_SIZE.'_dealloc_warnu'BufferedRandom.closed'u'BufferedRandom.mode'u'BufferedRandom.name'_io.BufferedRandomBufferedRandomu'Create a new buffered reader using the given readable raw IO object.'u'BufferedReader.closed'u'BufferedReader.mode'u'BufferedReader.name'_io.BufferedReaderBufferedReaderu'A buffer for a writeable sequential RawIO object.

The constructor creates a BufferedWriter for the given writeable raw
stream. If the buffer_size is not given, it defaults to
DEFAULT_BUFFER_SIZE.'u'BufferedWriter.closed'u'BufferedWriter.mode'u'BufferedWriter.name'_io.BufferedWriteru'Buffered I/O implementation using an in-memory bytes buffer.'u'True if the file is closed.'u'BytesIO.closed'getbuffer_io.BytesIOu'Open a file.

The mode can be 'r' (default), 'w', 'x' or 'a' for reading,
writing, exclusive creation or appending.  The file will be created if it
doesn't exist when opened for writing or appending; it will be truncated
when opened for writing.  A FileExistsError will be raised if it already
exists when opened for creating. Opening a file for creating implies
writing so this mode behaves in a similar way to 'w'.Add a '+' to the mode
to allow simultaneous reading and writing. A custom opener can be used by
passing a callable as *opener*. The underlying file descriptor for the file
object is then obtained by calling opener with (*name*, *flags*).
*opener* must return an open file descriptor (passing os.open as *opener*
results in functionality similar to passing None).'_blksizeu'True if the file is closed'u'FileIO.closed'u'True if the file descriptor will be closed by close().'u'FileIO.closefd'closefdu'String giving the file mode'u'FileIO.mode'u'Base class for raw binary I/O.'_io._RawIOBase_io.FileIOu'Codec used when reading a file in universal newlines mode.

It wraps another incremental decoder, translating \r\n and \r into \n.
It also records the types of newlines encountered.  When used with
translate=False, it ensures that the newline sequence is returned in
one piece. When used with decoder=None, it expects unicode strings as
decode input and translates newlines without first invoking an external
decoder.'getstateu'IncrementalNewlineDecoder.newlines'setstate_io.IncrementalNewlineDecoderu'Text I/O implementation using an in-memory buffer.

The initial_value argument sets the value of object.  The newline
argument is like the one of TextIOWrapper's constructor.'u'StringIO.closed'u'StringIO.line_buffering'u'StringIO.newlines'_io.StringIOu'UnsupportedOperation.__weakref__'io.UnsupportedOperation_BufferedIOBase_IOBase_RawIOBase_TextIOBaseu'The io module provides the Python interfaces to stream handling. The
builtin open function is defined in this module.

At the top of the I/O hierarchy is the abstract base class IOBase. It
defines the basic interface to a stream. Note, however, that there is no
separation between reading and writing to streams; implementations are
allowed to raise an OSError if they do not support a given operation.

Extending IOBase is RawIOBase which deals simply with the reading and
writing of raw bytes to a stream. FileIO subclasses RawIOBase to provide
an interface to OS files.

BufferedIOBase deals with buffering on a raw byte stream (RawIOBase). Its
subclasses, BufferedWriter, BufferedReader, and BufferedRWPair buffer
streams that are readable, writable, and both respectively.
BufferedRandom provides a buffered interface to random access
streams. BytesIO is a simple stream of in-memory bytes.

Another IOBase subclass, TextIOBase, deals with the encoding and decoding
of streams into text. TextIOWrapper, which extends it, is a buffered text
interface to a buffered raw stream (`BufferedIOBase`). Finally, StringIO
is an in-memory stream for text.

Argument names are not part of the specification, and only the arguments
of open() are intended to be used as keyword arguments.

data:

DEFAULT_BUFFER_SIZE

   An int containing the default buffer size used by the module's buffered
   I/O classes. open() uses the file's blksize (as obtained by os.stat) if
   possible.
'u'json speedups
'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_json.cpython-310-darwin.so'u'_json'encode_basestringencode_basestring_asciiu'_iterencode(obj, _current_indent_level) -> iterable'item_separatorkey_separatormarkers_json.Encodermake_encoderu'JSON scanner object'_json.Scannermake_scannerscanstring_jsonABDAY_1ABDAY_2ABDAY_3ABDAY_4ABDAY_5ABDAY_6ABDAY_7ABMON_142ABMON_1043ABMON_1144ABMON_12ABMON_2ABMON_3ABMON_4ABMON_5ABMON_639ABMON_7ABMON_841ABMON_949ALT_DIGITSAM_STRCHAR_MAXCODESET56CRNCYSTRDAY_1DAY_2DAY_3DAY_4DAY_5DAY_6DAY_7D_FMTD_T_FMT45ERA46ERA_D_FMT47ERA_D_T_FMT48ERA_T_FMTu'locale'u'Error.__weakref__'locale.ErrorLC_ALLLC_COLLATELC_CTYPELC_MESSAGESLC_MONETARYLC_NUMERICLC_TIMEMON_1MON_10MON_11MON_12MON_2MON_3MON_4MON_5MON_6MON_7MON_8MON_9NOEXPRPM_STRRADIXCHAR51THOUSEPT_FMTT_FMT_AMPM52YESEXPRu'Support for POSIX locales.'_get_locale_encodinglocaleconvnl_langinfostrcollstrxfrm_localeCHECK_CRC32CHECK_CRC64CHECK_ID_MAXCHECK_NONECHECK_SHA256CHECK_UNKNOWNFILTER_ARMFILTER_ARMTHUMBFILTER_DELTAFILTER_IA644611686018427387905FILTER_LZMA1FILTER_LZMA2FILTER_POWERPCFILTER_SPARCFILTER_X86FORMAT_ALONEFORMAT_AUTOFORMAT_RAWFORMAT_XZu'LZMACompressor(format=FORMAT_XZ, check=-1, preset=None, filters=None)

Create a compressor object for compressing data incrementally.

format specifies the container format to use for the output. This can
be FORMAT_XZ (default), FORMAT_ALONE, or FORMAT_RAW.

check specifies the integrity check to use. For FORMAT_XZ, the default
is CHECK_CRC64. FORMAT_ALONE and FORMAT_RAW do not support integrity
checks; for these formats, check must be omitted, or be CHECK_NONE.

The settings used by the compressor can be specified either as a
preset compression level (with the 'preset' argument), or in detail
as a custom filter chain (with the 'filters' argument). For FORMAT_XZ
and FORMAT_ALONE, the default is to use the PRESET_DEFAULT preset
level. For FORMAT_RAW, the caller must always specify a filter chain;
the raw compressor does not support preset compression levels.

preset (if provided) should be an integer in the range 0-9, optionally
OR-ed with the constant PRESET_EXTREME.

filters (if provided) should be a sequence of dicts. Each dict should
have an entry for "id" indicating the ID of the filter, plus
additional entries for options to the filter.

For one-shot compression, use the compress() function instead.
'u'_lzma'_lzma.LZMACompressorLZMACompressoru'Create a decompressor object for decompressing data incrementally.

  format
    Specifies the container format of the input stream.  If this is
    FORMAT_AUTO (the default), the decompressor will automatically detect
    whether the input is FORMAT_XZ or FORMAT_ALONE.  Streams created with
    FORMAT_RAW cannot be autodetected.
  memlimit
    Limit the amount of memory used by the decompressor.  This will cause
    decompression to fail if the input cannot be decompressed within the
    given limit.
  filters
    A custom filter chain.  This argument is required for FORMAT_RAW, and
    not accepted with any other format.  When provided, this should be a
    sequence of dicts, each indicating the ID and options for a single
    filter.

For one-shot decompression, use the decompress() function instead.'_lzma.LZMADecompressorLZMADecompressoru'Call to liblzma failed.'u'LZMAError.__weakref__'_lzma.LZMAErrorLZMAErrorMF_BT2MF_BT3MF_BT4MF_HC3MF_HC4MODE_FASTMODE_NORMALPRESET_DEFAULT2147483648PRESET_EXTREMEu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_lzma.cpython-310-darwin.so'_decode_filter_properties_encode_filter_propertiesis_check_supported_lzmaShared support for scanning document type declarations in HTML and XHTML.

This module is used as a foundation for the html.parser module.  It has no
documented public API and should not be used directly.

[a-zA-Z][-_.a-zA-Z0-9]*\s*_declname_match(\'[^\']*\'|"[^"]*")\s*_declstringlit_match--\s*>_commentclose]\s*]\s*>_markedsectionclose]\s*>_msmarkedsectioncloseParserBaseParser base class which provides some common support methods used
    by the SGML/HTML and XHTML parsers._markupbase.ParserBase must be subclassedgetposReturn current line number and offset.updateposrawdatanlines_decl_othercharsparse_declaration<!unexpected call to parse_declarationparse_commentparse_marked_section_scan_namedecltypehandle_declunknown_decl"'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_parse_doctype_subsetattlistlinktypeunsupported '[' char in %s declarationunexpected '[' char in declarationunexpected %r char in declarationreport<![unexpected call to parse_marked_section()sectNametempcdataincludercdataifelseendifunknown status keyword %r in marked sectionunexpected call to parse_comment()handle_commentdeclstartposunexpected char in internal subset (in %r)notationunknown declaration %r in internal subset_parse_doctype_methunexpected char after internal subsetunexpected char %r in internal subset_parse_doctype_element_parse_doctype_attlist_parse_doctype_notation_parse_doctype_entityexpected name token at %r# An analysis of the MS-Word extensions is available at# http://www.planetpublish.com/xmlarena/xap/Thursday/WordtoXML.pdf# Internal -- update line number and offset.  This should be# called for each piece of data exactly once, in order -- in other# words the concatenation of all the input strings to this# function should be exactly the entire input.# Should not fail# Internal -- parse declaration (for use by subclasses).# This is some sort of declaration; in "HTML as# deployed," this should only be the document type# declaration ("<!DOCTYPE html...>").# ISO 8879:1986, however, has more complex# declaration syntax for elements in <!...>, including:# --comment--# [marked section]# name in the following list: ENTITY, DOCTYPE, ELEMENT,# ATTLIST, NOTATION, SHORTREF, USEMAP,# LINKTYPE, LINK, IDLINK, USELINK, SYSTEM# the empty comment <!># Start of comment followed by buffer boundary,# or just a buffer boundary.# A simple, practical version could look like: ((name|stringlit) S*) + '>'#comment# Locate --.*-- as the body of the comment#marked section# Locate [statusWord [...arbitrary SGML...]] as the body of the marked section# Where statusWord is one of TEMP, CDATA, IGNORE, INCLUDE, RCDATA# Note that this is extended by Microsoft Office "Save as Web" function# to include [if...] and [endif].#all other declaration elements# end of declaration syntax# According to the HTML5 specs sections "8.2.4.44 Bogus# comment state" and "8.2.4.45 Markup declaration open# state", a comment token should be emitted.# Calling unknown_decl provides more flexibility though.# incomplete# this could be handled in a separate doctype parser# must tolerate []'d groups in a content model in an element declaration# also in data attribute specifications of attlist declaration# also link type declaration subsets in linktype declarations# also link attribute specification lists in link declarations# Internal -- parse a marked section# Override this to handle MS-word extension syntax <![if word]>content<![endif]># look for standard ]]> ending# look for MS Office ]> ending# Internal -- parse comment, return length or -1 if not terminated# Internal -- scan past the internal subset in a <!DOCTYPE declaration,# returning the index just past any whitespace following the trailing ']'.# end of buffer; incomplete# handle the individual names# parameter entity reference# end of buffer reached# Internal -- scan past <!ELEMENT declarations# style content model; just skip until '>'# Internal -- scan past <!ATTLIST declarations# scan a series of attribute descriptions; simplified:#   name type [value] [#constraint]# an enumerated type; look for ')'# end of buffer, incomplete# end of buffer# all done# Internal -- scan past <!NOTATION declarations# Internal -- scan past <!ENTITY declarations# Internal -- scan a name token and the new position and the token, or# return -1 if we've reached the end of the buffer.# To be overridden -- handlers for unknown objectsb'Shared support for scanning document type declarations in HTML and XHTML.

This module is used as a foundation for the html.parser module.  It has no
documented public API and should not be used directly.

'u'Shared support for scanning document type declarations in HTML and XHTML.

This module is used as a foundation for the html.parser module.  It has no
documented public API and should not be used directly.

'b'[a-zA-Z][-_.a-zA-Z0-9]*\s*'u'[a-zA-Z][-_.a-zA-Z0-9]*\s*'b'(\'[^\']*\'|"[^"]*")\s*'u'(\'[^\']*\'|"[^"]*")\s*'b'--\s*>'u'--\s*>'b']\s*]\s*>'u']\s*]\s*>'b']\s*>'u']\s*>'b'Parser base class which provides some common support methods used
    by the SGML/HTML and XHTML parsers.'u'Parser base class which provides some common support methods used
    by the SGML/HTML and XHTML parsers.'b'_markupbase.ParserBase must be subclassed'u'_markupbase.ParserBase must be subclassed'b'Return current line number and offset.'u'Return current line number and offset.'b'<!'u'<!'b'unexpected call to parse_declaration'u'unexpected call to parse_declaration'b'"''u'"''b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'u'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'b'attlist'u'attlist'b'linktype'u'linktype'b'unsupported '[' char in %s declaration'u'unsupported '[' char in %s declaration'b'unexpected '[' char in declaration'u'unexpected '[' char in declaration'b'unexpected %r char in declaration'u'unexpected %r char in declaration'b'<!['u'<!['b'unexpected call to parse_marked_section()'u'unexpected call to parse_marked_section()'b'temp'u'temp'b'cdata'u'cdata'b'include'u'include'b'rcdata'u'rcdata'b'if'u'if'b'else'u'else'b'endif'u'endif'b'unknown status keyword %r in marked section'u'unknown status keyword %r in marked section'b'unexpected call to parse_comment()'u'unexpected call to parse_comment()'b'unexpected char in internal subset (in %r)'u'unexpected char in internal subset (in %r)'b'entity'u'entity'b'notation'u'notation'b'unknown declaration %r in internal subset'u'unknown declaration %r in internal subset'b'_parse_doctype_'u'_parse_doctype_'b'unexpected char after internal subset'u'unexpected char after internal subset'b'unexpected char %r in internal subset'u'unexpected char %r in internal subset'b'expected name token at %r'u'expected name token at %r'u'_md5'u'md5.block_size'u'md5.digest_size'u'md5.name'_md5.md5MD5Typeu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_md5.cpython-310-darwin.so'md5_md5u'_multibytecodec'u'how to treat errors'u'MultibyteIncrementalDecoder.errors'_multibytecodec.MultibyteIncrementalDecoderMultibyteIncrementalDecoderu'MultibyteIncrementalEncoder.errors'_multibytecodec.MultibyteIncrementalEncoderMultibyteIncrementalEncoderu'MultibyteStreamReader.errors'_multibytecodec.MultibyteStreamReaderMultibyteStreamReaderu'MultibyteStreamWriter.errors'_multibytecodec.MultibyteStreamWriterMultibyteStreamWriter__create_codecu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_multibytecodec.cpython-310-darwin.so'_multibytecodec32767SEM_VALUE_MAXu'Semaphore/Mutex type'_after_fork_get_value_is_mine_is_zero_rebuildmaxvalue_multiprocessing.SemLockSemLocku'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_multiprocessing.cpython-310-darwin.so'sem_unlinku'Opcode support module.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_opcode.cpython-310-darwin.so'u'_opcode'stack_effect_opcodeu'Operator interface.

This module exports a set of functions implemented in C corresponding
to the intrinsic operators of Python.  For example, operator.add(x, y)
is equivalent to the expression x+y.  The function names are those
used for special methods; variants without leading and trailing
'__' are also provided for convenience.'_compare_digestand_u'attrgetter(attr, ...) --> attrgetter object

Return a callable object that fetches the given attribute(s) from its operand.
After f = attrgetter('name'), the call f(r) returns r.name.
After g = attrgetter('name', 'date'), the call g(r) returns (r.name, r.date).
After h = attrgetter('name.first', 'name.last'), the call h(r) returns
(r.name.first, r.name.last).'u'operator'operator.attrgetterconcatcontainscountOfdelitemfloordivgegtiaddiandiconcatifloordivilshiftimatmulimodimulindexOfinvinvertioripowirshiftis_is_notisubu'itemgetter(item, ...) --> itemgetter object

Return a callable object that fetches the given item(s) from its operand.
After f = itemgetter(2), the call f(r) returns r[2].
After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])'operator.itemgetteritruedivixorlelength_hintlshiftltmatmulu'methodcaller(name, ...) --> methodcaller object

Return a callable object that calls the given method on its operand.
After f = methodcaller('name'), the call f(r) returns r.name().
After g = methodcaller('name', 'date', foo=1), the call g(r) returns
r.name('date', foo=1).'operator.methodcallermethodcallermulnenegnot_or_rshiftsetitemtruedivtruthxor_operatorShared OS X support functions.compiler_fixupcustomize_config_varsget_platform_osxLDFLAGSCPPFLAGSBASECFLAGSBLDSHAREDLDSHAREDCCCXXPY_LDFLAGSPY_CPPFLAGSPY_CORE_CFLAGSPY_CORE_LDFLAGS_UNIVERSAL_CONFIG_VARS_COMPILER_CONFIG_VARS_OSX_SUPPORT_INITIAL__INITPRE_find_executableTries to find 'executable' in the directories listed in 'path'.

    A string listing directories separated by 'os.pathsep'; defaults to
    os.environ['PATH'].  Returns the complete filename or None if not found.
    PATHpathsep.exe_read_outputcommandstringcapture_stderrOutput from successful command execution or NoneNamedTemporaryFile/tmp/_osx_support.%sw+bclosing%s >'%s' 2>&1%s 2>/dev/null >'%s'_find_build_tooltoolnameFind a build tool on current path or using xcrun/usr/bin/xcrun -find %s_SYSTEM_VERSION_get_system_versionReturn the OS X system version as a string/System/Library/CoreServices/SystemVersion.plist<key>ProductUserVisibleVersion</key>\s*<string>(.*?)</string>r'<key>ProductUserVisibleVersion</key>\s*'r'<string>(.*?)</string>'_SYSTEM_VERSION_TUPLE_get_system_version_tuple
    Return the macOS system version as a tuple

    The return value is safe to use to compare
    two version numbers.
    osx_version_remove_original_values_config_varsRemove original unmodified values for testing_save_modified_valuecvSave modified and original unmodified value of configuration varoldvalue_cache_default_sysroot_default_sysrootcc Returns the root of the default SDK for this system, or '/' %s -c -E -v - </dev/nullin_incdirs#include <...>End of search list/usr/include.sdk/usr/include_supports_universal_buildsReturns True if universal builds are supported on this system_supports_arm64_buildsReturns True if arm64 builds are supported on this system_find_appropriate_compilerFind appropriate C compiler for extension module buildsoldccclanggcc'%s' --version'"'"'llvm-gccCannot locate working compilercv_split++_remove_universal_flagsRemove all universal build arguments from config vars-arch\s+\w+\s-isysroot\s*\S+_remove_unsupported_archsRemove any unsupported archs from config vars-arch\s+ppcecho 'int main{};' | '%s' -c -arch ppc -x c -o /dev/null /dev/null 2>/dev/null"""echo 'int main{};' | """"""'%s' -c -arch ppc -x c -o /dev/null /dev/null 2>/dev/null"""-arch\s+ppc\w*\s_override_all_archsAllow override of all archs with ARCHFLAGS env varARCHFLAGSarch-arch_check_for_unavailable_sdkRemove references to any SDKs not available-isysroot\s*(\S+)sdk-isysroot\s*\S+(?:\s|$)compiler_socc_args
    This function will strip '-isysroot PATH' and '-arch ARCH' from the
    compile flags if the user has specified one them in extra_compile_flags.

    This is needed because '-arch ARCH' adds another architecture to the
    build, without a way to remove an architecture. Furthermore GCC will
    barf if multiple '-isysroot' arguments are present.
    stripArchstripSysroot-isysrootidxarm64sysrootargvarisdirCompiling with an SDK that doesn't seem to exist: Please check your Xcode installation
Customize Python build configuration variables.

    Called internally from sysconfig with a mutable mapping
    containing name/value pairs parsed from the configured
    makefile used to build this interpreter.  Returns
    the mapping updated as needed to reflect the environment
    in which the interpreter is running; in the case of
    a Python from a binary installer, the installed
    environment may be very different from the build
    environment, i.e. different OS levels, different
    built tools, different available CPU architectures.

    This customization is performed whenever
    distutils.sysconfig.get_config_vars() is first
    called.  It may be used in environments where no
    compilers are present, i.e. when installing pure
    Python dists.  Customization of compiler paths
    and detection of unavailable archs is deferred
    until the first extension module build is
    requested (in distutils.sysconfig.customize_compiler).

    Currently called from distutils.sysconfig
    Customize compiler path and configuration variables.

    This customization is performed when the first
    extension module build is requested
    in distutils.sysconfig.customize_compiler.
    osnamemachineFilter values for get_platform()MACOSX_DEPLOYMENT_TARGETmacvermacreleasemacosxfat-arch\s+(\S+)archsx86_64universal2i386ppcintelfat3ppc64fat64universalDon't know machine value for archs=%rPowerPCPower_Macintosh# configuration variables that may contain universal build flags,# like "-arch" or "-isdkroot", that may need customization for# the user environment# configuration variables that may contain compiler calls# prefix added to original configuration variable names# the file exists, we have a shot at spawn working# Similar to os.popen(commandstring, "r").read(),# but without actually using os.popen because that# function is not usable during python bootstrap.# tempfile is also not available then.# Reading this plist is a documented way to get the system# version (see the documentation for the Gestalt Manager)# We avoid using platform.mac_ver to avoid possible bootstrap issues during# the build of Python itself (distutils is used to build standard library# extensions).# We're on a plain darwin box, fall back to the default# behaviour.# else: fall back to the default behaviour# This is needed for higher-level cross-platform tests of get_platform.# As an approximation, we assume that if we are running on 10.4 or above,# then we are running with an Xcode environment that supports universal# builds, in particular -isysroot and -arch arguments to the compiler. This# is in support of allowing 10.4 universal builds to run on 10.3.x systems.# There are two sets of systems supporting macOS/arm64 builds:# 1. macOS 11 and later, unconditionally# 2. macOS 10.15 with Xcode 12.2 or later# For now the second category is ignored.# Issue #13590:#    The OSX location for the compiler varies between OSX#    (or rather Xcode) releases.  With older releases (up-to 10.5)#    the compiler is in /usr/bin, with newer releases the compiler#    can only be found inside Xcode.app if the "Command Line Tools"#    are not installed.#    Furthermore, the compiler that can be used varies between#    Xcode releases. Up to Xcode 4 it was possible to use 'gcc-4.2'#    as the compiler, after that 'clang' should be used because#    gcc-4.2 is either not present, or a copy of 'llvm-gcc' that#    miscompiles Python.# skip checks if the compiler was overridden with a CC env variable# The CC config var might contain additional arguments.# Ignore them while searching.# Compiler is not found on the shell search PATH.# Now search for clang, first on PATH (if the Command LIne# Tools have been installed in / or if the user has provided# another location via CC).  If not found, try using xcrun# to find an uninstalled clang (within a selected Xcode).# NOTE: Cannot use subprocess here because of bootstrap# issues when building Python itself (and os.popen is# implemented on top of subprocess and is therefore not# usable as well)# Compiler is GCC, check if it is LLVM-GCC# Found LLVM-GCC, fall back to clang# Found a replacement compiler.# Modify config vars using new compiler, if not already explicitly# overridden by an env variable, preserving additional arguments.# Do not alter a config var explicitly overridden by env var# Different Xcode releases support different sets for '-arch'# flags. In particular, Xcode 4.x no longer supports the# PPC architectures.# This code automatically removes '-arch ppc' and '-arch ppc64'# when these are not supported. That makes it possible to# build extensions on OSX 10.7 and later with the prebuilt# 32-bit installer on the python.org website.# issues when building Python itself# The compile failed for some reason.  Because of differences# across Xcode and compiler versions, there is no reliable way# to be sure why it failed.  Assume here it was due to lack of# PPC support and remove the related '-arch' flags from each# config variables not explicitly overridden by an environment# variable.  If the error was for some other reason, we hope the# failure will show up again when trying to compile an extension# module.# NOTE: This name was introduced by Apple in OSX 10.5 and# is used by several scripting languages distributed with# that OS release.# If we're on OSX 10.5 or later and the user tries to# compile an extension using an SDK that is not present# on the current machine it is better to not use an SDK# than to fail.  This is particularly important with# the standalone Command Line Tools alternative to a# full-blown Xcode install since the CLT packages do not# provide SDKs.  If the SDK is not present, it is assumed# that the header files and dev libs have been installed# to /usr and /System/Library by either a standalone CLT# package or the CLT component within Xcode.# OSX before 10.4.0, these don't support -arch and -isysroot at# all.# Strip this argument and the next one:# Look for "-arch arm64" and drop that# User specified different -arch flags in the environ,# see also distutils.sysconfig# It's '-isysroot/some/path' in one arg# Check if the SDK that is used during compilation actually exists,# the universal build requires the usage of a universal SDK and not all# users have that installed by default.# On Mac OS X before 10.4, check if -arch and -isysroot# are in CFLAGS or LDFLAGS and remove them if they are.# This is needed when building extensions on a 10.3 system# using a universal build of python.# Allow user to override all archs with ARCHFLAGS env var# Remove references to sdks that are not found# Find a compiler to use for extension module builds# Remove ppc arch flags if not supported here# called from get_platform() in sysconfig and distutils.util# For our purposes, we'll assume that the system version from# distutils' perspective is what MACOSX_DEPLOYMENT_TARGET is set# to. This makes the compatibility story a bit more sane because the# machine is going to compile and link as if it were# MACOSX_DEPLOYMENT_TARGET.# Use the original CFLAGS value, if available, so that we# return the same machine type for the platform string.# Otherwise, distutils may consider this a cross-compiling# case and disallow installs.# assume no universal support# The universal build will build fat binaries, but not on# systems before 10.4# On OSX the machine type returned by uname is always the# 32-bit variant, even if the executable architecture is# the 64-bit variant# Pick a sane name for the PPC architecture.# See 'i386' caseb'Shared OS X support functions.'u'Shared OS X support functions.'b'compiler_fixup'u'compiler_fixup'b'customize_config_vars'u'customize_config_vars'b'customize_compiler'u'customize_compiler'b'get_platform_osx'u'get_platform_osx'b'LDFLAGS'u'LDFLAGS'b'CPPFLAGS'u'CPPFLAGS'b'BASECFLAGS'u'BASECFLAGS'b'BLDSHARED'u'BLDSHARED'b'LDSHARED'u'LDSHARED'b'CC'u'CC'b'CXX'u'CXX'b'PY_LDFLAGS'u'PY_LDFLAGS'b'PY_CPPFLAGS'u'PY_CPPFLAGS'b'PY_CORE_CFLAGS'u'PY_CORE_CFLAGS'b'PY_CORE_LDFLAGS'u'PY_CORE_LDFLAGS'b'_OSX_SUPPORT_INITIAL_'u'_OSX_SUPPORT_INITIAL_'b'Tries to find 'executable' in the directories listed in 'path'.

    A string listing directories separated by 'os.pathsep'; defaults to
    os.environ['PATH'].  Returns the complete filename or None if not found.
    'u'Tries to find 'executable' in the directories listed in 'path'.

    A string listing directories separated by 'os.pathsep'; defaults to
    os.environ['PATH'].  Returns the complete filename or None if not found.
    'b'PATH'u'PATH'b'.exe'u'.exe'b'Output from successful command execution or None'u'Output from successful command execution or None'b'/tmp/_osx_support.%s'u'/tmp/_osx_support.%s'b'w+b'u'w+b'b'%s >'%s' 2>&1'u'%s >'%s' 2>&1'b'%s 2>/dev/null >'%s''u'%s 2>/dev/null >'%s''b'Find a build tool on current path or using xcrun'u'Find a build tool on current path or using xcrun'b'/usr/bin/xcrun -find %s'u'/usr/bin/xcrun -find %s'b'Return the OS X system version as a string'u'Return the OS X system version as a string'b'/System/Library/CoreServices/SystemVersion.plist'u'/System/Library/CoreServices/SystemVersion.plist'b'<key>ProductUserVisibleVersion</key>\s*<string>(.*?)</string>'u'<key>ProductUserVisibleVersion</key>\s*<string>(.*?)</string>'b'
    Return the macOS system version as a tuple

    The return value is safe to use to compare
    two version numbers.
    'u'
    Return the macOS system version as a tuple

    The return value is safe to use to compare
    two version numbers.
    'b'Remove original unmodified values for testing'u'Remove original unmodified values for testing'b'Save modified and original unmodified value of configuration var'u'Save modified and original unmodified value of configuration var'b' Returns the root of the default SDK for this system, or '/' 'u' Returns the root of the default SDK for this system, or '/' 'b'%s -c -E -v - </dev/null'u'%s -c -E -v - </dev/null'b'#include <...>'u'#include <...>'b'End of search list'u'End of search list'b'/usr/include'u'/usr/include'b'.sdk/usr/include'u'.sdk/usr/include'b'Returns True if universal builds are supported on this system'u'Returns True if universal builds are supported on this system'b'Returns True if arm64 builds are supported on this system'u'Returns True if arm64 builds are supported on this system'b'Find appropriate C compiler for extension module builds'u'Find appropriate C compiler for extension module builds'b'clang'u'clang'b'gcc'u'gcc'b''%s' --version'u''%s' --version'b''"'"''u''"'"''b'llvm-gcc'u'llvm-gcc'b'Cannot locate working compiler'u'Cannot locate working compiler'b'++'u'++'b'Remove all universal build arguments from config vars'u'Remove all universal build arguments from config vars'b'-arch\s+\w+\s'u'-arch\s+\w+\s'b'-isysroot\s*\S+'u'-isysroot\s*\S+'b'Remove any unsupported archs from config vars'u'Remove any unsupported archs from config vars'b'-arch\s+ppc'u'-arch\s+ppc'b'echo 'int main{};' | '%s' -c -arch ppc -x c -o /dev/null /dev/null 2>/dev/null'u'echo 'int main{};' | '%s' -c -arch ppc -x c -o /dev/null /dev/null 2>/dev/null'b'-arch\s+ppc\w*\s'u'-arch\s+ppc\w*\s'b'Allow override of all archs with ARCHFLAGS env var'u'Allow override of all archs with ARCHFLAGS env var'b'ARCHFLAGS'u'ARCHFLAGS'b'-arch'u'-arch'b'Remove references to any SDKs not available'u'Remove references to any SDKs not available'b'-isysroot\s*(\S+)'u'-isysroot\s*(\S+)'b'-isysroot\s*\S+(?:\s|$)'u'-isysroot\s*\S+(?:\s|$)'b'
    This function will strip '-isysroot PATH' and '-arch ARCH' from the
    compile flags if the user has specified one them in extra_compile_flags.

    This is needed because '-arch ARCH' adds another architecture to the
    build, without a way to remove an architecture. Furthermore GCC will
    barf if multiple '-isysroot' arguments are present.
    'u'
    This function will strip '-isysroot PATH' and '-arch ARCH' from the
    compile flags if the user has specified one them in extra_compile_flags.

    This is needed because '-arch ARCH' adds another architecture to the
    build, without a way to remove an architecture. Furthermore GCC will
    barf if multiple '-isysroot' arguments are present.
    'b'-isysroot'u'-isysroot'b'arm64'u'arm64'b'Compiling with an SDK that doesn't seem to exist: 'u'Compiling with an SDK that doesn't seem to exist: 'b'Please check your Xcode installation
'u'Please check your Xcode installation
'b'Customize Python build configuration variables.

    Called internally from sysconfig with a mutable mapping
    containing name/value pairs parsed from the configured
    makefile used to build this interpreter.  Returns
    the mapping updated as needed to reflect the environment
    in which the interpreter is running; in the case of
    a Python from a binary installer, the installed
    environment may be very different from the build
    environment, i.e. different OS levels, different
    built tools, different available CPU architectures.

    This customization is performed whenever
    distutils.sysconfig.get_config_vars() is first
    called.  It may be used in environments where no
    compilers are present, i.e. when installing pure
    Python dists.  Customization of compiler paths
    and detection of unavailable archs is deferred
    until the first extension module build is
    requested (in distutils.sysconfig.customize_compiler).

    Currently called from distutils.sysconfig
    'u'Customize Python build configuration variables.

    Called internally from sysconfig with a mutable mapping
    containing name/value pairs parsed from the configured
    makefile used to build this interpreter.  Returns
    the mapping updated as needed to reflect the environment
    in which the interpreter is running; in the case of
    a Python from a binary installer, the installed
    environment may be very different from the build
    environment, i.e. different OS levels, different
    built tools, different available CPU architectures.

    This customization is performed whenever
    distutils.sysconfig.get_config_vars() is first
    called.  It may be used in environments where no
    compilers are present, i.e. when installing pure
    Python dists.  Customization of compiler paths
    and detection of unavailable archs is deferred
    until the first extension module build is
    requested (in distutils.sysconfig.customize_compiler).

    Currently called from distutils.sysconfig
    'b'Customize compiler path and configuration variables.

    This customization is performed when the first
    extension module build is requested
    in distutils.sysconfig.customize_compiler.
    'u'Customize compiler path and configuration variables.

    This customization is performed when the first
    extension module build is requested
    in distutils.sysconfig.customize_compiler.
    'b'Filter values for get_platform()'u'Filter values for get_platform()'b'MACOSX_DEPLOYMENT_TARGET'u'MACOSX_DEPLOYMENT_TARGET'b'macosx'u'macosx'b'fat'u'fat'b'-arch\s+(\S+)'u'-arch\s+(\S+)'b'x86_64'u'x86_64'b'universal2'u'universal2'b'i386'u'i386'b'ppc'u'ppc'b'intel'u'intel'b'fat3'u'fat3'b'ppc64'u'ppc64'b'fat64'u'fat64'b'universal'u'universal'b'Don't know machine value for archs=%r'u'Don't know machine value for archs=%r'b'PowerPC'u'PowerPC'b'Power_Macintosh'u'Power_Macintosh'u'_osx_support'Email address parsing code.

Lifted directly from rfc822.py.  This should eventually be rewritten.
mktime_tzparsedateparsedate_tzcalendarSPACEEMPTYSTRINGCOMMASPACEjanfebmaraprmayjunjulaugnovjanuaryfebruarymarchapriljunejulyaugustseptemberoctobernovemberdecember_monthnamesmontuewedthufrisatsun_daynamesUTGMTADTESTEDT600CSTCDT700MSTMDT800PSTPDT_timezonesConvert a date string to a time tuple.

    Accounts for military timezones.
    _parsedate_tzConvert date to extended time tuple.

    The last (additional) element is the time zone offset in seconds, except if
    the timezone was specified as -0000.  In that case the last element is
    None.  This indicates a UTC timestamp that explicitly declaims knowledge of
    the source timezone, as opposed to a +0000 timestamp that indicates the
    source timezone really was UTC.

    stuffddmmyytmthhtmmtss6819002000tzsign360060Convert a time string to a time tuple.Turn a 10-tuple as returned by parsedate_tz() into a POSIX timestamp.mktimetimegmPrepare string to be used in a quoted string.

    Turns backslash and double quote characters into quoted pairs.  These
    are the only characters that need to be quoted inside a quoted string.
    Does not add the surrounding double quotes.
    AddrlistClassAddress parser class by Ben Escoto.

    To understand what this class does, it helps to have a copy of RFC 2822 in
    front of you.

    Note: this class interface is deprecated and may be removed in the future.
    Use email.utils.AddressList instead.
    Initialize a new instance.

        `field' is an unparsed address header field, containing
        one or more addresses.
        ()<>@,:;."[]specialsLWSCRFWSatomendsphraseendscommentlistgotonextSkip white space and extract comments.wslist
getcommentgetaddrlistParse all addresses.

        Returns a list containing all of the addresses.
        getaddressadParse the next address.oldposoldclgetphraselistplistreturnlist.@getaddrspecaddrspecfieldlengetrouteaddrrouteaddrParse a route address (Return-path value).

        This method just skips all the route stuff and returns the addrspec.
        expectrouteadlistgetdomainParse an RFC 2822 addr-spec.aslistpreserve_ws"%s"getquotegetatomGet the complete domain name from an address.sdlistgetdomainliteralgetdelimitedbegincharallowcommentsParse a header fragment delimited by special characters.

        `beginchar' is the start character for the fragment.
        If self is not looking at an instance of `beginchar' then
        getdelimited returns the empty string.

        `endchars' is a sequence of allowable end-delimiting characters.
        Parsing stops when one of these is encountered.

        If `allowcomments' is non-zero, embedded RFC 2822 comments are allowed
        within the parsed fragment.
        slistGet a quote-delimited fragment from self's field."Get a parenthesis-delimited fragment from self's field.)Parse an RFC 2822 domain-literal.]Parse an RFC 2822 atom.

        Optional atomends specifies a different set of end token delimiters
        (the default is to use self.atomends).  This is used e.g. in
        getphraselist() since phrase endings must not include the `.' (which
        is legal in phrases).atomlistParse a sequence of RFC 2822 phrases.

        A phrase is a sequence of words, which are in turn either RFC 2822
        atoms or quoted-strings.  Phrases are canonicalized by squeezing all
        runs of continuous whitespace into one space.
        An AddressList encapsulates a list of parsed RFC 2822 addresses.addresslistnewaddr# Copyright (C) 2002-2007 Python Software Foundation# Parse a date field# The timezone table does not include the military time zones defined# in RFC822, other than Z.  According to RFC1123, the description in# RFC822 gets the signs wrong, so we can't rely on any such time# zones.  RFC1123 recommends that numeric timezone indicators be used# instead of timezone names.# Atlantic (used in Canada)# Eastern# Central# Mountain# Pacific# This happens for whitespace-only input.# The FWS after the comma after the day-of-week is optional, so search and# adjust for this.# There's a dayname here. Skip it# RFC 850 date, deprecated# Dummy tz# Some non-compliant MUAs use '.' to separate time elements.# Check for a yy specified in two-digit format, then convert it to the# appropriate four-digit format, according to the POSIX standard. RFC 822# calls for a two-digit yy, but RFC 2822 (which obsoletes RFC 822)# mandates a 4-digit yy. For more information, see the documentation for# the time module.# The year is between 1969 and 1999 (inclusive).# The year is between 2000 and 2068 (inclusive).# Convert a timezone offset into seconds ; -0500 -> -18000# Daylight Saving Time flag is set to -1, since DST is unknown.# No zone info, so localtime is better assumption than GMT# Note that RFC 2822 now specifies `.' as obs-phrase, meaning that it# is obsolete syntax.  RFC 2822 requires that we recognize obsolete# syntax, so allow dots in phrases.# Bad email address technically, no domain.# email address is just an addrspec# this isn't very efficient since we start over# address is a group# Address is a phrase then a route addr# Invalid domain, return an empty address instead of returning a# local part to denote failed parsing.# bpo-34155: Don't parse domains with two `@` like# `a@malicious.org@important.com`.# have already advanced pos from getcomment# Set union# Set union, in-place# Set difference# Set difference, in-place# Make indexing, slices, and 'in' workb'Email address parsing code.

Lifted directly from rfc822.py.  This should eventually be rewritten.
'u'Email address parsing code.

Lifted directly from rfc822.py.  This should eventually be rewritten.
'b'mktime_tz'u'mktime_tz'b'parsedate'u'parsedate'b'parsedate_tz'u'parsedate_tz'b'jan'u'jan'b'feb'u'feb'b'mar'u'mar'b'apr'u'apr'b'may'u'may'b'jun'u'jun'b'jul'u'jul'b'aug'u'aug'b'sep'u'sep'b'oct'u'oct'b'nov'u'nov'b'dec'u'dec'b'january'u'january'b'february'u'february'b'march'u'march'b'april'u'april'b'june'u'june'b'july'u'july'b'august'u'august'b'september'u'september'b'october'u'october'b'november'u'november'b'december'u'december'b'mon'u'mon'b'tue'u'tue'b'wed'u'wed'b'thu'u'thu'b'fri'u'fri'b'sat'u'sat'b'sun'u'sun'b'UT'u'UT'b'GMT'u'GMT'b'AST'u'AST'b'ADT'u'ADT'b'EST'u'EST'b'EDT'u'EDT'b'CST'u'CST'b'CDT'u'CDT'b'MST'u'MST'b'MDT'u'MDT'b'PST'u'PST'b'PDT'u'PDT'b'Convert a date string to a time tuple.

    Accounts for military timezones.
    'u'Convert a date string to a time tuple.

    Accounts for military timezones.
    'b'Convert date to extended time tuple.

    The last (additional) element is the time zone offset in seconds, except if
    the timezone was specified as -0000.  In that case the last element is
    None.  This indicates a UTC timestamp that explicitly declaims knowledge of
    the source timezone, as opposed to a +0000 timestamp that indicates the
    source timezone really was UTC.

    'u'Convert date to extended time tuple.

    The last (additional) element is the time zone offset in seconds, except if
    the timezone was specified as -0000.  In that case the last element is
    None.  This indicates a UTC timestamp that explicitly declaims knowledge of
    the source timezone, as opposed to a +0000 timestamp that indicates the
    source timezone really was UTC.

    'b'Convert a time string to a time tuple.'u'Convert a time string to a time tuple.'b'Turn a 10-tuple as returned by parsedate_tz() into a POSIX timestamp.'u'Turn a 10-tuple as returned by parsedate_tz() into a POSIX timestamp.'b'Prepare string to be used in a quoted string.

    Turns backslash and double quote characters into quoted pairs.  These
    are the only characters that need to be quoted inside a quoted string.
    Does not add the surrounding double quotes.
    'u'Prepare string to be used in a quoted string.

    Turns backslash and double quote characters into quoted pairs.  These
    are the only characters that need to be quoted inside a quoted string.
    Does not add the surrounding double quotes.
    'b'Address parser class by Ben Escoto.

    To understand what this class does, it helps to have a copy of RFC 2822 in
    front of you.

    Note: this class interface is deprecated and may be removed in the future.
    Use email.utils.AddressList instead.
    'u'Address parser class by Ben Escoto.

    To understand what this class does, it helps to have a copy of RFC 2822 in
    front of you.

    Note: this class interface is deprecated and may be removed in the future.
    Use email.utils.AddressList instead.
    'b'Initialize a new instance.

        `field' is an unparsed address header field, containing
        one or more addresses.
        'u'Initialize a new instance.

        `field' is an unparsed address header field, containing
        one or more addresses.
        'b'()<>@,:;."[]'u'()<>@,:;."[]'u'
'b'Skip white space and extract comments.'u'Skip white space and extract comments.'b'
'u'
'b'Parse all addresses.

        Returns a list containing all of the addresses.
        'u'Parse all addresses.

        Returns a list containing all of the addresses.
        'b'Parse the next address.'u'Parse the next address.'b'.@'u'.@'b'Parse a route address (Return-path value).

        This method just skips all the route stuff and returns the addrspec.
        'u'Parse a route address (Return-path value).

        This method just skips all the route stuff and returns the addrspec.
        'b'Parse an RFC 2822 addr-spec.'u'Parse an RFC 2822 addr-spec.'b'"%s"'u'"%s"'b'Get the complete domain name from an address.'u'Get the complete domain name from an address.'b'Parse a header fragment delimited by special characters.

        `beginchar' is the start character for the fragment.
        If self is not looking at an instance of `beginchar' then
        getdelimited returns the empty string.

        `endchars' is a sequence of allowable end-delimiting characters.
        Parsing stops when one of these is encountered.

        If `allowcomments' is non-zero, embedded RFC 2822 comments are allowed
        within the parsed fragment.
        'u'Parse a header fragment delimited by special characters.

        `beginchar' is the start character for the fragment.
        If self is not looking at an instance of `beginchar' then
        getdelimited returns the empty string.

        `endchars' is a sequence of allowable end-delimiting characters.
        Parsing stops when one of these is encountered.

        If `allowcomments' is non-zero, embedded RFC 2822 comments are allowed
        within the parsed fragment.
        'b'Get a quote-delimited fragment from self's field.'u'Get a quote-delimited fragment from self's field.'b'"'u'"'b'Get a parenthesis-delimited fragment from self's field.'u'Get a parenthesis-delimited fragment from self's field.'b')'u')'b'Parse an RFC 2822 domain-literal.'u'Parse an RFC 2822 domain-literal.'b']'u']'b'Parse an RFC 2822 atom.

        Optional atomends specifies a different set of end token delimiters
        (the default is to use self.atomends).  This is used e.g. in
        getphraselist() since phrase endings must not include the `.' (which
        is legal in phrases).'u'Parse an RFC 2822 atom.

        Optional atomends specifies a different set of end token delimiters
        (the default is to use self.atomends).  This is used e.g. in
        getphraselist() since phrase endings must not include the `.' (which
        is legal in phrases).'b'Parse a sequence of RFC 2822 phrases.

        A phrase is a sequence of words, which are in turn either RFC 2822
        atoms or quoted-strings.  Phrases are canonicalized by squeezing all
        runs of continuous whitespace into one space.
        'u'Parse a sequence of RFC 2822 phrases.

        A phrase is a sequence of words, which are in turn either RFC 2822
        atoms or quoted-strings.  Phrases are canonicalized by squeezing all
        runs of continuous whitespace into one space.
        'b'An AddressList encapsulates a list of parsed RFC 2822 addresses.'u'An AddressList encapsulates a list of parsed RFC 2822 addresses.'u'email._parseaddr'u'_parseaddr'
This module offers a generic date/time string parser which is able to parse
most known formats to represent a date and/or time.

This module attempts to be forgiving with regards to unlikely input formats,
returning a datetime object even for dates which are ambiguous. If an element
of a date/time stamp is omitted, the following rules are applied:

- If AM or PM is left unspecified, a 24-hour clock is assumed, however, an hour
  on a 12-hour clock (``0 <= hour <= 12``) *must* be specified if AM or PM is
  specified.
- If a time zone is omitted, a timezone-naive datetime is returned.

If any other elements are missing, they are taken from the
:class:`datetime.datetime` object passed to the parameter ``default``. If this
results in a day number exceeding the valid number of days per month, the
value falls back to the end of the month.

Additional resources about date/time string formats can be found below:

- `A summary of the international standard date and time notation
  <https://www.cl.cam.ac.uk/~mgk25/iso-time.html>`_
- `W3C Date and Time Formats <https://www.w3.org/TR/NOTE-datetime>`_
- `Time Formats (Planetary Rings Node) <https://pds-rings.seti.org:443/tools/time_formats.html>`_
- `CPAN ParseDate module
  <https://metacpan.org/pod/release/MUIR/Time-modules-2013.0912/lib/Time/ParseDate.pm>`_
- `Java SimpleDateFormat Class
  <https://docs.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html>`_
monthrange([.,])_split_decimalinstreamParser must be a string or character stream, not {itype}'Parser must be a string or character stream, not ''{itype}'itypecharstacktokenstack
        This function breaks the time string into lexical units (tokens), which
        can be parsed by the parser. Lexical units are demarcated by changes in
        the character set, so any continuous string of letters is considered
        one unit, any continuous string of numbers is considered one unit.

        The main complication arises from the fact that dots ('.') can be used
        both as separators (e.g. "Sep.20.2009") or decimal points (e.g.
        "4:30:21.447"). As such, it is necessary to read the full context of
        any dot-separated strings before breaking it into tokens; as such, this
        function maintains a "token stack", for when the ambiguous context
        demands that multiple tokens be parsed at once.
        seenlettersnextchar iswordisnuma.0.., Whether or not the next character is part of a word  Whether the next character is part of a number  Whether the next character is whitespace _reprclassname%s=%s
    Class which handles what inputs are accepted. Subclass this to customize
    the language and acceptable values for each parameter.

    :param dayfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
        ``yearfirst`` is set to ``True``, this distinguishes between YDM
        and YMD. Default is ``False``.

    :param yearfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the year. If ``True``, the first number is taken
        to be the year, otherwise the last number is taken to be the year.
        Default is ``False``.
    atandofndrdthJUMPMonMondayTueTuesdayWedWednesdayThuThursdayFriFridaySatSaturdaySunSundayWEEKDAYSJanJanuaryFebFebruaryMarMarchAprAprilMayJunJuneJulJulyAugAugustSepSeptSeptemberOctOctoberNovNovemberDecDecemberMONTHShoursminutesHMSampmAMPMUTCZONEPERTAINTZOFFSETdayfirstyearfirst_convert_jump_weekdays_months_hms_ampm_utczone_pertaintm_year_year_centurydctjumphmsampmpertainutczoneconvertyearcentury_specified
        Converts two-digit years to year within [-50, 49]
        range of self._year (current local time)
        _ymddstridxmstridxystridxhas_yearhas_monthhas_daycould_be_dayMMonth is already setDay is already setYear is already set_resolve_from_stridxsstrids
        Try to resolve the identities of year/month/day elements using
        ystridx, mstridx, and dstridx, if enough of these are specified.
        missingresolve_ymdlen_ymdMore than three YMD valuestimestrignoretztzinfos
        Parse the date/time string into a :class:`datetime.datetime` object.

        :param timestr:
            Any date/time string using the supported formats.

        :param default:
            The default datetime object, if this is a datetime object and not
            ``None``, elements specified in ``timestr`` replace elements in the
            default object.

        :param ignoretz:
            If set ``True``, time zones in parsed strings are ignored and a
            naive :class:`datetime.datetime` object is returned.

        :param tzinfos:
            Additional time zone names / aliases which may be present in the
            string. This argument maps time zone names (and optionally offsets
            from those time zones) to time zones. This parameter can be a
            dictionary with timezone aliases mapping time zone names to time
            zones or a function taking two parameters (``tzname`` and
            ``tzoffset``) and returning a time zone.

            The timezones to which the names are mapped can be an integer
            offset from UTC in seconds or a :class:`tzinfo` object.

            .. doctest::
               :options: +NORMALIZE_WHITESPACE

                >>> from dateutil.parser import parse
                >>> from dateutil.tz import gettz
                >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
                >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
                datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
                >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
                datetime.datetime(2012, 1, 19, 17, 21,
                                  tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))

            This parameter is ignored if ``ignoretz`` is set.

        :param \*\*kwargs:
            Keyword arguments as passed to ``_parse()``.

        :return:
            Returns a :class:`datetime.datetime` object or, if the
            ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
            first element being a :class:`datetime.datetime` object, the second
            a tuple containing the fuzzy tokens.

        :raises ParserError:
            Raised for invalid or unknown string format, if the provided
            :class:`tzinfo` is not in a valid format, or if an invalid date
            would be created.

        :raises TypeError:
            Raised for non-string or character stream input.

        :raises OverflowError:
            Raised if the parsed date exceeds the largest valid C integer on
            your system.
        _parseskipped_tokensUnknown string format: %sString does not contain a date: %s_build_naiveretraise_from: %s_build_tzawarefuzzy_with_tokensany_unused_tokensfuzzy
        Private method which performs the heavy lifting of parsing, called from
        ``parse()``, which passes on its ``kwargs`` to this function.

        :param timestr:
            The string to parse.

        :param dayfirst:
            Whether to interpret the first value in an ambiguous 3-integer date
            (e.g. 01/05/09) as the day (``True``) or month (``False``). If
            ``yearfirst`` is set to ``True``, this distinguishes between YDM
            and YMD. If set to ``None``, this value is retrieved from the
            current :class:`parserinfo` object (which itself defaults to
            ``False``).

        :param yearfirst:
            Whether to interpret the first value in an ambiguous 3-integer date
            (e.g. 01/05/09) as the year. If ``True``, the first number is taken
            to be the year, otherwise the last number is taken to be the year.
            If this is set to ``None``, the value is retrieved from the current
            :class:`parserinfo` object (which itself defaults to ``False``).

        :param fuzzy:
            Whether to allow fuzzy parsing, allowing for string like "Today is
            January 1, 2047 at 8:21:00AM".

        :param fuzzy_with_tokens:
            If ``True``, ``fuzzy`` is automatically set to True, and the parser
            will return a tuple where the first element is the parsed
            :class:`datetime.datetime` datetimestamp and the second element is
            a tuple containing the portions of the string which were ignored:

            .. doctest::

                >>> from dateutil.parser import parse
                >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
                (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))

        skipped_idxsymdlen_lvalue_repr_parse_numeric_token_ampm_validval_is_ampm_adjust_ampm_could_be_tznamelen_lihour_offsetmin_offset_recombine_skipped_to_decimalUnknown numeric token_parsems_find_hms_idxallow_jumphms_idx_parse_hms_assign_hms_parse_min_secascii_uppercase
        For fuzzy parsing, 'a' or 'am' (both valid English words)
        may erroneously trigger the AM/PM flag. Deal with that
        here.
        No hour specified with AM or PM flag.Invalid hour specified for 12-hour clock.sec_remaindernew_idxParse a I[.F] seconds value into (seconds, microseconds).decimal_valueConverted decimal value is infinite or NaNCould not convert %s to decimal_build_tzinfotzdataOffset must be tzinfo subclass, tz string, or int offset."Offset must be tzinfo subclass, tz string, ""or int offset."naiveaware_assign_tznametzname {tzname} identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception."tzname {tzname} identified but not understood.  ""Pass `tzinfos` argument in order to correctly ""return a timezone-aware datetime.  In a future ""version, this will raise an ""exception."replcyearcmonthcdaynew_dt
        >>> tokens = ["foo", " ", "bar", " ", "19June2000", "baz"]
        >>> skipped_idxs = [0, 1, 2, 5]
        >>> _recombine_skipped(tokens, skipped_idxs)
        ["foo bar", "baz"]
        

    Parse a string in one of the supported formats, using the
    ``parserinfo`` parameters.

    :param timestr:
        A string containing a date/time stamp.

    :param parserinfo:
        A :class:`parserinfo` object containing parameters for the parser.
        If ``None``, the default arguments to the :class:`parserinfo`
        constructor are used.

    The ``**kwargs`` parameter takes the following keyword arguments:

    :param default:
        The default datetime object, if this is a datetime object and not
        ``None``, elements specified in ``timestr`` replace elements in the
        default object.

    :param ignoretz:
        If set ``True``, time zones in parsed strings are ignored and a naive
        :class:`datetime` object is returned.

    :param tzinfos:
        Additional time zone names / aliases which may be present in the
        string. This argument maps time zone names (and optionally offsets
        from those time zones) to time zones. This parameter can be a
        dictionary with timezone aliases mapping time zone names to time
        zones or a function taking two parameters (``tzname`` and
        ``tzoffset``) and returning a time zone.

        The timezones to which the names are mapped can be an integer
        offset from UTC in seconds or a :class:`tzinfo` object.

        .. doctest::
           :options: +NORMALIZE_WHITESPACE

            >>> from dateutil.parser import parse
            >>> from dateutil.tz import gettz
            >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
            >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
            datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
            >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
            datetime.datetime(2012, 1, 19, 17, 21,
                              tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))

        This parameter is ignored if ``ignoretz`` is set.

    :param dayfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
        ``yearfirst`` is set to ``True``, this distinguishes between YDM and
        YMD. If set to ``None``, this value is retrieved from the current
        :class:`parserinfo` object (which itself defaults to ``False``).

    :param yearfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the year. If ``True``, the first number is taken to
        be the year, otherwise the last number is taken to be the year. If
        this is set to ``None``, the value is retrieved from the current
        :class:`parserinfo` object (which itself defaults to ``False``).

    :param fuzzy:
        Whether to allow fuzzy parsing, allowing for string like "Today is
        January 1, 2047 at 8:21:00AM".

    :param fuzzy_with_tokens:
        If ``True``, ``fuzzy`` is automatically set to True, and the parser
        will return a tuple where the first element is the parsed
        :class:`datetime.datetime` datetimestamp and the second element is
        a tuple containing the portions of the string which were ignored:

        .. doctest::

            >>> from dateutil.parser import parse
            >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
            (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))

    :return:
        Returns a :class:`datetime.datetime` object or, if the
        ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
        first element being a :class:`datetime.datetime` object, the second
        a tuple containing the fuzzy tokens.

    :raises ParserError:
        Raised for invalid or unknown string formats, if the provided
        :class:`tzinfo` is not in a valid format, or if an invalid date would
        be created.

    :raises OverflowError:
        Raised if the parsed date exceeds the largest valid C integer on
        your system.
    stdabbrstdoffsetdstabbrdstoffset_attrweekydayjyday([,:.]|[a-zA-Z]+|[0-9]+)used_idxs0123456789:,-+offattrii01234567890123456789+-Parsed time zone "%s"is in a non-standard dateutil-specific format, which is now deprecated; support for parsing this format will be removed in future versions. It is recommended that you switch to a standard format like the GNU TZ variable format.Junused_idxsException subclass used for any failure to parse a datetime string.

    This is a subclass of :py:exc:`ValueError`, and should be raised any time
    earlier versions of ``dateutil`` would have raised ``ValueError``.

    .. versionadded:: 2.8.1
    '%s'Raised when the parser finds a timezone it cannot parse into a tzinfo.

    .. versionadded:: 2.7.0
    # TODO: pandas.core.tools.datetimes imports this explicitly.  Might be worth# making public and/or figuring out if there is something we can# take off their plate.# Fractional seconds are sometimes split by a comma# We only realize that we've reached the end of a token when we# find a character that's not part of the current token - since# that character may be part of the next token, it's stored in the# charstack.# First character of the token - determines if we're starting# to parse a word, a number or something else.# emit token# If we've already started reading a word, we keep reading# letters until we find something that's not part of a word.# If we've already started reading a number, we keep reading# numbers until we find something that doesn't fit.# If we've seen some letters and a dot separator, continue# parsing, and the tokens will be broken up later.# If we've seen at least one dot separator, keep going, we'll# break up the tokens later.# Python 2.x support# m from a.m/p.m, t from ISO T separator# TODO: "Tues"# TODO: "Thurs"# TODO: "Febr"# TODO: ERA = ["AD", "BC", "CE", "BCE", "Stardate",#              "Anno Domini", "Year of Our Lord"]# Function contract is that the year is always positive# assume current century to start# if too far in future# if too far in past# move to info# Be permissive, assume leap year# we can back out the remaining stridx value# otherwise this should not be called# One member, or two members with a month string# since mstridx is 0 or 1, self[mstridx-1] always# looks up the other element# Two members with numbers# 99-01# 01-99# 13-01# 01-13# Three members# Apr-2003-25# 99-Jan-01# 01-Jan-01# Give precedence to day-first, since# two-digit years is usually hand-written.# WTF!?# 01-99-Jan# 99-01-Jan# 99-01-01# 13-01-01# 01-13-01# Splits the timestr into tokens# year/month/day list# Check if it's a number# Numeric token# Check weekday# Check month name# Jan-01[-99]# Jan-01-99# Jan of 01# In this case, 01 is clearly year# Convert it here to become unambiguous# Wrong guess# TODO: not hit in tests# Check am/pm# Check for a timezone name# Check for something like GMT+3, or BRST+3. Notice# that it doesn't mean "I am 3 hours after GMT", but# "my time +3 is GMT". If found, we reverse the# logic so that timezone parsing code will get it# right.# With something like GMT+3, the timezone# is *not* GMT.# Check for a numbered timezone# TODO: check that l[i + 1] is integer?# -0300# -03:00# TODO: Check that l[i+3] is minute-like?# -[0]3# Look for a timezone name between parenthesis# -0300 (BRST)# Check jumps# Process year/month/day# Token is a number# 19990101T23[59]# YYMMDD or HHMMSS[.ss]# 19990101T235959[.59]# TODO: Check if res attributes already set.# YYYYMMDD# HH[ ]h or MM[ ]m or SS[.ss][ ]s# TODO: checking that hour/minute/second are not# already set?# HH:MM[:SS[.ss]]# TODO: try/except for this?# 01-01[-01]# 01-Jan[-01]# We have three members# 12 am# Year, month or day# 12am# There is an "h", "m", or "s" label following this token.  We take# assign the upcoming label to the current token.# e.g. the "12" in 12h"# There is a space and then an "h", "m", or "s" label.# e.g. the "12" in "12 h"# There is a "h", "m", or "s" preceding this token.  Since neither# of the previous cases was hit, there is no label following this# token, so we use the previous label.# e.g. the "04" in "12h04"# If we are looking at the final token, we allow for a# backward-looking check to skip over a space.# TODO: Are we sure this is the right condition here?# See GH issue #427, fixing float rounding# Hour# If there's already an AM/PM flag, this one isn't one.# If AM/PM is found and hour is not, raise a ValueError# If AM/PM is found, it's a 12 hour clock, so raise# an error for invalid range# TODO: Every usage of this function sets res.second to the return# value. Are there any cases where second will be returned as None and# we *don't* want to set res.second = None?# TODO: Is this going to admit a lot of false-positives for when we# just happen to have digits and "h", "m" or "s" characters in non-date# text?  I guess hex hashes won't have that problem, but there's plenty# of random junk out there.# Looking backwards, increment one.# ------------------------------------------------------------------# Handling for individual tokens.  These are kept as methods instead#  of functions for the sake of customizability via subclassing.# See GH 662, edge case, infinite value should not be converted#  via `_to_decimal`# Post-Parsing construction of datetime output.  These are kept as#  methods instead of functions for the sake of customizability via#  subclassing.# handle case where tzinfo is paased an options that returns None# eg tzinfos = {'BRST' : None}# Handle ambiguous local datetime# This is mostly relevant for winter GMT zones parsed in the UK# i.e. no timezone information was found.# tz-like string was parsed but we don't know what to do# with it# If the default day exceeds the last day of the month, fall back# to the end of the month.# BRST+3[BRDT[+2]]# Yes, that's right.  See the TZ variable# documentation.# GMT0BST,3,0,30,3600,10,0,26,7200[,3600]# This was a made-up format that is not in normal use# non-leap year day (1 based)# month[-.]week[-.]weekday# year day (zero based)# start timeb'
This module offers a generic date/time string parser which is able to parse
most known formats to represent a date and/or time.

This module attempts to be forgiving with regards to unlikely input formats,
returning a datetime object even for dates which are ambiguous. If an element
of a date/time stamp is omitted, the following rules are applied:

- If AM or PM is left unspecified, a 24-hour clock is assumed, however, an hour
  on a 12-hour clock (``0 <= hour <= 12``) *must* be specified if AM or PM is
  specified.
- If a time zone is omitted, a timezone-naive datetime is returned.

If any other elements are missing, they are taken from the
:class:`datetime.datetime` object passed to the parameter ``default``. If this
results in a day number exceeding the valid number of days per month, the
value falls back to the end of the month.

Additional resources about date/time string formats can be found below:

- `A summary of the international standard date and time notation
  <https://www.cl.cam.ac.uk/~mgk25/iso-time.html>`_
- `W3C Date and Time Formats <https://www.w3.org/TR/NOTE-datetime>`_
- `Time Formats (Planetary Rings Node) <https://pds-rings.seti.org:443/tools/time_formats.html>`_
- `CPAN ParseDate module
  <https://metacpan.org/pod/release/MUIR/Time-modules-2013.0912/lib/Time/ParseDate.pm>`_
- `Java SimpleDateFormat Class
  <https://docs.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html>`_
'u'
This module offers a generic date/time string parser which is able to parse
most known formats to represent a date and/or time.

This module attempts to be forgiving with regards to unlikely input formats,
returning a datetime object even for dates which are ambiguous. If an element
of a date/time stamp is omitted, the following rules are applied:

- If AM or PM is left unspecified, a 24-hour clock is assumed, however, an hour
  on a 12-hour clock (``0 <= hour <= 12``) *must* be specified if AM or PM is
  specified.
- If a time zone is omitted, a timezone-naive datetime is returned.

If any other elements are missing, they are taken from the
:class:`datetime.datetime` object passed to the parameter ``default``. If this
results in a day number exceeding the valid number of days per month, the
value falls back to the end of the month.

Additional resources about date/time string formats can be found below:

- `A summary of the international standard date and time notation
  <https://www.cl.cam.ac.uk/~mgk25/iso-time.html>`_
- `W3C Date and Time Formats <https://www.w3.org/TR/NOTE-datetime>`_
- `Time Formats (Planetary Rings Node) <https://pds-rings.seti.org:443/tools/time_formats.html>`_
- `CPAN ParseDate module
  <https://metacpan.org/pod/release/MUIR/Time-modules-2013.0912/lib/Time/ParseDate.pm>`_
- `Java SimpleDateFormat Class
  <https://docs.oracle.com/javase/6/docs/api/java/text/SimpleDateFormat.html>`_
'b'([.,])'u'([.,])'b'Parser must be a string or character stream, not {itype}'u'Parser must be a string or character stream, not {itype}'b'
        This function breaks the time string into lexical units (tokens), which
        can be parsed by the parser. Lexical units are demarcated by changes in
        the character set, so any continuous string of letters is considered
        one unit, any continuous string of numbers is considered one unit.

        The main complication arises from the fact that dots ('.') can be used
        both as separators (e.g. "Sep.20.2009") or decimal points (e.g.
        "4:30:21.447"). As such, it is necessary to read the full context of
        any dot-separated strings before breaking it into tokens; as such, this
        function maintains a "token stack", for when the ambiguous context
        demands that multiple tokens be parsed at once.
        'u'
        This function breaks the time string into lexical units (tokens), which
        can be parsed by the parser. Lexical units are demarcated by changes in
        the character set, so any continuous string of letters is considered
        one unit, any continuous string of numbers is considered one unit.

        The main complication arises from the fact that dots ('.') can be used
        both as separators (e.g. "Sep.20.2009") or decimal points (e.g.
        "4:30:21.447"). As such, it is necessary to read the full context of
        any dot-separated strings before breaking it into tokens; as such, this
        function maintains a "token stack", for when the ambiguous context
        demands that multiple tokens be parsed at once.
        'b' 'u' 'b'a.'u'a.'b'0.'u'0.'b'.,'u'.,'b' Whether or not the next character is part of a word 'u' Whether or not the next character is part of a word 'b' Whether the next character is part of a number 'u' Whether the next character is part of a number 'b' Whether the next character is whitespace 'u' Whether the next character is whitespace 'b'%s=%s'u'%s=%s'b'
    Class which handles what inputs are accepted. Subclass this to customize
    the language and acceptable values for each parameter.

    :param dayfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
        ``yearfirst`` is set to ``True``, this distinguishes between YDM
        and YMD. Default is ``False``.

    :param yearfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the year. If ``True``, the first number is taken
        to be the year, otherwise the last number is taken to be the year.
        Default is ``False``.
    'u'
    Class which handles what inputs are accepted. Subclass this to customize
    the language and acceptable values for each parameter.

    :param dayfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
        ``yearfirst`` is set to ``True``, this distinguishes between YDM
        and YMD. Default is ``False``.

    :param yearfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the year. If ``True``, the first number is taken
        to be the year, otherwise the last number is taken to be the year.
        Default is ``False``.
    'b'at'u'at'b'and'u'and'b'ad'u'ad'b'of'u'of'b'st'u'st'b'nd'u'nd'b'rd'u'rd'b'th'u'th'b'Mon'u'Mon'b'Monday'u'Monday'b'Tue'u'Tue'b'Tuesday'u'Tuesday'b'Wed'u'Wed'b'Wednesday'u'Wednesday'b'Thu'u'Thu'b'Thursday'u'Thursday'b'Fri'u'Fri'b'Friday'u'Friday'b'Sat'u'Sat'b'Saturday'u'Saturday'b'Sun'u'Sun'b'Sunday'u'Sunday'b'Jan'u'Jan'b'January'u'January'b'Feb'u'Feb'b'February'u'February'b'Mar'u'Mar'b'March'u'March'b'Apr'u'Apr'b'April'u'April'b'May'u'May'b'Jun'u'Jun'b'June'u'June'b'Jul'u'Jul'b'July'u'July'b'Aug'u'Aug'b'August'u'August'b'Sep'u'Sep'b'Sept'u'Sept'b'September'u'September'b'Oct'u'Oct'b'October'u'October'b'Nov'u'Nov'b'November'u'November'b'Dec'u'Dec'b'December'u'December'b'hours'u'hours'b'minutes'u'minutes'b'seconds'u'seconds'b'am'u'am'b'pm'u'pm'b'
        Converts two-digit years to year within [-50, 49]
        range of self._year (current local time)
        'u'
        Converts two-digit years to year within [-50, 49]
        range of self._year (current local time)
        'b'Y'u'Y'b'M'u'M'b'Month is already set'u'Month is already set'b'D'u'D'b'Day is already set'u'Day is already set'b'Year is already set'u'Year is already set'b'
        Try to resolve the identities of year/month/day elements using
        ystridx, mstridx, and dstridx, if enough of these are specified.
        'u'
        Try to resolve the identities of year/month/day elements using
        ystridx, mstridx, and dstridx, if enough of these are specified.
        'b'More than three YMD values'u'More than three YMD values'b'
        Parse the date/time string into a :class:`datetime.datetime` object.

        :param timestr:
            Any date/time string using the supported formats.

        :param default:
            The default datetime object, if this is a datetime object and not
            ``None``, elements specified in ``timestr`` replace elements in the
            default object.

        :param ignoretz:
            If set ``True``, time zones in parsed strings are ignored and a
            naive :class:`datetime.datetime` object is returned.

        :param tzinfos:
            Additional time zone names / aliases which may be present in the
            string. This argument maps time zone names (and optionally offsets
            from those time zones) to time zones. This parameter can be a
            dictionary with timezone aliases mapping time zone names to time
            zones or a function taking two parameters (``tzname`` and
            ``tzoffset``) and returning a time zone.

            The timezones to which the names are mapped can be an integer
            offset from UTC in seconds or a :class:`tzinfo` object.

            .. doctest::
               :options: +NORMALIZE_WHITESPACE

                >>> from dateutil.parser import parse
                >>> from dateutil.tz import gettz
                >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
                >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
                datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
                >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
                datetime.datetime(2012, 1, 19, 17, 21,
                                  tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))

            This parameter is ignored if ``ignoretz`` is set.

        :param \*\*kwargs:
            Keyword arguments as passed to ``_parse()``.

        :return:
            Returns a :class:`datetime.datetime` object or, if the
            ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
            first element being a :class:`datetime.datetime` object, the second
            a tuple containing the fuzzy tokens.

        :raises ParserError:
            Raised for invalid or unknown string format, if the provided
            :class:`tzinfo` is not in a valid format, or if an invalid date
            would be created.

        :raises TypeError:
            Raised for non-string or character stream input.

        :raises OverflowError:
            Raised if the parsed date exceeds the largest valid C integer on
            your system.
        'u'
        Parse the date/time string into a :class:`datetime.datetime` object.

        :param timestr:
            Any date/time string using the supported formats.

        :param default:
            The default datetime object, if this is a datetime object and not
            ``None``, elements specified in ``timestr`` replace elements in the
            default object.

        :param ignoretz:
            If set ``True``, time zones in parsed strings are ignored and a
            naive :class:`datetime.datetime` object is returned.

        :param tzinfos:
            Additional time zone names / aliases which may be present in the
            string. This argument maps time zone names (and optionally offsets
            from those time zones) to time zones. This parameter can be a
            dictionary with timezone aliases mapping time zone names to time
            zones or a function taking two parameters (``tzname`` and
            ``tzoffset``) and returning a time zone.

            The timezones to which the names are mapped can be an integer
            offset from UTC in seconds or a :class:`tzinfo` object.

            .. doctest::
               :options: +NORMALIZE_WHITESPACE

                >>> from dateutil.parser import parse
                >>> from dateutil.tz import gettz
                >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
                >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
                datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
                >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
                datetime.datetime(2012, 1, 19, 17, 21,
                                  tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))

            This parameter is ignored if ``ignoretz`` is set.

        :param \*\*kwargs:
            Keyword arguments as passed to ``_parse()``.

        :return:
            Returns a :class:`datetime.datetime` object or, if the
            ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
            first element being a :class:`datetime.datetime` object, the second
            a tuple containing the fuzzy tokens.

        :raises ParserError:
            Raised for invalid or unknown string format, if the provided
            :class:`tzinfo` is not in a valid format, or if an invalid date
            would be created.

        :raises TypeError:
            Raised for non-string or character stream input.

        :raises OverflowError:
            Raised if the parsed date exceeds the largest valid C integer on
            your system.
        'b'Unknown string format: %s'u'Unknown string format: %s'b'String does not contain a date: %s'u'String does not contain a date: %s'b': %s'u': %s'b'fuzzy_with_tokens'u'fuzzy_with_tokens'b'tzname'u'tzname'b'ampm'u'ampm'b'any_unused_tokens'u'any_unused_tokens'b'
        Private method which performs the heavy lifting of parsing, called from
        ``parse()``, which passes on its ``kwargs`` to this function.

        :param timestr:
            The string to parse.

        :param dayfirst:
            Whether to interpret the first value in an ambiguous 3-integer date
            (e.g. 01/05/09) as the day (``True``) or month (``False``). If
            ``yearfirst`` is set to ``True``, this distinguishes between YDM
            and YMD. If set to ``None``, this value is retrieved from the
            current :class:`parserinfo` object (which itself defaults to
            ``False``).

        :param yearfirst:
            Whether to interpret the first value in an ambiguous 3-integer date
            (e.g. 01/05/09) as the year. If ``True``, the first number is taken
            to be the year, otherwise the last number is taken to be the year.
            If this is set to ``None``, the value is retrieved from the current
            :class:`parserinfo` object (which itself defaults to ``False``).

        :param fuzzy:
            Whether to allow fuzzy parsing, allowing for string like "Today is
            January 1, 2047 at 8:21:00AM".

        :param fuzzy_with_tokens:
            If ``True``, ``fuzzy`` is automatically set to True, and the parser
            will return a tuple where the first element is the parsed
            :class:`datetime.datetime` datetimestamp and the second element is
            a tuple containing the portions of the string which were ignored:

            .. doctest::

                >>> from dateutil.parser import parse
                >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
                (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))

        'u'
        Private method which performs the heavy lifting of parsing, called from
        ``parse()``, which passes on its ``kwargs`` to this function.

        :param timestr:
            The string to parse.

        :param dayfirst:
            Whether to interpret the first value in an ambiguous 3-integer date
            (e.g. 01/05/09) as the day (``True``) or month (``False``). If
            ``yearfirst`` is set to ``True``, this distinguishes between YDM
            and YMD. If set to ``None``, this value is retrieved from the
            current :class:`parserinfo` object (which itself defaults to
            ``False``).

        :param yearfirst:
            Whether to interpret the first value in an ambiguous 3-integer date
            (e.g. 01/05/09) as the year. If ``True``, the first number is taken
            to be the year, otherwise the last number is taken to be the year.
            If this is set to ``None``, the value is retrieved from the current
            :class:`parserinfo` object (which itself defaults to ``False``).

        :param fuzzy:
            Whether to allow fuzzy parsing, allowing for string like "Today is
            January 1, 2047 at 8:21:00AM".

        :param fuzzy_with_tokens:
            If ``True``, ``fuzzy`` is automatically set to True, and the parser
            will return a tuple where the first element is the parsed
            :class:`datetime.datetime` datetimestamp and the second element is
            a tuple containing the portions of the string which were ignored:

            .. doctest::

                >>> from dateutil.parser import parse
                >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
                (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))

        'b'Unknown numeric token'u'Unknown numeric token'b'
        For fuzzy parsing, 'a' or 'am' (both valid English words)
        may erroneously trigger the AM/PM flag. Deal with that
        here.
        'u'
        For fuzzy parsing, 'a' or 'am' (both valid English words)
        may erroneously trigger the AM/PM flag. Deal with that
        here.
        'b'No hour specified with AM or PM flag.'u'No hour specified with AM or PM flag.'b'Invalid hour specified for 12-hour clock.'u'Invalid hour specified for 12-hour clock.'b'Parse a I[.F] seconds value into (seconds, microseconds).'u'Parse a I[.F] seconds value into (seconds, microseconds).'b'Converted decimal value is infinite or NaN'u'Converted decimal value is infinite or NaN'b'Could not convert %s to decimal'u'Could not convert %s to decimal'b'Offset must be tzinfo subclass, tz string, or int offset.'u'Offset must be tzinfo subclass, tz string, or int offset.'b'tzname {tzname} identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.'u'tzname {tzname} identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.'b'
        >>> tokens = ["foo", " ", "bar", " ", "19June2000", "baz"]
        >>> skipped_idxs = [0, 1, 2, 5]
        >>> _recombine_skipped(tokens, skipped_idxs)
        ["foo bar", "baz"]
        'u'
        >>> tokens = ["foo", " ", "bar", " ", "19June2000", "baz"]
        >>> skipped_idxs = [0, 1, 2, 5]
        >>> _recombine_skipped(tokens, skipped_idxs)
        ["foo bar", "baz"]
        'b'

    Parse a string in one of the supported formats, using the
    ``parserinfo`` parameters.

    :param timestr:
        A string containing a date/time stamp.

    :param parserinfo:
        A :class:`parserinfo` object containing parameters for the parser.
        If ``None``, the default arguments to the :class:`parserinfo`
        constructor are used.

    The ``**kwargs`` parameter takes the following keyword arguments:

    :param default:
        The default datetime object, if this is a datetime object and not
        ``None``, elements specified in ``timestr`` replace elements in the
        default object.

    :param ignoretz:
        If set ``True``, time zones in parsed strings are ignored and a naive
        :class:`datetime` object is returned.

    :param tzinfos:
        Additional time zone names / aliases which may be present in the
        string. This argument maps time zone names (and optionally offsets
        from those time zones) to time zones. This parameter can be a
        dictionary with timezone aliases mapping time zone names to time
        zones or a function taking two parameters (``tzname`` and
        ``tzoffset``) and returning a time zone.

        The timezones to which the names are mapped can be an integer
        offset from UTC in seconds or a :class:`tzinfo` object.

        .. doctest::
           :options: +NORMALIZE_WHITESPACE

            >>> from dateutil.parser import parse
            >>> from dateutil.tz import gettz
            >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
            >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
            datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
            >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
            datetime.datetime(2012, 1, 19, 17, 21,
                              tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))

        This parameter is ignored if ``ignoretz`` is set.

    :param dayfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
        ``yearfirst`` is set to ``True``, this distinguishes between YDM and
        YMD. If set to ``None``, this value is retrieved from the current
        :class:`parserinfo` object (which itself defaults to ``False``).

    :param yearfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the year. If ``True``, the first number is taken to
        be the year, otherwise the last number is taken to be the year. If
        this is set to ``None``, the value is retrieved from the current
        :class:`parserinfo` object (which itself defaults to ``False``).

    :param fuzzy:
        Whether to allow fuzzy parsing, allowing for string like "Today is
        January 1, 2047 at 8:21:00AM".

    :param fuzzy_with_tokens:
        If ``True``, ``fuzzy`` is automatically set to True, and the parser
        will return a tuple where the first element is the parsed
        :class:`datetime.datetime` datetimestamp and the second element is
        a tuple containing the portions of the string which were ignored:

        .. doctest::

            >>> from dateutil.parser import parse
            >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
            (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))

    :return:
        Returns a :class:`datetime.datetime` object or, if the
        ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
        first element being a :class:`datetime.datetime` object, the second
        a tuple containing the fuzzy tokens.

    :raises ParserError:
        Raised for invalid or unknown string formats, if the provided
        :class:`tzinfo` is not in a valid format, or if an invalid date would
        be created.

    :raises OverflowError:
        Raised if the parsed date exceeds the largest valid C integer on
        your system.
    'u'

    Parse a string in one of the supported formats, using the
    ``parserinfo`` parameters.

    :param timestr:
        A string containing a date/time stamp.

    :param parserinfo:
        A :class:`parserinfo` object containing parameters for the parser.
        If ``None``, the default arguments to the :class:`parserinfo`
        constructor are used.

    The ``**kwargs`` parameter takes the following keyword arguments:

    :param default:
        The default datetime object, if this is a datetime object and not
        ``None``, elements specified in ``timestr`` replace elements in the
        default object.

    :param ignoretz:
        If set ``True``, time zones in parsed strings are ignored and a naive
        :class:`datetime` object is returned.

    :param tzinfos:
        Additional time zone names / aliases which may be present in the
        string. This argument maps time zone names (and optionally offsets
        from those time zones) to time zones. This parameter can be a
        dictionary with timezone aliases mapping time zone names to time
        zones or a function taking two parameters (``tzname`` and
        ``tzoffset``) and returning a time zone.

        The timezones to which the names are mapped can be an integer
        offset from UTC in seconds or a :class:`tzinfo` object.

        .. doctest::
           :options: +NORMALIZE_WHITESPACE

            >>> from dateutil.parser import parse
            >>> from dateutil.tz import gettz
            >>> tzinfos = {"BRST": -7200, "CST": gettz("America/Chicago")}
            >>> parse("2012-01-19 17:21:00 BRST", tzinfos=tzinfos)
            datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))
            >>> parse("2012-01-19 17:21:00 CST", tzinfos=tzinfos)
            datetime.datetime(2012, 1, 19, 17, 21,
                              tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))

        This parameter is ignored if ``ignoretz`` is set.

    :param dayfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the day (``True``) or month (``False``). If
        ``yearfirst`` is set to ``True``, this distinguishes between YDM and
        YMD. If set to ``None``, this value is retrieved from the current
        :class:`parserinfo` object (which itself defaults to ``False``).

    :param yearfirst:
        Whether to interpret the first value in an ambiguous 3-integer date
        (e.g. 01/05/09) as the year. If ``True``, the first number is taken to
        be the year, otherwise the last number is taken to be the year. If
        this is set to ``None``, the value is retrieved from the current
        :class:`parserinfo` object (which itself defaults to ``False``).

    :param fuzzy:
        Whether to allow fuzzy parsing, allowing for string like "Today is
        January 1, 2047 at 8:21:00AM".

    :param fuzzy_with_tokens:
        If ``True``, ``fuzzy`` is automatically set to True, and the parser
        will return a tuple where the first element is the parsed
        :class:`datetime.datetime` datetimestamp and the second element is
        a tuple containing the portions of the string which were ignored:

        .. doctest::

            >>> from dateutil.parser import parse
            >>> parse("Today is January 1, 2047 at 8:21:00AM", fuzzy_with_tokens=True)
            (datetime.datetime(2047, 1, 1, 8, 21), (u'Today is ', u' ', u'at '))

    :return:
        Returns a :class:`datetime.datetime` object or, if the
        ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the
        first element being a :class:`datetime.datetime` object, the second
        a tuple containing the fuzzy tokens.

    :raises ParserError:
        Raised for invalid or unknown string formats, if the provided
        :class:`tzinfo` is not in a valid format, or if an invalid date would
        be created.

    :raises OverflowError:
        Raised if the parsed date exceeds the largest valid C integer on
        your system.
    'b'stdabbr'u'stdabbr'b'stdoffset'u'stdoffset'b'dstabbr'u'dstabbr'b'dstoffset'u'dstoffset'b'week'u'week'b'yday'u'yday'b'jyday'u'jyday'b'time'b'([,:.]|[a-zA-Z]+|[0-9]+)'u'([,:.]|[a-zA-Z]+|[0-9]+)'b'0123456789:,-+'u'0123456789:,-+'b'0123456789'u'0123456789'b'0123456789+-'u'0123456789+-'b'Parsed time zone "%s"'u'Parsed time zone "%s"'b'is in a non-standard dateutil-specific format, which 'u'is in a non-standard dateutil-specific format, which 'b'is now deprecated; support for parsing this format 'u'is now deprecated; support for parsing this format 'b'will be removed in future versions. It is recommended 'u'will be removed in future versions. It is recommended 'b'that you switch to a standard format like the GNU 'u'that you switch to a standard format like the GNU 'b'TZ variable format.'u'TZ variable format.'b'J'u'J'b'Exception subclass used for any failure to parse a datetime string.

    This is a subclass of :py:exc:`ValueError`, and should be raised any time
    earlier versions of ``dateutil`` would have raised ``ValueError``.

    .. versionadded:: 2.8.1
    'u'Exception subclass used for any failure to parse a datetime string.

    This is a subclass of :py:exc:`ValueError`, and should be raised any time
    earlier versions of ``dateutil`` would have raised ``ValueError``.

    .. versionadded:: 2.8.1
    'b''%s''u''%s''b'Raised when the parser finds a timezone it cannot parse into a tzinfo.

    .. versionadded:: 2.7.0
    'u'Raised when the parser finds a timezone it cannot parse into a tzinfo.

    .. versionadded:: 2.7.0
    'u'dateutil.parser._parser'u'parser._parser'u'_parser'u'Wrapper for potentially out-of-band buffers'pickle.PickleBufferPickleBufferu'PickleError.__weakref__'_pickle.PickleErrorPickleErroru'This takes a binary file for writing a pickle data stream.

The optional *protocol* argument tells the pickler to use the given
protocol; supported protocols are 0, 1, 2, 3, 4 and 5.  The default
protocol is 4. It was introduced in Python 3.4, and is incompatible
with previous versions.

Specifying a negative protocol version selects the highest protocol
version supported.  The higher the protocol used, the more recent the
version of Python needed to read the pickle produced.

The *file* argument must have a write() method that accepts a single
bytes argument. It can thus be a file object opened for binary
writing, an io.BytesIO instance, or any other custom object that meets
this interface.

If *fix_imports* is True and protocol is less than 3, pickle will try
to map the new Python 3 names to the old module names used in Python
2, so that the pickle data stream is readable with Python 2.

If *buffer_callback* is None (the default), buffer views are
serialized into *file* as part of the pickle stream.

If *buffer_callback* is not None, then it can be called any number
of times with a buffer view.  If the callback returns a false value
(such as None), the given buffer is out-of-band; otherwise the
buffer is serialized in-band, i.e. inside the pickle stream.

It is an error if *buffer_callback* is not None and *protocol*
is None or smaller than 5.'clear_memodispatch_tablefastu'Pickler.memo'memou'Pickler.persistent_id'persistent_id_pickle.PicklerPickler_pickle.PicklingErroru'This takes a binary file for reading a pickle data stream.

The protocol version of the pickle is detected automatically, so no
protocol argument is needed.  Bytes past the pickled object's
representation are ignored.

The argument *file* must have two methods, a read() method that takes
an integer argument, and a readline() method that requires no
arguments.  Both methods should return bytes.  Thus *file* can be a
binary file object opened for reading, an io.BytesIO object, or any
other custom object that meets this interface.

Optional keyword arguments are *fix_imports*, *encoding* and *errors*,
which are used to control compatibility support for pickle stream
generated by Python 2.  If *fix_imports* is True, pickle will try to
map the old Python 2 names to the new names used in Python 3.  The
*encoding* and *errors* tell pickle how to decode 8-bit string
instances pickled by Python 2; these default to 'ASCII' and 'strict',
respectively.  The *encoding* can be 'bytes' to read these 8-bit
string instances as bytes objects.'find_classu'Unpickler.memo'u'Unpickler.persistent_load'persistent_load_pickle.UnpicklerUnpickler_pickle.UnpicklingErrorUnpicklingErroru'Optimized C implementation for the Python pickle module.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_pickle.cpython-310-darwin.so'Policy framework for the email package.

Allows fine grained feature control of how the package parses and emits data.
_charsetemail.utilsPolicyCompat32compat32_PolicyBasePolicy Object basic framework.

    This class is useless unless subclassed.  A subclass should define
    class attributes with defaults for any values that are to be
    managed by the Policy object.  The constructor will then allow
    non-default values to be set for these attributes at instance
    creation time.  The instance will be callable, taking these same
    attributes keyword arguments, and returning a new instance
    identical to the called instance except for those values changed
    by the keyword arguments.  Instances may be added, yielding new
    instances with any non-default values from the right hand
    operand overriding those in the left hand operand.  That is,

        A + B == A(<non-default values of B>)

    The repr of an instance can be used to reconstruct the object
    if and only if the repr of the values can be used to reconstruct
    those values.

    Create new Policy, possibly overriding some defaults.

        See class docstring for a list of overridable attributes.

        {!r} is an invalid keyword argument for {}{}={!r}Return a new instance with specified attributes changed.

        The new instance has the same attribute values as the current object,
        except for the changes passed in as keyword arguments.

        newpolicy{!r} object attribute {!r} is read-only{!r} object has no attribute {!r}Non-default values from right operand override those from left.

        The object returned is a new instance of the subclass.

        _append_docadded_doc_extend_docstringsControls for how messages are interpreted and formatted.

    Most of the classes and many of the methods in the email package accept
    Policy objects as parameters.  A Policy object contains a set of values and
    functions that control how input is interpreted and how output is rendered.
    For example, the parameter 'raise_on_defect' controls whether or not an RFC
    violation results in an error being raised or not, while 'max_line_length'
    controls the maximum length of output lines when a Message is serialized.

    Any valid attribute may be overridden when a Policy is created by passing
    it as a keyword argument to the constructor.  Policy objects are immutable,
    but a new Policy object can be created with only certain values changed by
    calling the Policy instance with keyword arguments.  Policy objects can
    also be added, producing a new Policy object in which the non-default
    attributes set in the right hand operand overwrite those specified in the
    left operand.

    Settable attributes:

    raise_on_defect     -- If true, then defects should be raised as errors.
                           Default: False.

    linesep             -- string containing the value to use as separation
                           between output lines.  Default '\n'.

    cte_type            -- Type of allowed content transfer encodings

                           7bit  -- ASCII only
                           8bit  -- Content-Transfer-Encoding: 8bit is allowed

                           Default: 8bit.  Also controls the disposition of
                           (RFC invalid) binary data in headers; see the
                           documentation of the binary_fold method.

    max_line_length     -- maximum length of lines, excluding 'linesep',
                           during serialization.  None or 0 means no line
                           wrapping is done.  Default is 78.

    mangle_from_        -- a flag that, when True escapes From_ lines in the
                           body of the message by putting a `>' in front of
                           them. This is used when the message is being
                           serialized by a generator. Default: True.

    message_factory     -- the class to use to create new message objects.
                           If the value is None, the default is Message.

    raise_on_defect8bitcte_typemangle_from_message_factoryhandle_defectdefectBased on policy, either raise defect or call register_defect.

            handle_defect(obj, defect)

        defect should be a Defect subclass, but in any case must be an
        Exception subclass.  obj is the object on which the defect should be
        registered if it is not raised.  If the raise_on_defect is True, the
        defect is raised as an error, otherwise the object and the defect are
        passed to register_defect.

        This method is intended to be called by parsers that discover defects.
        The email package parsers always call it with Defect instances.

        register_defectRecord 'defect' on 'obj'.

        Called by handle_defect if raise_on_defect is False.  This method is
        part of the Policy API so that Policy subclasses can implement custom
        defect handling.  The default implementation calls the append method of
        the defects attribute of obj.  The objects used by the email package by
        default that get passed to this method will always have a defects
        attribute with an append method.

        header_max_countReturn the maximum allowed number of headers named 'name'.

        Called when a header is added to a Message object.  If the returned
        value is not 0 or None, and there are already a number of headers with
        the name 'name' equal to the value returned, a ValueError is raised.

        Because the default behavior of Message's __setitem__ is to append the
        value to the list of headers, it is easy to create duplicate headers
        without realizing it.  This method allows certain headers to be limited
        in the number of instances of that header that may be added to a
        Message programmatically.  (The limit is not observed by the parser,
        which will faithfully produce as many headers as exist in the message
        being parsed.)

        The default implementation returns None for all header names.
        header_source_parsesourcelinesGiven a list of linesep terminated strings constituting the lines of
        a single header, return the (name, value) tuple that should be stored
        in the model.  The input lines should retain their terminating linesep
        characters.  The lines passed in by the email package may contain
        surrogateescaped binary data.
        header_store_parseGiven the header name and the value provided by the application
        program, return the (name, value) that should be stored in the model.
        header_fetch_parseGiven the header name and the value from the model, return the value
        to be returned to the application program that is requesting that
        header.  The value passed in by the email package may contain
        surrogateescaped binary data if the lines were parsed by a BytesParser.
        The returned value should not contain any surrogateescaped data.

        Given the header name and the value from the model, return a string
        containing linesep characters that implement the folding of the header
        according to the policy controls.  The value passed in by the email
        package may contain surrogateescaped binary data if the lines were
        parsed by a BytesParser.  The returned value should not contain any
        surrogateescaped data.

        fold_binaryGiven the header name and the value from the model, return binary
        data containing linesep characters that implement the folding of the
        header according to the policy controls.  The value passed in by the
        email package may contain surrogateescaped binary data.

        +
    This particular policy is the backward compatibility Policy.  It
    replicates the behavior of the email package version 5.1.
    _sanitize_headerUNKNOWN8BITheader_name+
        The name is parsed as everything up to the ':' and returned unmodified.
        The value is determined by stripping leading whitespace off the
        remainder of the first line, joining all subsequent lines together, and
        stripping any trailing carriage return or linefeed characters.

        +
        The name and value are returned unmodified.
        +
        If the value contains binary data, it is converted into a Header object
        using the unknown-8bit charset.  Otherwise it is returned unmodified.
        +
        Headers are folded using the Header folding algorithm, which preserves
        existing line breaks in the value, and wraps each resulting line to the
        max_line_length.  Non-ASCII binary data are CTE encoded using the
        unknown-8bit charset.

        sanitize+
        Headers are folded using the Header folding algorithm, which preserves
        existing line breaks in the value, and wraps each resulting line to the
        max_line_length.  If cte_type is 7bit, non-ascii binary data is CTE
        encoded using the unknown-8bit charset.  Otherwise the original source
        header is used, with its existing line breaks and/or binary data.

        folded%s: maxlinelen# If the header value contains surrogates, return a Header using# the unknown-8bit charset to encode the bytes as encoded words.# Assume it is already a header object# If we have raw 8bit data in a byte string, we have no idea# what the encoding is.  There is no safe way to split this# string.  If it's ascii-subset, then we could do a normal# ascii split, but if it's multibyte then we could break the# string.  There's no way to know so the least harm seems to# be to not split the string and risk it being too long.# Assume it is a Header-like object.# The Header class interprets a value of None for maxlinelen as the# default value of 78, as recommended by RFC 2822.b'Policy framework for the email package.

Allows fine grained feature control of how the package parses and emits data.
'u'Policy framework for the email package.

Allows fine grained feature control of how the package parses and emits data.
'b'Policy'u'Policy'b'Compat32'u'Compat32'b'compat32'u'compat32'b'Policy Object basic framework.

    This class is useless unless subclassed.  A subclass should define
    class attributes with defaults for any values that are to be
    managed by the Policy object.  The constructor will then allow
    non-default values to be set for these attributes at instance
    creation time.  The instance will be callable, taking these same
    attributes keyword arguments, and returning a new instance
    identical to the called instance except for those values changed
    by the keyword arguments.  Instances may be added, yielding new
    instances with any non-default values from the right hand
    operand overriding those in the left hand operand.  That is,

        A + B == A(<non-default values of B>)

    The repr of an instance can be used to reconstruct the object
    if and only if the repr of the values can be used to reconstruct
    those values.

    'u'Policy Object basic framework.

    This class is useless unless subclassed.  A subclass should define
    class attributes with defaults for any values that are to be
    managed by the Policy object.  The constructor will then allow
    non-default values to be set for these attributes at instance
    creation time.  The instance will be callable, taking these same
    attributes keyword arguments, and returning a new instance
    identical to the called instance except for those values changed
    by the keyword arguments.  Instances may be added, yielding new
    instances with any non-default values from the right hand
    operand overriding those in the left hand operand.  That is,

        A + B == A(<non-default values of B>)

    The repr of an instance can be used to reconstruct the object
    if and only if the repr of the values can be used to reconstruct
    those values.

    'b'Create new Policy, possibly overriding some defaults.

        See class docstring for a list of overridable attributes.

        'u'Create new Policy, possibly overriding some defaults.

        See class docstring for a list of overridable attributes.

        'b'{!r} is an invalid keyword argument for {}'u'{!r} is an invalid keyword argument for {}'b'{}={!r}'u'{}={!r}'b'Return a new instance with specified attributes changed.

        The new instance has the same attribute values as the current object,
        except for the changes passed in as keyword arguments.

        'u'Return a new instance with specified attributes changed.

        The new instance has the same attribute values as the current object,
        except for the changes passed in as keyword arguments.

        'b'{!r} object attribute {!r} is read-only'u'{!r} object attribute {!r} is read-only'b'{!r} object has no attribute {!r}'u'{!r} object has no attribute {!r}'b'Non-default values from right operand override those from left.

        The object returned is a new instance of the subclass.

        'u'Non-default values from right operand override those from left.

        The object returned is a new instance of the subclass.

        'b'Controls for how messages are interpreted and formatted.

    Most of the classes and many of the methods in the email package accept
    Policy objects as parameters.  A Policy object contains a set of values and
    functions that control how input is interpreted and how output is rendered.
    For example, the parameter 'raise_on_defect' controls whether or not an RFC
    violation results in an error being raised or not, while 'max_line_length'
    controls the maximum length of output lines when a Message is serialized.

    Any valid attribute may be overridden when a Policy is created by passing
    it as a keyword argument to the constructor.  Policy objects are immutable,
    but a new Policy object can be created with only certain values changed by
    calling the Policy instance with keyword arguments.  Policy objects can
    also be added, producing a new Policy object in which the non-default
    attributes set in the right hand operand overwrite those specified in the
    left operand.

    Settable attributes:

    raise_on_defect     -- If true, then defects should be raised as errors.
                           Default: False.

    linesep             -- string containing the value to use as separation
                           between output lines.  Default '\n'.

    cte_type            -- Type of allowed content transfer encodings

                           7bit  -- ASCII only
                           8bit  -- Content-Transfer-Encoding: 8bit is allowed

                           Default: 8bit.  Also controls the disposition of
                           (RFC invalid) binary data in headers; see the
                           documentation of the binary_fold method.

    max_line_length     -- maximum length of lines, excluding 'linesep',
                           during serialization.  None or 0 means no line
                           wrapping is done.  Default is 78.

    mangle_from_        -- a flag that, when True escapes From_ lines in the
                           body of the message by putting a `>' in front of
                           them. This is used when the message is being
                           serialized by a generator. Default: True.

    message_factory     -- the class to use to create new message objects.
                           If the value is None, the default is Message.

    'u'Controls for how messages are interpreted and formatted.

    Most of the classes and many of the methods in the email package accept
    Policy objects as parameters.  A Policy object contains a set of values and
    functions that control how input is interpreted and how output is rendered.
    For example, the parameter 'raise_on_defect' controls whether or not an RFC
    violation results in an error being raised or not, while 'max_line_length'
    controls the maximum length of output lines when a Message is serialized.

    Any valid attribute may be overridden when a Policy is created by passing
    it as a keyword argument to the constructor.  Policy objects are immutable,
    but a new Policy object can be created with only certain values changed by
    calling the Policy instance with keyword arguments.  Policy objects can
    also be added, producing a new Policy object in which the non-default
    attributes set in the right hand operand overwrite those specified in the
    left operand.

    Settable attributes:

    raise_on_defect     -- If true, then defects should be raised as errors.
                           Default: False.

    linesep             -- string containing the value to use as separation
                           between output lines.  Default '\n'.

    cte_type            -- Type of allowed content transfer encodings

                           7bit  -- ASCII only
                           8bit  -- Content-Transfer-Encoding: 8bit is allowed

                           Default: 8bit.  Also controls the disposition of
                           (RFC invalid) binary data in headers; see the
                           documentation of the binary_fold method.

    max_line_length     -- maximum length of lines, excluding 'linesep',
                           during serialization.  None or 0 means no line
                           wrapping is done.  Default is 78.

    mangle_from_        -- a flag that, when True escapes From_ lines in the
                           body of the message by putting a `>' in front of
                           them. This is used when the message is being
                           serialized by a generator. Default: True.

    message_factory     -- the class to use to create new message objects.
                           If the value is None, the default is Message.

    'b'8bit'u'8bit'b'Based on policy, either raise defect or call register_defect.

            handle_defect(obj, defect)

        defect should be a Defect subclass, but in any case must be an
        Exception subclass.  obj is the object on which the defect should be
        registered if it is not raised.  If the raise_on_defect is True, the
        defect is raised as an error, otherwise the object and the defect are
        passed to register_defect.

        This method is intended to be called by parsers that discover defects.
        The email package parsers always call it with Defect instances.

        'u'Based on policy, either raise defect or call register_defect.

            handle_defect(obj, defect)

        defect should be a Defect subclass, but in any case must be an
        Exception subclass.  obj is the object on which the defect should be
        registered if it is not raised.  If the raise_on_defect is True, the
        defect is raised as an error, otherwise the object and the defect are
        passed to register_defect.

        This method is intended to be called by parsers that discover defects.
        The email package parsers always call it with Defect instances.

        'b'Record 'defect' on 'obj'.

        Called by handle_defect if raise_on_defect is False.  This method is
        part of the Policy API so that Policy subclasses can implement custom
        defect handling.  The default implementation calls the append method of
        the defects attribute of obj.  The objects used by the email package by
        default that get passed to this method will always have a defects
        attribute with an append method.

        'u'Record 'defect' on 'obj'.

        Called by handle_defect if raise_on_defect is False.  This method is
        part of the Policy API so that Policy subclasses can implement custom
        defect handling.  The default implementation calls the append method of
        the defects attribute of obj.  The objects used by the email package by
        default that get passed to this method will always have a defects
        attribute with an append method.

        'b'Return the maximum allowed number of headers named 'name'.

        Called when a header is added to a Message object.  If the returned
        value is not 0 or None, and there are already a number of headers with
        the name 'name' equal to the value returned, a ValueError is raised.

        Because the default behavior of Message's __setitem__ is to append the
        value to the list of headers, it is easy to create duplicate headers
        without realizing it.  This method allows certain headers to be limited
        in the number of instances of that header that may be added to a
        Message programmatically.  (The limit is not observed by the parser,
        which will faithfully produce as many headers as exist in the message
        being parsed.)

        The default implementation returns None for all header names.
        'u'Return the maximum allowed number of headers named 'name'.

        Called when a header is added to a Message object.  If the returned
        value is not 0 or None, and there are already a number of headers with
        the name 'name' equal to the value returned, a ValueError is raised.

        Because the default behavior of Message's __setitem__ is to append the
        value to the list of headers, it is easy to create duplicate headers
        without realizing it.  This method allows certain headers to be limited
        in the number of instances of that header that may be added to a
        Message programmatically.  (The limit is not observed by the parser,
        which will faithfully produce as many headers as exist in the message
        being parsed.)

        The default implementation returns None for all header names.
        'b'Given a list of linesep terminated strings constituting the lines of
        a single header, return the (name, value) tuple that should be stored
        in the model.  The input lines should retain their terminating linesep
        characters.  The lines passed in by the email package may contain
        surrogateescaped binary data.
        'u'Given a list of linesep terminated strings constituting the lines of
        a single header, return the (name, value) tuple that should be stored
        in the model.  The input lines should retain their terminating linesep
        characters.  The lines passed in by the email package may contain
        surrogateescaped binary data.
        'b'Given the header name and the value provided by the application
        program, return the (name, value) that should be stored in the model.
        'u'Given the header name and the value provided by the application
        program, return the (name, value) that should be stored in the model.
        'b'Given the header name and the value from the model, return the value
        to be returned to the application program that is requesting that
        header.  The value passed in by the email package may contain
        surrogateescaped binary data if the lines were parsed by a BytesParser.
        The returned value should not contain any surrogateescaped data.

        'u'Given the header name and the value from the model, return the value
        to be returned to the application program that is requesting that
        header.  The value passed in by the email package may contain
        surrogateescaped binary data if the lines were parsed by a BytesParser.
        The returned value should not contain any surrogateescaped data.

        'b'Given the header name and the value from the model, return a string
        containing linesep characters that implement the folding of the header
        according to the policy controls.  The value passed in by the email
        package may contain surrogateescaped binary data if the lines were
        parsed by a BytesParser.  The returned value should not contain any
        surrogateescaped data.

        'u'Given the header name and the value from the model, return a string
        containing linesep characters that implement the folding of the header
        according to the policy controls.  The value passed in by the email
        package may contain surrogateescaped binary data if the lines were
        parsed by a BytesParser.  The returned value should not contain any
        surrogateescaped data.

        'b'Given the header name and the value from the model, return binary
        data containing linesep characters that implement the folding of the
        header according to the policy controls.  The value passed in by the
        email package may contain surrogateescaped binary data.

        'u'Given the header name and the value from the model, return binary
        data containing linesep characters that implement the folding of the
        header according to the policy controls.  The value passed in by the
        email package may contain surrogateescaped binary data.

        'b'+
    This particular policy is the backward compatibility Policy.  It
    replicates the behavior of the email package version 5.1.
    'u'+
    This particular policy is the backward compatibility Policy.  It
    replicates the behavior of the email package version 5.1.
    'b'+
        The name is parsed as everything up to the ':' and returned unmodified.
        The value is determined by stripping leading whitespace off the
        remainder of the first line, joining all subsequent lines together, and
        stripping any trailing carriage return or linefeed characters.

        'u'+
        The name is parsed as everything up to the ':' and returned unmodified.
        The value is determined by stripping leading whitespace off the
        remainder of the first line, joining all subsequent lines together, and
        stripping any trailing carriage return or linefeed characters.

        'b'+
        The name and value are returned unmodified.
        'u'+
        The name and value are returned unmodified.
        'b'+
        If the value contains binary data, it is converted into a Header object
        using the unknown-8bit charset.  Otherwise it is returned unmodified.
        'u'+
        If the value contains binary data, it is converted into a Header object
        using the unknown-8bit charset.  Otherwise it is returned unmodified.
        'b'+
        Headers are folded using the Header folding algorithm, which preserves
        existing line breaks in the value, and wraps each resulting line to the
        max_line_length.  Non-ASCII binary data are CTE encoded using the
        unknown-8bit charset.

        'u'+
        Headers are folded using the Header folding algorithm, which preserves
        existing line breaks in the value, and wraps each resulting line to the
        max_line_length.  Non-ASCII binary data are CTE encoded using the
        unknown-8bit charset.

        'b'+
        Headers are folded using the Header folding algorithm, which preserves
        existing line breaks in the value, and wraps each resulting line to the
        max_line_length.  If cte_type is 7bit, non-ascii binary data is CTE
        encoded using the unknown-8bit charset.  Otherwise the original source
        header is used, with its existing line breaks and/or binary data.

        'u'+
        Headers are folded using the Header folding algorithm, which preserves
        existing line breaks in the value, and wraps each resulting line to the
        max_line_length.  If cte_type is 7bit, non-ascii binary data is CTE
        encoded using the unknown-8bit charset.  Otherwise the original source
        header is used, with its existing line breaks and/or binary data.

        'b'%s: 'u'%s: 'u'email._policybase'u'_policybase'u'POSIX shared memory module'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_posixshmem.cpython-310-darwin.so'u'_posixshmem'shm_openshm_unlink_posixshmemu'A POSIX helper for the subprocess module.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_posixsubprocess.cpython-310-darwin.so'u'_posixsubprocess'fork_exec_posixsubprocess_weakrefsetReturns the current ABC cache token.

    The token is an opaque object (supporting equality testing) identifying the
    current version of the ABC cache for virtual subclasses. The token changes
    with every call to ``register()`` on any ABC.
    _abc_invalidation_counterMetaclass for defining Abstract Base Classes (ABCs).

    Use this metaclass to create an ABC.  An ABC can be subclassed
    directly, and then acts as a mix-in class.  You can also register
    unrelated concrete classes (even built-in classes) and unrelated
    ABCs as 'virtual subclasses' -- these and their descendants will
    be considered subclasses of the registering ABC by the built-in
    issubclass() function, but the registering ABC won't show up in
    their MRO (Method Resolution Order) nor will method
    implementations defined by the registering ABC be callable (not
    even via super()).
    mclsabstracts_abc_registry_abc_cache_abc_negative_cache_abc_negative_cache_versionsubclassRegister a virtual subclass of an ABC.

        Returns the subclass, to allow usage as a class decorator.
        Can only register classesRefusing to create an inheritance cycle_dump_registryDebug helper to print the ABC registry.Class: Inv. counter: _abc__abc_registry_clearClear the registry (for debugging or testing)._abc_caches_clearClear the caches (for debugging or testing).Override for isinstance(instance, cls).Override for issubclass(subclass, cls).issubclass() arg 1 must be a classrclsscls# A global counter that is incremented each time a class is# registered as a virtual subclass of anything.  It forces the# negative cache to be cleared before its next use.# Note: this counter is private. Use `abc.get_cache_token()` for#       external code.# Compute set of abstract method names# Set up inheritance registry# Already a subclass# Subtle: test for cycles *after* testing for "already a subclass";# this means we allow X.register(X) and interpret it as a no-op.# This would create a cycle, which is bad for the algorithm below# Invalidate negative cache# Inline the cache checking# Fall back to the subclass check.# Check cache# Check negative cache; may have to invalidate# Invalidate the negative cache# Check the subclass hook# Check if it's a direct subclass# Check if it's a subclass of a registered class (recursive)# Check if it's a subclass of a subclass (recursive)# No dice; update negative cacheb'Returns the current ABC cache token.

    The token is an opaque object (supporting equality testing) identifying the
    current version of the ABC cache for virtual subclasses. The token changes
    with every call to ``register()`` on any ABC.
    'u'Returns the current ABC cache token.

    The token is an opaque object (supporting equality testing) identifying the
    current version of the ABC cache for virtual subclasses. The token changes
    with every call to ``register()`` on any ABC.
    'b'Metaclass for defining Abstract Base Classes (ABCs).

    Use this metaclass to create an ABC.  An ABC can be subclassed
    directly, and then acts as a mix-in class.  You can also register
    unrelated concrete classes (even built-in classes) and unrelated
    ABCs as 'virtual subclasses' -- these and their descendants will
    be considered subclasses of the registering ABC by the built-in
    issubclass() function, but the registering ABC won't show up in
    their MRO (Method Resolution Order) nor will method
    implementations defined by the registering ABC be callable (not
    even via super()).
    'u'Metaclass for defining Abstract Base Classes (ABCs).

    Use this metaclass to create an ABC.  An ABC can be subclassed
    directly, and then acts as a mix-in class.  You can also register
    unrelated concrete classes (even built-in classes) and unrelated
    ABCs as 'virtual subclasses' -- these and their descendants will
    be considered subclasses of the registering ABC by the built-in
    issubclass() function, but the registering ABC won't show up in
    their MRO (Method Resolution Order) nor will method
    implementations defined by the registering ABC be callable (not
    even via super()).
    'b'__isabstractmethod__'u'__isabstractmethod__'b'__abstractmethods__'u'__abstractmethods__'b'Register a virtual subclass of an ABC.

        Returns the subclass, to allow usage as a class decorator.
        'u'Register a virtual subclass of an ABC.

        Returns the subclass, to allow usage as a class decorator.
        'b'Can only register classes'u'Can only register classes'b'Refusing to create an inheritance cycle'u'Refusing to create an inheritance cycle'b'Debug helper to print the ABC registry.'u'Debug helper to print the ABC registry.'b'Class: 'u'Class: 'b'Inv. counter: 'u'Inv. counter: 'b'_abc_'u'_abc_'b'Clear the registry (for debugging or testing).'u'Clear the registry (for debugging or testing).'b'Clear the caches (for debugging or testing).'u'Clear the caches (for debugging or testing).'b'Override for isinstance(instance, cls).'u'Override for isinstance(instance, cls).'b'Override for issubclass(subclass, cls).'u'Override for issubclass(subclass, cls).'b'issubclass() arg 1 must be a class'u'issubclass() arg 1 must be a class'b'__mro__'u'__mro__'u'_py_abc'
This is an implementation of decimal floating point arithmetic based on
the General Decimal Arithmetic Specification:

    http://speleotrove.com/decimal/decarith.html

and IEEE standard 854-1987:

    http://en.wikipedia.org/wiki/IEEE_854-1987

Decimal floating point has finite precision with arbitrarily large bounds.

The purpose of this module is to support arithmetic using familiar
"schoolhouse" rules and to avoid some of the tricky representation
issues associated with binary floating point.  The package is especially
useful for financial applications or for contexts where users have
expectations that are at odds with binary floating point (for instance,
in binary floating point, 1.00 % 0.1 gives 0.09999999999999995 instead
of 0.0; Decimal('1.00') % Decimal('0.1') returns the expected
Decimal('0.00')).

Here are some examples of using the decimal module:

>>> from decimal import *
>>> setcontext(ExtendedContext)
>>> Decimal(0)
Decimal('0')
>>> Decimal('1')
Decimal('1')
>>> Decimal('-.0123')
Decimal('-0.0123')
>>> Decimal(123456)
Decimal('123456')
>>> Decimal('123.45e12345678')
Decimal('1.2345E+12345680')
>>> Decimal('1.33') + Decimal('1.27')
Decimal('2.60')
>>> Decimal('12.34') + Decimal('3.87') - Decimal('18.41')
Decimal('-2.20')
>>> dig = Decimal(1)
>>> print(dig / Decimal(3))
0.333333333
>>> getcontext().prec = 18
>>> print(dig / Decimal(3))
0.333333333333333333
>>> print(dig.sqrt())
1
>>> print(Decimal(3).sqrt())
1.73205080756887729
>>> print(Decimal(3) ** 123)
4.85192780976896427E+58
>>> inf = Decimal(1) / Decimal(0)
>>> print(inf)
Infinity
>>> neginf = Decimal(-1) / Decimal(0)
>>> print(neginf)
-Infinity
>>> print(neginf + inf)
NaN
>>> print(neginf * inf)
-Infinity
>>> print(dig / 0)
Infinity
>>> getcontext().traps[DivisionByZero] = 1
>>> print(dig / 0)
Traceback (most recent call last):
  ...
  ...
  ...
decimal.DivisionByZero: x / 0
>>> c = Context()
>>> c.traps[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> c.divide(Decimal(0), Decimal(0))
Decimal('NaN')
>>> c.traps[InvalidOperation] = 1
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> print(c.divide(Decimal(0), Decimal(0)))
Traceback (most recent call last):
  ...
  ...
  ...
decimal.InvalidOperation: 0 / 0
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> c.traps[InvalidOperation] = 0
>>> print(c.divide(Decimal(0), Decimal(0)))
NaN
>>> print(c.flags[InvalidOperation])
1
>>>
__xname__1.702.4.2math_mathnumbers_numbers_namedtuplesign digits exponent425000000Base exception class.

    Used exceptions derive from this.
    If an exception derives from another exception besides this (such as
    Underflow (Inexact, Rounded, Subnormal) that indicates that it is only
    called if the others are present.  This isn't actually used for
    anything, though.

    handle  -- Called when context._raise_error is called and the
               trap_enabler is not set.  First argument is self, second is the
               context.  More arguments can be given, those being after
               the explanation in _raise_error (For example,
               context._raise_error(NewError, '(-x)!', self._sign) would
               call NewError().handle(context, self._sign).)

    To define a new exception, it should be sufficient to have it derive
    from DecimalException.
    Exponent of a 0 changed to fit bounds.

    This occurs and signals clamped if the exponent of a result has been
    altered in order to fit the constraints of a specific concrete
    representation.  This may occur when the exponent of a zero result would
    be outside the bounds of a representation, or when a large normal
    number would have an encoded exponent that cannot be represented.  In
    this latter case, the exponent is reduced to fit and the corresponding
    number of zero digits are appended to the coefficient ("fold-down").
    An invalid operation was performed.

    Various bad things cause this:

    Something creates a signaling NaN
    -INF + INF
    0 * (+-)INF
    (+-)INF / (+-)INF
    x % 0
    (+-)INF % x
    x._rescale( non-integer )
    sqrt(-x) , x > 0
    0 ** 0
    x ** (non-integer)
    x ** (+-)INF
    An operand is invalid

    The result of the operation after these is a quiet positive NaN,
    except when the cause is a signaling NaN, in which case the result is
    also a quiet NaN, but with the original sign, and an optional
    diagnostic information.
    _dec_from_triple_sign_intans_fix_nan_NaNTrying to convert badly formed string.

    This occurs and signals invalid-operation if a string is being
    converted to a number and it does not conform to the numeric string
    syntax.  The result is [0,qNaN].
    Division by 0.

    This occurs and signals division-by-zero if division of a finite number
    by zero was attempted (during a divide-integer or divide operation, or a
    power operation with negative right-hand operand), and the dividend was
    not zero.

    The result of the operation is [sign,inf], where sign is the exclusive
    or of the signs of the operands for divide, or is 1 for an odd power of
    -0, for power.
    _SignedInfinityCannot perform the division adequately.

    This occurs and signals invalid-operation if the integer result of a
    divide-integer or remainder operation had too many digits (would be
    longer than precision).  The result is [0,qNaN].
    Undefined result of division.

    This occurs and signals invalid-operation if division by zero was
    attempted (during a divide-integer, divide, or remainder operation), and
    the dividend is also zero.  The result is [0,qNaN].
    Had to round, losing information.

    This occurs and signals inexact whenever the result of an operation is
    not exact (that is, it needed to be rounded and any discarded digits
    were non-zero), or if an overflow or underflow condition occurs.  The
    result in all cases is unchanged.

    The inexact signal may be tested (or trapped) to determine if a given
    operation (or sequence of operations) was inexact.
    Invalid context.  Unknown rounding, for example.

    This occurs and signals invalid-operation if an invalid context was
    detected during an operation.  This can occur if contexts are not checked
    on creation and either the precision exceeds the capability of the
    underlying concrete representation or an unknown or unsupported rounding
    was specified.  These aspects of the context need only be checked when
    the values are required to be used.  The result is [0,qNaN].
    Number got rounded (not  necessarily changed during rounding).

    This occurs and signals rounded whenever the result of an operation is
    rounded (that is, some zero or non-zero digits were discarded from the
    coefficient), or if an overflow or underflow condition occurs.  The
    result in all cases is unchanged.

    The rounded signal may be tested (or trapped) to determine if a given
    operation (or sequence of operations) caused a loss of precision.
    Exponent < Emin before rounding.

    This occurs and signals subnormal whenever the result of a conversion or
    operation is subnormal (that is, its adjusted exponent is less than
    Emin, before any rounding).  The result in all cases is unchanged.

    The subnormal signal may be tested (or trapped) to determine if a given
    or operation (or sequence of operations) yielded a subnormal result.
    Numerical overflow.

    This occurs and signals overflow if the adjusted exponent of a result
    (from a conversion or from an operation that is not an attempt to divide
    by zero), after rounding, would be greater than the largest value that
    can be handled by the implementation (the value Emax).

    The result depends on the rounding mode:

    For round-half-up and round-half-even (and for round-half-down and
    round-up, if implemented), the result of the operation is [sign,inf],
    where sign is the sign of the intermediate result.  For round-down, the
    result is the largest finite number that can be represented in the
    current precision, with the sign of the intermediate result.  For
    round-ceiling, the result is the same as for round-down if the sign of
    the intermediate result is 1, or is [0,inf] otherwise.  For round-floor,
    the result is the same as for round-down if the sign of the intermediate
    result is 0, or is [1,inf] otherwise.  In all cases, Inexact and Rounded
    will also be raised.
    Numerical underflow with result rounded to 0.

    This occurs and signals underflow if a result is inexact and the
    adjusted exponent of the result would be smaller (more negative) than
    the smallest value that can be handled by the implementation (the value
    Emin).  That is, the result is both inexact and subnormal.

    The result after an underflow will be a subnormal number rounded, if
    necessary, so that its exponent is not less than Etiny.  This may result
    in 0 with the sign of the intermediate result and an exponent of Etiny.

    In all cases, Inexact, Rounded, and Subnormal will also be raised.
    Enable stricter semantics for mixing floats and Decimals.

    If the signal is not trapped (default), mixing floats and Decimals is
    permitted in the Decimal() constructor, context.create_decimal() and
    all comparison operators. Both conversion and comparisons are exact.
    Any occurrence of a mixed operation is silently recorded by setting
    FloatOperation in the context flags.  Explicit conversions with
    Decimal.from_float() or context.create_decimal_from_float() do not
    set the flag.

    Otherwise (the signal is trapped), only equality comparisons and explicit
    conversions are silent. All other mixed operations raise FloatOperation.
    _signals_condition_map_rounding_modescontextvarsdecimal_context_current_context_varReturns this thread's context.

    If this thread does not yet have a context, returns
    a new context and sets this thread's context.
    New contexts are copies of DefaultContext.
    Set this thread's context to context.Return a context manager for a copy of the supplied context

    Uses a copy of the current context if no context is specified
    The returned context manager creates a local decimal context
    in a with statement:
        def sin(x):
             with localcontext() as ctx:
                 ctx.prec += 2
                 # Rest of sin calculation algorithm
                 # uses a precision 2 greater than normal
             return +s  # Convert result to normal precision

         def sin(x):
             with localcontext(ExtendedContext):
                 # Rest of sin calculation algorithm
                 # uses the Extended Context from the
                 # General Decimal Arithmetic Specification
             return +s  # Convert result to normal context

    >>> setcontext(DefaultContext)
    >>> print(getcontext().prec)
    28
    >>> with localcontext():
    ...     ctx = getcontext()
    ...     ctx.prec += 2
    ...     print(ctx.prec)
    ...
    30
    >>> with localcontext(ExtendedContext):
    ...     print(getcontext().prec)
    ...
    9
    >>> print(getcontext().prec)
    28
    _ContextManagerFloating point class for decimal arithmetic._exp_is_specialCreate a decimal point instance.

        >>> Decimal('3.14')              # string input
        Decimal('3.14')
        >>> Decimal((0, (3, 1, 4), -2))  # tuple (sign, digit_tuple, exponent)
        Decimal('3.14')
        >>> Decimal(314)                 # int
        Decimal('314')
        >>> Decimal(Decimal(314))        # another decimal instance
        Decimal('314')
        >>> Decimal('  3.14  \n')        # leading and trailing whitespace okay
        Decimal('3.14')
        _raise_errorInvalid literal for Decimal: %rintpartfracfracpartdiagF_WorkRepInvalid tuple size in creation of Decimal from list or tuple.  The list or tuple should have exactly three elements.'Invalid tuple size in creation of Decimal ''from list or tuple.  The list or tuple ''should have exactly three elements.'Invalid sign.  The first value in the tuple should be an integer; either 0 for a positive number or 1 for a negative number."Invalid sign.  The first value in the tuple ""should be an integer; either 0 for a ""positive number or 1 for a negative number."digitThe second value in the tuple must be composed of integers in the range 0 through 9."The second value in the tuple must ""be composed of integers in the range ""0 through 9."The third value in the tuple must be an integer, or one of the strings 'F', 'n', 'N'."The third value in the tuple must ""be an integer, or one of the ""strings 'F', 'n', 'N'."strict semantics for mixing floats and Decimals are enabled"strict semantics for mixing floats and Decimals are ""enabled"Cannot convert %r to DecimalConverts a float to a decimal number, exactly.

        Note that Decimal.from_float(0.1) is not the same as Decimal('0.1').
        Since 0.1 is not exactly representable in binary floating point, the
        value is stored as the nearest representable value which is
        0x1.999999999999ap-4.  The exact equivalent of the value in decimal
        is 0.1000000000000000055511151231257827021181583404541015625.

        >>> Decimal.from_float(0.1)
        Decimal('0.1000000000000000055511151231257827021181583404541015625')
        >>> Decimal.from_float(float('nan'))
        Decimal('NaN')
        >>> Decimal.from_float(float('inf'))
        Decimal('Infinity')
        >>> Decimal.from_float(-float('inf'))
        Decimal('-Infinity')
        >>> Decimal.from_float(-0.0)
        Decimal('-0')

        coeffisinfisnancopysignargument must be int or float._isnanReturns whether the number is not actually one.

        0 if a number
        1 if NaN
        2 if sNaN
        _isinfinityReturns whether the number is infinite

        0 if finite or not a number
        1 if +INF
        -1 if -INF
        _check_nansReturns whether the number is not actually one.

        if self, other are sNaN, signal
        if self, other are NaN return nan
        return 0

        Done before operations.
        self_is_nanother_is_nansNaN_compare_check_nansVersion of _check_nans used for the signaling comparisons
        compare_signal, __le__, __lt__, __ge__, __gt__.

        Signal InvalidOperation if either self or other is a (quiet
        or signaling) NaN.  Signaling NaNs take precedence over quiet
        NaNs.

        Return 0 if neither operand is a NaN.

        comparison involving sNaNcomparison involving NaNReturn True if self is nonzero; otherwise return False.

        NaNs and infinities are considered nonzero.
        _cmpCompare the two non-NaN decimal instances self and other.

        Returns -1 if self < other, 0 if self == other and 1
        if self > other.  This routine is for internal use only.self_infother_infself_adjustedother_adjustedself_paddedother_padded_convert_for_comparisonequality_opCompare self to other.  Return a decimal value:

        a or b is a NaN ==> Decimal('NaN')
        a < b           ==> Decimal('-1')
        a == b          ==> Decimal('0')
        a > b           ==> Decimal('1')
        _convert_otherraiseitx.__hash__() <==> hash(x)Cannot hash a signaling NaN value._PyHASH_INF_PyHASH_MODULUSexp_hash_PyHASH_10INVhash_Represents the number as a triple tuple.

        To show the internals exactly as they are.
        Express a finite Decimal instance in the form n / d.

        Returns a pair (n, d) of integers.  When called on an infinity
        or NaN, raises OverflowError or ValueError respectively.

        >>> Decimal('3.14').as_integer_ratio()
        (157, 50)
        >>> Decimal('-123e5').as_integer_ratio()
        (-12300000, 1)
        >>> Decimal('0.00').as_integer_ratio()
        (0, 1)

        cannot convert NaN to integer ratiocannot convert Infinity to integer ratiod5d2shift2Represents the number as an instance of Decimal.Decimal('%s')engReturn string representation of the number in scientific notation.

        Captures all of the information in the underlying representation.
        InfinityNaNleftdigitsdotplace%+dConvert to a string, using engineering notation if an exponent is needed.

        Engineering notation has an exponent which is a multiple of 3.  This
        can leave up to 3 digits to the left of the decimal place and may
        require the addition of either one or two trailing zeros.
        Returns a copy with the sign switched.

        Rounds, if it has reason.
        _fixReturns a copy, unless it is a sNaN.

        Rounds the number (if more than precision digits)
        Returns the absolute value of self.

        If the keyword argument 'round' is false, do not round.  The
        expression self.__abs__(round=False) is equivalent to
        self.copy_abs().
        Returns self + other.

        -INF + INF (or the reverse) cause InvalidOperation errors.
        -INF + INFnegativezero_rescaleop1op2_normalizeReturn self - otherReturn other - selfReturn self * other.

        (+-) INF * 0 (or its reverse) raise InvalidOperation.
        resultsign(+-)INF * 00 * (+-)INFresultexpReturn self / other.(+-)INF/(+-)INFDivision by infinity0 / 0x / 0ideal_exp_divideReturn (self // other, self % other), to context.prec precision.

        Assumes that neither self nor other is a NaN, that self is not
        infinite and that other is nonzero.
        expdiffquotient too large in //, % or divmodSwaps self/other and returns __truediv__.
        Return (self // other, self % other)
        divmod(INF, INF)INF % xdivmod(0, 0)x // 0x % 0quotientSwaps self/other and returns __divmod__.
        self % other
        0 % 0Swaps self/other and returns __mod__.
        Remainder nearest to 0-  abs(remainder-near) <= other/2
        remainder_near(infinity, x)remainder_near(x, 0)remainder_near(0, 0)ideal_exponentself // otherINF // INF0 // 0Swaps self/other and returns __floordiv__.Float representation.Cannot convert signaling NaN to float-nanConverts self to an int, truncating if necessary.Cannot convert NaN to integerCannot convert infinity to integerDecapitate the payload of a NaN to fit the contextpayloadmax_payload_lenRound if it is necessary to keep self within prec precision.

        Rounds and fixes the exponent.  Does not raise on a sNaN.

        Arguments:
        self - Decimal instance
        context - context used.
        exp_maxnew_expexp_minabove Emaxself_is_subnormal_pick_rounding_functionrounding_methodchanged_round_downAlso known as round-towards-0, truncate._all_zeros_round_upRounds away from 0._round_half_upRounds 5 up (away from 0)56789_round_half_downRound 5 down_exact_half_round_half_evenRound 5 to even, rest to nearest.02468_round_ceilingRounds up (not away from 0 if negative.)_round_floorRounds down (not towards 0 if negative)_round_05upRound down unless digit prec-1 is 0 or 5.05Round self to the nearest integer, or to a given precision.

        If only one argument is supplied, round a finite Decimal
        instance self to the nearest integer.  If self is infinite or
        a NaN then a Python exception is raised.  If self is finite
        and lies exactly halfway between two integers then it is
        rounded to the integer with even last digit.

        >>> round(Decimal('123.456'))
        123
        >>> round(Decimal('-456.789'))
        -457
        >>> round(Decimal('-3.0'))
        -3
        >>> round(Decimal('2.5'))
        2
        >>> round(Decimal('3.5'))
        4
        >>> round(Decimal('Inf'))
        Traceback (most recent call last):
          ...
        OverflowError: cannot round an infinity
        >>> round(Decimal('NaN'))
        Traceback (most recent call last):
          ...
        ValueError: cannot round a NaN

        If a second argument n is supplied, self is rounded to n
        decimal places using the rounding mode for the current
        context.

        For an integer n, round(self, -n) is exactly equivalent to
        self.quantize(Decimal('1En')).

        >>> round(Decimal('123.456'), 0)
        Decimal('123')
        >>> round(Decimal('123.456'), 2)
        Decimal('123.46')
        >>> round(Decimal('123.456'), -2)
        Decimal('1E+2')
        >>> round(Decimal('-Infinity'), 37)
        Decimal('NaN')
        >>> round(Decimal('sNaN123'), 0)
        Decimal('NaN123')

        Second argument to round should be integralcannot round a NaNcannot round an infinityReturn the floor of self, as an integer.

        For a finite Decimal instance self, return the greatest
        integer n such that n <= self.  If self is infinite or a NaN
        then a Python exception is raised.

        Return the ceiling of self, as an integer.

        For a finite Decimal instance self, return the least integer n
        such that n >= self.  If self is infinite or a NaN then a
        Python exception is raised.

        thirdFused multiply-add.

        Returns self*other+third with no rounding of the intermediate
        product self*other.

        self and other are multiplied together, with no rounding of
        the result.  The third operand is then added to the result,
        and a single final rounding is performed.
        productINF * 0 in fma0 * INF in fma_power_modulomoduloThree argument version of __pow__modulo_is_nan_isintegerpow() 3rd argument not allowed unless all arguments are integers'pow() 3rd argument not allowed ''unless all arguments are integers'pow() 2nd argument cannot be negative when 3rd argument specified'pow() 2nd argument cannot be ''negative when 3rd argument specified'pow() 3rd argument cannot be 0insufficient precision: pow() 3rd argument must not have more than precision digits'insufficient precision: pow() 3rd ''argument must not have more than ''precision digits'at least one of pow() 1st argument and 2nd argument must be nonzero; 0**0 is not defined'at least one of pow() 1st argument ''and 2nd argument must be nonzero; ''0**0 is not defined'_iseven_power_exactAttempt to compute self**other exactly.

        Given Decimals self and other and an integer p, attempt to
        compute an exact result for the power self**other, with p
        digits of precision.  Return None if self**other is not
        exactly representable in p digits.

        Assumes that elimination of special cases has already been
        performed: self and other must both be nonspecial; self must
        be positive and not numerically equal to 1; other must be
        nonzero.  For efficiency, other._exp should not be too large,
        so that 10**abs(other._exp) is a feasible calculation.xcxeycyezeroslast_digit_nbits9365emax_decimal_lshift_exactxc_bitsrem_log10_lbstr_xcReturn self ** other [ % modulo].

        With two arguments, compute self**other.

        With three arguments, compute (self**other) % modulo.  For the
        three argument form, the following restrictions on the
        arguments hold:

         - all three arguments must be integral
         - other must be nonnegative
         - either self or other (or both) must be nonzero
         - modulo must be nonzero and must have at most p digits,
           where p is the context precision.

        If any of these restrictions is violated the InvalidOperation
        flag is raised.

        The result of pow(self, other, modulo) is identical to the
        result that would be obtained by computing (self**other) %
        modulo with unbounded precision, but is computed more
        efficiently.  It is always exact.
        0 ** 0_Oneresult_signx ** y with x negative and y not an integermultiplierself_adj_log10_exp_boundbound_dpowernewcontexttrapsSwaps self/other and returns __pow__.Normalize- strip trailing 0s, change anything equal to 0 to 0e0dupQuantize self so its exponent is the same as that of exp.

        Similar to self._rescale(exp._exp) but with error checking.
        quantize with one INFtarget exponent out of bounds in quantizeexponent of quantize result too large for current contextquantize result has too many digits for current contextReturn True if self and other have the same exponent; otherwise
        return False.

        If either operand is a special value, the following rules are used:
           * return True if both operands are infinities
           * return True if both operands are NaNs
           * otherwise, return False.
        Rescale self so that the exponent is exp, either by padding with zeros
        or by truncating digits, using the given rounding mode.

        Specials are returned without change.  This operation is
        quiet: it raises no flags, and uses no information from the
        context.

        exp = exp to scale to (an integer)
        rounding = rounding mode
        this_function_roundplacesRound a nonzero, nonspecial Decimal to a fixed number of
        significant figures, using the given rounding mode.

        Infinities, NaNs and zeros are returned unaltered.

        This operation is quiet: it raises no flags, and uses no
        information from the context.

        argument should be at least 1 in _roundRounds to a nearby integer.

        If no rounding mode is specified, take the rounding mode from
        the context.  This method raises the Rounded and Inexact flags
        when appropriate.

        See also: to_integral_value, which does exactly the same as
        this method except that it doesn't raise Inexact or Rounded.
        Rounds to the nearest integer, without raising inexact, rounded.Return the square root of self.sqrt(-x), x > 0_shallow_copy_set_roundingReturns the larger value.

        Like max(self, other) except if one is not a number, returns
        NaN (and signals if one is sNaN).  Also rounds.
        snReturns the smaller value.

        Like min(self, other) except if one is not a number, returns
        NaN (and signals if one is sNaN).  Also rounds.
        Returns whether self is an integerReturns True if self is even.  Assumes self is an integer.Return the adjusted exponent of selfReturns the same Decimal object.

        As we do not have different encodings for the same number, the
        received object already is in its canonical form.
        Compares self to the other operand numerically.

        It's pretty much like compare(), but all NaNs signal, with signaling
        NaNs taking precedence over quiet NaNs.
        Compares self to other using the abstract representations.

        This is not like the standard compare, which use their numerical
        value. Note that a total ordering is defined for all possible abstract
        representations.
        _NegativeOneself_nanother_nanself_keyother_key_ZeroCompares self to other using abstract repr., ignoring sign.

        Like compare_total, but with operand's sign ignored and assumed to be 0.
        Returns a copy with the sign set to 0. Returns a copy with the sign inverted.Returns self with the sign of other.Returns e ** self.adj_dexpReturn True if self is canonical; otherwise return False.

        Currently, the encoding of a Decimal instance is always
        canonical, so this method returns True for any Decimal.
        Return True if self is finite; otherwise return False.

        A Decimal instance is considered finite if it is neither
        infinite nor a NaN.
        Return True if self is infinite; otherwise return False.Return True if self is a qNaN or sNaN; otherwise return False.Return True if self is a normal number; otherwise return False.Return True if self is a quiet NaN; otherwise return False.Return True if self is negative; otherwise return False.Return True if self is a signaling NaN; otherwise return False.Return True if self is subnormal; otherwise return False.Return True if self is a zero; otherwise return False._ln_exp_boundCompute a lower bound for the adjusted exponent of self.ln().
        In other words, compute r such that self.ln() >= 10**r.  Assumes
        that self is finite and positive and that self != 1.
        denReturns the natural (base e) logarithm of self._NegativeInfinity_Infinityln of a negative value_dlogCompute a lower bound for the adjusted exponent of self.log10().
        In other words, find r such that self.log10() >= 10**r.
        Assumes that self is finite and positive and that self != 1.
        231Returns the base 10 logarithm of self.log10 of a negative value_dlog10 Returns the exponent of the magnitude of self's MSD.

        The result is the integer which is the exponent of the magnitude
        of the most significant digit of self (as though it were truncated
        to a single digit while maintaining the value of that digit and
        without limiting the resulting exponent).
        logb(0)_islogicalReturn True if self is a logical operand.

        For being logical, it must be a finite number with a sign of 0,
        an exponent of 0, and a coefficient whose digits must all be
        either 0 or 1.
        01_fill_logicalopaopbdifApplies an 'and' operation between self and other's digits.Invert all its digits.Applies an 'or' operation between self and other's digits.Applies an 'xor' operation between self and other's digits.Compares the values numerically with their sign ignored.Returns the largest representable number smaller than itself._ignore_all_flagsnew_selfReturns the smallest representable number larger than itself.Returns the number closest to self, in the direction towards other.

        The result is the closest representable number to self
        (excluding self) that is in the direction towards other,
        unless both have the same value.  If the two operands are
        numerically equal, then the result is a copy of self with the
        sign set to be the same as the sign of other.
        comparisonInfinite result from next_towardReturns an indication of the class of self.

        The class is one of the following strings:
          sNaN
          NaN
          -Infinity
          -Normal
          -Subnormal
          -Zero
          +Zero
          +Subnormal
          +Normal
          +Infinity
        +Infinity-Infinity-Zero+Zero-Subnormal+Subnormal-Normal+NormalJust returns 10, as this is Decimal, :)Returns a rotated copy of self, value-of-other times.torotrotdigtopadrotatedReturns self operand after adding the second value to its exp.liminflimsupReturns a shifted copy of self, value-of-other times.shiftedspecifier_localeconvFormat a Decimal instance according to the given specifier.

        The specifier should be a standard format specifier, with the
        form described in PEP 3101.  Formatting types 'e', 'E', 'f',
        'F', 'g', 'G', 'n' and '%' are supported.  If the formatting
        type is omitted it defaults to 'g' or 'G', depending on the
        value of context.capitals.
        _parse_format_specifier_format_signbody_format_alignGprecisioneEfF%gG_format_numbercoefficientspecialCreate a decimal instance directly, without any validation,
    normalization (e.g. removal of leading zeros) or argument
    conversion.

    This function is for *internal use only*.
    NumberContext manager class to support localcontext().

      Sets a copy of the supplied context in __enter__() and restores
      the previous decimal context in __exit__()
    new_contextsaved_contextContains the context for a Decimal instance.

    Contains:
    prec - precision (for use in rounding, division, square roots..)
    rounding - rounding type (how you round)
    traps - If traps[exception] = 1, then the exception is
                    raised when it is caused.  Otherwise, a value is
                    substituted in.
    flags  - When an exception is caused, flags[exception] is set.
             (Whether or not the trap_enabler is set)
             Should be reset by user of Decimal instance.
    Emin -   Minimum exponent
    Emax -   Maximum exponent
    capitals -      If 1, 1*10^1 is printed as 1E+1.
                    If 0, printed as 1e1
    clamp -  If 1, change exponents if too high (Default 0)
    _ignored_flags_set_integer_checkvminvmax%s must be an integer-inf%s must be in [%s, %d]. got: %s%s must be in [%d, %s]. got: %s%s must be in [%d, %d]. got %s_set_signal_dict%s must be a signal dict%s is not a valid signal dict%s: invalid rounding mode'decimal.Context' object has no attribute '%s'%s cannot be deletedsigShow the current context.Context(prec=%(prec)d, rounding=%(rounding)s, Emin=%(Emin)d, Emax=%(Emax)d, capitals=%(capitals)d, clamp=%(clamp)d'Context(prec=%(prec)d, rounding=%(rounding)s, ''Emin=%(Emin)d, Emax=%(Emax)d, capitals=%(capitals)d, ''clamp=%(clamp)d'flags=[traps=[Reset all flags to zeroReset all traps to zeroReturns a shallow copy from self.ncReturns a deep copy from self.explanationHandles an error

        If the flag is in _ignored_flags, returns the default response.
        Otherwise, it sets the flag, then, if the corresponding
        trap_enabler is set, it reraises the exception.  Otherwise, it returns
        the default value after setting the flag.
        Ignore all flags, if they are raised_ignore_flagsIgnore the flags, if they are raised_regard_flagsStop ignoring the flags, if they are raisedReturns Etiny (= Emin - prec + 1)Returns maximum exponent (= Emax - prec + 1)Sets the rounding type.

        Sets the rounding type, and returns the current (previous)
        rounding type.  Often used like:

        context = context.copy()
        # so you don't change the calling context
        # if an error occurs in the middle.
        rounding = context._set_rounding(ROUND_UP)
        val = self.__sub__(other, context=context)
        context._set_rounding(rounding)

        This will make it round up for that operation.
        Creates a new Decimal instance but using self as context.

        This method implements the to-number operation of the
        IBM Decimal specification.trailing or leading whitespace and underscores are not permitted."trailing or leading whitespace and ""underscores are not permitted."diagnostic info too long in NaNCreates a new Decimal instance from a float but rounding using self
        as the context.

        >>> context = Context(prec=5, rounding=ROUND_DOWN)
        >>> context.create_decimal_from_float(3.1415926535897932)
        Decimal('3.1415')
        >>> context = Context(prec=5, traps=[Inexact])
        >>> context.create_decimal_from_float(3.1415926535897932)
        Traceback (most recent call last):
            ...
        decimal.Inexact: None

        Returns the absolute value of the operand.

        If the operand is negative, the result is the same as using the minus
        operation on the operand.  Otherwise, the result is the same as using
        the plus operation on the operand.

        >>> ExtendedContext.abs(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.abs(Decimal('-100'))
        Decimal('100')
        >>> ExtendedContext.abs(Decimal('101.5'))
        Decimal('101.5')
        >>> ExtendedContext.abs(Decimal('-101.5'))
        Decimal('101.5')
        >>> ExtendedContext.abs(-1)
        Decimal('1')
        Return the sum of the two operands.

        >>> ExtendedContext.add(Decimal('12'), Decimal('7.00'))
        Decimal('19.00')
        >>> ExtendedContext.add(Decimal('1E+2'), Decimal('1.01E+4'))
        Decimal('1.02E+4')
        >>> ExtendedContext.add(1, Decimal(2))
        Decimal('3')
        >>> ExtendedContext.add(Decimal(8), 5)
        Decimal('13')
        >>> ExtendedContext.add(5, 5)
        Decimal('10')
        Unable to convert %s to DecimalReturns the same Decimal object.

        As we do not have different encodings for the same number, the
        received object already is in its canonical form.

        >>> ExtendedContext.canonical(Decimal('2.50'))
        Decimal('2.50')
        canonical requires a Decimal as an argument.Compares values numerically.

        If the signs of the operands differ, a value representing each operand
        ('-1' if the operand is less than zero, '0' if the operand is zero or
        negative zero, or '1' if the operand is greater than zero) is used in
        place of that operand for the comparison instead of the actual
        operand.

        The comparison is then effected by subtracting the second operand from
        the first and then returning a value according to the result of the
        subtraction: '-1' if the result is less than zero, '0' if the result is
        zero or negative zero, or '1' if the result is greater than zero.

        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.1'))
        Decimal('0')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.10'))
        Decimal('0')
        >>> ExtendedContext.compare(Decimal('3'), Decimal('2.1'))
        Decimal('1')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('-3'))
        Decimal('1')
        >>> ExtendedContext.compare(Decimal('-3'), Decimal('2.1'))
        Decimal('-1')
        >>> ExtendedContext.compare(1, 2)
        Decimal('-1')
        >>> ExtendedContext.compare(Decimal(1), 2)
        Decimal('-1')
        >>> ExtendedContext.compare(1, Decimal(2))
        Decimal('-1')
        Compares the values of the two operands numerically.

        It's pretty much like compare(), but all NaNs signal, with signaling
        NaNs taking precedence over quiet NaNs.

        >>> c = ExtendedContext
        >>> c.compare_signal(Decimal('2.1'), Decimal('3'))
        Decimal('-1')
        >>> c.compare_signal(Decimal('2.1'), Decimal('2.1'))
        Decimal('0')
        >>> c.flags[InvalidOperation] = 0
        >>> print(c.flags[InvalidOperation])
        0
        >>> c.compare_signal(Decimal('NaN'), Decimal('2.1'))
        Decimal('NaN')
        >>> print(c.flags[InvalidOperation])
        1
        >>> c.flags[InvalidOperation] = 0
        >>> print(c.flags[InvalidOperation])
        0
        >>> c.compare_signal(Decimal('sNaN'), Decimal('2.1'))
        Decimal('NaN')
        >>> print(c.flags[InvalidOperation])
        1
        >>> c.compare_signal(-1, 2)
        Decimal('-1')
        >>> c.compare_signal(Decimal(-1), 2)
        Decimal('-1')
        >>> c.compare_signal(-1, Decimal(2))
        Decimal('-1')
        Compares two operands using their abstract representation.

        This is not like the standard compare, which use their numerical
        value. Note that a total ordering is defined for all possible abstract
        representations.

        >>> ExtendedContext.compare_total(Decimal('12.73'), Decimal('127.9'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('-127'),  Decimal('12'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.3'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.30'))
        Decimal('0')
        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('12.300'))
        Decimal('1')
        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('NaN'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(1, 2)
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal(1), 2)
        Decimal('-1')
        >>> ExtendedContext.compare_total(1, Decimal(2))
        Decimal('-1')
        Compares two operands using their abstract representation ignoring sign.

        Like compare_total, but with operand's sign ignored and assumed to be 0.
        Returns a copy of the operand with the sign set to 0.

        >>> ExtendedContext.copy_abs(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.copy_abs(Decimal('-100'))
        Decimal('100')
        >>> ExtendedContext.copy_abs(-1)
        Decimal('1')
        Returns a copy of the decimal object.

        >>> ExtendedContext.copy_decimal(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.copy_decimal(Decimal('-1.00'))
        Decimal('-1.00')
        >>> ExtendedContext.copy_decimal(1)
        Decimal('1')
        Returns a copy of the operand with the sign inverted.

        >>> ExtendedContext.copy_negate(Decimal('101.5'))
        Decimal('-101.5')
        >>> ExtendedContext.copy_negate(Decimal('-101.5'))
        Decimal('101.5')
        >>> ExtendedContext.copy_negate(1)
        Decimal('-1')
        Copies the second operand's sign to the first one.

        In detail, it returns a copy of the first operand with the sign
        equal to the sign of the second operand.

        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('7.33'))
        Decimal('1.50')
        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('7.33'))
        Decimal('1.50')
        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('-7.33'))
        Decimal('-1.50')
        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('-7.33'))
        Decimal('-1.50')
        >>> ExtendedContext.copy_sign(1, -2)
        Decimal('-1')
        >>> ExtendedContext.copy_sign(Decimal(1), -2)
        Decimal('-1')
        >>> ExtendedContext.copy_sign(1, Decimal(-2))
        Decimal('-1')
        Decimal division in a specified context.

        >>> ExtendedContext.divide(Decimal('1'), Decimal('3'))
        Decimal('0.333333333')
        >>> ExtendedContext.divide(Decimal('2'), Decimal('3'))
        Decimal('0.666666667')
        >>> ExtendedContext.divide(Decimal('5'), Decimal('2'))
        Decimal('2.5')
        >>> ExtendedContext.divide(Decimal('1'), Decimal('10'))
        Decimal('0.1')
        >>> ExtendedContext.divide(Decimal('12'), Decimal('12'))
        Decimal('1')
        >>> ExtendedContext.divide(Decimal('8.00'), Decimal('2'))
        Decimal('4.00')
        >>> ExtendedContext.divide(Decimal('2.400'), Decimal('2.0'))
        Decimal('1.20')
        >>> ExtendedContext.divide(Decimal('1000'), Decimal('100'))
        Decimal('10')
        >>> ExtendedContext.divide(Decimal('1000'), Decimal('1'))
        Decimal('1000')
        >>> ExtendedContext.divide(Decimal('2.40E+6'), Decimal('2'))
        Decimal('1.20E+6')
        >>> ExtendedContext.divide(5, 5)
        Decimal('1')
        >>> ExtendedContext.divide(Decimal(5), 5)
        Decimal('1')
        >>> ExtendedContext.divide(5, Decimal(5))
        Decimal('1')
        Divides two numbers and returns the integer part of the result.

        >>> ExtendedContext.divide_int(Decimal('2'), Decimal('3'))
        Decimal('0')
        >>> ExtendedContext.divide_int(Decimal('10'), Decimal('3'))
        Decimal('3')
        >>> ExtendedContext.divide_int(Decimal('1'), Decimal('0.3'))
        Decimal('3')
        >>> ExtendedContext.divide_int(10, 3)
        Decimal('3')
        >>> ExtendedContext.divide_int(Decimal(10), 3)
        Decimal('3')
        >>> ExtendedContext.divide_int(10, Decimal(3))
        Decimal('3')
        Return (a // b, a % b).

        >>> ExtendedContext.divmod(Decimal(8), Decimal(3))
        (Decimal('2'), Decimal('2'))
        >>> ExtendedContext.divmod(Decimal(8), Decimal(4))
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(8, 4)
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(Decimal(8), 4)
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(8, Decimal(4))
        (Decimal('2'), Decimal('0'))
        Returns e ** a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.exp(Decimal('-Infinity'))
        Decimal('0')
        >>> c.exp(Decimal('-1'))
        Decimal('0.367879441')
        >>> c.exp(Decimal('0'))
        Decimal('1')
        >>> c.exp(Decimal('1'))
        Decimal('2.71828183')
        >>> c.exp(Decimal('0.693147181'))
        Decimal('2.00000000')
        >>> c.exp(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.exp(10)
        Decimal('22026.4658')
        Returns a multiplied by b, plus c.

        The first two operands are multiplied together, using multiply,
        the third operand is then added to the result of that
        multiplication, using add, all with only one final rounding.

        >>> ExtendedContext.fma(Decimal('3'), Decimal('5'), Decimal('7'))
        Decimal('22')
        >>> ExtendedContext.fma(Decimal('3'), Decimal('-5'), Decimal('7'))
        Decimal('-8')
        >>> ExtendedContext.fma(Decimal('888565290'), Decimal('1557.96930'), Decimal('-86087.7578'))
        Decimal('1.38435736E+12')
        >>> ExtendedContext.fma(1, 3, 4)
        Decimal('7')
        >>> ExtendedContext.fma(1, Decimal(3), 4)
        Decimal('7')
        >>> ExtendedContext.fma(1, 3, Decimal(4))
        Decimal('7')
        Return True if the operand is canonical; otherwise return False.

        Currently, the encoding of a Decimal instance is always
        canonical, so this method returns True for any Decimal.

        >>> ExtendedContext.is_canonical(Decimal('2.50'))
        True
        is_canonical requires a Decimal as an argument.Return True if the operand is finite; otherwise return False.

        A Decimal instance is considered finite if it is neither
        infinite nor a NaN.

        >>> ExtendedContext.is_finite(Decimal('2.50'))
        True
        >>> ExtendedContext.is_finite(Decimal('-0.3'))
        True
        >>> ExtendedContext.is_finite(Decimal('0'))
        True
        >>> ExtendedContext.is_finite(Decimal('Inf'))
        False
        >>> ExtendedContext.is_finite(Decimal('NaN'))
        False
        >>> ExtendedContext.is_finite(1)
        True
        Return True if the operand is infinite; otherwise return False.

        >>> ExtendedContext.is_infinite(Decimal('2.50'))
        False
        >>> ExtendedContext.is_infinite(Decimal('-Inf'))
        True
        >>> ExtendedContext.is_infinite(Decimal('NaN'))
        False
        >>> ExtendedContext.is_infinite(1)
        False
        Return True if the operand is a qNaN or sNaN;
        otherwise return False.

        >>> ExtendedContext.is_nan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_nan(Decimal('NaN'))
        True
        >>> ExtendedContext.is_nan(Decimal('-sNaN'))
        True
        >>> ExtendedContext.is_nan(1)
        False
        Return True if the operand is a normal number;
        otherwise return False.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.is_normal(Decimal('2.50'))
        True
        >>> c.is_normal(Decimal('0.1E-999'))
        False
        >>> c.is_normal(Decimal('0.00'))
        False
        >>> c.is_normal(Decimal('-Inf'))
        False
        >>> c.is_normal(Decimal('NaN'))
        False
        >>> c.is_normal(1)
        True
        Return True if the operand is a quiet NaN; otherwise return False.

        >>> ExtendedContext.is_qnan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_qnan(Decimal('NaN'))
        True
        >>> ExtendedContext.is_qnan(Decimal('sNaN'))
        False
        >>> ExtendedContext.is_qnan(1)
        False
        Return True if the operand is negative; otherwise return False.

        >>> ExtendedContext.is_signed(Decimal('2.50'))
        False
        >>> ExtendedContext.is_signed(Decimal('-12'))
        True
        >>> ExtendedContext.is_signed(Decimal('-0'))
        True
        >>> ExtendedContext.is_signed(8)
        False
        >>> ExtendedContext.is_signed(-8)
        True
        Return True if the operand is a signaling NaN;
        otherwise return False.

        >>> ExtendedContext.is_snan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_snan(Decimal('NaN'))
        False
        >>> ExtendedContext.is_snan(Decimal('sNaN'))
        True
        >>> ExtendedContext.is_snan(1)
        False
        Return True if the operand is subnormal; otherwise return False.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.is_subnormal(Decimal('2.50'))
        False
        >>> c.is_subnormal(Decimal('0.1E-999'))
        True
        >>> c.is_subnormal(Decimal('0.00'))
        False
        >>> c.is_subnormal(Decimal('-Inf'))
        False
        >>> c.is_subnormal(Decimal('NaN'))
        False
        >>> c.is_subnormal(1)
        False
        Return True if the operand is a zero; otherwise return False.

        >>> ExtendedContext.is_zero(Decimal('0'))
        True
        >>> ExtendedContext.is_zero(Decimal('2.50'))
        False
        >>> ExtendedContext.is_zero(Decimal('-0E+2'))
        True
        >>> ExtendedContext.is_zero(1)
        False
        >>> ExtendedContext.is_zero(0)
        True
        Returns the natural (base e) logarithm of the operand.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.ln(Decimal('0'))
        Decimal('-Infinity')
        >>> c.ln(Decimal('1.000'))
        Decimal('0')
        >>> c.ln(Decimal('2.71828183'))
        Decimal('1.00000000')
        >>> c.ln(Decimal('10'))
        Decimal('2.30258509')
        >>> c.ln(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.ln(1)
        Decimal('0')
        Returns the base 10 logarithm of the operand.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.log10(Decimal('0'))
        Decimal('-Infinity')
        >>> c.log10(Decimal('0.001'))
        Decimal('-3')
        >>> c.log10(Decimal('1.000'))
        Decimal('0')
        >>> c.log10(Decimal('2'))
        Decimal('0.301029996')
        >>> c.log10(Decimal('10'))
        Decimal('1')
        >>> c.log10(Decimal('70'))
        Decimal('1.84509804')
        >>> c.log10(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.log10(0)
        Decimal('-Infinity')
        >>> c.log10(1)
        Decimal('0')
         Returns the exponent of the magnitude of the operand's MSD.

        The result is the integer which is the exponent of the magnitude
        of the most significant digit of the operand (as though the
        operand were truncated to a single digit while maintaining the
        value of that digit and without limiting the resulting exponent).

        >>> ExtendedContext.logb(Decimal('250'))
        Decimal('2')
        >>> ExtendedContext.logb(Decimal('2.50'))
        Decimal('0')
        >>> ExtendedContext.logb(Decimal('0.03'))
        Decimal('-2')
        >>> ExtendedContext.logb(Decimal('0'))
        Decimal('-Infinity')
        >>> ExtendedContext.logb(1)
        Decimal('0')
        >>> ExtendedContext.logb(10)
        Decimal('1')
        >>> ExtendedContext.logb(100)
        Decimal('2')
        Applies the logical operation 'and' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('1'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_and(Decimal('1100'), Decimal('1010'))
        Decimal('1000')
        >>> ExtendedContext.logical_and(Decimal('1111'), Decimal('10'))
        Decimal('10')
        >>> ExtendedContext.logical_and(110, 1101)
        Decimal('100')
        >>> ExtendedContext.logical_and(Decimal(110), 1101)
        Decimal('100')
        >>> ExtendedContext.logical_and(110, Decimal(1101))
        Decimal('100')
        Invert all the digits in the operand.

        The operand must be a logical number.

        >>> ExtendedContext.logical_invert(Decimal('0'))
        Decimal('111111111')
        >>> ExtendedContext.logical_invert(Decimal('1'))
        Decimal('111111110')
        >>> ExtendedContext.logical_invert(Decimal('111111111'))
        Decimal('0')
        >>> ExtendedContext.logical_invert(Decimal('101010101'))
        Decimal('10101010')
        >>> ExtendedContext.logical_invert(1101)
        Decimal('111110010')
        Applies the logical operation 'or' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('0'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1100'), Decimal('1010'))
        Decimal('1110')
        >>> ExtendedContext.logical_or(Decimal('1110'), Decimal('10'))
        Decimal('1110')
        >>> ExtendedContext.logical_or(110, 1101)
        Decimal('1111')
        >>> ExtendedContext.logical_or(Decimal(110), 1101)
        Decimal('1111')
        >>> ExtendedContext.logical_or(110, Decimal(1101))
        Decimal('1111')
        Applies the logical operation 'xor' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('0'))
        Decimal('1')
        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('1'))
        Decimal('0')
        >>> ExtendedContext.logical_xor(Decimal('1100'), Decimal('1010'))
        Decimal('110')
        >>> ExtendedContext.logical_xor(Decimal('1111'), Decimal('10'))
        Decimal('1101')
        >>> ExtendedContext.logical_xor(110, 1101)
        Decimal('1011')
        >>> ExtendedContext.logical_xor(Decimal(110), 1101)
        Decimal('1011')
        >>> ExtendedContext.logical_xor(110, Decimal(1101))
        Decimal('1011')
        max compares two values numerically and returns the maximum.

        If either operand is a NaN then the general rules apply.
        Otherwise, the operands are compared as though by the compare
        operation.  If they are numerically equal then the left-hand operand
        is chosen as the result.  Otherwise the maximum (closer to positive
        infinity) of the two operands is chosen as the result.

        >>> ExtendedContext.max(Decimal('3'), Decimal('2'))
        Decimal('3')
        >>> ExtendedContext.max(Decimal('-10'), Decimal('3'))
        Decimal('3')
        >>> ExtendedContext.max(Decimal('1.0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.max(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.max(1, 2)
        Decimal('2')
        >>> ExtendedContext.max(Decimal(1), 2)
        Decimal('2')
        >>> ExtendedContext.max(1, Decimal(2))
        Decimal('2')
        Compares the values numerically with their sign ignored.

        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('-10'))
        Decimal('-10')
        >>> ExtendedContext.max_mag(1, -2)
        Decimal('-2')
        >>> ExtendedContext.max_mag(Decimal(1), -2)
        Decimal('-2')
        >>> ExtendedContext.max_mag(1, Decimal(-2))
        Decimal('-2')
        min compares two values numerically and returns the minimum.

        If either operand is a NaN then the general rules apply.
        Otherwise, the operands are compared as though by the compare
        operation.  If they are numerically equal then the left-hand operand
        is chosen as the result.  Otherwise the minimum (closer to negative
        infinity) of the two operands is chosen as the result.

        >>> ExtendedContext.min(Decimal('3'), Decimal('2'))
        Decimal('2')
        >>> ExtendedContext.min(Decimal('-10'), Decimal('3'))
        Decimal('-10')
        >>> ExtendedContext.min(Decimal('1.0'), Decimal('1'))
        Decimal('1.0')
        >>> ExtendedContext.min(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.min(1, 2)
        Decimal('1')
        >>> ExtendedContext.min(Decimal(1), 2)
        Decimal('1')
        >>> ExtendedContext.min(1, Decimal(29))
        Decimal('1')
        Compares the values numerically with their sign ignored.

        >>> ExtendedContext.min_mag(Decimal('3'), Decimal('-2'))
        Decimal('-2')
        >>> ExtendedContext.min_mag(Decimal('-3'), Decimal('NaN'))
        Decimal('-3')
        >>> ExtendedContext.min_mag(1, -2)
        Decimal('1')
        >>> ExtendedContext.min_mag(Decimal(1), -2)
        Decimal('1')
        >>> ExtendedContext.min_mag(1, Decimal(-2))
        Decimal('1')
        Minus corresponds to unary prefix minus in Python.

        The operation is evaluated using the same rules as subtract; the
        operation minus(a) is calculated as subtract('0', a) where the '0'
        has the same exponent as the operand.

        >>> ExtendedContext.minus(Decimal('1.3'))
        Decimal('-1.3')
        >>> ExtendedContext.minus(Decimal('-1.3'))
        Decimal('1.3')
        >>> ExtendedContext.minus(1)
        Decimal('-1')
        multiply multiplies two operands.

        If either operand is a special value then the general rules apply.
        Otherwise, the operands are multiplied together
        ('long multiplication'), resulting in a number which may be as long as
        the sum of the lengths of the two operands.

        >>> ExtendedContext.multiply(Decimal('1.20'), Decimal('3'))
        Decimal('3.60')
        >>> ExtendedContext.multiply(Decimal('7'), Decimal('3'))
        Decimal('21')
        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('0.8'))
        Decimal('0.72')
        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('-0'))
        Decimal('-0.0')
        >>> ExtendedContext.multiply(Decimal('654321'), Decimal('654321'))
        Decimal('4.28135971E+11')
        >>> ExtendedContext.multiply(7, 7)
        Decimal('49')
        >>> ExtendedContext.multiply(Decimal(7), 7)
        Decimal('49')
        >>> ExtendedContext.multiply(7, Decimal(7))
        Decimal('49')
        Returns the largest representable number smaller than a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> ExtendedContext.next_minus(Decimal('1'))
        Decimal('0.999999999')
        >>> c.next_minus(Decimal('1E-1007'))
        Decimal('0E-1007')
        >>> ExtendedContext.next_minus(Decimal('-1.00000003'))
        Decimal('-1.00000004')
        >>> c.next_minus(Decimal('Infinity'))
        Decimal('9.99999999E+999')
        >>> c.next_minus(1)
        Decimal('0.999999999')
        Returns the smallest representable number larger than a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> ExtendedContext.next_plus(Decimal('1'))
        Decimal('1.00000001')
        >>> c.next_plus(Decimal('-1E-1007'))
        Decimal('-0E-1007')
        >>> ExtendedContext.next_plus(Decimal('-1.00000003'))
        Decimal('-1.00000002')
        >>> c.next_plus(Decimal('-Infinity'))
        Decimal('-9.99999999E+999')
        >>> c.next_plus(1)
        Decimal('1.00000001')
        Returns the number closest to a, in direction towards b.

        The result is the closest representable number from the first
        operand (but not the first operand) that is in the direction
        towards the second operand, unless the operands have the same
        value.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.next_toward(Decimal('1'), Decimal('2'))
        Decimal('1.00000001')
        >>> c.next_toward(Decimal('-1E-1007'), Decimal('1'))
        Decimal('-0E-1007')
        >>> c.next_toward(Decimal('-1.00000003'), Decimal('0'))
        Decimal('-1.00000002')
        >>> c.next_toward(Decimal('1'), Decimal('0'))
        Decimal('0.999999999')
        >>> c.next_toward(Decimal('1E-1007'), Decimal('-100'))
        Decimal('0E-1007')
        >>> c.next_toward(Decimal('-1.00000003'), Decimal('-10'))
        Decimal('-1.00000004')
        >>> c.next_toward(Decimal('0.00'), Decimal('-0.0000'))
        Decimal('-0.00')
        >>> c.next_toward(0, 1)
        Decimal('1E-1007')
        >>> c.next_toward(Decimal(0), 1)
        Decimal('1E-1007')
        >>> c.next_toward(0, Decimal(1))
        Decimal('1E-1007')
        normalize reduces an operand to its simplest form.

        Essentially a plus operation with all trailing zeros removed from the
        result.

        >>> ExtendedContext.normalize(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.normalize(Decimal('-2.0'))
        Decimal('-2')
        >>> ExtendedContext.normalize(Decimal('1.200'))
        Decimal('1.2')
        >>> ExtendedContext.normalize(Decimal('-120'))
        Decimal('-1.2E+2')
        >>> ExtendedContext.normalize(Decimal('120.00'))
        Decimal('1.2E+2')
        >>> ExtendedContext.normalize(Decimal('0.00'))
        Decimal('0')
        >>> ExtendedContext.normalize(6)
        Decimal('6')
        Returns an indication of the class of the operand.

        The class is one of the following strings:
          -sNaN
          -NaN
          -Infinity
          -Normal
          -Subnormal
          -Zero
          +Zero
          +Subnormal
          +Normal
          +Infinity

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.number_class(Decimal('Infinity'))
        '+Infinity'
        >>> c.number_class(Decimal('1E-10'))
        '+Normal'
        >>> c.number_class(Decimal('2.50'))
        '+Normal'
        >>> c.number_class(Decimal('0.1E-999'))
        '+Subnormal'
        >>> c.number_class(Decimal('0'))
        '+Zero'
        >>> c.number_class(Decimal('-0'))
        '-Zero'
        >>> c.number_class(Decimal('-0.1E-999'))
        '-Subnormal'
        >>> c.number_class(Decimal('-1E-10'))
        '-Normal'
        >>> c.number_class(Decimal('-2.50'))
        '-Normal'
        >>> c.number_class(Decimal('-Infinity'))
        '-Infinity'
        >>> c.number_class(Decimal('NaN'))
        'NaN'
        >>> c.number_class(Decimal('-NaN'))
        'NaN'
        >>> c.number_class(Decimal('sNaN'))
        'sNaN'
        >>> c.number_class(123)
        '+Normal'
        Plus corresponds to unary prefix plus in Python.

        The operation is evaluated using the same rules as add; the
        operation plus(a) is calculated as add('0', a) where the '0'
        has the same exponent as the operand.

        >>> ExtendedContext.plus(Decimal('1.3'))
        Decimal('1.3')
        >>> ExtendedContext.plus(Decimal('-1.3'))
        Decimal('-1.3')
        >>> ExtendedContext.plus(-1)
        Decimal('-1')
        Raises a to the power of b, to modulo if given.

        With two arguments, compute a**b.  If a is negative then b
        must be integral.  The result will be inexact unless b is
        integral and the result is finite and can be expressed exactly
        in 'precision' digits.

        With three arguments, compute (a**b) % modulo.  For the
        three argument form, the following restrictions on the
        arguments hold:

         - all three arguments must be integral
         - b must be nonnegative
         - at least one of a or b must be nonzero
         - modulo must be nonzero and have at most 'precision' digits

        The result of pow(a, b, modulo) is identical to the result
        that would be obtained by computing (a**b) % modulo with
        unbounded precision, but is computed more efficiently.  It is
        always exact.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.power(Decimal('2'), Decimal('3'))
        Decimal('8')
        >>> c.power(Decimal('-2'), Decimal('3'))
        Decimal('-8')
        >>> c.power(Decimal('2'), Decimal('-3'))
        Decimal('0.125')
        >>> c.power(Decimal('1.7'), Decimal('8'))
        Decimal('69.7575744')
        >>> c.power(Decimal('10'), Decimal('0.301029996'))
        Decimal('2.00000000')
        >>> c.power(Decimal('Infinity'), Decimal('-1'))
        Decimal('0')
        >>> c.power(Decimal('Infinity'), Decimal('0'))
        Decimal('1')
        >>> c.power(Decimal('Infinity'), Decimal('1'))
        Decimal('Infinity')
        >>> c.power(Decimal('-Infinity'), Decimal('-1'))
        Decimal('-0')
        >>> c.power(Decimal('-Infinity'), Decimal('0'))
        Decimal('1')
        >>> c.power(Decimal('-Infinity'), Decimal('1'))
        Decimal('-Infinity')
        >>> c.power(Decimal('-Infinity'), Decimal('2'))
        Decimal('Infinity')
        >>> c.power(Decimal('0'), Decimal('0'))
        Decimal('NaN')

        >>> c.power(Decimal('3'), Decimal('7'), Decimal('16'))
        Decimal('11')
        >>> c.power(Decimal('-3'), Decimal('7'), Decimal('16'))
        Decimal('-11')
        >>> c.power(Decimal('-3'), Decimal('8'), Decimal('16'))
        Decimal('1')
        >>> c.power(Decimal('3'), Decimal('7'), Decimal('-16'))
        Decimal('11')
        >>> c.power(Decimal('23E12345'), Decimal('67E189'), Decimal('123456789'))
        Decimal('11729830')
        >>> c.power(Decimal('-0'), Decimal('17'), Decimal('1729'))
        Decimal('-0')
        >>> c.power(Decimal('-23'), Decimal('0'), Decimal('65537'))
        Decimal('1')
        >>> ExtendedContext.power(7, 7)
        Decimal('823543')
        >>> ExtendedContext.power(Decimal(7), 7)
        Decimal('823543')
        >>> ExtendedContext.power(7, Decimal(7), 2)
        Decimal('1')
        Returns a value equal to 'a' (rounded), having the exponent of 'b'.

        The coefficient of the result is derived from that of the left-hand
        operand.  It may be rounded using the current rounding setting (if the
        exponent is being increased), multiplied by a positive power of ten (if
        the exponent is being decreased), or is unchanged (if the exponent is
        already equal to that of the right-hand operand).

        Unlike other operations, if the length of the coefficient after the
        quantize operation would be greater than precision then an Invalid
        operation condition is raised.  This guarantees that, unless there is
        an error condition, the exponent of the result of a quantize is always
        equal to that of the right-hand operand.

        Also unlike other operations, quantize will never raise Underflow, even
        if the result is subnormal and inexact.

        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.001'))
        Decimal('2.170')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.01'))
        Decimal('2.17')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.1'))
        Decimal('2.2')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+0'))
        Decimal('2')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+1'))
        Decimal('0E+1')
        >>> ExtendedContext.quantize(Decimal('-Inf'), Decimal('Infinity'))
        Decimal('-Infinity')
        >>> ExtendedContext.quantize(Decimal('2'), Decimal('Infinity'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('-0.1'), Decimal('1'))
        Decimal('-0')
        >>> ExtendedContext.quantize(Decimal('-0'), Decimal('1e+5'))
        Decimal('-0E+5')
        >>> ExtendedContext.quantize(Decimal('+35236450.6'), Decimal('1e-2'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('-35236450.6'), Decimal('1e-2'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-1'))
        Decimal('217.0')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-0'))
        Decimal('217')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+1'))
        Decimal('2.2E+2')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+2'))
        Decimal('2E+2')
        >>> ExtendedContext.quantize(1, 2)
        Decimal('1')
        >>> ExtendedContext.quantize(Decimal(1), 2)
        Decimal('1')
        >>> ExtendedContext.quantize(1, Decimal(2))
        Decimal('1')
        Just returns 10, as this is Decimal, :)

        >>> ExtendedContext.radix()
        Decimal('10')
        Returns the remainder from integer division.

        The result is the residue of the dividend after the operation of
        calculating integer division as described for divide-integer, rounded
        to precision digits if necessary.  The sign of the result, if
        non-zero, is the same as that of the original dividend.

        This operation will fail under the same conditions as integer division
        (that is, if integer division on the same two operands would fail, the
        remainder cannot be calculated).

        >>> ExtendedContext.remainder(Decimal('2.1'), Decimal('3'))
        Decimal('2.1')
        >>> ExtendedContext.remainder(Decimal('10'), Decimal('3'))
        Decimal('1')
        >>> ExtendedContext.remainder(Decimal('-10'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.remainder(Decimal('10.2'), Decimal('1'))
        Decimal('0.2')
        >>> ExtendedContext.remainder(Decimal('10'), Decimal('0.3'))
        Decimal('0.1')
        >>> ExtendedContext.remainder(Decimal('3.6'), Decimal('1.3'))
        Decimal('1.0')
        >>> ExtendedContext.remainder(22, 6)
        Decimal('4')
        >>> ExtendedContext.remainder(Decimal(22), 6)
        Decimal('4')
        >>> ExtendedContext.remainder(22, Decimal(6))
        Decimal('4')
        Returns to be "a - b * n", where n is the integer nearest the exact
        value of "x / b" (if two integers are equally near then the even one
        is chosen).  If the result is equal to 0 then its sign will be the
        sign of a.

        This operation will fail under the same conditions as integer division
        (that is, if integer division on the same two operands would fail, the
        remainder cannot be calculated).

        >>> ExtendedContext.remainder_near(Decimal('2.1'), Decimal('3'))
        Decimal('-0.9')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('6'))
        Decimal('-2')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('3'))
        Decimal('1')
        >>> ExtendedContext.remainder_near(Decimal('-10'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.remainder_near(Decimal('10.2'), Decimal('1'))
        Decimal('0.2')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('0.3'))
        Decimal('0.1')
        >>> ExtendedContext.remainder_near(Decimal('3.6'), Decimal('1.3'))
        Decimal('-0.3')
        >>> ExtendedContext.remainder_near(3, 11)
        Decimal('3')
        >>> ExtendedContext.remainder_near(Decimal(3), 11)
        Decimal('3')
        >>> ExtendedContext.remainder_near(3, Decimal(11))
        Decimal('3')
        Returns a rotated copy of a, b times.

        The coefficient of the result is a rotated copy of the digits in
        the coefficient of the first operand.  The number of places of
        rotation is taken from the absolute value of the second operand,
        with the rotation being to the left if the second operand is
        positive or to the right otherwise.

        >>> ExtendedContext.rotate(Decimal('34'), Decimal('8'))
        Decimal('400000003')
        >>> ExtendedContext.rotate(Decimal('12'), Decimal('9'))
        Decimal('12')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('-2'))
        Decimal('891234567')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('0'))
        Decimal('123456789')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('+2'))
        Decimal('345678912')
        >>> ExtendedContext.rotate(1333333, 1)
        Decimal('13333330')
        >>> ExtendedContext.rotate(Decimal(1333333), 1)
        Decimal('13333330')
        >>> ExtendedContext.rotate(1333333, Decimal(1))
        Decimal('13333330')
        Returns True if the two operands have the same exponent.

        The result is never affected by either the sign or the coefficient of
        either operand.

        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.001'))
        False
        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.01'))
        True
        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('1'))
        False
        >>> ExtendedContext.same_quantum(Decimal('Inf'), Decimal('-Inf'))
        True
        >>> ExtendedContext.same_quantum(10000, -1)
        True
        >>> ExtendedContext.same_quantum(Decimal(10000), -1)
        True
        >>> ExtendedContext.same_quantum(10000, Decimal(-1))
        True
        Returns the first operand after adding the second value its exp.

        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('-2'))
        Decimal('0.0750')
        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('0'))
        Decimal('7.50')
        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('3'))
        Decimal('7.50E+3')
        >>> ExtendedContext.scaleb(1, 4)
        Decimal('1E+4')
        >>> ExtendedContext.scaleb(Decimal(1), 4)
        Decimal('1E+4')
        >>> ExtendedContext.scaleb(1, Decimal(4))
        Decimal('1E+4')
        Returns a shifted copy of a, b times.

        The coefficient of the result is a shifted copy of the digits
        in the coefficient of the first operand.  The number of places
        to shift is taken from the absolute value of the second operand,
        with the shift being to the left if the second operand is
        positive or to the right otherwise.  Digits shifted into the
        coefficient are zeros.

        >>> ExtendedContext.shift(Decimal('34'), Decimal('8'))
        Decimal('400000000')
        >>> ExtendedContext.shift(Decimal('12'), Decimal('9'))
        Decimal('0')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('-2'))
        Decimal('1234567')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('0'))
        Decimal('123456789')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('+2'))
        Decimal('345678900')
        >>> ExtendedContext.shift(88888888, 2)
        Decimal('888888800')
        >>> ExtendedContext.shift(Decimal(88888888), 2)
        Decimal('888888800')
        >>> ExtendedContext.shift(88888888, Decimal(2))
        Decimal('888888800')
        Square root of a non-negative number to context precision.

        If the result must be inexact, it is rounded using the round-half-even
        algorithm.

        >>> ExtendedContext.sqrt(Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.sqrt(Decimal('-0'))
        Decimal('-0')
        >>> ExtendedContext.sqrt(Decimal('0.39'))
        Decimal('0.624499800')
        >>> ExtendedContext.sqrt(Decimal('100'))
        Decimal('10')
        >>> ExtendedContext.sqrt(Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.sqrt(Decimal('1.0'))
        Decimal('1.0')
        >>> ExtendedContext.sqrt(Decimal('1.00'))
        Decimal('1.0')
        >>> ExtendedContext.sqrt(Decimal('7'))
        Decimal('2.64575131')
        >>> ExtendedContext.sqrt(Decimal('10'))
        Decimal('3.16227766')
        >>> ExtendedContext.sqrt(2)
        Decimal('1.41421356')
        >>> ExtendedContext.prec
        9
        Return the difference between the two operands.

        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.07'))
        Decimal('0.23')
        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.30'))
        Decimal('0.00')
        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('2.07'))
        Decimal('-0.77')
        >>> ExtendedContext.subtract(8, 5)
        Decimal('3')
        >>> ExtendedContext.subtract(Decimal(8), 5)
        Decimal('3')
        >>> ExtendedContext.subtract(8, Decimal(5))
        Decimal('3')
        Convert to a string, using engineering notation if an exponent is needed.

        Engineering notation has an exponent which is a multiple of 3.  This
        can leave up to 3 digits to the left of the decimal place and may
        require the addition of either one or two trailing zeros.

        The operation is not affected by the context.

        >>> ExtendedContext.to_eng_string(Decimal('123E+1'))
        '1.23E+3'
        >>> ExtendedContext.to_eng_string(Decimal('123E+3'))
        '123E+3'
        >>> ExtendedContext.to_eng_string(Decimal('123E-10'))
        '12.3E-9'
        >>> ExtendedContext.to_eng_string(Decimal('-123E-12'))
        '-123E-12'
        >>> ExtendedContext.to_eng_string(Decimal('7E-7'))
        '700E-9'
        >>> ExtendedContext.to_eng_string(Decimal('7E+1'))
        '70'
        >>> ExtendedContext.to_eng_string(Decimal('0E+1'))
        '0.00E+3'

        Converts a number to a string, using scientific notation.

        The operation is not affected by the context.
        Rounds to an integer.

        When the operand has a negative exponent, the result is the same
        as using the quantize() operation using the given operand as the
        left-hand-operand, 1E+0 as the right-hand-operand, and the precision
        of the operand as the precision setting; Inexact and Rounded flags
        are allowed in this operation.  The rounding mode is taken from the
        context.

        >>> ExtendedContext.to_integral_exact(Decimal('2.1'))
        Decimal('2')
        >>> ExtendedContext.to_integral_exact(Decimal('100'))
        Decimal('100')
        >>> ExtendedContext.to_integral_exact(Decimal('100.0'))
        Decimal('100')
        >>> ExtendedContext.to_integral_exact(Decimal('101.5'))
        Decimal('102')
        >>> ExtendedContext.to_integral_exact(Decimal('-101.5'))
        Decimal('-102')
        >>> ExtendedContext.to_integral_exact(Decimal('10E+5'))
        Decimal('1.0E+6')
        >>> ExtendedContext.to_integral_exact(Decimal('7.89E+77'))
        Decimal('7.89E+77')
        >>> ExtendedContext.to_integral_exact(Decimal('-Inf'))
        Decimal('-Infinity')
        Rounds to an integer.

        When the operand has a negative exponent, the result is the same
        as using the quantize() operation using the given operand as the
        left-hand-operand, 1E+0 as the right-hand-operand, and the precision
        of the operand as the precision setting, except that no flags will
        be set.  The rounding mode is taken from the context.

        >>> ExtendedContext.to_integral_value(Decimal('2.1'))
        Decimal('2')
        >>> ExtendedContext.to_integral_value(Decimal('100'))
        Decimal('100')
        >>> ExtendedContext.to_integral_value(Decimal('100.0'))
        Decimal('100')
        >>> ExtendedContext.to_integral_value(Decimal('101.5'))
        Decimal('102')
        >>> ExtendedContext.to_integral_value(Decimal('-101.5'))
        Decimal('-102')
        >>> ExtendedContext.to_integral_value(Decimal('10E+5'))
        Decimal('1.0E+6')
        >>> ExtendedContext.to_integral_value(Decimal('7.89E+77'))
        Decimal('7.89E+77')
        >>> ExtendedContext.to_integral_value(Decimal('-Inf'))
        Decimal('-Infinity')
        (%r, %r, %r)Normalizes op1, op2 to have the same exp and length of coefficient.

    Done during addition.
    tmptmp_lenother_len Given integers n and e, return n * 10**e if it's an integer, else None.

    The computation is designed to avoid computing large powers of 10
    unnecessarily.

    >>> _decimal_lshift_exact(3, 4)
    30000
    >>> _decimal_lshift_exact(300, -999999999)  # returns None

    str_nval_n_sqrt_nearestClosest integer to the square root of the positive integer n.  a is
    an initial approximation to the square root.  Any positive integer
    will do for a, but the closer a is to the square root of n the
    faster convergence will be.

    Both arguments to _sqrt_nearest should be positive._rshift_nearestGiven an integer x and a nonnegative integer shift, return closest
    integer to x / 2**shift; use round-to-even in case of a tie.

    _div_nearestClosest integer to a/b, a and b positive integers; rounds to even
    in the case of a tie.

    _ilogInteger approximation to M*log(x/M), with absolute error boundable
    in terms only of x/M.

    Given positive integers x and M, return an integer approximation to
    M * log(x/M).  For L = 8 and 0.1 <= x/M <= 10 the difference
    between the approximation and the exact result is at most 22.  For
    L = 8 and 1.0 <= x/M <= 10.0 the difference is at most 15.  In
    both cases these are upper bounds on the error; it will usually be
    much smaller.RyshiftGiven integers c, e and p with c > 0, p >= 0, compute an integer
    approximation to 10**p * log10(c*10**e), with an absolute error of
    at most 1.  Assumes that c*10**e is not exactly 1.log_d_log10_digitslog_10log_tenpowerGiven integers c, e and p with c > 0, compute an integer
    approximation to 10**p * log(c*10**e), with an absolute error of
    at most 1.  Assumes that c*10**e is not exactly 1.f_log_ten_Log10MemoizeClass to compute, store, and allow retrieval of, digits of the
    constant log(10) = 2.302585....  This constant is needed by
    Decimal.ln, Decimal.log10, Decimal.exp and Decimal.__pow__.23025850929940456840179914546843642076011014886getdigitsGiven an integer p >= 0, return floor(10**p)*log(10).

        For example, self.getdigits(3) returns 2302.
        p should be nonnegative_iexpGiven integers x and M, M > 0, such that x/M is small in absolute
    value, compute an integer approximation to M*exp(x/M).  For 0 <=
    x/M <= 2.4, the absolute error in the result is bounded by 60 (and
    is usually much smaller).MshiftCompute an approximation to exp(c*10**e), with p decimal places of
    precision.

    Returns integers d, f such that:

      10**(p-1) <= d <= 10**p, and
      (d-1)*10**f < exp(c*10**e) < (d+1)*10**f

    In other words, d*10**f is an approximation to exp(c*10**e) with p
    digits of precision, and with an error in d of at most 1.  This is
    almost, but not quite, the same as the error being < 1ulp: when d
    = 10**(p-1) the error could be up to 10 ulp.cshiftquotGiven integers xc, xe, yc and ye representing Decimals x = xc*10**xe and
    y = yc*10**ye, compute x**y.  Returns a pair of integers (c, e) such that:

      10**(p-1) <= c <= 10**p, and
      (c-1)*10**e < x**y < (c+1)*10**e

    in other words, c*10**e is an approximation to x**y with p digits
    of precision, and with an error in c of at most 1.  (This is
    almost, but not quite, the same as the error being < 1ulp: when c
    == 10**(p-1) we can only guarantee error < 10ulp.)

    We assume that: x is positive and not equal to 1, and y is nonzero.
    lxcpc70correctionCompute a lower bound for 100*log10(c) for a positive integer c.The argument to _log10_lb should be nonnegative.str_callow_floatConvert other to Decimal.

    Verifies that it's ok to use in an implicit construction.
    If allow_float is true, allow conversion from float;  this
    is used in the comparison methods (__eq__ and friends).

    Given a Decimal instance self and a Python object other, return
    a pair (s, o) of Decimal instances such that "s op o" is
    equivalent to "self op other" for any of the 6 comparison
    operators "op".

    RationalComplex999999        # A numeric string consists of:
#    \s*
    (?P<sign>[-+])?              # an optional sign, followed by either...
    (
        (?=\d|\.\d)              # ...a number (with at least one digit)
        (?P<int>\d*)             # having a (possibly empty) integer part
        (\.(?P<frac>\d*))?       # followed by an optional fractional part
        (E(?P<exp>[-+]?\d+))?    # followed by an optional exponent, or...
    |
        Inf(inity)?              # ...an infinity, or...
    |
        (?P<signal>s)?           # ...an (optionally signaling)
        NaN                      # NaN
        (?P<diag>\d*)            # with (possibly empty) diagnostic info.
    )
#    \s*
    \Z
0*$50*$\A
(?:
   (?P<fill>.)?
   (?P<align>[<>=^])
)?
(?P<sign>[-+ ])?
(?P<alt>\#)?
(?P<zeropad>0)?
(?P<minimumwidth>(?!0)\d+)?
(?P<thousands_sep>,)?
(?:\.(?P<precision>0|(?!0)\d+))?
(?P<type>[eEfFgGn%])?
\Z
DOTALL_parse_format_specifier_regexParse and validate a format specifier.

    Turns a standard numeric format specifier into a dict, with the
    following entries:

      fill: fill character to pad field to minimum width
      align: alignment type, either '<', '>', '=' or '^'
      sign: either '+', '-' or ' '
      minimumwidth: nonnegative integer giving minimum width
      zeropad: boolean, indicating whether to pad with zeros
      thousands_sep: string to use as thousands separator, or ''
      grouping: grouping for thousands separators, in format
        used by localeconv
      decimal_point: string to use for decimal point
      precision: nonnegative integer giving precision, or None
      type: one of the characters 'eEfFgG%', or None

    Invalid format specifier: format_dictfillalignzeropadFill character conflicts with '0' in format specifier: "Fill character conflicts with '0'"" in format specifier: "Alignment conflicts with '0' in format specifier: "Alignment conflicts with '0' in ""format specifier: "minimumwidthgGnthousands_sepExplicit thousands separator conflicts with 'n' type in format specifier: "Explicit thousands separator conflicts with ""'n' type in format specifier: "groupingdecimal_pointGiven an unpadded, non-aligned numeric string 'body' and sign
    string 'sign', add padding and alignment conforming to the given
    format specifier dictionary 'spec' (as produced by
    parse_format_specifier).

    ^halfUnrecognised alignment field_group_lengthsConvert a localeconv-style grouping into a (possibly infinite)
    iterable of integers representing group lengths.

    unrecognised format for grouping_insert_thousands_sepmin_widthInsert thousands separators into a digit string.

    spec is a dictionary whose keys should include 'thousands_sep' and
    'grouping'; typically it's the result of parsing the format
    specifier using _parse_format_specifier.

    The min_width keyword argument gives the minimum length of the
    result, which will be padded on the left with zeros if necessary.

    If necessary, the zero padding adds an extra '0' on the left to
    avoid a leading thousands separator.  For example, inserting
    commas every three digits in '123456', with min_width=8, gives
    '0,123,456', even though that has length 9.

    groupsgroup length should be positiveis_negativeDetermine sign character. +Format a number, given the following data:

    is_negative: true if the number is negative, else false
    intpart: string of digits that must appear before the decimal point
    fracpart: string of digits that must come after the point
    exp: exponent, as an integer
    spec: dictionary resulting from parsing the format specifier

    This function uses the information in spec to:
      insert separators (decimal separator and thousands separators)
      format the sign
      format the exponent
      add trailing '%' for the '%' type
      zero-pad if necessary
      fill and align if necessary
    altechar{0}{1:+}Inf-Inf_PyHASH_NAN# Copyright (c) 2004 Python Software Foundation.# All rights reserved.# Written by Eric Price <eprice at tjhsst.edu>#    and Facundo Batista <facundo at taniquetil.com.ar>#    and Raymond Hettinger <python at rcn.com>#    and Aahz <aahz at pobox.com>#    and Tim Peters# This module should be kept in sync with the latest updates of the# IBM specification as it evolves.  Those updates will be treated# as bug fixes (deviation from the spec is a compatibility, usability# bug) and will be backported.  At this point the spec is stabilizing# and the updates are becoming fewer, smaller, and less significant.# Two major classes# Named tuple representation# Contexts# Exceptions# Exceptional conditions that trigger InvalidOperation# Constants for use in setting up contexts# Functions for manipulating contexts# Limits for the C version for compatibility# C version: compile time choice that enables the thread local context (deprecated, now always true)# C version: compile time choice that enables the coroutine local context# sys.modules lookup (--without-threads)# For pickling# Highest version of the spec this complies with# See http://speleotrove.com/decimal/# compatible libmpdec version# Rounding# Compatibility with the C version# Errors# List of public traps and flags# Map conditions (per the spec) to signals# Valid rounding modes##### Context Functions ################################################### The getcontext() and setcontext() function manage access to a thread-local# current context.# Don't contaminate the namespace##### Decimal class ######################################################## Do not subclass Decimal from numbers.Real and do not register it as such# (because Decimals are not interoperable with floats).  See the notes in# numbers.py for more detail.# Generally, the value of the Decimal instance is given by#  (-1)**_sign * _int * 10**_exp# Special values are signified by _is_special == True# We're immutable, so use __new__ not __init__# Note that the coefficient, self._int, is actually stored as# a string rather than as a tuple of digits.  This speeds up# the "digits to integer" and "integer to digits" conversions# that are used in almost every arithmetic operation on# Decimals.  This is an internal detail: the as_tuple function# and the Decimal constructor still deal with tuples of# digits.# From a string# REs insist on real strings, so we can too.# finite number# NaN# infinity# From an integer# From another decimal# From an internal working value# tuple/list conversion (possibly from as_tuple())# process sign.  The isinstance test rejects floats# infinity: value[1] is ignored# process and validate the digits in value[1]# skip leading zeros# NaN: digits form the diagnostic# finite number: digits give the coefficient# handle integer inputs# check for zeros;  Decimal('0') == Decimal('-0')# If different signs, neg one is less# self_adjusted < other_adjusted# Note: The Decimal standard doesn't cover rich comparisons for# Decimals.  In particular, the specification is silent on the# subject of what should happen for a comparison involving a NaN.# We take the following approach:#   == comparisons involving a quiet NaN always return False#   != comparisons involving a quiet NaN always return True#   == or != comparisons involving a signaling NaN signal#      InvalidOperation, and return False or True as above if the#      InvalidOperation is not trapped.#   <, >, <= and >= comparisons involving a (quiet or signaling)#      NaN signal InvalidOperation, and return False if the# This behavior is designed to conform as closely as possible to# that specified by IEEE 754.# Compare(NaN, NaN) = NaN# In order to make sure that the hash of a Decimal instance# agrees with the hash of a numerically equal integer, float# or Fraction, we follow the rules for numeric hashes outlined# in the documentation.  (See library docs, 'Built-in Types').# Find n, d in lowest terms such that abs(self) == n / d;# we'll deal with the sign later.# self is an integer.# Find d2, d5 such that abs(self) = n / (2**d2 * 5**d5).# (n & -n).bit_length() - 1 counts trailing zeros in binary# representation of n (provided n is nonzero).# Invariant:  eval(repr(d)) == d# self._exp == 'N'# number of digits of self._int to left of decimal point# dotplace is number of digits of self._int to the left of the# decimal point in the mantissa of the output string (that is,# after adjusting the exponent)# no exponent required# usual scientific notation: 1 digit on left of the point# engineering notation, zero# engineering notation, nonzero# -Decimal('0') is Decimal('0'), not Decimal('-0'), except# in ROUND_FLOOR rounding mode.# + (-0) = 0, except in ROUND_FLOOR rounding mode.# If both INF, same sign => same as both, opposite => error.# Can't both be infinity here# If the answer is 0, the sign should be negative, in this case.# Equal and opposite# OK, now abs(op1) > abs(op2)# So we know the sign, and op1 > 0.# Now, op1 > abs(op2) > 0# self - other is computed as self + other.copy_negate()# Special case for multiplying by zero# Fixing in case the exponent is out of bounds# Special case for multiplying by power of 10# Special cases for zeroes# OK, so neither = 0, INF or NaN# result is not exact; adjust to ensure correct rounding# result is exact; get as close to ideal exponent as possible# Here the quotient is too large to be representable# self == +/-infinity -> InvalidOperation# other == 0 -> either InvalidOperation or DivisionUndefined# other = +/-infinity -> remainder = self# self = 0 -> remainder = self, with ideal exponent# catch most cases of large or small quotient# expdiff >= prec+1 => abs(self/other) > 10**prec# expdiff <= -2 => abs(self/other) < 0.1# adjust both arguments to have the same exponent, then divide# remainder is r*10**ideal_exponent; other is +/-op2.int *# 10**ideal_exponent.   Apply correction to ensure that# abs(remainder) <= abs(other)/2# result has same sign as self unless r is negative# maximum length of payload is precision if clamp=0,# precision-1 if clamp=1.# decapitate payload if necessary# self is +/-Infinity; return unaltered# if self is zero then exponent should be between Etiny and# Emax if clamp==0, and between Etiny and Etop if clamp==1.# exp_min is the smallest allowable exponent of the result,# equal to max(self.adjusted()-context.prec+1, Etiny)# overflow: exp_min > Etop iff self.adjusted() > Emax# round if self has too many digits# check whether the rounding pushed the exponent out of range# raise the appropriate signals, taking care to respect# the precedence described in the specification# raise Clamped on underflow to 0# fold down if clamp == 1 and self has too few digits# here self was representable to begin with; return unchanged# for each of the rounding functions below:#   self is a finite, nonzero Decimal#   prec is an integer satisfying 0 <= prec < len(self._int)# each function returns either -1, 0, or 1, as follows:#   1 indicates that self should be rounded up (away from zero)#   0 indicates that self should be truncated, and that all the#     digits to be truncated are zeros (so the value is unchanged)#  -1 indicates that there are nonzero digits to be truncated# two-argument form: use the equivalent quantize call# one-argument form# compute product; raise InvalidOperation if either operand is# a signaling NaN or if the product is zero times infinity.# deal with NaNs: if there are any sNaNs then first one wins,# (i.e. behaviour for NaNs is identical to that of fma)# check inputs: we apply same restrictions as Python's pow()# additional restriction for decimal: the modulus must be less# than 10**prec in absolute value# define 0**0 == NaN, for consistency with two-argument pow# (even though it hurts!)# compute sign of result# convert modulo to a Python integer, and self and other to# Decimal integers (i.e. force their exponents to be >= 0)# compute result using integer pow()# In the comments below, we write x for the value of self and y for the# value of other.  Write x = xc*10**xe and abs(y) = yc*10**ye, with xc# and yc positive integers not divisible by 10.# The main purpose of this method is to identify the *failure*# of x**y to be exactly representable with as little effort as# possible.  So we look for cheap and easy tests that# eliminate the possibility of x**y being exact.  Only if all# these tests are passed do we go on to actually compute x**y.# Here's the main idea.  Express y as a rational number m/n, with m and# n relatively prime and n>0.  Then for x**y to be exactly# representable (at *any* precision), xc must be the nth power of a# positive integer and xe must be divisible by n.  If y is negative# then additionally xc must be a power of either 2 or 5, hence a power# of 2**n or 5**n.# There's a limit to how small |y| can be: if y=m/n as above#  (1) if xc != 1 then for the result to be representable we#      need xc**(1/n) >= 2, and hence also xc**|y| >= 2.  So#      if |y| <= 1/nbits(xc) then xc < 2**nbits(xc) <=#      2**(1/|y|), hence xc**|y| < 2 and the result is not#      representable.#  (2) if xe != 0, |xe|*(1/n) >= 1, so |xe|*|y| >= 1.  Hence if#      |y| < 1/|xe| then the result is not representable.# Note that since x is not equal to 1, at least one of (1) and# (2) must apply.  Now |y| < 1/nbits(xc) iff |yc|*nbits(xc) <# 10**-ye iff len(str(|yc|*nbits(xc)) <= -ye.# There's also a limit to how large y can be, at least if it's# positive: the normalized result will have coefficient xc**y,# so if it's representable then xc**y < 10**p, and y <# p/log10(xc).  Hence if y*log10(xc) >= p then the result is# not exactly representable.# if len(str(abs(yc*xe)) <= -ye then abs(yc*xe) < 10**-ye,# so |y| < 1/xe and the result is not representable.# Similarly, len(str(abs(yc)*xc_bits)) <= -ye implies |y|# < 1/nbits(xc).# case where xc == 1: result is 10**(xe*y), with xe*y# required to be an integer# result is now 10**(xe * 10**ye);  xe * 10**ye must be integral# if other is a nonnegative integer, use ideal exponent# case where y is negative: xc must be either a power# of 2 or a power of 5.# quick test for power of 2# now xc is a power of 2; e is its exponent# We now have:#   x = 2**e * 10**xe, e > 0, and y < 0.# The exact result is:#   x**y = 5**(-e*y) * 10**(e*y + xe*y)# provided that both e*y and xe*y are integers.  Note that if# 5**(-e*y) >= 10**p, then the result can't be expressed# exactly with p digits of precision.# Using the above, we can guard against large values of ye.# 93/65 is an upper bound for log(10)/log(5), so if#   ye >= len(str(93*p//65))# then#   -e*y >= -y >= 10**ye > 93*p/65 > p*log(10)/log(5),# so 5**(-e*y) >= 10**p, and the coefficient of the result# can't be expressed in p digits.# emax >= largest e such that 5**e < 10**p.# Find -e*y and -xe*y; both must be integers# e >= log_5(xc) if xc is a power of 5; we have# equality all the way up to xc=5**2658# Guard against large values of ye, using the same logic as in# the 'xc is a power of 2' branch.  10/3 is an upper bound for# log(10)/log(2).# now y is positive; find m and n such that y = m/n# compute nth root of xc*10**xe# if 1 < xc < 2**n then xc isn't an nth power# compute nth root of xc using Newton's method# initial estimate# now xc*10**xe is the nth root of the original xc*10**xe# compute mth power of xc*10**xe# if m > p*100//_log10_lb(xc) then m > p/log10(xc), hence xc**m ># 10**p and the result is not representable.# by this point the result *is* exactly representable# adjust the exponent to get as close as possible to the ideal# exponent, if necessary# either argument is a NaN => result is NaN# 0**0 = NaN (!), x**0 = 1 for nonzero x (including +/-Infinity)# result has sign 1 iff self._sign is 1 and other is an odd integer# -ve**noninteger = NaN# (-0)**noninteger = 0**noninteger# negate self, without doing any unwanted rounding# 0**(+ve or Inf)= 0; 0**(-ve or -Inf) = Infinity# Inf**(+ve or Inf) = Inf; Inf**(-ve or -Inf) = 0# 1**other = 1, but the choice of exponent and the flags# depend on the exponent of self, and on whether other is a# positive integer, a negative integer, or neither# exp = max(self._exp*max(int(other), 0),# 1-context.prec) but evaluating int(other) directly# is dangerous until we know other is small (other# could be 1e999999999)# compute adjusted exponent of self# self ** infinity is infinity if self > 1, 0 if self < 1# self ** -infinity is infinity if self < 1, 0 if self > 1# from here on, the result always goes through the call# to _fix at the end of this function.# crude test to catch cases of extreme overflow/underflow.  If# log10(self)*other >= 10**bound and bound >= len(str(Emax))# then 10**bound >= 10**len(str(Emax)) >= Emax+1 and hence# self**other >= 10**(Emax+1), so overflow occurs.  The test# for underflow is similar.# self > 1 and other +ve, or self < 1 and other -ve# possibility of overflow# self > 1 and other -ve, or self < 1 and other +ve# possibility of underflow to 0# try for an exact result with precision +1# usual case: inexact result, x**y computed directly as exp(y*log(x))# compute correctly rounded result:  start with precision +3,# then increase precision until result is unambiguously roundable# unlike exp, ln and log10, the power function respects the# rounding mode; no need to switch to ROUND_HALF_EVEN here# There's a difficulty here when 'other' is not an integer and# the result is exact.  In this case, the specification# requires that the Inexact flag be raised (in spite of# exactness), but since the result is exact _fix won't do this# for us.  (Correspondingly, the Underflow signal should also# be raised for subnormal results.)  We can't directly raise# these signals either before or after calling _fix, since# that would violate the precedence for signals.  So we wrap# the ._fix call in a temporary context, and reraise# afterwards.# pad with zeros up to length context.prec+1 if necessary; this# ensures that the Rounded signal will be raised.# create a copy of the current context, with cleared flags/traps# round in the new context# raise Inexact, and if necessary, Underflow# propagate signals to the original context; _fix could# have raised any of Overflow, Underflow, Subnormal,# Inexact, Rounded, Clamped.  Overflow needs the correct# arguments.  Note that the order of the exceptions is# important here.# if both are inf, it is OK# exp._exp should be between Etiny and Emax# raise appropriate flags# call to fix takes care of any necessary folddown, and# signals Clamped if necessary# pad answer with zeros if necessary# too many digits; round and lose data.  If self.adjusted() <# exp-1, replace self by 10**(exp-1) before rounding# it can happen that the rescale alters the adjusted exponent;# for example when rounding 99.97 to 3 significant figures.# When this happens we end up with an extra 0 at the end of# the number; a second rescale fixes this.# the method name changed, but we provide also the old one, for compatibility# exponent = self._exp // 2.  sqrt(-0) = -0# At this point self represents a positive number.  Let p be# the desired precision and express self in the form c*100**e# with c a positive real number and e an integer, c and e# being chosen so that 100**(p-1) <= c < 100**p.  Then the# (exact) square root of self is sqrt(c)*10**e, and 10**(p-1)# <= sqrt(c) < 10**p, so the closest representable Decimal at# precision p is n*10**e where n = round_half_even(sqrt(c)),# the closest integer to sqrt(c) with the even integer chosen# in the case of a tie.# To ensure correct rounding in all cases, we use the# following trick: we compute the square root to an extra# place (precision p+1 instead of precision p), rounding down.# Then, if the result is inexact and its last digit is 0 or 5,# we increase the last digit to 1 or 6 respectively; if it's# exact we leave the last digit alone.  Now the final round to# p places (or fewer in the case of underflow) will round# correctly and raise the appropriate flags.# use an extra digit of precision# write argument in the form c*100**e where e = self._exp//2# is the 'ideal' exponent, to be used if the square root is# exactly representable.  l is the number of 'digits' of c in# base 100, so that 100**(l-1) <= c < 100**l.# rescale so that c has exactly prec base 100 'digits'# find n = floor(sqrt(c)) using Newton's method# result is exact; rescale to use ideal exponent e# assert n % 10**shift == 0# result is not exact; fix last digit as described above# round, and fit to current context# If one operand is a quiet NaN and the other is number, then the# number is always returned# If both operands are finite and equal in numerical value# then an ordering is applied:# If the signs differ then max returns the operand with the# positive sign and min returns the operand with the negative sign# If the signs are the same then the exponent is used to select# the result.  This is exactly the ordering used in compare_total.# If NaN or Infinity, self._exp is string# if one is negative and the other is positive, it's easy# let's handle both NaN types# compare payloads as though they're integers# exp(NaN) = NaN# exp(-Infinity) = 0# exp(0) = 1# exp(Infinity) = Infinity# the result is now guaranteed to be inexact (the true# mathematical result is transcendental). There's no need to# raise Rounded and Inexact here---they'll always be raised as# a result of the call to _fix.# we only need to do any computation for quite a small range# of adjusted exponents---for example, -29 <= adj <= 10 for# the default context.  For smaller exponent the result is# indistinguishable from 1 at the given precision, while for# larger exponent the result either overflows or underflows.# overflow# underflow to 0# p+1 digits; final round will raise correct flags# general case# compute correctly rounded result: increase precision by# 3 digits at a time until we get an unambiguously# roundable result# at this stage, ans should round correctly with *any*# rounding mode, not just with ROUND_HALF_EVEN# for 0.1 <= x <= 10 we use the inequalities 1-1/x <= ln(x) <= x-1# argument >= 10; we use 23/10 = 2.3 as a lower bound for ln(10)# argument <= 0.1# 1 < self < 10# adj == -1, 0.1 <= self < 1# ln(NaN) = NaN# ln(0.0) == -Infinity# ln(Infinity) = Infinity# ln(1.0) == 0.0# ln(negative) raises InvalidOperation# result is irrational, so necessarily inexact# correctly rounded result: repeatedly increase precision by 3# until we get an unambiguously roundable result# at least p+3 places# assert len(str(abs(coeff)))-p >= 1# For x >= 10 or x < 0.1 we only need a bound on the integer# part of log10(self), and this comes directly from the# exponent of x.  For 0.1 <= x <= 10 we use the inequalities# 1-1/x <= log(x) <= x-1. If x > 1 we have |log10(x)| ># (1-1/x)/2.31 > 0.  If x < 1 then |log10(x)| > (1-x)/2.31 > 0# self >= 10# self < 0.1# log10(NaN) = NaN# log10(0.0) == -Infinity# log10(Infinity) = Infinity# log10(negative or -Infinity) raises InvalidOperation# log10(10**n) = n# answer may need rounding# correctly rounded result: repeatedly increase precision# until result is unambiguously roundable# logb(NaN) = NaN# logb(+/-Inf) = +Inf# logb(0) = -Inf, DivisionByZero# otherwise, simply return the adjusted exponent of self, as a# Decimal.  Note that no attempt is made to fit the result# into the current context.# fill to context.prec# make the operation, and clean starting zeroes# comparison == 1# decide which flags to raise using value of ans# if precision == 1 then we don't raise Clamped for a# result 0E-Etiny.# just a normal, regular, boring number, :)# get values, pad if necessary# let's rotate!# let's shift!# Support for pickling, copy, and deepcopy# I'm immutable; therefore I am my own clone# My components are also immutable# PEP 3101 support.  the _localeconv keyword argument should be# considered private: it's provided for ease of testing only.# Note: PEP 3101 says that if the type is not present then# there should be at least one digit after the decimal point.# We take the liberty of ignoring this requirement for# Decimal---it's presumably there to make sure that# format(float, '') behaves similarly to str(float).# special values don't care about the type or precision# a type of None defaults to 'g' or 'G', depending on context# if type is '%', adjust exponent of self accordingly# round if necessary, taking rounding mode from the context# special case: zeros with a positive exponent can't be# represented in fixed point; rescale them to 0e0.# figure out placement of the decimal point# find digits before and after decimal point, and get exponent# done with the decimal-specific stuff;  hand over the rest# of the formatting to the _format_number function# Register Decimal as a kind of Number (an abstract base class).# However, do not register it as Real (because Decimals are not# interoperable with floats).##### Context class ######################################################## Set defaults; for everything except flags and _ignored_flags,# inherit from DefaultContext.# raise TypeError even for strings to have consistency# among various implementations.# Don't touch the flag# The errors define how to handle themselves.# Errors should only be risked on copies of the context# self._ignored_flags = []# Do not mutate-- This way, copies of a context leave the original# alone.# We inherit object.__hash__, so we must deny this explicitly# An exact conversion# Apply the context rounding# Methods# sign: 0 or 1# int:  int# exp:  None, int, or string# assert isinstance(value, tuple)# Let exp = min(tmp.exp - 1, tmp.adjusted() - precision - 1).# Then adding 10**exp to tmp has the same effect (after rounding)# as adding any positive quantity smaller than 10**exp; similarly# for subtraction.  So if other is smaller than 10**exp we replace# it with 10**exp.  This avoids tmp.exp - other.exp getting too large.##### Integer arithmetic functions used by ln, log10, exp and __pow__ ###### val_n = largest power of 10 dividing n.# The basic algorithm is the following: let log1p be the function# log1p(x) = log(1+x).  Then log(x/M) = log1p((x-M)/M).  We use# the reduction#    log1p(y) = 2*log1p(y/(1+sqrt(1+y)))# repeatedly until the argument to log1p is small (< 2**-L in# absolute value).  For small y we can use the Taylor series# expansion#    log1p(y) ~ y - y**2/2 + y**3/3 - ... - (-y)**T/T# truncating at T such that y**T is small enough.  The whole# computation is carried out in a form of fixed-point arithmetic,# with a real number z being represented by an integer# approximation to z*M.  To avoid loss of precision, the y below# is actually an integer approximation to 2**R*y*M, where R is the# number of reductions performed so far.# argument reduction; R = number of reductions performed# Taylor series with T terms# increase precision by 2; compensate for this by dividing# final result by 100# write c*10**e as d*10**f with either:#   f >= 0 and 1 <= d <= 10, or#   f <= 0 and 0.1 <= d <= 1.# Thus for c*10**e close to 1, f = 0# error < 5 + 22 = 27# error < 1# exact# error < 2.31# error < 0.5# Increase precision by 2. The precision increase is compensated# for at the end with a division by 100.# rewrite c*10**e as d*10**f with either f >= 0 and 1 <= d <= 10,# or f <= 0 and 0.1 <= d <= 1.  Then we can compute 10**p * log(c*10**e)# as 10**p * log(d) + 10**p*f * log(10).# compute approximation to 10**p*log(d), with error < 27# error of <= 0.5 in c# _ilog magnifies existing error in c by a factor of at most 10# p <= 0: just approximate the whole thing by 0; error < 2.31# compute approximation to f*10**p*log(10), with error < 11.# error in f * _log10_digits(p+extra) < |f| * 1 = |f|# after division, error < |f|/10**extra + 0.5 < 10 + 0.5 < 11# error in sum < 11+27 = 38; error after division < 0.38 + 0.5 < 1# digits are stored as a string, for quick conversion to# integer in the case that we've already computed enough# digits; the stored digits should always be correct# (truncated, not rounded to nearest).# compute p+3, p+6, p+9, ... digits; continue until at# least one of the extra digits is nonzero# compute p+extra digits, correct to within 1ulp# keep all reliable digits so far; remove trailing zeros# and next nonzero digit# Algorithm: to compute exp(z) for a real number z, first divide z# by a suitable power R of 2 so that |z/2**R| < 2**-L.  Then# compute expm1(z/2**R) = exp(z/2**R) - 1 using the usual Taylor# series#     expm1(x) = x + x**2/2! + x**3/3! + ...# Now use the identity#     expm1(2x) = expm1(x)*(expm1(x)+2)# R times to compute the sequence expm1(z/2**R),# expm1(z/2**(R-1)), ... , exp(z/2), exp(z).# Find R such that x/2**R/M <= 2**-L# Taylor series.  (2**L)**T > M# Expansion# we'll call iexp with M = 10**(p+2), giving p+3 digits of precision# compute log(10) with extra precision = adjusted exponent of c*10**e# compute quotient c*10**e/(log(10)) = c*10**(e+q)/(log(10)*10**q),# rounding down# reduce remainder back to original precision# error in result of _iexp < 120;  error after division < 0.62# Find b such that 10**(b-1) <= |y| <= 10**b# log(x) = lxc*10**(-p-b-1), to p+b+1 places after the decimal point# compute product y*log(x) = yc*lxc*10**(-p-b-1+ye) = pc*10**(-p-1)# we prefer a result that isn't exactly 1; this makes it# easier to compute a correctly rounded result in __pow__# if x**y > 1:##### Helper Functions ##################################################### Comparison with a Rational instance (also includes integers):# self op n/d <=> self*d op n (for n and d integers, d positive).# A NaN or infinity can be left unchanged without affecting the# comparison result.# Comparisons with float and complex types.  == and != comparisons# with complex numbers should succeed, returning either True or False# as appropriate.  Other comparisons return NotImplemented.##### Setup Specific Contexts ############################################# The default context prototype used by Context()# Is mutable, so that new contexts can have different default values# Pre-made alternate contexts offered by the specification# Don't change these; the user should be able to select these# contexts and be able to reproduce results from other implementations# of the spec.##### crud for parsing strings ############################################## Regular expression used for parsing numeric strings.  Additional# comments:# 1. Uncomment the two '\s*' lines to allow leading and/or trailing# whitespace.  But note that the specification disallows whitespace in# a numeric string.# 2. For finite numbers (not infinities and NaNs) the body of the# number between the optional sign and the optional exponent must have# at least one decimal digit, possibly after the decimal point.  The# lookahead expression '(?=\d|\.\d)' checks this.##### PEP3101 support functions ############################################### The functions in this section have little to do with the Decimal# class, and could potentially be reused or adapted for other pure# Python numeric classes that want to implement __format__# A format specifier for Decimal looks like:#   [[fill]align][sign][#][0][minimumwidth][,][.precision][type]# The locale module is only needed for the 'n' format specifier.  The# rest of the PEP 3101 code functions quite happily without it, so we# don't care too much if locale isn't present.# get the dictionary# zeropad; defaults for fill and alignment.  If zero padding# is requested, the fill and align fields should be absent.# PEP 3101 originally specified that the default alignment should# be left;  it was later agreed that right-aligned makes more sense# for numeric types.  See http://bugs.python.org/issue6857.# default sign handling: '-' for negative, '' for positive# minimumwidth defaults to 0; precision remains None if not given# if format type is 'g' or 'G' then a precision of 0 makes little# sense; convert it to 1.  Same if format type is unspecified.# determine thousands separator, grouping, and decimal separator, and# add appropriate entries to format_dict# apart from separators, 'n' behaves just like 'g'# how much extra space do we have to play with?# The result from localeconv()['grouping'], and the input to this# function, should be a list of integers in one of the# following three forms:#   (1) an empty list, or#   (2) nonempty list of positive integers + [0]#   (3) list of positive integers + [locale.CHAR_MAX], or# max(..., 1) forces at least 1 digit to the left of a separator##### Useful Constants (internal use only) ################################# Reusable defaults# _SignedInfinity[sign] is infinity w/ that sign# Constants related to the hash implementation;  hash(x) is based# on the reduction of x modulo _PyHASH_MODULUS# hash values to use for positive and negative infinities, and nans# _PyHASH_10INV is the inverse of 10 modulo the prime _PyHASH_MODULUSb'
This is an implementation of decimal floating point arithmetic based on
the General Decimal Arithmetic Specification:

    http://speleotrove.com/decimal/decarith.html

and IEEE standard 854-1987:

    http://en.wikipedia.org/wiki/IEEE_854-1987

Decimal floating point has finite precision with arbitrarily large bounds.

The purpose of this module is to support arithmetic using familiar
"schoolhouse" rules and to avoid some of the tricky representation
issues associated with binary floating point.  The package is especially
useful for financial applications or for contexts where users have
expectations that are at odds with binary floating point (for instance,
in binary floating point, 1.00 % 0.1 gives 0.09999999999999995 instead
of 0.0; Decimal('1.00') % Decimal('0.1') returns the expected
Decimal('0.00')).

Here are some examples of using the decimal module:

>>> from decimal import *
>>> setcontext(ExtendedContext)
>>> Decimal(0)
Decimal('0')
>>> Decimal('1')
Decimal('1')
>>> Decimal('-.0123')
Decimal('-0.0123')
>>> Decimal(123456)
Decimal('123456')
>>> Decimal('123.45e12345678')
Decimal('1.2345E+12345680')
>>> Decimal('1.33') + Decimal('1.27')
Decimal('2.60')
>>> Decimal('12.34') + Decimal('3.87') - Decimal('18.41')
Decimal('-2.20')
>>> dig = Decimal(1)
>>> print(dig / Decimal(3))
0.333333333
>>> getcontext().prec = 18
>>> print(dig / Decimal(3))
0.333333333333333333
>>> print(dig.sqrt())
1
>>> print(Decimal(3).sqrt())
1.73205080756887729
>>> print(Decimal(3) ** 123)
4.85192780976896427E+58
>>> inf = Decimal(1) / Decimal(0)
>>> print(inf)
Infinity
>>> neginf = Decimal(-1) / Decimal(0)
>>> print(neginf)
-Infinity
>>> print(neginf + inf)
NaN
>>> print(neginf * inf)
-Infinity
>>> print(dig / 0)
Infinity
>>> getcontext().traps[DivisionByZero] = 1
>>> print(dig / 0)
Traceback (most recent call last):
  ...
  ...
  ...
decimal.DivisionByZero: x / 0
>>> c = Context()
>>> c.traps[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> c.divide(Decimal(0), Decimal(0))
Decimal('NaN')
>>> c.traps[InvalidOperation] = 1
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> print(c.divide(Decimal(0), Decimal(0)))
Traceback (most recent call last):
  ...
  ...
  ...
decimal.InvalidOperation: 0 / 0
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> c.traps[InvalidOperation] = 0
>>> print(c.divide(Decimal(0), Decimal(0)))
NaN
>>> print(c.flags[InvalidOperation])
1
>>>
'u'
This is an implementation of decimal floating point arithmetic based on
the General Decimal Arithmetic Specification:

    http://speleotrove.com/decimal/decarith.html

and IEEE standard 854-1987:

    http://en.wikipedia.org/wiki/IEEE_854-1987

Decimal floating point has finite precision with arbitrarily large bounds.

The purpose of this module is to support arithmetic using familiar
"schoolhouse" rules and to avoid some of the tricky representation
issues associated with binary floating point.  The package is especially
useful for financial applications or for contexts where users have
expectations that are at odds with binary floating point (for instance,
in binary floating point, 1.00 % 0.1 gives 0.09999999999999995 instead
of 0.0; Decimal('1.00') % Decimal('0.1') returns the expected
Decimal('0.00')).

Here are some examples of using the decimal module:

>>> from decimal import *
>>> setcontext(ExtendedContext)
>>> Decimal(0)
Decimal('0')
>>> Decimal('1')
Decimal('1')
>>> Decimal('-.0123')
Decimal('-0.0123')
>>> Decimal(123456)
Decimal('123456')
>>> Decimal('123.45e12345678')
Decimal('1.2345E+12345680')
>>> Decimal('1.33') + Decimal('1.27')
Decimal('2.60')
>>> Decimal('12.34') + Decimal('3.87') - Decimal('18.41')
Decimal('-2.20')
>>> dig = Decimal(1)
>>> print(dig / Decimal(3))
0.333333333
>>> getcontext().prec = 18
>>> print(dig / Decimal(3))
0.333333333333333333
>>> print(dig.sqrt())
1
>>> print(Decimal(3).sqrt())
1.73205080756887729
>>> print(Decimal(3) ** 123)
4.85192780976896427E+58
>>> inf = Decimal(1) / Decimal(0)
>>> print(inf)
Infinity
>>> neginf = Decimal(-1) / Decimal(0)
>>> print(neginf)
-Infinity
>>> print(neginf + inf)
NaN
>>> print(neginf * inf)
-Infinity
>>> print(dig / 0)
Infinity
>>> getcontext().traps[DivisionByZero] = 1
>>> print(dig / 0)
Traceback (most recent call last):
  ...
  ...
  ...
decimal.DivisionByZero: x / 0
>>> c = Context()
>>> c.traps[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> c.divide(Decimal(0), Decimal(0))
Decimal('NaN')
>>> c.traps[InvalidOperation] = 1
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> print(c.divide(Decimal(0), Decimal(0)))
Traceback (most recent call last):
  ...
  ...
  ...
decimal.InvalidOperation: 0 / 0
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> c.traps[InvalidOperation] = 0
>>> print(c.divide(Decimal(0), Decimal(0)))
NaN
>>> print(c.flags[InvalidOperation])
1
>>>
'b'Decimal'u'Decimal'b'Context'u'Context'b'DecimalTuple'u'DecimalTuple'b'DefaultContext'u'DefaultContext'b'BasicContext'u'BasicContext'b'ExtendedContext'u'ExtendedContext'b'DecimalException'u'DecimalException'b'Clamped'u'Clamped'b'InvalidOperation'u'InvalidOperation'b'DivisionByZero'u'DivisionByZero'b'Inexact'u'Inexact'b'Rounded'u'Rounded'b'Subnormal'u'Subnormal'b'Overflow'u'Overflow'b'Underflow'u'Underflow'b'FloatOperation'u'FloatOperation'b'DivisionImpossible'u'DivisionImpossible'b'InvalidContext'u'InvalidContext'b'ConversionSyntax'u'ConversionSyntax'b'DivisionUndefined'u'DivisionUndefined'b'ROUND_DOWN'b'ROUND_HALF_UP'b'ROUND_HALF_EVEN'b'ROUND_CEILING'b'ROUND_FLOOR'b'ROUND_UP'b'ROUND_HALF_DOWN'b'ROUND_05UP'b'setcontext'u'setcontext'b'getcontext'u'getcontext'b'localcontext'u'localcontext'b'MAX_PREC'u'MAX_PREC'b'MAX_EMAX'u'MAX_EMAX'b'MIN_EMIN'u'MIN_EMIN'b'MIN_ETINY'u'MIN_ETINY'b'HAVE_THREADS'u'HAVE_THREADS'b'HAVE_CONTEXTVAR'u'HAVE_CONTEXTVAR'b'decimal'b'1.70'b'2.4.2'u'2.4.2'b'sign digits exponent'u'sign digits exponent'b'Base exception class.

    Used exceptions derive from this.
    If an exception derives from another exception besides this (such as
    Underflow (Inexact, Rounded, Subnormal) that indicates that it is only
    called if the others are present.  This isn't actually used for
    anything, though.

    handle  -- Called when context._raise_error is called and the
               trap_enabler is not set.  First argument is self, second is the
               context.  More arguments can be given, those being after
               the explanation in _raise_error (For example,
               context._raise_error(NewError, '(-x)!', self._sign) would
               call NewError().handle(context, self._sign).)

    To define a new exception, it should be sufficient to have it derive
    from DecimalException.
    'u'Base exception class.

    Used exceptions derive from this.
    If an exception derives from another exception besides this (such as
    Underflow (Inexact, Rounded, Subnormal) that indicates that it is only
    called if the others are present.  This isn't actually used for
    anything, though.

    handle  -- Called when context._raise_error is called and the
               trap_enabler is not set.  First argument is self, second is the
               context.  More arguments can be given, those being after
               the explanation in _raise_error (For example,
               context._raise_error(NewError, '(-x)!', self._sign) would
               call NewError().handle(context, self._sign).)

    To define a new exception, it should be sufficient to have it derive
    from DecimalException.
    'b'Exponent of a 0 changed to fit bounds.

    This occurs and signals clamped if the exponent of a result has been
    altered in order to fit the constraints of a specific concrete
    representation.  This may occur when the exponent of a zero result would
    be outside the bounds of a representation, or when a large normal
    number would have an encoded exponent that cannot be represented.  In
    this latter case, the exponent is reduced to fit and the corresponding
    number of zero digits are appended to the coefficient ("fold-down").
    'u'Exponent of a 0 changed to fit bounds.

    This occurs and signals clamped if the exponent of a result has been
    altered in order to fit the constraints of a specific concrete
    representation.  This may occur when the exponent of a zero result would
    be outside the bounds of a representation, or when a large normal
    number would have an encoded exponent that cannot be represented.  In
    this latter case, the exponent is reduced to fit and the corresponding
    number of zero digits are appended to the coefficient ("fold-down").
    'b'An invalid operation was performed.

    Various bad things cause this:

    Something creates a signaling NaN
    -INF + INF
    0 * (+-)INF
    (+-)INF / (+-)INF
    x % 0
    (+-)INF % x
    x._rescale( non-integer )
    sqrt(-x) , x > 0
    0 ** 0
    x ** (non-integer)
    x ** (+-)INF
    An operand is invalid

    The result of the operation after these is a quiet positive NaN,
    except when the cause is a signaling NaN, in which case the result is
    also a quiet NaN, but with the original sign, and an optional
    diagnostic information.
    'u'An invalid operation was performed.

    Various bad things cause this:

    Something creates a signaling NaN
    -INF + INF
    0 * (+-)INF
    (+-)INF / (+-)INF
    x % 0
    (+-)INF % x
    x._rescale( non-integer )
    sqrt(-x) , x > 0
    0 ** 0
    x ** (non-integer)
    x ** (+-)INF
    An operand is invalid

    The result of the operation after these is a quiet positive NaN,
    except when the cause is a signaling NaN, in which case the result is
    also a quiet NaN, but with the original sign, and an optional
    diagnostic information.
    'b'Trying to convert badly formed string.

    This occurs and signals invalid-operation if a string is being
    converted to a number and it does not conform to the numeric string
    syntax.  The result is [0,qNaN].
    'u'Trying to convert badly formed string.

    This occurs and signals invalid-operation if a string is being
    converted to a number and it does not conform to the numeric string
    syntax.  The result is [0,qNaN].
    'b'Division by 0.

    This occurs and signals division-by-zero if division of a finite number
    by zero was attempted (during a divide-integer or divide operation, or a
    power operation with negative right-hand operand), and the dividend was
    not zero.

    The result of the operation is [sign,inf], where sign is the exclusive
    or of the signs of the operands for divide, or is 1 for an odd power of
    -0, for power.
    'u'Division by 0.

    This occurs and signals division-by-zero if division of a finite number
    by zero was attempted (during a divide-integer or divide operation, or a
    power operation with negative right-hand operand), and the dividend was
    not zero.

    The result of the operation is [sign,inf], where sign is the exclusive
    or of the signs of the operands for divide, or is 1 for an odd power of
    -0, for power.
    'b'Cannot perform the division adequately.

    This occurs and signals invalid-operation if the integer result of a
    divide-integer or remainder operation had too many digits (would be
    longer than precision).  The result is [0,qNaN].
    'u'Cannot perform the division adequately.

    This occurs and signals invalid-operation if the integer result of a
    divide-integer or remainder operation had too many digits (would be
    longer than precision).  The result is [0,qNaN].
    'b'Undefined result of division.

    This occurs and signals invalid-operation if division by zero was
    attempted (during a divide-integer, divide, or remainder operation), and
    the dividend is also zero.  The result is [0,qNaN].
    'u'Undefined result of division.

    This occurs and signals invalid-operation if division by zero was
    attempted (during a divide-integer, divide, or remainder operation), and
    the dividend is also zero.  The result is [0,qNaN].
    'b'Had to round, losing information.

    This occurs and signals inexact whenever the result of an operation is
    not exact (that is, it needed to be rounded and any discarded digits
    were non-zero), or if an overflow or underflow condition occurs.  The
    result in all cases is unchanged.

    The inexact signal may be tested (or trapped) to determine if a given
    operation (or sequence of operations) was inexact.
    'u'Had to round, losing information.

    This occurs and signals inexact whenever the result of an operation is
    not exact (that is, it needed to be rounded and any discarded digits
    were non-zero), or if an overflow or underflow condition occurs.  The
    result in all cases is unchanged.

    The inexact signal may be tested (or trapped) to determine if a given
    operation (or sequence of operations) was inexact.
    'b'Invalid context.  Unknown rounding, for example.

    This occurs and signals invalid-operation if an invalid context was
    detected during an operation.  This can occur if contexts are not checked
    on creation and either the precision exceeds the capability of the
    underlying concrete representation or an unknown or unsupported rounding
    was specified.  These aspects of the context need only be checked when
    the values are required to be used.  The result is [0,qNaN].
    'u'Invalid context.  Unknown rounding, for example.

    This occurs and signals invalid-operation if an invalid context was
    detected during an operation.  This can occur if contexts are not checked
    on creation and either the precision exceeds the capability of the
    underlying concrete representation or an unknown or unsupported rounding
    was specified.  These aspects of the context need only be checked when
    the values are required to be used.  The result is [0,qNaN].
    'b'Number got rounded (not  necessarily changed during rounding).

    This occurs and signals rounded whenever the result of an operation is
    rounded (that is, some zero or non-zero digits were discarded from the
    coefficient), or if an overflow or underflow condition occurs.  The
    result in all cases is unchanged.

    The rounded signal may be tested (or trapped) to determine if a given
    operation (or sequence of operations) caused a loss of precision.
    'u'Number got rounded (not  necessarily changed during rounding).

    This occurs and signals rounded whenever the result of an operation is
    rounded (that is, some zero or non-zero digits were discarded from the
    coefficient), or if an overflow or underflow condition occurs.  The
    result in all cases is unchanged.

    The rounded signal may be tested (or trapped) to determine if a given
    operation (or sequence of operations) caused a loss of precision.
    'b'Exponent < Emin before rounding.

    This occurs and signals subnormal whenever the result of a conversion or
    operation is subnormal (that is, its adjusted exponent is less than
    Emin, before any rounding).  The result in all cases is unchanged.

    The subnormal signal may be tested (or trapped) to determine if a given
    or operation (or sequence of operations) yielded a subnormal result.
    'u'Exponent < Emin before rounding.

    This occurs and signals subnormal whenever the result of a conversion or
    operation is subnormal (that is, its adjusted exponent is less than
    Emin, before any rounding).  The result in all cases is unchanged.

    The subnormal signal may be tested (or trapped) to determine if a given
    or operation (or sequence of operations) yielded a subnormal result.
    'b'Numerical overflow.

    This occurs and signals overflow if the adjusted exponent of a result
    (from a conversion or from an operation that is not an attempt to divide
    by zero), after rounding, would be greater than the largest value that
    can be handled by the implementation (the value Emax).

    The result depends on the rounding mode:

    For round-half-up and round-half-even (and for round-half-down and
    round-up, if implemented), the result of the operation is [sign,inf],
    where sign is the sign of the intermediate result.  For round-down, the
    result is the largest finite number that can be represented in the
    current precision, with the sign of the intermediate result.  For
    round-ceiling, the result is the same as for round-down if the sign of
    the intermediate result is 1, or is [0,inf] otherwise.  For round-floor,
    the result is the same as for round-down if the sign of the intermediate
    result is 0, or is [1,inf] otherwise.  In all cases, Inexact and Rounded
    will also be raised.
    'u'Numerical overflow.

    This occurs and signals overflow if the adjusted exponent of a result
    (from a conversion or from an operation that is not an attempt to divide
    by zero), after rounding, would be greater than the largest value that
    can be handled by the implementation (the value Emax).

    The result depends on the rounding mode:

    For round-half-up and round-half-even (and for round-half-down and
    round-up, if implemented), the result of the operation is [sign,inf],
    where sign is the sign of the intermediate result.  For round-down, the
    result is the largest finite number that can be represented in the
    current precision, with the sign of the intermediate result.  For
    round-ceiling, the result is the same as for round-down if the sign of
    the intermediate result is 1, or is [0,inf] otherwise.  For round-floor,
    the result is the same as for round-down if the sign of the intermediate
    result is 0, or is [1,inf] otherwise.  In all cases, Inexact and Rounded
    will also be raised.
    'b'Numerical underflow with result rounded to 0.

    This occurs and signals underflow if a result is inexact and the
    adjusted exponent of the result would be smaller (more negative) than
    the smallest value that can be handled by the implementation (the value
    Emin).  That is, the result is both inexact and subnormal.

    The result after an underflow will be a subnormal number rounded, if
    necessary, so that its exponent is not less than Etiny.  This may result
    in 0 with the sign of the intermediate result and an exponent of Etiny.

    In all cases, Inexact, Rounded, and Subnormal will also be raised.
    'u'Numerical underflow with result rounded to 0.

    This occurs and signals underflow if a result is inexact and the
    adjusted exponent of the result would be smaller (more negative) than
    the smallest value that can be handled by the implementation (the value
    Emin).  That is, the result is both inexact and subnormal.

    The result after an underflow will be a subnormal number rounded, if
    necessary, so that its exponent is not less than Etiny.  This may result
    in 0 with the sign of the intermediate result and an exponent of Etiny.

    In all cases, Inexact, Rounded, and Subnormal will also be raised.
    'b'Enable stricter semantics for mixing floats and Decimals.

    If the signal is not trapped (default), mixing floats and Decimals is
    permitted in the Decimal() constructor, context.create_decimal() and
    all comparison operators. Both conversion and comparisons are exact.
    Any occurrence of a mixed operation is silently recorded by setting
    FloatOperation in the context flags.  Explicit conversions with
    Decimal.from_float() or context.create_decimal_from_float() do not
    set the flag.

    Otherwise (the signal is trapped), only equality comparisons and explicit
    conversions are silent. All other mixed operations raise FloatOperation.
    'u'Enable stricter semantics for mixing floats and Decimals.

    If the signal is not trapped (default), mixing floats and Decimals is
    permitted in the Decimal() constructor, context.create_decimal() and
    all comparison operators. Both conversion and comparisons are exact.
    Any occurrence of a mixed operation is silently recorded by setting
    FloatOperation in the context flags.  Explicit conversions with
    Decimal.from_float() or context.create_decimal_from_float() do not
    set the flag.

    Otherwise (the signal is trapped), only equality comparisons and explicit
    conversions are silent. All other mixed operations raise FloatOperation.
    'b'decimal_context'u'decimal_context'b'Returns this thread's context.

    If this thread does not yet have a context, returns
    a new context and sets this thread's context.
    New contexts are copies of DefaultContext.
    'u'Returns this thread's context.

    If this thread does not yet have a context, returns
    a new context and sets this thread's context.
    New contexts are copies of DefaultContext.
    'b'Set this thread's context to context.'u'Set this thread's context to context.'b'Return a context manager for a copy of the supplied context

    Uses a copy of the current context if no context is specified
    The returned context manager creates a local decimal context
    in a with statement:
        def sin(x):
             with localcontext() as ctx:
                 ctx.prec += 2
                 # Rest of sin calculation algorithm
                 # uses a precision 2 greater than normal
             return +s  # Convert result to normal precision

         def sin(x):
             with localcontext(ExtendedContext):
                 # Rest of sin calculation algorithm
                 # uses the Extended Context from the
                 # General Decimal Arithmetic Specification
             return +s  # Convert result to normal context

    >>> setcontext(DefaultContext)
    >>> print(getcontext().prec)
    28
    >>> with localcontext():
    ...     ctx = getcontext()
    ...     ctx.prec += 2
    ...     print(ctx.prec)
    ...
    30
    >>> with localcontext(ExtendedContext):
    ...     print(getcontext().prec)
    ...
    9
    >>> print(getcontext().prec)
    28
    'u'Return a context manager for a copy of the supplied context

    Uses a copy of the current context if no context is specified
    The returned context manager creates a local decimal context
    in a with statement:
        def sin(x):
             with localcontext() as ctx:
                 ctx.prec += 2
                 # Rest of sin calculation algorithm
                 # uses a precision 2 greater than normal
             return +s  # Convert result to normal precision

         def sin(x):
             with localcontext(ExtendedContext):
                 # Rest of sin calculation algorithm
                 # uses the Extended Context from the
                 # General Decimal Arithmetic Specification
             return +s  # Convert result to normal context

    >>> setcontext(DefaultContext)
    >>> print(getcontext().prec)
    28
    >>> with localcontext():
    ...     ctx = getcontext()
    ...     ctx.prec += 2
    ...     print(ctx.prec)
    ...
    30
    >>> with localcontext(ExtendedContext):
    ...     print(getcontext().prec)
    ...
    9
    >>> print(getcontext().prec)
    28
    'b'Floating point class for decimal arithmetic.'u'Floating point class for decimal arithmetic.'b'_exp'u'_exp'b'_int'u'_int'b'_sign'u'_sign'b'_is_special'u'_is_special'b'Create a decimal point instance.

        >>> Decimal('3.14')              # string input
        Decimal('3.14')
        >>> Decimal((0, (3, 1, 4), -2))  # tuple (sign, digit_tuple, exponent)
        Decimal('3.14')
        >>> Decimal(314)                 # int
        Decimal('314')
        >>> Decimal(Decimal(314))        # another decimal instance
        Decimal('314')
        >>> Decimal('  3.14  \n')        # leading and trailing whitespace okay
        Decimal('3.14')
        'u'Create a decimal point instance.

        >>> Decimal('3.14')              # string input
        Decimal('3.14')
        >>> Decimal((0, (3, 1, 4), -2))  # tuple (sign, digit_tuple, exponent)
        Decimal('3.14')
        >>> Decimal(314)                 # int
        Decimal('314')
        >>> Decimal(Decimal(314))        # another decimal instance
        Decimal('314')
        >>> Decimal('  3.14  \n')        # leading and trailing whitespace okay
        Decimal('3.14')
        'b'Invalid literal for Decimal: %r'u'Invalid literal for Decimal: %r'b'sign'b'frac'u'frac'b'exp'u'exp'b'diag'u'diag'b'signal'u'signal'b'N'u'N'b'F'u'F'b'Invalid tuple size in creation of Decimal from list or tuple.  The list or tuple should have exactly three elements.'u'Invalid tuple size in creation of Decimal from list or tuple.  The list or tuple should have exactly three elements.'b'Invalid sign.  The first value in the tuple should be an integer; either 0 for a positive number or 1 for a negative number.'u'Invalid sign.  The first value in the tuple should be an integer; either 0 for a positive number or 1 for a negative number.'b'The second value in the tuple must be composed of integers in the range 0 through 9.'u'The second value in the tuple must be composed of integers in the range 0 through 9.'b'The third value in the tuple must be an integer, or one of the strings 'F', 'n', 'N'.'u'The third value in the tuple must be an integer, or one of the strings 'F', 'n', 'N'.'b'strict semantics for mixing floats and Decimals are enabled'u'strict semantics for mixing floats and Decimals are enabled'b'Cannot convert %r to Decimal'u'Cannot convert %r to Decimal'b'Converts a float to a decimal number, exactly.

        Note that Decimal.from_float(0.1) is not the same as Decimal('0.1').
        Since 0.1 is not exactly representable in binary floating point, the
        value is stored as the nearest representable value which is
        0x1.999999999999ap-4.  The exact equivalent of the value in decimal
        is 0.1000000000000000055511151231257827021181583404541015625.

        >>> Decimal.from_float(0.1)
        Decimal('0.1000000000000000055511151231257827021181583404541015625')
        >>> Decimal.from_float(float('nan'))
        Decimal('NaN')
        >>> Decimal.from_float(float('inf'))
        Decimal('Infinity')
        >>> Decimal.from_float(-float('inf'))
        Decimal('-Infinity')
        >>> Decimal.from_float(-0.0)
        Decimal('-0')

        'u'Converts a float to a decimal number, exactly.

        Note that Decimal.from_float(0.1) is not the same as Decimal('0.1').
        Since 0.1 is not exactly representable in binary floating point, the
        value is stored as the nearest representable value which is
        0x1.999999999999ap-4.  The exact equivalent of the value in decimal
        is 0.1000000000000000055511151231257827021181583404541015625.

        >>> Decimal.from_float(0.1)
        Decimal('0.1000000000000000055511151231257827021181583404541015625')
        >>> Decimal.from_float(float('nan'))
        Decimal('NaN')
        >>> Decimal.from_float(float('inf'))
        Decimal('Infinity')
        >>> Decimal.from_float(-float('inf'))
        Decimal('-Infinity')
        >>> Decimal.from_float(-0.0)
        Decimal('-0')

        'b'argument must be int or float.'u'argument must be int or float.'b'Returns whether the number is not actually one.

        0 if a number
        1 if NaN
        2 if sNaN
        'u'Returns whether the number is not actually one.

        0 if a number
        1 if NaN
        2 if sNaN
        'b'Returns whether the number is infinite

        0 if finite or not a number
        1 if +INF
        -1 if -INF
        'u'Returns whether the number is infinite

        0 if finite or not a number
        1 if +INF
        -1 if -INF
        'b'Returns whether the number is not actually one.

        if self, other are sNaN, signal
        if self, other are NaN return nan
        return 0

        Done before operations.
        'u'Returns whether the number is not actually one.

        if self, other are sNaN, signal
        if self, other are NaN return nan
        return 0

        Done before operations.
        'b'sNaN'u'sNaN'b'Version of _check_nans used for the signaling comparisons
        compare_signal, __le__, __lt__, __ge__, __gt__.

        Signal InvalidOperation if either self or other is a (quiet
        or signaling) NaN.  Signaling NaNs take precedence over quiet
        NaNs.

        Return 0 if neither operand is a NaN.

        'u'Version of _check_nans used for the signaling comparisons
        compare_signal, __le__, __lt__, __ge__, __gt__.

        Signal InvalidOperation if either self or other is a (quiet
        or signaling) NaN.  Signaling NaNs take precedence over quiet
        NaNs.

        Return 0 if neither operand is a NaN.

        'b'comparison involving sNaN'u'comparison involving sNaN'b'comparison involving NaN'u'comparison involving NaN'b'Return True if self is nonzero; otherwise return False.

        NaNs and infinities are considered nonzero.
        'u'Return True if self is nonzero; otherwise return False.

        NaNs and infinities are considered nonzero.
        'b'Compare the two non-NaN decimal instances self and other.

        Returns -1 if self < other, 0 if self == other and 1
        if self > other.  This routine is for internal use only.'u'Compare the two non-NaN decimal instances self and other.

        Returns -1 if self < other, 0 if self == other and 1
        if self > other.  This routine is for internal use only.'b'Compare self to other.  Return a decimal value:

        a or b is a NaN ==> Decimal('NaN')
        a < b           ==> Decimal('-1')
        a == b          ==> Decimal('0')
        a > b           ==> Decimal('1')
        'u'Compare self to other.  Return a decimal value:

        a or b is a NaN ==> Decimal('NaN')
        a < b           ==> Decimal('-1')
        a == b          ==> Decimal('0')
        a > b           ==> Decimal('1')
        'b'x.__hash__() <==> hash(x)'u'x.__hash__() <==> hash(x)'b'Cannot hash a signaling NaN value.'u'Cannot hash a signaling NaN value.'b'Represents the number as a triple tuple.

        To show the internals exactly as they are.
        'u'Represents the number as a triple tuple.

        To show the internals exactly as they are.
        'b'Express a finite Decimal instance in the form n / d.

        Returns a pair (n, d) of integers.  When called on an infinity
        or NaN, raises OverflowError or ValueError respectively.

        >>> Decimal('3.14').as_integer_ratio()
        (157, 50)
        >>> Decimal('-123e5').as_integer_ratio()
        (-12300000, 1)
        >>> Decimal('0.00').as_integer_ratio()
        (0, 1)

        'u'Express a finite Decimal instance in the form n / d.

        Returns a pair (n, d) of integers.  When called on an infinity
        or NaN, raises OverflowError or ValueError respectively.

        >>> Decimal('3.14').as_integer_ratio()
        (157, 50)
        >>> Decimal('-123e5').as_integer_ratio()
        (-12300000, 1)
        >>> Decimal('0.00').as_integer_ratio()
        (0, 1)

        'b'cannot convert NaN to integer ratio'u'cannot convert NaN to integer ratio'b'cannot convert Infinity to integer ratio'u'cannot convert Infinity to integer ratio'b'Represents the number as an instance of Decimal.'u'Represents the number as an instance of Decimal.'b'Decimal('%s')'u'Decimal('%s')'b'Return string representation of the number in scientific notation.

        Captures all of the information in the underlying representation.
        'u'Return string representation of the number in scientific notation.

        Captures all of the information in the underlying representation.
        'b'Infinity'u'Infinity'b'NaN'u'NaN'b'E'u'E'b'%+d'u'%+d'b'Convert to a string, using engineering notation if an exponent is needed.

        Engineering notation has an exponent which is a multiple of 3.  This
        can leave up to 3 digits to the left of the decimal place and may
        require the addition of either one or two trailing zeros.
        'u'Convert to a string, using engineering notation if an exponent is needed.

        Engineering notation has an exponent which is a multiple of 3.  This
        can leave up to 3 digits to the left of the decimal place and may
        require the addition of either one or two trailing zeros.
        'b'Returns a copy with the sign switched.

        Rounds, if it has reason.
        'u'Returns a copy with the sign switched.

        Rounds, if it has reason.
        'b'Returns a copy, unless it is a sNaN.

        Rounds the number (if more than precision digits)
        'u'Returns a copy, unless it is a sNaN.

        Rounds the number (if more than precision digits)
        'b'Returns the absolute value of self.

        If the keyword argument 'round' is false, do not round.  The
        expression self.__abs__(round=False) is equivalent to
        self.copy_abs().
        'u'Returns the absolute value of self.

        If the keyword argument 'round' is false, do not round.  The
        expression self.__abs__(round=False) is equivalent to
        self.copy_abs().
        'b'Returns self + other.

        -INF + INF (or the reverse) cause InvalidOperation errors.
        'u'Returns self + other.

        -INF + INF (or the reverse) cause InvalidOperation errors.
        'b'-INF + INF'u'-INF + INF'b'Return self - other'u'Return self - other'b'Return other - self'u'Return other - self'b'Return self * other.

        (+-) INF * 0 (or its reverse) raise InvalidOperation.
        'u'Return self * other.

        (+-) INF * 0 (or its reverse) raise InvalidOperation.
        'b'(+-)INF * 0'u'(+-)INF * 0'b'0 * (+-)INF'u'0 * (+-)INF'b'Return self / other.'u'Return self / other.'b'(+-)INF/(+-)INF'u'(+-)INF/(+-)INF'b'Division by infinity'u'Division by infinity'b'0 / 0'u'0 / 0'b'x / 0'u'x / 0'b'Return (self // other, self % other), to context.prec precision.

        Assumes that neither self nor other is a NaN, that self is not
        infinite and that other is nonzero.
        'u'Return (self // other, self % other), to context.prec precision.

        Assumes that neither self nor other is a NaN, that self is not
        infinite and that other is nonzero.
        'b'quotient too large in //, % or divmod'u'quotient too large in //, % or divmod'b'Swaps self/other and returns __truediv__.'u'Swaps self/other and returns __truediv__.'b'
        Return (self // other, self % other)
        'u'
        Return (self // other, self % other)
        'b'divmod(INF, INF)'u'divmod(INF, INF)'b'INF % x'u'INF % x'b'divmod(0, 0)'u'divmod(0, 0)'b'x // 0'u'x // 0'b'x % 0'u'x % 0'b'Swaps self/other and returns __divmod__.'u'Swaps self/other and returns __divmod__.'b'
        self % other
        'u'
        self % other
        'b'0 % 0'u'0 % 0'b'Swaps self/other and returns __mod__.'u'Swaps self/other and returns __mod__.'b'
        Remainder nearest to 0-  abs(remainder-near) <= other/2
        'u'
        Remainder nearest to 0-  abs(remainder-near) <= other/2
        'b'remainder_near(infinity, x)'u'remainder_near(infinity, x)'b'remainder_near(x, 0)'u'remainder_near(x, 0)'b'remainder_near(0, 0)'u'remainder_near(0, 0)'b'self // other'u'self // other'b'INF // INF'u'INF // INF'b'0 // 0'u'0 // 0'b'Swaps self/other and returns __floordiv__.'u'Swaps self/other and returns __floordiv__.'b'Float representation.'u'Float representation.'b'Cannot convert signaling NaN to float'u'Cannot convert signaling NaN to float'b'-nan'u'-nan'b'nan'b'Converts self to an int, truncating if necessary.'u'Converts self to an int, truncating if necessary.'b'Cannot convert NaN to integer'u'Cannot convert NaN to integer'b'Cannot convert infinity to integer'u'Cannot convert infinity to integer'b'Decapitate the payload of a NaN to fit the context'u'Decapitate the payload of a NaN to fit the context'b'Round if it is necessary to keep self within prec precision.

        Rounds and fixes the exponent.  Does not raise on a sNaN.

        Arguments:
        self - Decimal instance
        context - context used.
        'u'Round if it is necessary to keep self within prec precision.

        Rounds and fixes the exponent.  Does not raise on a sNaN.

        Arguments:
        self - Decimal instance
        context - context used.
        'b'above Emax'u'above Emax'b'Also known as round-towards-0, truncate.'u'Also known as round-towards-0, truncate.'b'Rounds away from 0.'u'Rounds away from 0.'b'Rounds 5 up (away from 0)'u'Rounds 5 up (away from 0)'b'56789'u'56789'b'Round 5 down'u'Round 5 down'b'Round 5 to even, rest to nearest.'u'Round 5 to even, rest to nearest.'b'02468'u'02468'b'Rounds up (not away from 0 if negative.)'u'Rounds up (not away from 0 if negative.)'b'Rounds down (not towards 0 if negative)'u'Rounds down (not towards 0 if negative)'b'Round down unless digit prec-1 is 0 or 5.'u'Round down unless digit prec-1 is 0 or 5.'b'05'u'05'b'Round self to the nearest integer, or to a given precision.

        If only one argument is supplied, round a finite Decimal
        instance self to the nearest integer.  If self is infinite or
        a NaN then a Python exception is raised.  If self is finite
        and lies exactly halfway between two integers then it is
        rounded to the integer with even last digit.

        >>> round(Decimal('123.456'))
        123
        >>> round(Decimal('-456.789'))
        -457
        >>> round(Decimal('-3.0'))
        -3
        >>> round(Decimal('2.5'))
        2
        >>> round(Decimal('3.5'))
        4
        >>> round(Decimal('Inf'))
        Traceback (most recent call last):
          ...
        OverflowError: cannot round an infinity
        >>> round(Decimal('NaN'))
        Traceback (most recent call last):
          ...
        ValueError: cannot round a NaN

        If a second argument n is supplied, self is rounded to n
        decimal places using the rounding mode for the current
        context.

        For an integer n, round(self, -n) is exactly equivalent to
        self.quantize(Decimal('1En')).

        >>> round(Decimal('123.456'), 0)
        Decimal('123')
        >>> round(Decimal('123.456'), 2)
        Decimal('123.46')
        >>> round(Decimal('123.456'), -2)
        Decimal('1E+2')
        >>> round(Decimal('-Infinity'), 37)
        Decimal('NaN')
        >>> round(Decimal('sNaN123'), 0)
        Decimal('NaN123')

        'u'Round self to the nearest integer, or to a given precision.

        If only one argument is supplied, round a finite Decimal
        instance self to the nearest integer.  If self is infinite or
        a NaN then a Python exception is raised.  If self is finite
        and lies exactly halfway between two integers then it is
        rounded to the integer with even last digit.

        >>> round(Decimal('123.456'))
        123
        >>> round(Decimal('-456.789'))
        -457
        >>> round(Decimal('-3.0'))
        -3
        >>> round(Decimal('2.5'))
        2
        >>> round(Decimal('3.5'))
        4
        >>> round(Decimal('Inf'))
        Traceback (most recent call last):
          ...
        OverflowError: cannot round an infinity
        >>> round(Decimal('NaN'))
        Traceback (most recent call last):
          ...
        ValueError: cannot round a NaN

        If a second argument n is supplied, self is rounded to n
        decimal places using the rounding mode for the current
        context.

        For an integer n, round(self, -n) is exactly equivalent to
        self.quantize(Decimal('1En')).

        >>> round(Decimal('123.456'), 0)
        Decimal('123')
        >>> round(Decimal('123.456'), 2)
        Decimal('123.46')
        >>> round(Decimal('123.456'), -2)
        Decimal('1E+2')
        >>> round(Decimal('-Infinity'), 37)
        Decimal('NaN')
        >>> round(Decimal('sNaN123'), 0)
        Decimal('NaN123')

        'b'Second argument to round should be integral'u'Second argument to round should be integral'b'cannot round a NaN'u'cannot round a NaN'b'cannot round an infinity'u'cannot round an infinity'b'Return the floor of self, as an integer.

        For a finite Decimal instance self, return the greatest
        integer n such that n <= self.  If self is infinite or a NaN
        then a Python exception is raised.

        'u'Return the floor of self, as an integer.

        For a finite Decimal instance self, return the greatest
        integer n such that n <= self.  If self is infinite or a NaN
        then a Python exception is raised.

        'b'Return the ceiling of self, as an integer.

        For a finite Decimal instance self, return the least integer n
        such that n >= self.  If self is infinite or a NaN then a
        Python exception is raised.

        'u'Return the ceiling of self, as an integer.

        For a finite Decimal instance self, return the least integer n
        such that n >= self.  If self is infinite or a NaN then a
        Python exception is raised.

        'b'Fused multiply-add.

        Returns self*other+third with no rounding of the intermediate
        product self*other.

        self and other are multiplied together, with no rounding of
        the result.  The third operand is then added to the result,
        and a single final rounding is performed.
        'u'Fused multiply-add.

        Returns self*other+third with no rounding of the intermediate
        product self*other.

        self and other are multiplied together, with no rounding of
        the result.  The third operand is then added to the result,
        and a single final rounding is performed.
        'b'INF * 0 in fma'u'INF * 0 in fma'b'0 * INF in fma'u'0 * INF in fma'b'Three argument version of __pow__'u'Three argument version of __pow__'b'pow() 3rd argument not allowed unless all arguments are integers'u'pow() 3rd argument not allowed unless all arguments are integers'b'pow() 2nd argument cannot be negative when 3rd argument specified'u'pow() 2nd argument cannot be negative when 3rd argument specified'b'pow() 3rd argument cannot be 0'u'pow() 3rd argument cannot be 0'b'insufficient precision: pow() 3rd argument must not have more than precision digits'u'insufficient precision: pow() 3rd argument must not have more than precision digits'b'at least one of pow() 1st argument and 2nd argument must be nonzero; 0**0 is not defined'u'at least one of pow() 1st argument and 2nd argument must be nonzero; 0**0 is not defined'b'Attempt to compute self**other exactly.

        Given Decimals self and other and an integer p, attempt to
        compute an exact result for the power self**other, with p
        digits of precision.  Return None if self**other is not
        exactly representable in p digits.

        Assumes that elimination of special cases has already been
        performed: self and other must both be nonspecial; self must
        be positive and not numerically equal to 1; other must be
        nonzero.  For efficiency, other._exp should not be too large,
        so that 10**abs(other._exp) is a feasible calculation.'u'Attempt to compute self**other exactly.

        Given Decimals self and other and an integer p, attempt to
        compute an exact result for the power self**other, with p
        digits of precision.  Return None if self**other is not
        exactly representable in p digits.

        Assumes that elimination of special cases has already been
        performed: self and other must both be nonspecial; self must
        be positive and not numerically equal to 1; other must be
        nonzero.  For efficiency, other._exp should not be too large,
        so that 10**abs(other._exp) is a feasible calculation.'b'Return self ** other [ % modulo].

        With two arguments, compute self**other.

        With three arguments, compute (self**other) % modulo.  For the
        three argument form, the following restrictions on the
        arguments hold:

         - all three arguments must be integral
         - other must be nonnegative
         - either self or other (or both) must be nonzero
         - modulo must be nonzero and must have at most p digits,
           where p is the context precision.

        If any of these restrictions is violated the InvalidOperation
        flag is raised.

        The result of pow(self, other, modulo) is identical to the
        result that would be obtained by computing (self**other) %
        modulo with unbounded precision, but is computed more
        efficiently.  It is always exact.
        'u'Return self ** other [ % modulo].

        With two arguments, compute self**other.

        With three arguments, compute (self**other) % modulo.  For the
        three argument form, the following restrictions on the
        arguments hold:

         - all three arguments must be integral
         - other must be nonnegative
         - either self or other (or both) must be nonzero
         - modulo must be nonzero and must have at most p digits,
           where p is the context precision.

        If any of these restrictions is violated the InvalidOperation
        flag is raised.

        The result of pow(self, other, modulo) is identical to the
        result that would be obtained by computing (self**other) %
        modulo with unbounded precision, but is computed more
        efficiently.  It is always exact.
        'b'0 ** 0'u'0 ** 0'b'x ** y with x negative and y not an integer'u'x ** y with x negative and y not an integer'b'Swaps self/other and returns __pow__.'u'Swaps self/other and returns __pow__.'b'Normalize- strip trailing 0s, change anything equal to 0 to 0e0'u'Normalize- strip trailing 0s, change anything equal to 0 to 0e0'b'Quantize self so its exponent is the same as that of exp.

        Similar to self._rescale(exp._exp) but with error checking.
        'u'Quantize self so its exponent is the same as that of exp.

        Similar to self._rescale(exp._exp) but with error checking.
        'b'quantize with one INF'u'quantize with one INF'b'target exponent out of bounds in quantize'u'target exponent out of bounds in quantize'b'exponent of quantize result too large for current context'u'exponent of quantize result too large for current context'b'quantize result has too many digits for current context'u'quantize result has too many digits for current context'b'Return True if self and other have the same exponent; otherwise
        return False.

        If either operand is a special value, the following rules are used:
           * return True if both operands are infinities
           * return True if both operands are NaNs
           * otherwise, return False.
        'u'Return True if self and other have the same exponent; otherwise
        return False.

        If either operand is a special value, the following rules are used:
           * return True if both operands are infinities
           * return True if both operands are NaNs
           * otherwise, return False.
        'b'Rescale self so that the exponent is exp, either by padding with zeros
        or by truncating digits, using the given rounding mode.

        Specials are returned without change.  This operation is
        quiet: it raises no flags, and uses no information from the
        context.

        exp = exp to scale to (an integer)
        rounding = rounding mode
        'u'Rescale self so that the exponent is exp, either by padding with zeros
        or by truncating digits, using the given rounding mode.

        Specials are returned without change.  This operation is
        quiet: it raises no flags, and uses no information from the
        context.

        exp = exp to scale to (an integer)
        rounding = rounding mode
        'b'Round a nonzero, nonspecial Decimal to a fixed number of
        significant figures, using the given rounding mode.

        Infinities, NaNs and zeros are returned unaltered.

        This operation is quiet: it raises no flags, and uses no
        information from the context.

        'u'Round a nonzero, nonspecial Decimal to a fixed number of
        significant figures, using the given rounding mode.

        Infinities, NaNs and zeros are returned unaltered.

        This operation is quiet: it raises no flags, and uses no
        information from the context.

        'b'argument should be at least 1 in _round'u'argument should be at least 1 in _round'b'Rounds to a nearby integer.

        If no rounding mode is specified, take the rounding mode from
        the context.  This method raises the Rounded and Inexact flags
        when appropriate.

        See also: to_integral_value, which does exactly the same as
        this method except that it doesn't raise Inexact or Rounded.
        'u'Rounds to a nearby integer.

        If no rounding mode is specified, take the rounding mode from
        the context.  This method raises the Rounded and Inexact flags
        when appropriate.

        See also: to_integral_value, which does exactly the same as
        this method except that it doesn't raise Inexact or Rounded.
        'b'Rounds to the nearest integer, without raising inexact, rounded.'u'Rounds to the nearest integer, without raising inexact, rounded.'b'Return the square root of self.'u'Return the square root of self.'b'sqrt(-x), x > 0'u'sqrt(-x), x > 0'b'Returns the larger value.

        Like max(self, other) except if one is not a number, returns
        NaN (and signals if one is sNaN).  Also rounds.
        'u'Returns the larger value.

        Like max(self, other) except if one is not a number, returns
        NaN (and signals if one is sNaN).  Also rounds.
        'b'Returns the smaller value.

        Like min(self, other) except if one is not a number, returns
        NaN (and signals if one is sNaN).  Also rounds.
        'u'Returns the smaller value.

        Like min(self, other) except if one is not a number, returns
        NaN (and signals if one is sNaN).  Also rounds.
        'b'Returns whether self is an integer'u'Returns whether self is an integer'b'Returns True if self is even.  Assumes self is an integer.'u'Returns True if self is even.  Assumes self is an integer.'b'Return the adjusted exponent of self'u'Return the adjusted exponent of self'b'Returns the same Decimal object.

        As we do not have different encodings for the same number, the
        received object already is in its canonical form.
        'u'Returns the same Decimal object.

        As we do not have different encodings for the same number, the
        received object already is in its canonical form.
        'b'Compares self to the other operand numerically.

        It's pretty much like compare(), but all NaNs signal, with signaling
        NaNs taking precedence over quiet NaNs.
        'u'Compares self to the other operand numerically.

        It's pretty much like compare(), but all NaNs signal, with signaling
        NaNs taking precedence over quiet NaNs.
        'b'Compares self to other using the abstract representations.

        This is not like the standard compare, which use their numerical
        value. Note that a total ordering is defined for all possible abstract
        representations.
        'u'Compares self to other using the abstract representations.

        This is not like the standard compare, which use their numerical
        value. Note that a total ordering is defined for all possible abstract
        representations.
        'b'Compares self to other using abstract repr., ignoring sign.

        Like compare_total, but with operand's sign ignored and assumed to be 0.
        'u'Compares self to other using abstract repr., ignoring sign.

        Like compare_total, but with operand's sign ignored and assumed to be 0.
        'b'Returns a copy with the sign set to 0. 'u'Returns a copy with the sign set to 0. 'b'Returns a copy with the sign inverted.'u'Returns a copy with the sign inverted.'b'Returns self with the sign of other.'u'Returns self with the sign of other.'b'Returns e ** self.'u'Returns e ** self.'b'Return True if self is canonical; otherwise return False.

        Currently, the encoding of a Decimal instance is always
        canonical, so this method returns True for any Decimal.
        'u'Return True if self is canonical; otherwise return False.

        Currently, the encoding of a Decimal instance is always
        canonical, so this method returns True for any Decimal.
        'b'Return True if self is finite; otherwise return False.

        A Decimal instance is considered finite if it is neither
        infinite nor a NaN.
        'u'Return True if self is finite; otherwise return False.

        A Decimal instance is considered finite if it is neither
        infinite nor a NaN.
        'b'Return True if self is infinite; otherwise return False.'u'Return True if self is infinite; otherwise return False.'b'Return True if self is a qNaN or sNaN; otherwise return False.'u'Return True if self is a qNaN or sNaN; otherwise return False.'b'Return True if self is a normal number; otherwise return False.'u'Return True if self is a normal number; otherwise return False.'b'Return True if self is a quiet NaN; otherwise return False.'u'Return True if self is a quiet NaN; otherwise return False.'b'Return True if self is negative; otherwise return False.'u'Return True if self is negative; otherwise return False.'b'Return True if self is a signaling NaN; otherwise return False.'u'Return True if self is a signaling NaN; otherwise return False.'b'Return True if self is subnormal; otherwise return False.'u'Return True if self is subnormal; otherwise return False.'b'Return True if self is a zero; otherwise return False.'u'Return True if self is a zero; otherwise return False.'b'Compute a lower bound for the adjusted exponent of self.ln().
        In other words, compute r such that self.ln() >= 10**r.  Assumes
        that self is finite and positive and that self != 1.
        'u'Compute a lower bound for the adjusted exponent of self.ln().
        In other words, compute r such that self.ln() >= 10**r.  Assumes
        that self is finite and positive and that self != 1.
        'b'Returns the natural (base e) logarithm of self.'u'Returns the natural (base e) logarithm of self.'b'ln of a negative value'u'ln of a negative value'b'Compute a lower bound for the adjusted exponent of self.log10().
        In other words, find r such that self.log10() >= 10**r.
        Assumes that self is finite and positive and that self != 1.
        'u'Compute a lower bound for the adjusted exponent of self.log10().
        In other words, find r such that self.log10() >= 10**r.
        Assumes that self is finite and positive and that self != 1.
        'b'231'u'231'b'Returns the base 10 logarithm of self.'u'Returns the base 10 logarithm of self.'b'log10 of a negative value'u'log10 of a negative value'b' Returns the exponent of the magnitude of self's MSD.

        The result is the integer which is the exponent of the magnitude
        of the most significant digit of self (as though it were truncated
        to a single digit while maintaining the value of that digit and
        without limiting the resulting exponent).
        'u' Returns the exponent of the magnitude of self's MSD.

        The result is the integer which is the exponent of the magnitude
        of the most significant digit of self (as though it were truncated
        to a single digit while maintaining the value of that digit and
        without limiting the resulting exponent).
        'b'logb(0)'u'logb(0)'b'Return True if self is a logical operand.

        For being logical, it must be a finite number with a sign of 0,
        an exponent of 0, and a coefficient whose digits must all be
        either 0 or 1.
        'u'Return True if self is a logical operand.

        For being logical, it must be a finite number with a sign of 0,
        an exponent of 0, and a coefficient whose digits must all be
        either 0 or 1.
        'b'01'u'01'b'Applies an 'and' operation between self and other's digits.'u'Applies an 'and' operation between self and other's digits.'b'Invert all its digits.'u'Invert all its digits.'b'Applies an 'or' operation between self and other's digits.'u'Applies an 'or' operation between self and other's digits.'b'Applies an 'xor' operation between self and other's digits.'u'Applies an 'xor' operation between self and other's digits.'b'Compares the values numerically with their sign ignored.'u'Compares the values numerically with their sign ignored.'b'Returns the largest representable number smaller than itself.'u'Returns the largest representable number smaller than itself.'b'Returns the smallest representable number larger than itself.'u'Returns the smallest representable number larger than itself.'b'Returns the number closest to self, in the direction towards other.

        The result is the closest representable number to self
        (excluding self) that is in the direction towards other,
        unless both have the same value.  If the two operands are
        numerically equal, then the result is a copy of self with the
        sign set to be the same as the sign of other.
        'u'Returns the number closest to self, in the direction towards other.

        The result is the closest representable number to self
        (excluding self) that is in the direction towards other,
        unless both have the same value.  If the two operands are
        numerically equal, then the result is a copy of self with the
        sign set to be the same as the sign of other.
        'b'Infinite result from next_toward'u'Infinite result from next_toward'b'Returns an indication of the class of self.

        The class is one of the following strings:
          sNaN
          NaN
          -Infinity
          -Normal
          -Subnormal
          -Zero
          +Zero
          +Subnormal
          +Normal
          +Infinity
        'u'Returns an indication of the class of self.

        The class is one of the following strings:
          sNaN
          NaN
          -Infinity
          -Normal
          -Subnormal
          -Zero
          +Zero
          +Subnormal
          +Normal
          +Infinity
        'b'+Infinity'u'+Infinity'b'-Infinity'u'-Infinity'b'-Zero'u'-Zero'b'+Zero'u'+Zero'b'-Subnormal'u'-Subnormal'b'+Subnormal'u'+Subnormal'b'-Normal'u'-Normal'b'+Normal'u'+Normal'b'Just returns 10, as this is Decimal, :)'u'Just returns 10, as this is Decimal, :)'b'Returns a rotated copy of self, value-of-other times.'u'Returns a rotated copy of self, value-of-other times.'b'Returns self operand after adding the second value to its exp.'u'Returns self operand after adding the second value to its exp.'b'Returns a shifted copy of self, value-of-other times.'u'Returns a shifted copy of self, value-of-other times.'b'Format a Decimal instance according to the given specifier.

        The specifier should be a standard format specifier, with the
        form described in PEP 3101.  Formatting types 'e', 'E', 'f',
        'F', 'g', 'G', 'n' and '%' are supported.  If the formatting
        type is omitted it defaults to 'g' or 'G', depending on the
        value of context.capitals.
        'u'Format a Decimal instance according to the given specifier.

        The specifier should be a standard format specifier, with the
        form described in PEP 3101.  Formatting types 'e', 'E', 'f',
        'F', 'g', 'G', 'n' and '%' are supported.  If the formatting
        type is omitted it defaults to 'g' or 'G', depending on the
        value of context.capitals.
        'b'G'u'G'b'precision'u'precision'b'eE'u'eE'b'fF%'u'fF%'b'gG'u'gG'b'Create a decimal instance directly, without any validation,
    normalization (e.g. removal of leading zeros) or argument
    conversion.

    This function is for *internal use only*.
    'u'Create a decimal instance directly, without any validation,
    normalization (e.g. removal of leading zeros) or argument
    conversion.

    This function is for *internal use only*.
    'b'Context manager class to support localcontext().

      Sets a copy of the supplied context in __enter__() and restores
      the previous decimal context in __exit__()
    'u'Context manager class to support localcontext().

      Sets a copy of the supplied context in __enter__() and restores
      the previous decimal context in __exit__()
    'b'Contains the context for a Decimal instance.

    Contains:
    prec - precision (for use in rounding, division, square roots..)
    rounding - rounding type (how you round)
    traps - If traps[exception] = 1, then the exception is
                    raised when it is caused.  Otherwise, a value is
                    substituted in.
    flags  - When an exception is caused, flags[exception] is set.
             (Whether or not the trap_enabler is set)
             Should be reset by user of Decimal instance.
    Emin -   Minimum exponent
    Emax -   Maximum exponent
    capitals -      If 1, 1*10^1 is printed as 1E+1.
                    If 0, printed as 1e1
    clamp -  If 1, change exponents if too high (Default 0)
    'u'Contains the context for a Decimal instance.

    Contains:
    prec - precision (for use in rounding, division, square roots..)
    rounding - rounding type (how you round)
    traps - If traps[exception] = 1, then the exception is
                    raised when it is caused.  Otherwise, a value is
                    substituted in.
    flags  - When an exception is caused, flags[exception] is set.
             (Whether or not the trap_enabler is set)
             Should be reset by user of Decimal instance.
    Emin -   Minimum exponent
    Emax -   Maximum exponent
    capitals -      If 1, 1*10^1 is printed as 1E+1.
                    If 0, printed as 1e1
    clamp -  If 1, change exponents if too high (Default 0)
    'b'%s must be an integer'u'%s must be an integer'b'-inf'u'-inf'b'%s must be in [%s, %d]. got: %s'u'%s must be in [%s, %d]. got: %s'b'inf'b'%s must be in [%d, %s]. got: %s'u'%s must be in [%d, %s]. got: %s'b'%s must be in [%d, %d]. got %s'u'%s must be in [%d, %d]. got %s'b'%s must be a signal dict'u'%s must be a signal dict'b'%s is not a valid signal dict'u'%s is not a valid signal dict'b'prec'u'prec'b'Emin'u'Emin'b'Emax'u'Emax'b'capitals'u'capitals'b'clamp'u'clamp'b'rounding'u'rounding'b'%s: invalid rounding mode'u'%s: invalid rounding mode'b'flags'u'flags'b'traps'u'traps'b'_ignored_flags'u'_ignored_flags'b''decimal.Context' object has no attribute '%s''u''decimal.Context' object has no attribute '%s''b'%s cannot be deleted'u'%s cannot be deleted'b'Show the current context.'u'Show the current context.'b'Context(prec=%(prec)d, rounding=%(rounding)s, Emin=%(Emin)d, Emax=%(Emax)d, capitals=%(capitals)d, clamp=%(clamp)d'u'Context(prec=%(prec)d, rounding=%(rounding)s, Emin=%(Emin)d, Emax=%(Emax)d, capitals=%(capitals)d, clamp=%(clamp)d'b'flags=['u'flags=['b'traps=['u'traps=['b'Reset all flags to zero'u'Reset all flags to zero'b'Reset all traps to zero'u'Reset all traps to zero'b'Returns a shallow copy from self.'u'Returns a shallow copy from self.'b'Returns a deep copy from self.'u'Returns a deep copy from self.'b'Handles an error

        If the flag is in _ignored_flags, returns the default response.
        Otherwise, it sets the flag, then, if the corresponding
        trap_enabler is set, it reraises the exception.  Otherwise, it returns
        the default value after setting the flag.
        'u'Handles an error

        If the flag is in _ignored_flags, returns the default response.
        Otherwise, it sets the flag, then, if the corresponding
        trap_enabler is set, it reraises the exception.  Otherwise, it returns
        the default value after setting the flag.
        'b'Ignore all flags, if they are raised'u'Ignore all flags, if they are raised'b'Ignore the flags, if they are raised'u'Ignore the flags, if they are raised'b'Stop ignoring the flags, if they are raised'u'Stop ignoring the flags, if they are raised'b'Returns Etiny (= Emin - prec + 1)'u'Returns Etiny (= Emin - prec + 1)'b'Returns maximum exponent (= Emax - prec + 1)'u'Returns maximum exponent (= Emax - prec + 1)'b'Sets the rounding type.

        Sets the rounding type, and returns the current (previous)
        rounding type.  Often used like:

        context = context.copy()
        # so you don't change the calling context
        # if an error occurs in the middle.
        rounding = context._set_rounding(ROUND_UP)
        val = self.__sub__(other, context=context)
        context._set_rounding(rounding)

        This will make it round up for that operation.
        'u'Sets the rounding type.

        Sets the rounding type, and returns the current (previous)
        rounding type.  Often used like:

        context = context.copy()
        # so you don't change the calling context
        # if an error occurs in the middle.
        rounding = context._set_rounding(ROUND_UP)
        val = self.__sub__(other, context=context)
        context._set_rounding(rounding)

        This will make it round up for that operation.
        'b'Creates a new Decimal instance but using self as context.

        This method implements the to-number operation of the
        IBM Decimal specification.'u'Creates a new Decimal instance but using self as context.

        This method implements the to-number operation of the
        IBM Decimal specification.'b'trailing or leading whitespace and underscores are not permitted.'u'trailing or leading whitespace and underscores are not permitted.'b'diagnostic info too long in NaN'u'diagnostic info too long in NaN'b'Creates a new Decimal instance from a float but rounding using self
        as the context.

        >>> context = Context(prec=5, rounding=ROUND_DOWN)
        >>> context.create_decimal_from_float(3.1415926535897932)
        Decimal('3.1415')
        >>> context = Context(prec=5, traps=[Inexact])
        >>> context.create_decimal_from_float(3.1415926535897932)
        Traceback (most recent call last):
            ...
        decimal.Inexact: None

        'u'Creates a new Decimal instance from a float but rounding using self
        as the context.

        >>> context = Context(prec=5, rounding=ROUND_DOWN)
        >>> context.create_decimal_from_float(3.1415926535897932)
        Decimal('3.1415')
        >>> context = Context(prec=5, traps=[Inexact])
        >>> context.create_decimal_from_float(3.1415926535897932)
        Traceback (most recent call last):
            ...
        decimal.Inexact: None

        'b'Returns the absolute value of the operand.

        If the operand is negative, the result is the same as using the minus
        operation on the operand.  Otherwise, the result is the same as using
        the plus operation on the operand.

        >>> ExtendedContext.abs(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.abs(Decimal('-100'))
        Decimal('100')
        >>> ExtendedContext.abs(Decimal('101.5'))
        Decimal('101.5')
        >>> ExtendedContext.abs(Decimal('-101.5'))
        Decimal('101.5')
        >>> ExtendedContext.abs(-1)
        Decimal('1')
        'u'Returns the absolute value of the operand.

        If the operand is negative, the result is the same as using the minus
        operation on the operand.  Otherwise, the result is the same as using
        the plus operation on the operand.

        >>> ExtendedContext.abs(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.abs(Decimal('-100'))
        Decimal('100')
        >>> ExtendedContext.abs(Decimal('101.5'))
        Decimal('101.5')
        >>> ExtendedContext.abs(Decimal('-101.5'))
        Decimal('101.5')
        >>> ExtendedContext.abs(-1)
        Decimal('1')
        'b'Return the sum of the two operands.

        >>> ExtendedContext.add(Decimal('12'), Decimal('7.00'))
        Decimal('19.00')
        >>> ExtendedContext.add(Decimal('1E+2'), Decimal('1.01E+4'))
        Decimal('1.02E+4')
        >>> ExtendedContext.add(1, Decimal(2))
        Decimal('3')
        >>> ExtendedContext.add(Decimal(8), 5)
        Decimal('13')
        >>> ExtendedContext.add(5, 5)
        Decimal('10')
        'u'Return the sum of the two operands.

        >>> ExtendedContext.add(Decimal('12'), Decimal('7.00'))
        Decimal('19.00')
        >>> ExtendedContext.add(Decimal('1E+2'), Decimal('1.01E+4'))
        Decimal('1.02E+4')
        >>> ExtendedContext.add(1, Decimal(2))
        Decimal('3')
        >>> ExtendedContext.add(Decimal(8), 5)
        Decimal('13')
        >>> ExtendedContext.add(5, 5)
        Decimal('10')
        'b'Unable to convert %s to Decimal'u'Unable to convert %s to Decimal'b'Returns the same Decimal object.

        As we do not have different encodings for the same number, the
        received object already is in its canonical form.

        >>> ExtendedContext.canonical(Decimal('2.50'))
        Decimal('2.50')
        'u'Returns the same Decimal object.

        As we do not have different encodings for the same number, the
        received object already is in its canonical form.

        >>> ExtendedContext.canonical(Decimal('2.50'))
        Decimal('2.50')
        'b'canonical requires a Decimal as an argument.'u'canonical requires a Decimal as an argument.'b'Compares values numerically.

        If the signs of the operands differ, a value representing each operand
        ('-1' if the operand is less than zero, '0' if the operand is zero or
        negative zero, or '1' if the operand is greater than zero) is used in
        place of that operand for the comparison instead of the actual
        operand.

        The comparison is then effected by subtracting the second operand from
        the first and then returning a value according to the result of the
        subtraction: '-1' if the result is less than zero, '0' if the result is
        zero or negative zero, or '1' if the result is greater than zero.

        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.1'))
        Decimal('0')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.10'))
        Decimal('0')
        >>> ExtendedContext.compare(Decimal('3'), Decimal('2.1'))
        Decimal('1')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('-3'))
        Decimal('1')
        >>> ExtendedContext.compare(Decimal('-3'), Decimal('2.1'))
        Decimal('-1')
        >>> ExtendedContext.compare(1, 2)
        Decimal('-1')
        >>> ExtendedContext.compare(Decimal(1), 2)
        Decimal('-1')
        >>> ExtendedContext.compare(1, Decimal(2))
        Decimal('-1')
        'u'Compares values numerically.

        If the signs of the operands differ, a value representing each operand
        ('-1' if the operand is less than zero, '0' if the operand is zero or
        negative zero, or '1' if the operand is greater than zero) is used in
        place of that operand for the comparison instead of the actual
        operand.

        The comparison is then effected by subtracting the second operand from
        the first and then returning a value according to the result of the
        subtraction: '-1' if the result is less than zero, '0' if the result is
        zero or negative zero, or '1' if the result is greater than zero.

        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.1'))
        Decimal('0')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.10'))
        Decimal('0')
        >>> ExtendedContext.compare(Decimal('3'), Decimal('2.1'))
        Decimal('1')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('-3'))
        Decimal('1')
        >>> ExtendedContext.compare(Decimal('-3'), Decimal('2.1'))
        Decimal('-1')
        >>> ExtendedContext.compare(1, 2)
        Decimal('-1')
        >>> ExtendedContext.compare(Decimal(1), 2)
        Decimal('-1')
        >>> ExtendedContext.compare(1, Decimal(2))
        Decimal('-1')
        'b'Compares the values of the two operands numerically.

        It's pretty much like compare(), but all NaNs signal, with signaling
        NaNs taking precedence over quiet NaNs.

        >>> c = ExtendedContext
        >>> c.compare_signal(Decimal('2.1'), Decimal('3'))
        Decimal('-1')
        >>> c.compare_signal(Decimal('2.1'), Decimal('2.1'))
        Decimal('0')
        >>> c.flags[InvalidOperation] = 0
        >>> print(c.flags[InvalidOperation])
        0
        >>> c.compare_signal(Decimal('NaN'), Decimal('2.1'))
        Decimal('NaN')
        >>> print(c.flags[InvalidOperation])
        1
        >>> c.flags[InvalidOperation] = 0
        >>> print(c.flags[InvalidOperation])
        0
        >>> c.compare_signal(Decimal('sNaN'), Decimal('2.1'))
        Decimal('NaN')
        >>> print(c.flags[InvalidOperation])
        1
        >>> c.compare_signal(-1, 2)
        Decimal('-1')
        >>> c.compare_signal(Decimal(-1), 2)
        Decimal('-1')
        >>> c.compare_signal(-1, Decimal(2))
        Decimal('-1')
        'u'Compares the values of the two operands numerically.

        It's pretty much like compare(), but all NaNs signal, with signaling
        NaNs taking precedence over quiet NaNs.

        >>> c = ExtendedContext
        >>> c.compare_signal(Decimal('2.1'), Decimal('3'))
        Decimal('-1')
        >>> c.compare_signal(Decimal('2.1'), Decimal('2.1'))
        Decimal('0')
        >>> c.flags[InvalidOperation] = 0
        >>> print(c.flags[InvalidOperation])
        0
        >>> c.compare_signal(Decimal('NaN'), Decimal('2.1'))
        Decimal('NaN')
        >>> print(c.flags[InvalidOperation])
        1
        >>> c.flags[InvalidOperation] = 0
        >>> print(c.flags[InvalidOperation])
        0
        >>> c.compare_signal(Decimal('sNaN'), Decimal('2.1'))
        Decimal('NaN')
        >>> print(c.flags[InvalidOperation])
        1
        >>> c.compare_signal(-1, 2)
        Decimal('-1')
        >>> c.compare_signal(Decimal(-1), 2)
        Decimal('-1')
        >>> c.compare_signal(-1, Decimal(2))
        Decimal('-1')
        'b'Compares two operands using their abstract representation.

        This is not like the standard compare, which use their numerical
        value. Note that a total ordering is defined for all possible abstract
        representations.

        >>> ExtendedContext.compare_total(Decimal('12.73'), Decimal('127.9'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('-127'),  Decimal('12'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.3'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.30'))
        Decimal('0')
        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('12.300'))
        Decimal('1')
        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('NaN'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(1, 2)
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal(1), 2)
        Decimal('-1')
        >>> ExtendedContext.compare_total(1, Decimal(2))
        Decimal('-1')
        'u'Compares two operands using their abstract representation.

        This is not like the standard compare, which use their numerical
        value. Note that a total ordering is defined for all possible abstract
        representations.

        >>> ExtendedContext.compare_total(Decimal('12.73'), Decimal('127.9'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('-127'),  Decimal('12'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.3'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.30'))
        Decimal('0')
        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('12.300'))
        Decimal('1')
        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('NaN'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(1, 2)
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal(1), 2)
        Decimal('-1')
        >>> ExtendedContext.compare_total(1, Decimal(2))
        Decimal('-1')
        'b'Compares two operands using their abstract representation ignoring sign.

        Like compare_total, but with operand's sign ignored and assumed to be 0.
        'u'Compares two operands using their abstract representation ignoring sign.

        Like compare_total, but with operand's sign ignored and assumed to be 0.
        'b'Returns a copy of the operand with the sign set to 0.

        >>> ExtendedContext.copy_abs(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.copy_abs(Decimal('-100'))
        Decimal('100')
        >>> ExtendedContext.copy_abs(-1)
        Decimal('1')
        'u'Returns a copy of the operand with the sign set to 0.

        >>> ExtendedContext.copy_abs(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.copy_abs(Decimal('-100'))
        Decimal('100')
        >>> ExtendedContext.copy_abs(-1)
        Decimal('1')
        'b'Returns a copy of the decimal object.

        >>> ExtendedContext.copy_decimal(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.copy_decimal(Decimal('-1.00'))
        Decimal('-1.00')
        >>> ExtendedContext.copy_decimal(1)
        Decimal('1')
        'u'Returns a copy of the decimal object.

        >>> ExtendedContext.copy_decimal(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.copy_decimal(Decimal('-1.00'))
        Decimal('-1.00')
        >>> ExtendedContext.copy_decimal(1)
        Decimal('1')
        'b'Returns a copy of the operand with the sign inverted.

        >>> ExtendedContext.copy_negate(Decimal('101.5'))
        Decimal('-101.5')
        >>> ExtendedContext.copy_negate(Decimal('-101.5'))
        Decimal('101.5')
        >>> ExtendedContext.copy_negate(1)
        Decimal('-1')
        'u'Returns a copy of the operand with the sign inverted.

        >>> ExtendedContext.copy_negate(Decimal('101.5'))
        Decimal('-101.5')
        >>> ExtendedContext.copy_negate(Decimal('-101.5'))
        Decimal('101.5')
        >>> ExtendedContext.copy_negate(1)
        Decimal('-1')
        'b'Copies the second operand's sign to the first one.

        In detail, it returns a copy of the first operand with the sign
        equal to the sign of the second operand.

        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('7.33'))
        Decimal('1.50')
        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('7.33'))
        Decimal('1.50')
        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('-7.33'))
        Decimal('-1.50')
        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('-7.33'))
        Decimal('-1.50')
        >>> ExtendedContext.copy_sign(1, -2)
        Decimal('-1')
        >>> ExtendedContext.copy_sign(Decimal(1), -2)
        Decimal('-1')
        >>> ExtendedContext.copy_sign(1, Decimal(-2))
        Decimal('-1')
        'u'Copies the second operand's sign to the first one.

        In detail, it returns a copy of the first operand with the sign
        equal to the sign of the second operand.

        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('7.33'))
        Decimal('1.50')
        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('7.33'))
        Decimal('1.50')
        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('-7.33'))
        Decimal('-1.50')
        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('-7.33'))
        Decimal('-1.50')
        >>> ExtendedContext.copy_sign(1, -2)
        Decimal('-1')
        >>> ExtendedContext.copy_sign(Decimal(1), -2)
        Decimal('-1')
        >>> ExtendedContext.copy_sign(1, Decimal(-2))
        Decimal('-1')
        'b'Decimal division in a specified context.

        >>> ExtendedContext.divide(Decimal('1'), Decimal('3'))
        Decimal('0.333333333')
        >>> ExtendedContext.divide(Decimal('2'), Decimal('3'))
        Decimal('0.666666667')
        >>> ExtendedContext.divide(Decimal('5'), Decimal('2'))
        Decimal('2.5')
        >>> ExtendedContext.divide(Decimal('1'), Decimal('10'))
        Decimal('0.1')
        >>> ExtendedContext.divide(Decimal('12'), Decimal('12'))
        Decimal('1')
        >>> ExtendedContext.divide(Decimal('8.00'), Decimal('2'))
        Decimal('4.00')
        >>> ExtendedContext.divide(Decimal('2.400'), Decimal('2.0'))
        Decimal('1.20')
        >>> ExtendedContext.divide(Decimal('1000'), Decimal('100'))
        Decimal('10')
        >>> ExtendedContext.divide(Decimal('1000'), Decimal('1'))
        Decimal('1000')
        >>> ExtendedContext.divide(Decimal('2.40E+6'), Decimal('2'))
        Decimal('1.20E+6')
        >>> ExtendedContext.divide(5, 5)
        Decimal('1')
        >>> ExtendedContext.divide(Decimal(5), 5)
        Decimal('1')
        >>> ExtendedContext.divide(5, Decimal(5))
        Decimal('1')
        'u'Decimal division in a specified context.

        >>> ExtendedContext.divide(Decimal('1'), Decimal('3'))
        Decimal('0.333333333')
        >>> ExtendedContext.divide(Decimal('2'), Decimal('3'))
        Decimal('0.666666667')
        >>> ExtendedContext.divide(Decimal('5'), Decimal('2'))
        Decimal('2.5')
        >>> ExtendedContext.divide(Decimal('1'), Decimal('10'))
        Decimal('0.1')
        >>> ExtendedContext.divide(Decimal('12'), Decimal('12'))
        Decimal('1')
        >>> ExtendedContext.divide(Decimal('8.00'), Decimal('2'))
        Decimal('4.00')
        >>> ExtendedContext.divide(Decimal('2.400'), Decimal('2.0'))
        Decimal('1.20')
        >>> ExtendedContext.divide(Decimal('1000'), Decimal('100'))
        Decimal('10')
        >>> ExtendedContext.divide(Decimal('1000'), Decimal('1'))
        Decimal('1000')
        >>> ExtendedContext.divide(Decimal('2.40E+6'), Decimal('2'))
        Decimal('1.20E+6')
        >>> ExtendedContext.divide(5, 5)
        Decimal('1')
        >>> ExtendedContext.divide(Decimal(5), 5)
        Decimal('1')
        >>> ExtendedContext.divide(5, Decimal(5))
        Decimal('1')
        'b'Divides two numbers and returns the integer part of the result.

        >>> ExtendedContext.divide_int(Decimal('2'), Decimal('3'))
        Decimal('0')
        >>> ExtendedContext.divide_int(Decimal('10'), Decimal('3'))
        Decimal('3')
        >>> ExtendedContext.divide_int(Decimal('1'), Decimal('0.3'))
        Decimal('3')
        >>> ExtendedContext.divide_int(10, 3)
        Decimal('3')
        >>> ExtendedContext.divide_int(Decimal(10), 3)
        Decimal('3')
        >>> ExtendedContext.divide_int(10, Decimal(3))
        Decimal('3')
        'u'Divides two numbers and returns the integer part of the result.

        >>> ExtendedContext.divide_int(Decimal('2'), Decimal('3'))
        Decimal('0')
        >>> ExtendedContext.divide_int(Decimal('10'), Decimal('3'))
        Decimal('3')
        >>> ExtendedContext.divide_int(Decimal('1'), Decimal('0.3'))
        Decimal('3')
        >>> ExtendedContext.divide_int(10, 3)
        Decimal('3')
        >>> ExtendedContext.divide_int(Decimal(10), 3)
        Decimal('3')
        >>> ExtendedContext.divide_int(10, Decimal(3))
        Decimal('3')
        'b'Return (a // b, a % b).

        >>> ExtendedContext.divmod(Decimal(8), Decimal(3))
        (Decimal('2'), Decimal('2'))
        >>> ExtendedContext.divmod(Decimal(8), Decimal(4))
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(8, 4)
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(Decimal(8), 4)
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(8, Decimal(4))
        (Decimal('2'), Decimal('0'))
        'u'Return (a // b, a % b).

        >>> ExtendedContext.divmod(Decimal(8), Decimal(3))
        (Decimal('2'), Decimal('2'))
        >>> ExtendedContext.divmod(Decimal(8), Decimal(4))
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(8, 4)
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(Decimal(8), 4)
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(8, Decimal(4))
        (Decimal('2'), Decimal('0'))
        'b'Returns e ** a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.exp(Decimal('-Infinity'))
        Decimal('0')
        >>> c.exp(Decimal('-1'))
        Decimal('0.367879441')
        >>> c.exp(Decimal('0'))
        Decimal('1')
        >>> c.exp(Decimal('1'))
        Decimal('2.71828183')
        >>> c.exp(Decimal('0.693147181'))
        Decimal('2.00000000')
        >>> c.exp(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.exp(10)
        Decimal('22026.4658')
        'u'Returns e ** a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.exp(Decimal('-Infinity'))
        Decimal('0')
        >>> c.exp(Decimal('-1'))
        Decimal('0.367879441')
        >>> c.exp(Decimal('0'))
        Decimal('1')
        >>> c.exp(Decimal('1'))
        Decimal('2.71828183')
        >>> c.exp(Decimal('0.693147181'))
        Decimal('2.00000000')
        >>> c.exp(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.exp(10)
        Decimal('22026.4658')
        'b'Returns a multiplied by b, plus c.

        The first two operands are multiplied together, using multiply,
        the third operand is then added to the result of that
        multiplication, using add, all with only one final rounding.

        >>> ExtendedContext.fma(Decimal('3'), Decimal('5'), Decimal('7'))
        Decimal('22')
        >>> ExtendedContext.fma(Decimal('3'), Decimal('-5'), Decimal('7'))
        Decimal('-8')
        >>> ExtendedContext.fma(Decimal('888565290'), Decimal('1557.96930'), Decimal('-86087.7578'))
        Decimal('1.38435736E+12')
        >>> ExtendedContext.fma(1, 3, 4)
        Decimal('7')
        >>> ExtendedContext.fma(1, Decimal(3), 4)
        Decimal('7')
        >>> ExtendedContext.fma(1, 3, Decimal(4))
        Decimal('7')
        'u'Returns a multiplied by b, plus c.

        The first two operands are multiplied together, using multiply,
        the third operand is then added to the result of that
        multiplication, using add, all with only one final rounding.

        >>> ExtendedContext.fma(Decimal('3'), Decimal('5'), Decimal('7'))
        Decimal('22')
        >>> ExtendedContext.fma(Decimal('3'), Decimal('-5'), Decimal('7'))
        Decimal('-8')
        >>> ExtendedContext.fma(Decimal('888565290'), Decimal('1557.96930'), Decimal('-86087.7578'))
        Decimal('1.38435736E+12')
        >>> ExtendedContext.fma(1, 3, 4)
        Decimal('7')
        >>> ExtendedContext.fma(1, Decimal(3), 4)
        Decimal('7')
        >>> ExtendedContext.fma(1, 3, Decimal(4))
        Decimal('7')
        'b'Return True if the operand is canonical; otherwise return False.

        Currently, the encoding of a Decimal instance is always
        canonical, so this method returns True for any Decimal.

        >>> ExtendedContext.is_canonical(Decimal('2.50'))
        True
        'u'Return True if the operand is canonical; otherwise return False.

        Currently, the encoding of a Decimal instance is always
        canonical, so this method returns True for any Decimal.

        >>> ExtendedContext.is_canonical(Decimal('2.50'))
        True
        'b'is_canonical requires a Decimal as an argument.'u'is_canonical requires a Decimal as an argument.'b'Return True if the operand is finite; otherwise return False.

        A Decimal instance is considered finite if it is neither
        infinite nor a NaN.

        >>> ExtendedContext.is_finite(Decimal('2.50'))
        True
        >>> ExtendedContext.is_finite(Decimal('-0.3'))
        True
        >>> ExtendedContext.is_finite(Decimal('0'))
        True
        >>> ExtendedContext.is_finite(Decimal('Inf'))
        False
        >>> ExtendedContext.is_finite(Decimal('NaN'))
        False
        >>> ExtendedContext.is_finite(1)
        True
        'u'Return True if the operand is finite; otherwise return False.

        A Decimal instance is considered finite if it is neither
        infinite nor a NaN.

        >>> ExtendedContext.is_finite(Decimal('2.50'))
        True
        >>> ExtendedContext.is_finite(Decimal('-0.3'))
        True
        >>> ExtendedContext.is_finite(Decimal('0'))
        True
        >>> ExtendedContext.is_finite(Decimal('Inf'))
        False
        >>> ExtendedContext.is_finite(Decimal('NaN'))
        False
        >>> ExtendedContext.is_finite(1)
        True
        'b'Return True if the operand is infinite; otherwise return False.

        >>> ExtendedContext.is_infinite(Decimal('2.50'))
        False
        >>> ExtendedContext.is_infinite(Decimal('-Inf'))
        True
        >>> ExtendedContext.is_infinite(Decimal('NaN'))
        False
        >>> ExtendedContext.is_infinite(1)
        False
        'u'Return True if the operand is infinite; otherwise return False.

        >>> ExtendedContext.is_infinite(Decimal('2.50'))
        False
        >>> ExtendedContext.is_infinite(Decimal('-Inf'))
        True
        >>> ExtendedContext.is_infinite(Decimal('NaN'))
        False
        >>> ExtendedContext.is_infinite(1)
        False
        'b'Return True if the operand is a qNaN or sNaN;
        otherwise return False.

        >>> ExtendedContext.is_nan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_nan(Decimal('NaN'))
        True
        >>> ExtendedContext.is_nan(Decimal('-sNaN'))
        True
        >>> ExtendedContext.is_nan(1)
        False
        'u'Return True if the operand is a qNaN or sNaN;
        otherwise return False.

        >>> ExtendedContext.is_nan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_nan(Decimal('NaN'))
        True
        >>> ExtendedContext.is_nan(Decimal('-sNaN'))
        True
        >>> ExtendedContext.is_nan(1)
        False
        'b'Return True if the operand is a normal number;
        otherwise return False.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.is_normal(Decimal('2.50'))
        True
        >>> c.is_normal(Decimal('0.1E-999'))
        False
        >>> c.is_normal(Decimal('0.00'))
        False
        >>> c.is_normal(Decimal('-Inf'))
        False
        >>> c.is_normal(Decimal('NaN'))
        False
        >>> c.is_normal(1)
        True
        'u'Return True if the operand is a normal number;
        otherwise return False.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.is_normal(Decimal('2.50'))
        True
        >>> c.is_normal(Decimal('0.1E-999'))
        False
        >>> c.is_normal(Decimal('0.00'))
        False
        >>> c.is_normal(Decimal('-Inf'))
        False
        >>> c.is_normal(Decimal('NaN'))
        False
        >>> c.is_normal(1)
        True
        'b'Return True if the operand is a quiet NaN; otherwise return False.

        >>> ExtendedContext.is_qnan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_qnan(Decimal('NaN'))
        True
        >>> ExtendedContext.is_qnan(Decimal('sNaN'))
        False
        >>> ExtendedContext.is_qnan(1)
        False
        'u'Return True if the operand is a quiet NaN; otherwise return False.

        >>> ExtendedContext.is_qnan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_qnan(Decimal('NaN'))
        True
        >>> ExtendedContext.is_qnan(Decimal('sNaN'))
        False
        >>> ExtendedContext.is_qnan(1)
        False
        'b'Return True if the operand is negative; otherwise return False.

        >>> ExtendedContext.is_signed(Decimal('2.50'))
        False
        >>> ExtendedContext.is_signed(Decimal('-12'))
        True
        >>> ExtendedContext.is_signed(Decimal('-0'))
        True
        >>> ExtendedContext.is_signed(8)
        False
        >>> ExtendedContext.is_signed(-8)
        True
        'u'Return True if the operand is negative; otherwise return False.

        >>> ExtendedContext.is_signed(Decimal('2.50'))
        False
        >>> ExtendedContext.is_signed(Decimal('-12'))
        True
        >>> ExtendedContext.is_signed(Decimal('-0'))
        True
        >>> ExtendedContext.is_signed(8)
        False
        >>> ExtendedContext.is_signed(-8)
        True
        'b'Return True if the operand is a signaling NaN;
        otherwise return False.

        >>> ExtendedContext.is_snan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_snan(Decimal('NaN'))
        False
        >>> ExtendedContext.is_snan(Decimal('sNaN'))
        True
        >>> ExtendedContext.is_snan(1)
        False
        'u'Return True if the operand is a signaling NaN;
        otherwise return False.

        >>> ExtendedContext.is_snan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_snan(Decimal('NaN'))
        False
        >>> ExtendedContext.is_snan(Decimal('sNaN'))
        True
        >>> ExtendedContext.is_snan(1)
        False
        'b'Return True if the operand is subnormal; otherwise return False.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.is_subnormal(Decimal('2.50'))
        False
        >>> c.is_subnormal(Decimal('0.1E-999'))
        True
        >>> c.is_subnormal(Decimal('0.00'))
        False
        >>> c.is_subnormal(Decimal('-Inf'))
        False
        >>> c.is_subnormal(Decimal('NaN'))
        False
        >>> c.is_subnormal(1)
        False
        'u'Return True if the operand is subnormal; otherwise return False.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.is_subnormal(Decimal('2.50'))
        False
        >>> c.is_subnormal(Decimal('0.1E-999'))
        True
        >>> c.is_subnormal(Decimal('0.00'))
        False
        >>> c.is_subnormal(Decimal('-Inf'))
        False
        >>> c.is_subnormal(Decimal('NaN'))
        False
        >>> c.is_subnormal(1)
        False
        'b'Return True if the operand is a zero; otherwise return False.

        >>> ExtendedContext.is_zero(Decimal('0'))
        True
        >>> ExtendedContext.is_zero(Decimal('2.50'))
        False
        >>> ExtendedContext.is_zero(Decimal('-0E+2'))
        True
        >>> ExtendedContext.is_zero(1)
        False
        >>> ExtendedContext.is_zero(0)
        True
        'u'Return True if the operand is a zero; otherwise return False.

        >>> ExtendedContext.is_zero(Decimal('0'))
        True
        >>> ExtendedContext.is_zero(Decimal('2.50'))
        False
        >>> ExtendedContext.is_zero(Decimal('-0E+2'))
        True
        >>> ExtendedContext.is_zero(1)
        False
        >>> ExtendedContext.is_zero(0)
        True
        'b'Returns the natural (base e) logarithm of the operand.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.ln(Decimal('0'))
        Decimal('-Infinity')
        >>> c.ln(Decimal('1.000'))
        Decimal('0')
        >>> c.ln(Decimal('2.71828183'))
        Decimal('1.00000000')
        >>> c.ln(Decimal('10'))
        Decimal('2.30258509')
        >>> c.ln(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.ln(1)
        Decimal('0')
        'u'Returns the natural (base e) logarithm of the operand.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.ln(Decimal('0'))
        Decimal('-Infinity')
        >>> c.ln(Decimal('1.000'))
        Decimal('0')
        >>> c.ln(Decimal('2.71828183'))
        Decimal('1.00000000')
        >>> c.ln(Decimal('10'))
        Decimal('2.30258509')
        >>> c.ln(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.ln(1)
        Decimal('0')
        'b'Returns the base 10 logarithm of the operand.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.log10(Decimal('0'))
        Decimal('-Infinity')
        >>> c.log10(Decimal('0.001'))
        Decimal('-3')
        >>> c.log10(Decimal('1.000'))
        Decimal('0')
        >>> c.log10(Decimal('2'))
        Decimal('0.301029996')
        >>> c.log10(Decimal('10'))
        Decimal('1')
        >>> c.log10(Decimal('70'))
        Decimal('1.84509804')
        >>> c.log10(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.log10(0)
        Decimal('-Infinity')
        >>> c.log10(1)
        Decimal('0')
        'u'Returns the base 10 logarithm of the operand.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.log10(Decimal('0'))
        Decimal('-Infinity')
        >>> c.log10(Decimal('0.001'))
        Decimal('-3')
        >>> c.log10(Decimal('1.000'))
        Decimal('0')
        >>> c.log10(Decimal('2'))
        Decimal('0.301029996')
        >>> c.log10(Decimal('10'))
        Decimal('1')
        >>> c.log10(Decimal('70'))
        Decimal('1.84509804')
        >>> c.log10(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.log10(0)
        Decimal('-Infinity')
        >>> c.log10(1)
        Decimal('0')
        'b' Returns the exponent of the magnitude of the operand's MSD.

        The result is the integer which is the exponent of the magnitude
        of the most significant digit of the operand (as though the
        operand were truncated to a single digit while maintaining the
        value of that digit and without limiting the resulting exponent).

        >>> ExtendedContext.logb(Decimal('250'))
        Decimal('2')
        >>> ExtendedContext.logb(Decimal('2.50'))
        Decimal('0')
        >>> ExtendedContext.logb(Decimal('0.03'))
        Decimal('-2')
        >>> ExtendedContext.logb(Decimal('0'))
        Decimal('-Infinity')
        >>> ExtendedContext.logb(1)
        Decimal('0')
        >>> ExtendedContext.logb(10)
        Decimal('1')
        >>> ExtendedContext.logb(100)
        Decimal('2')
        'u' Returns the exponent of the magnitude of the operand's MSD.

        The result is the integer which is the exponent of the magnitude
        of the most significant digit of the operand (as though the
        operand were truncated to a single digit while maintaining the
        value of that digit and without limiting the resulting exponent).

        >>> ExtendedContext.logb(Decimal('250'))
        Decimal('2')
        >>> ExtendedContext.logb(Decimal('2.50'))
        Decimal('0')
        >>> ExtendedContext.logb(Decimal('0.03'))
        Decimal('-2')
        >>> ExtendedContext.logb(Decimal('0'))
        Decimal('-Infinity')
        >>> ExtendedContext.logb(1)
        Decimal('0')
        >>> ExtendedContext.logb(10)
        Decimal('1')
        >>> ExtendedContext.logb(100)
        Decimal('2')
        'b'Applies the logical operation 'and' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('1'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_and(Decimal('1100'), Decimal('1010'))
        Decimal('1000')
        >>> ExtendedContext.logical_and(Decimal('1111'), Decimal('10'))
        Decimal('10')
        >>> ExtendedContext.logical_and(110, 1101)
        Decimal('100')
        >>> ExtendedContext.logical_and(Decimal(110), 1101)
        Decimal('100')
        >>> ExtendedContext.logical_and(110, Decimal(1101))
        Decimal('100')
        'u'Applies the logical operation 'and' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('1'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_and(Decimal('1100'), Decimal('1010'))
        Decimal('1000')
        >>> ExtendedContext.logical_and(Decimal('1111'), Decimal('10'))
        Decimal('10')
        >>> ExtendedContext.logical_and(110, 1101)
        Decimal('100')
        >>> ExtendedContext.logical_and(Decimal(110), 1101)
        Decimal('100')
        >>> ExtendedContext.logical_and(110, Decimal(1101))
        Decimal('100')
        'b'Invert all the digits in the operand.

        The operand must be a logical number.

        >>> ExtendedContext.logical_invert(Decimal('0'))
        Decimal('111111111')
        >>> ExtendedContext.logical_invert(Decimal('1'))
        Decimal('111111110')
        >>> ExtendedContext.logical_invert(Decimal('111111111'))
        Decimal('0')
        >>> ExtendedContext.logical_invert(Decimal('101010101'))
        Decimal('10101010')
        >>> ExtendedContext.logical_invert(1101)
        Decimal('111110010')
        'u'Invert all the digits in the operand.

        The operand must be a logical number.

        >>> ExtendedContext.logical_invert(Decimal('0'))
        Decimal('111111111')
        >>> ExtendedContext.logical_invert(Decimal('1'))
        Decimal('111111110')
        >>> ExtendedContext.logical_invert(Decimal('111111111'))
        Decimal('0')
        >>> ExtendedContext.logical_invert(Decimal('101010101'))
        Decimal('10101010')
        >>> ExtendedContext.logical_invert(1101)
        Decimal('111110010')
        'b'Applies the logical operation 'or' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('0'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1100'), Decimal('1010'))
        Decimal('1110')
        >>> ExtendedContext.logical_or(Decimal('1110'), Decimal('10'))
        Decimal('1110')
        >>> ExtendedContext.logical_or(110, 1101)
        Decimal('1111')
        >>> ExtendedContext.logical_or(Decimal(110), 1101)
        Decimal('1111')
        >>> ExtendedContext.logical_or(110, Decimal(1101))
        Decimal('1111')
        'u'Applies the logical operation 'or' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('0'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1100'), Decimal('1010'))
        Decimal('1110')
        >>> ExtendedContext.logical_or(Decimal('1110'), Decimal('10'))
        Decimal('1110')
        >>> ExtendedContext.logical_or(110, 1101)
        Decimal('1111')
        >>> ExtendedContext.logical_or(Decimal(110), 1101)
        Decimal('1111')
        >>> ExtendedContext.logical_or(110, Decimal(1101))
        Decimal('1111')
        'b'Applies the logical operation 'xor' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('0'))
        Decimal('1')
        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('1'))
        Decimal('0')
        >>> ExtendedContext.logical_xor(Decimal('1100'), Decimal('1010'))
        Decimal('110')
        >>> ExtendedContext.logical_xor(Decimal('1111'), Decimal('10'))
        Decimal('1101')
        >>> ExtendedContext.logical_xor(110, 1101)
        Decimal('1011')
        >>> ExtendedContext.logical_xor(Decimal(110), 1101)
        Decimal('1011')
        >>> ExtendedContext.logical_xor(110, Decimal(1101))
        Decimal('1011')
        'u'Applies the logical operation 'xor' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('0'))
        Decimal('1')
        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('1'))
        Decimal('0')
        >>> ExtendedContext.logical_xor(Decimal('1100'), Decimal('1010'))
        Decimal('110')
        >>> ExtendedContext.logical_xor(Decimal('1111'), Decimal('10'))
        Decimal('1101')
        >>> ExtendedContext.logical_xor(110, 1101)
        Decimal('1011')
        >>> ExtendedContext.logical_xor(Decimal(110), 1101)
        Decimal('1011')
        >>> ExtendedContext.logical_xor(110, Decimal(1101))
        Decimal('1011')
        'b'max compares two values numerically and returns the maximum.

        If either operand is a NaN then the general rules apply.
        Otherwise, the operands are compared as though by the compare
        operation.  If they are numerically equal then the left-hand operand
        is chosen as the result.  Otherwise the maximum (closer to positive
        infinity) of the two operands is chosen as the result.

        >>> ExtendedContext.max(Decimal('3'), Decimal('2'))
        Decimal('3')
        >>> ExtendedContext.max(Decimal('-10'), Decimal('3'))
        Decimal('3')
        >>> ExtendedContext.max(Decimal('1.0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.max(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.max(1, 2)
        Decimal('2')
        >>> ExtendedContext.max(Decimal(1), 2)
        Decimal('2')
        >>> ExtendedContext.max(1, Decimal(2))
        Decimal('2')
        'u'max compares two values numerically and returns the maximum.

        If either operand is a NaN then the general rules apply.
        Otherwise, the operands are compared as though by the compare
        operation.  If they are numerically equal then the left-hand operand
        is chosen as the result.  Otherwise the maximum (closer to positive
        infinity) of the two operands is chosen as the result.

        >>> ExtendedContext.max(Decimal('3'), Decimal('2'))
        Decimal('3')
        >>> ExtendedContext.max(Decimal('-10'), Decimal('3'))
        Decimal('3')
        >>> ExtendedContext.max(Decimal('1.0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.max(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.max(1, 2)
        Decimal('2')
        >>> ExtendedContext.max(Decimal(1), 2)
        Decimal('2')
        >>> ExtendedContext.max(1, Decimal(2))
        Decimal('2')
        'b'Compares the values numerically with their sign ignored.

        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('-10'))
        Decimal('-10')
        >>> ExtendedContext.max_mag(1, -2)
        Decimal('-2')
        >>> ExtendedContext.max_mag(Decimal(1), -2)
        Decimal('-2')
        >>> ExtendedContext.max_mag(1, Decimal(-2))
        Decimal('-2')
        'u'Compares the values numerically with their sign ignored.

        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('-10'))
        Decimal('-10')
        >>> ExtendedContext.max_mag(1, -2)
        Decimal('-2')
        >>> ExtendedContext.max_mag(Decimal(1), -2)
        Decimal('-2')
        >>> ExtendedContext.max_mag(1, Decimal(-2))
        Decimal('-2')
        'b'min compares two values numerically and returns the minimum.

        If either operand is a NaN then the general rules apply.
        Otherwise, the operands are compared as though by the compare
        operation.  If they are numerically equal then the left-hand operand
        is chosen as the result.  Otherwise the minimum (closer to negative
        infinity) of the two operands is chosen as the result.

        >>> ExtendedContext.min(Decimal('3'), Decimal('2'))
        Decimal('2')
        >>> ExtendedContext.min(Decimal('-10'), Decimal('3'))
        Decimal('-10')
        >>> ExtendedContext.min(Decimal('1.0'), Decimal('1'))
        Decimal('1.0')
        >>> ExtendedContext.min(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.min(1, 2)
        Decimal('1')
        >>> ExtendedContext.min(Decimal(1), 2)
        Decimal('1')
        >>> ExtendedContext.min(1, Decimal(29))
        Decimal('1')
        'u'min compares two values numerically and returns the minimum.

        If either operand is a NaN then the general rules apply.
        Otherwise, the operands are compared as though by the compare
        operation.  If they are numerically equal then the left-hand operand
        is chosen as the result.  Otherwise the minimum (closer to negative
        infinity) of the two operands is chosen as the result.

        >>> ExtendedContext.min(Decimal('3'), Decimal('2'))
        Decimal('2')
        >>> ExtendedContext.min(Decimal('-10'), Decimal('3'))
        Decimal('-10')
        >>> ExtendedContext.min(Decimal('1.0'), Decimal('1'))
        Decimal('1.0')
        >>> ExtendedContext.min(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.min(1, 2)
        Decimal('1')
        >>> ExtendedContext.min(Decimal(1), 2)
        Decimal('1')
        >>> ExtendedContext.min(1, Decimal(29))
        Decimal('1')
        'b'Compares the values numerically with their sign ignored.

        >>> ExtendedContext.min_mag(Decimal('3'), Decimal('-2'))
        Decimal('-2')
        >>> ExtendedContext.min_mag(Decimal('-3'), Decimal('NaN'))
        Decimal('-3')
        >>> ExtendedContext.min_mag(1, -2)
        Decimal('1')
        >>> ExtendedContext.min_mag(Decimal(1), -2)
        Decimal('1')
        >>> ExtendedContext.min_mag(1, Decimal(-2))
        Decimal('1')
        'u'Compares the values numerically with their sign ignored.

        >>> ExtendedContext.min_mag(Decimal('3'), Decimal('-2'))
        Decimal('-2')
        >>> ExtendedContext.min_mag(Decimal('-3'), Decimal('NaN'))
        Decimal('-3')
        >>> ExtendedContext.min_mag(1, -2)
        Decimal('1')
        >>> ExtendedContext.min_mag(Decimal(1), -2)
        Decimal('1')
        >>> ExtendedContext.min_mag(1, Decimal(-2))
        Decimal('1')
        'b'Minus corresponds to unary prefix minus in Python.

        The operation is evaluated using the same rules as subtract; the
        operation minus(a) is calculated as subtract('0', a) where the '0'
        has the same exponent as the operand.

        >>> ExtendedContext.minus(Decimal('1.3'))
        Decimal('-1.3')
        >>> ExtendedContext.minus(Decimal('-1.3'))
        Decimal('1.3')
        >>> ExtendedContext.minus(1)
        Decimal('-1')
        'u'Minus corresponds to unary prefix minus in Python.

        The operation is evaluated using the same rules as subtract; the
        operation minus(a) is calculated as subtract('0', a) where the '0'
        has the same exponent as the operand.

        >>> ExtendedContext.minus(Decimal('1.3'))
        Decimal('-1.3')
        >>> ExtendedContext.minus(Decimal('-1.3'))
        Decimal('1.3')
        >>> ExtendedContext.minus(1)
        Decimal('-1')
        'b'multiply multiplies two operands.

        If either operand is a special value then the general rules apply.
        Otherwise, the operands are multiplied together
        ('long multiplication'), resulting in a number which may be as long as
        the sum of the lengths of the two operands.

        >>> ExtendedContext.multiply(Decimal('1.20'), Decimal('3'))
        Decimal('3.60')
        >>> ExtendedContext.multiply(Decimal('7'), Decimal('3'))
        Decimal('21')
        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('0.8'))
        Decimal('0.72')
        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('-0'))
        Decimal('-0.0')
        >>> ExtendedContext.multiply(Decimal('654321'), Decimal('654321'))
        Decimal('4.28135971E+11')
        >>> ExtendedContext.multiply(7, 7)
        Decimal('49')
        >>> ExtendedContext.multiply(Decimal(7), 7)
        Decimal('49')
        >>> ExtendedContext.multiply(7, Decimal(7))
        Decimal('49')
        'u'multiply multiplies two operands.

        If either operand is a special value then the general rules apply.
        Otherwise, the operands are multiplied together
        ('long multiplication'), resulting in a number which may be as long as
        the sum of the lengths of the two operands.

        >>> ExtendedContext.multiply(Decimal('1.20'), Decimal('3'))
        Decimal('3.60')
        >>> ExtendedContext.multiply(Decimal('7'), Decimal('3'))
        Decimal('21')
        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('0.8'))
        Decimal('0.72')
        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('-0'))
        Decimal('-0.0')
        >>> ExtendedContext.multiply(Decimal('654321'), Decimal('654321'))
        Decimal('4.28135971E+11')
        >>> ExtendedContext.multiply(7, 7)
        Decimal('49')
        >>> ExtendedContext.multiply(Decimal(7), 7)
        Decimal('49')
        >>> ExtendedContext.multiply(7, Decimal(7))
        Decimal('49')
        'b'Returns the largest representable number smaller than a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> ExtendedContext.next_minus(Decimal('1'))
        Decimal('0.999999999')
        >>> c.next_minus(Decimal('1E-1007'))
        Decimal('0E-1007')
        >>> ExtendedContext.next_minus(Decimal('-1.00000003'))
        Decimal('-1.00000004')
        >>> c.next_minus(Decimal('Infinity'))
        Decimal('9.99999999E+999')
        >>> c.next_minus(1)
        Decimal('0.999999999')
        'u'Returns the largest representable number smaller than a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> ExtendedContext.next_minus(Decimal('1'))
        Decimal('0.999999999')
        >>> c.next_minus(Decimal('1E-1007'))
        Decimal('0E-1007')
        >>> ExtendedContext.next_minus(Decimal('-1.00000003'))
        Decimal('-1.00000004')
        >>> c.next_minus(Decimal('Infinity'))
        Decimal('9.99999999E+999')
        >>> c.next_minus(1)
        Decimal('0.999999999')
        'b'Returns the smallest representable number larger than a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> ExtendedContext.next_plus(Decimal('1'))
        Decimal('1.00000001')
        >>> c.next_plus(Decimal('-1E-1007'))
        Decimal('-0E-1007')
        >>> ExtendedContext.next_plus(Decimal('-1.00000003'))
        Decimal('-1.00000002')
        >>> c.next_plus(Decimal('-Infinity'))
        Decimal('-9.99999999E+999')
        >>> c.next_plus(1)
        Decimal('1.00000001')
        'u'Returns the smallest representable number larger than a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> ExtendedContext.next_plus(Decimal('1'))
        Decimal('1.00000001')
        >>> c.next_plus(Decimal('-1E-1007'))
        Decimal('-0E-1007')
        >>> ExtendedContext.next_plus(Decimal('-1.00000003'))
        Decimal('-1.00000002')
        >>> c.next_plus(Decimal('-Infinity'))
        Decimal('-9.99999999E+999')
        >>> c.next_plus(1)
        Decimal('1.00000001')
        'b'Returns the number closest to a, in direction towards b.

        The result is the closest representable number from the first
        operand (but not the first operand) that is in the direction
        towards the second operand, unless the operands have the same
        value.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.next_toward(Decimal('1'), Decimal('2'))
        Decimal('1.00000001')
        >>> c.next_toward(Decimal('-1E-1007'), Decimal('1'))
        Decimal('-0E-1007')
        >>> c.next_toward(Decimal('-1.00000003'), Decimal('0'))
        Decimal('-1.00000002')
        >>> c.next_toward(Decimal('1'), Decimal('0'))
        Decimal('0.999999999')
        >>> c.next_toward(Decimal('1E-1007'), Decimal('-100'))
        Decimal('0E-1007')
        >>> c.next_toward(Decimal('-1.00000003'), Decimal('-10'))
        Decimal('-1.00000004')
        >>> c.next_toward(Decimal('0.00'), Decimal('-0.0000'))
        Decimal('-0.00')
        >>> c.next_toward(0, 1)
        Decimal('1E-1007')
        >>> c.next_toward(Decimal(0), 1)
        Decimal('1E-1007')
        >>> c.next_toward(0, Decimal(1))
        Decimal('1E-1007')
        'u'Returns the number closest to a, in direction towards b.

        The result is the closest representable number from the first
        operand (but not the first operand) that is in the direction
        towards the second operand, unless the operands have the same
        value.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.next_toward(Decimal('1'), Decimal('2'))
        Decimal('1.00000001')
        >>> c.next_toward(Decimal('-1E-1007'), Decimal('1'))
        Decimal('-0E-1007')
        >>> c.next_toward(Decimal('-1.00000003'), Decimal('0'))
        Decimal('-1.00000002')
        >>> c.next_toward(Decimal('1'), Decimal('0'))
        Decimal('0.999999999')
        >>> c.next_toward(Decimal('1E-1007'), Decimal('-100'))
        Decimal('0E-1007')
        >>> c.next_toward(Decimal('-1.00000003'), Decimal('-10'))
        Decimal('-1.00000004')
        >>> c.next_toward(Decimal('0.00'), Decimal('-0.0000'))
        Decimal('-0.00')
        >>> c.next_toward(0, 1)
        Decimal('1E-1007')
        >>> c.next_toward(Decimal(0), 1)
        Decimal('1E-1007')
        >>> c.next_toward(0, Decimal(1))
        Decimal('1E-1007')
        'b'normalize reduces an operand to its simplest form.

        Essentially a plus operation with all trailing zeros removed from the
        result.

        >>> ExtendedContext.normalize(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.normalize(Decimal('-2.0'))
        Decimal('-2')
        >>> ExtendedContext.normalize(Decimal('1.200'))
        Decimal('1.2')
        >>> ExtendedContext.normalize(Decimal('-120'))
        Decimal('-1.2E+2')
        >>> ExtendedContext.normalize(Decimal('120.00'))
        Decimal('1.2E+2')
        >>> ExtendedContext.normalize(Decimal('0.00'))
        Decimal('0')
        >>> ExtendedContext.normalize(6)
        Decimal('6')
        'u'normalize reduces an operand to its simplest form.

        Essentially a plus operation with all trailing zeros removed from the
        result.

        >>> ExtendedContext.normalize(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.normalize(Decimal('-2.0'))
        Decimal('-2')
        >>> ExtendedContext.normalize(Decimal('1.200'))
        Decimal('1.2')
        >>> ExtendedContext.normalize(Decimal('-120'))
        Decimal('-1.2E+2')
        >>> ExtendedContext.normalize(Decimal('120.00'))
        Decimal('1.2E+2')
        >>> ExtendedContext.normalize(Decimal('0.00'))
        Decimal('0')
        >>> ExtendedContext.normalize(6)
        Decimal('6')
        'b'Returns an indication of the class of the operand.

        The class is one of the following strings:
          -sNaN
          -NaN
          -Infinity
          -Normal
          -Subnormal
          -Zero
          +Zero
          +Subnormal
          +Normal
          +Infinity

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.number_class(Decimal('Infinity'))
        '+Infinity'
        >>> c.number_class(Decimal('1E-10'))
        '+Normal'
        >>> c.number_class(Decimal('2.50'))
        '+Normal'
        >>> c.number_class(Decimal('0.1E-999'))
        '+Subnormal'
        >>> c.number_class(Decimal('0'))
        '+Zero'
        >>> c.number_class(Decimal('-0'))
        '-Zero'
        >>> c.number_class(Decimal('-0.1E-999'))
        '-Subnormal'
        >>> c.number_class(Decimal('-1E-10'))
        '-Normal'
        >>> c.number_class(Decimal('-2.50'))
        '-Normal'
        >>> c.number_class(Decimal('-Infinity'))
        '-Infinity'
        >>> c.number_class(Decimal('NaN'))
        'NaN'
        >>> c.number_class(Decimal('-NaN'))
        'NaN'
        >>> c.number_class(Decimal('sNaN'))
        'sNaN'
        >>> c.number_class(123)
        '+Normal'
        'u'Returns an indication of the class of the operand.

        The class is one of the following strings:
          -sNaN
          -NaN
          -Infinity
          -Normal
          -Subnormal
          -Zero
          +Zero
          +Subnormal
          +Normal
          +Infinity

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.number_class(Decimal('Infinity'))
        '+Infinity'
        >>> c.number_class(Decimal('1E-10'))
        '+Normal'
        >>> c.number_class(Decimal('2.50'))
        '+Normal'
        >>> c.number_class(Decimal('0.1E-999'))
        '+Subnormal'
        >>> c.number_class(Decimal('0'))
        '+Zero'
        >>> c.number_class(Decimal('-0'))
        '-Zero'
        >>> c.number_class(Decimal('-0.1E-999'))
        '-Subnormal'
        >>> c.number_class(Decimal('-1E-10'))
        '-Normal'
        >>> c.number_class(Decimal('-2.50'))
        '-Normal'
        >>> c.number_class(Decimal('-Infinity'))
        '-Infinity'
        >>> c.number_class(Decimal('NaN'))
        'NaN'
        >>> c.number_class(Decimal('-NaN'))
        'NaN'
        >>> c.number_class(Decimal('sNaN'))
        'sNaN'
        >>> c.number_class(123)
        '+Normal'
        'b'Plus corresponds to unary prefix plus in Python.

        The operation is evaluated using the same rules as add; the
        operation plus(a) is calculated as add('0', a) where the '0'
        has the same exponent as the operand.

        >>> ExtendedContext.plus(Decimal('1.3'))
        Decimal('1.3')
        >>> ExtendedContext.plus(Decimal('-1.3'))
        Decimal('-1.3')
        >>> ExtendedContext.plus(-1)
        Decimal('-1')
        'u'Plus corresponds to unary prefix plus in Python.

        The operation is evaluated using the same rules as add; the
        operation plus(a) is calculated as add('0', a) where the '0'
        has the same exponent as the operand.

        >>> ExtendedContext.plus(Decimal('1.3'))
        Decimal('1.3')
        >>> ExtendedContext.plus(Decimal('-1.3'))
        Decimal('-1.3')
        >>> ExtendedContext.plus(-1)
        Decimal('-1')
        'b'Raises a to the power of b, to modulo if given.

        With two arguments, compute a**b.  If a is negative then b
        must be integral.  The result will be inexact unless b is
        integral and the result is finite and can be expressed exactly
        in 'precision' digits.

        With three arguments, compute (a**b) % modulo.  For the
        three argument form, the following restrictions on the
        arguments hold:

         - all three arguments must be integral
         - b must be nonnegative
         - at least one of a or b must be nonzero
         - modulo must be nonzero and have at most 'precision' digits

        The result of pow(a, b, modulo) is identical to the result
        that would be obtained by computing (a**b) % modulo with
        unbounded precision, but is computed more efficiently.  It is
        always exact.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.power(Decimal('2'), Decimal('3'))
        Decimal('8')
        >>> c.power(Decimal('-2'), Decimal('3'))
        Decimal('-8')
        >>> c.power(Decimal('2'), Decimal('-3'))
        Decimal('0.125')
        >>> c.power(Decimal('1.7'), Decimal('8'))
        Decimal('69.7575744')
        >>> c.power(Decimal('10'), Decimal('0.301029996'))
        Decimal('2.00000000')
        >>> c.power(Decimal('Infinity'), Decimal('-1'))
        Decimal('0')
        >>> c.power(Decimal('Infinity'), Decimal('0'))
        Decimal('1')
        >>> c.power(Decimal('Infinity'), Decimal('1'))
        Decimal('Infinity')
        >>> c.power(Decimal('-Infinity'), Decimal('-1'))
        Decimal('-0')
        >>> c.power(Decimal('-Infinity'), Decimal('0'))
        Decimal('1')
        >>> c.power(Decimal('-Infinity'), Decimal('1'))
        Decimal('-Infinity')
        >>> c.power(Decimal('-Infinity'), Decimal('2'))
        Decimal('Infinity')
        >>> c.power(Decimal('0'), Decimal('0'))
        Decimal('NaN')

        >>> c.power(Decimal('3'), Decimal('7'), Decimal('16'))
        Decimal('11')
        >>> c.power(Decimal('-3'), Decimal('7'), Decimal('16'))
        Decimal('-11')
        >>> c.power(Decimal('-3'), Decimal('8'), Decimal('16'))
        Decimal('1')
        >>> c.power(Decimal('3'), Decimal('7'), Decimal('-16'))
        Decimal('11')
        >>> c.power(Decimal('23E12345'), Decimal('67E189'), Decimal('123456789'))
        Decimal('11729830')
        >>> c.power(Decimal('-0'), Decimal('17'), Decimal('1729'))
        Decimal('-0')
        >>> c.power(Decimal('-23'), Decimal('0'), Decimal('65537'))
        Decimal('1')
        >>> ExtendedContext.power(7, 7)
        Decimal('823543')
        >>> ExtendedContext.power(Decimal(7), 7)
        Decimal('823543')
        >>> ExtendedContext.power(7, Decimal(7), 2)
        Decimal('1')
        'u'Raises a to the power of b, to modulo if given.

        With two arguments, compute a**b.  If a is negative then b
        must be integral.  The result will be inexact unless b is
        integral and the result is finite and can be expressed exactly
        in 'precision' digits.

        With three arguments, compute (a**b) % modulo.  For the
        three argument form, the following restrictions on the
        arguments hold:

         - all three arguments must be integral
         - b must be nonnegative
         - at least one of a or b must be nonzero
         - modulo must be nonzero and have at most 'precision' digits

        The result of pow(a, b, modulo) is identical to the result
        that would be obtained by computing (a**b) % modulo with
        unbounded precision, but is computed more efficiently.  It is
        always exact.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.power(Decimal('2'), Decimal('3'))
        Decimal('8')
        >>> c.power(Decimal('-2'), Decimal('3'))
        Decimal('-8')
        >>> c.power(Decimal('2'), Decimal('-3'))
        Decimal('0.125')
        >>> c.power(Decimal('1.7'), Decimal('8'))
        Decimal('69.7575744')
        >>> c.power(Decimal('10'), Decimal('0.301029996'))
        Decimal('2.00000000')
        >>> c.power(Decimal('Infinity'), Decimal('-1'))
        Decimal('0')
        >>> c.power(Decimal('Infinity'), Decimal('0'))
        Decimal('1')
        >>> c.power(Decimal('Infinity'), Decimal('1'))
        Decimal('Infinity')
        >>> c.power(Decimal('-Infinity'), Decimal('-1'))
        Decimal('-0')
        >>> c.power(Decimal('-Infinity'), Decimal('0'))
        Decimal('1')
        >>> c.power(Decimal('-Infinity'), Decimal('1'))
        Decimal('-Infinity')
        >>> c.power(Decimal('-Infinity'), Decimal('2'))
        Decimal('Infinity')
        >>> c.power(Decimal('0'), Decimal('0'))
        Decimal('NaN')

        >>> c.power(Decimal('3'), Decimal('7'), Decimal('16'))
        Decimal('11')
        >>> c.power(Decimal('-3'), Decimal('7'), Decimal('16'))
        Decimal('-11')
        >>> c.power(Decimal('-3'), Decimal('8'), Decimal('16'))
        Decimal('1')
        >>> c.power(Decimal('3'), Decimal('7'), Decimal('-16'))
        Decimal('11')
        >>> c.power(Decimal('23E12345'), Decimal('67E189'), Decimal('123456789'))
        Decimal('11729830')
        >>> c.power(Decimal('-0'), Decimal('17'), Decimal('1729'))
        Decimal('-0')
        >>> c.power(Decimal('-23'), Decimal('0'), Decimal('65537'))
        Decimal('1')
        >>> ExtendedContext.power(7, 7)
        Decimal('823543')
        >>> ExtendedContext.power(Decimal(7), 7)
        Decimal('823543')
        >>> ExtendedContext.power(7, Decimal(7), 2)
        Decimal('1')
        'b'Returns a value equal to 'a' (rounded), having the exponent of 'b'.

        The coefficient of the result is derived from that of the left-hand
        operand.  It may be rounded using the current rounding setting (if the
        exponent is being increased), multiplied by a positive power of ten (if
        the exponent is being decreased), or is unchanged (if the exponent is
        already equal to that of the right-hand operand).

        Unlike other operations, if the length of the coefficient after the
        quantize operation would be greater than precision then an Invalid
        operation condition is raised.  This guarantees that, unless there is
        an error condition, the exponent of the result of a quantize is always
        equal to that of the right-hand operand.

        Also unlike other operations, quantize will never raise Underflow, even
        if the result is subnormal and inexact.

        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.001'))
        Decimal('2.170')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.01'))
        Decimal('2.17')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.1'))
        Decimal('2.2')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+0'))
        Decimal('2')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+1'))
        Decimal('0E+1')
        >>> ExtendedContext.quantize(Decimal('-Inf'), Decimal('Infinity'))
        Decimal('-Infinity')
        >>> ExtendedContext.quantize(Decimal('2'), Decimal('Infinity'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('-0.1'), Decimal('1'))
        Decimal('-0')
        >>> ExtendedContext.quantize(Decimal('-0'), Decimal('1e+5'))
        Decimal('-0E+5')
        >>> ExtendedContext.quantize(Decimal('+35236450.6'), Decimal('1e-2'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('-35236450.6'), Decimal('1e-2'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-1'))
        Decimal('217.0')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-0'))
        Decimal('217')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+1'))
        Decimal('2.2E+2')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+2'))
        Decimal('2E+2')
        >>> ExtendedContext.quantize(1, 2)
        Decimal('1')
        >>> ExtendedContext.quantize(Decimal(1), 2)
        Decimal('1')
        >>> ExtendedContext.quantize(1, Decimal(2))
        Decimal('1')
        'u'Returns a value equal to 'a' (rounded), having the exponent of 'b'.

        The coefficient of the result is derived from that of the left-hand
        operand.  It may be rounded using the current rounding setting (if the
        exponent is being increased), multiplied by a positive power of ten (if
        the exponent is being decreased), or is unchanged (if the exponent is
        already equal to that of the right-hand operand).

        Unlike other operations, if the length of the coefficient after the
        quantize operation would be greater than precision then an Invalid
        operation condition is raised.  This guarantees that, unless there is
        an error condition, the exponent of the result of a quantize is always
        equal to that of the right-hand operand.

        Also unlike other operations, quantize will never raise Underflow, even
        if the result is subnormal and inexact.

        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.001'))
        Decimal('2.170')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.01'))
        Decimal('2.17')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.1'))
        Decimal('2.2')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+0'))
        Decimal('2')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+1'))
        Decimal('0E+1')
        >>> ExtendedContext.quantize(Decimal('-Inf'), Decimal('Infinity'))
        Decimal('-Infinity')
        >>> ExtendedContext.quantize(Decimal('2'), Decimal('Infinity'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('-0.1'), Decimal('1'))
        Decimal('-0')
        >>> ExtendedContext.quantize(Decimal('-0'), Decimal('1e+5'))
        Decimal('-0E+5')
        >>> ExtendedContext.quantize(Decimal('+35236450.6'), Decimal('1e-2'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('-35236450.6'), Decimal('1e-2'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-1'))
        Decimal('217.0')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-0'))
        Decimal('217')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+1'))
        Decimal('2.2E+2')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+2'))
        Decimal('2E+2')
        >>> ExtendedContext.quantize(1, 2)
        Decimal('1')
        >>> ExtendedContext.quantize(Decimal(1), 2)
        Decimal('1')
        >>> ExtendedContext.quantize(1, Decimal(2))
        Decimal('1')
        'b'Just returns 10, as this is Decimal, :)

        >>> ExtendedContext.radix()
        Decimal('10')
        'u'Just returns 10, as this is Decimal, :)

        >>> ExtendedContext.radix()
        Decimal('10')
        'b'Returns the remainder from integer division.

        The result is the residue of the dividend after the operation of
        calculating integer division as described for divide-integer, rounded
        to precision digits if necessary.  The sign of the result, if
        non-zero, is the same as that of the original dividend.

        This operation will fail under the same conditions as integer division
        (that is, if integer division on the same two operands would fail, the
        remainder cannot be calculated).

        >>> ExtendedContext.remainder(Decimal('2.1'), Decimal('3'))
        Decimal('2.1')
        >>> ExtendedContext.remainder(Decimal('10'), Decimal('3'))
        Decimal('1')
        >>> ExtendedContext.remainder(Decimal('-10'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.remainder(Decimal('10.2'), Decimal('1'))
        Decimal('0.2')
        >>> ExtendedContext.remainder(Decimal('10'), Decimal('0.3'))
        Decimal('0.1')
        >>> ExtendedContext.remainder(Decimal('3.6'), Decimal('1.3'))
        Decimal('1.0')
        >>> ExtendedContext.remainder(22, 6)
        Decimal('4')
        >>> ExtendedContext.remainder(Decimal(22), 6)
        Decimal('4')
        >>> ExtendedContext.remainder(22, Decimal(6))
        Decimal('4')
        'u'Returns the remainder from integer division.

        The result is the residue of the dividend after the operation of
        calculating integer division as described for divide-integer, rounded
        to precision digits if necessary.  The sign of the result, if
        non-zero, is the same as that of the original dividend.

        This operation will fail under the same conditions as integer division
        (that is, if integer division on the same two operands would fail, the
        remainder cannot be calculated).

        >>> ExtendedContext.remainder(Decimal('2.1'), Decimal('3'))
        Decimal('2.1')
        >>> ExtendedContext.remainder(Decimal('10'), Decimal('3'))
        Decimal('1')
        >>> ExtendedContext.remainder(Decimal('-10'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.remainder(Decimal('10.2'), Decimal('1'))
        Decimal('0.2')
        >>> ExtendedContext.remainder(Decimal('10'), Decimal('0.3'))
        Decimal('0.1')
        >>> ExtendedContext.remainder(Decimal('3.6'), Decimal('1.3'))
        Decimal('1.0')
        >>> ExtendedContext.remainder(22, 6)
        Decimal('4')
        >>> ExtendedContext.remainder(Decimal(22), 6)
        Decimal('4')
        >>> ExtendedContext.remainder(22, Decimal(6))
        Decimal('4')
        'b'Returns to be "a - b * n", where n is the integer nearest the exact
        value of "x / b" (if two integers are equally near then the even one
        is chosen).  If the result is equal to 0 then its sign will be the
        sign of a.

        This operation will fail under the same conditions as integer division
        (that is, if integer division on the same two operands would fail, the
        remainder cannot be calculated).

        >>> ExtendedContext.remainder_near(Decimal('2.1'), Decimal('3'))
        Decimal('-0.9')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('6'))
        Decimal('-2')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('3'))
        Decimal('1')
        >>> ExtendedContext.remainder_near(Decimal('-10'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.remainder_near(Decimal('10.2'), Decimal('1'))
        Decimal('0.2')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('0.3'))
        Decimal('0.1')
        >>> ExtendedContext.remainder_near(Decimal('3.6'), Decimal('1.3'))
        Decimal('-0.3')
        >>> ExtendedContext.remainder_near(3, 11)
        Decimal('3')
        >>> ExtendedContext.remainder_near(Decimal(3), 11)
        Decimal('3')
        >>> ExtendedContext.remainder_near(3, Decimal(11))
        Decimal('3')
        'u'Returns to be "a - b * n", where n is the integer nearest the exact
        value of "x / b" (if two integers are equally near then the even one
        is chosen).  If the result is equal to 0 then its sign will be the
        sign of a.

        This operation will fail under the same conditions as integer division
        (that is, if integer division on the same two operands would fail, the
        remainder cannot be calculated).

        >>> ExtendedContext.remainder_near(Decimal('2.1'), Decimal('3'))
        Decimal('-0.9')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('6'))
        Decimal('-2')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('3'))
        Decimal('1')
        >>> ExtendedContext.remainder_near(Decimal('-10'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.remainder_near(Decimal('10.2'), Decimal('1'))
        Decimal('0.2')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('0.3'))
        Decimal('0.1')
        >>> ExtendedContext.remainder_near(Decimal('3.6'), Decimal('1.3'))
        Decimal('-0.3')
        >>> ExtendedContext.remainder_near(3, 11)
        Decimal('3')
        >>> ExtendedContext.remainder_near(Decimal(3), 11)
        Decimal('3')
        >>> ExtendedContext.remainder_near(3, Decimal(11))
        Decimal('3')
        'b'Returns a rotated copy of a, b times.

        The coefficient of the result is a rotated copy of the digits in
        the coefficient of the first operand.  The number of places of
        rotation is taken from the absolute value of the second operand,
        with the rotation being to the left if the second operand is
        positive or to the right otherwise.

        >>> ExtendedContext.rotate(Decimal('34'), Decimal('8'))
        Decimal('400000003')
        >>> ExtendedContext.rotate(Decimal('12'), Decimal('9'))
        Decimal('12')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('-2'))
        Decimal('891234567')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('0'))
        Decimal('123456789')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('+2'))
        Decimal('345678912')
        >>> ExtendedContext.rotate(1333333, 1)
        Decimal('13333330')
        >>> ExtendedContext.rotate(Decimal(1333333), 1)
        Decimal('13333330')
        >>> ExtendedContext.rotate(1333333, Decimal(1))
        Decimal('13333330')
        'u'Returns a rotated copy of a, b times.

        The coefficient of the result is a rotated copy of the digits in
        the coefficient of the first operand.  The number of places of
        rotation is taken from the absolute value of the second operand,
        with the rotation being to the left if the second operand is
        positive or to the right otherwise.

        >>> ExtendedContext.rotate(Decimal('34'), Decimal('8'))
        Decimal('400000003')
        >>> ExtendedContext.rotate(Decimal('12'), Decimal('9'))
        Decimal('12')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('-2'))
        Decimal('891234567')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('0'))
        Decimal('123456789')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('+2'))
        Decimal('345678912')
        >>> ExtendedContext.rotate(1333333, 1)
        Decimal('13333330')
        >>> ExtendedContext.rotate(Decimal(1333333), 1)
        Decimal('13333330')
        >>> ExtendedContext.rotate(1333333, Decimal(1))
        Decimal('13333330')
        'b'Returns True if the two operands have the same exponent.

        The result is never affected by either the sign or the coefficient of
        either operand.

        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.001'))
        False
        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.01'))
        True
        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('1'))
        False
        >>> ExtendedContext.same_quantum(Decimal('Inf'), Decimal('-Inf'))
        True
        >>> ExtendedContext.same_quantum(10000, -1)
        True
        >>> ExtendedContext.same_quantum(Decimal(10000), -1)
        True
        >>> ExtendedContext.same_quantum(10000, Decimal(-1))
        True
        'u'Returns True if the two operands have the same exponent.

        The result is never affected by either the sign or the coefficient of
        either operand.

        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.001'))
        False
        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.01'))
        True
        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('1'))
        False
        >>> ExtendedContext.same_quantum(Decimal('Inf'), Decimal('-Inf'))
        True
        >>> ExtendedContext.same_quantum(10000, -1)
        True
        >>> ExtendedContext.same_quantum(Decimal(10000), -1)
        True
        >>> ExtendedContext.same_quantum(10000, Decimal(-1))
        True
        'b'Returns the first operand after adding the second value its exp.

        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('-2'))
        Decimal('0.0750')
        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('0'))
        Decimal('7.50')
        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('3'))
        Decimal('7.50E+3')
        >>> ExtendedContext.scaleb(1, 4)
        Decimal('1E+4')
        >>> ExtendedContext.scaleb(Decimal(1), 4)
        Decimal('1E+4')
        >>> ExtendedContext.scaleb(1, Decimal(4))
        Decimal('1E+4')
        'u'Returns the first operand after adding the second value its exp.

        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('-2'))
        Decimal('0.0750')
        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('0'))
        Decimal('7.50')
        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('3'))
        Decimal('7.50E+3')
        >>> ExtendedContext.scaleb(1, 4)
        Decimal('1E+4')
        >>> ExtendedContext.scaleb(Decimal(1), 4)
        Decimal('1E+4')
        >>> ExtendedContext.scaleb(1, Decimal(4))
        Decimal('1E+4')
        'b'Returns a shifted copy of a, b times.

        The coefficient of the result is a shifted copy of the digits
        in the coefficient of the first operand.  The number of places
        to shift is taken from the absolute value of the second operand,
        with the shift being to the left if the second operand is
        positive or to the right otherwise.  Digits shifted into the
        coefficient are zeros.

        >>> ExtendedContext.shift(Decimal('34'), Decimal('8'))
        Decimal('400000000')
        >>> ExtendedContext.shift(Decimal('12'), Decimal('9'))
        Decimal('0')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('-2'))
        Decimal('1234567')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('0'))
        Decimal('123456789')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('+2'))
        Decimal('345678900')
        >>> ExtendedContext.shift(88888888, 2)
        Decimal('888888800')
        >>> ExtendedContext.shift(Decimal(88888888), 2)
        Decimal('888888800')
        >>> ExtendedContext.shift(88888888, Decimal(2))
        Decimal('888888800')
        'u'Returns a shifted copy of a, b times.

        The coefficient of the result is a shifted copy of the digits
        in the coefficient of the first operand.  The number of places
        to shift is taken from the absolute value of the second operand,
        with the shift being to the left if the second operand is
        positive or to the right otherwise.  Digits shifted into the
        coefficient are zeros.

        >>> ExtendedContext.shift(Decimal('34'), Decimal('8'))
        Decimal('400000000')
        >>> ExtendedContext.shift(Decimal('12'), Decimal('9'))
        Decimal('0')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('-2'))
        Decimal('1234567')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('0'))
        Decimal('123456789')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('+2'))
        Decimal('345678900')
        >>> ExtendedContext.shift(88888888, 2)
        Decimal('888888800')
        >>> ExtendedContext.shift(Decimal(88888888), 2)
        Decimal('888888800')
        >>> ExtendedContext.shift(88888888, Decimal(2))
        Decimal('888888800')
        'b'Square root of a non-negative number to context precision.

        If the result must be inexact, it is rounded using the round-half-even
        algorithm.

        >>> ExtendedContext.sqrt(Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.sqrt(Decimal('-0'))
        Decimal('-0')
        >>> ExtendedContext.sqrt(Decimal('0.39'))
        Decimal('0.624499800')
        >>> ExtendedContext.sqrt(Decimal('100'))
        Decimal('10')
        >>> ExtendedContext.sqrt(Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.sqrt(Decimal('1.0'))
        Decimal('1.0')
        >>> ExtendedContext.sqrt(Decimal('1.00'))
        Decimal('1.0')
        >>> ExtendedContext.sqrt(Decimal('7'))
        Decimal('2.64575131')
        >>> ExtendedContext.sqrt(Decimal('10'))
        Decimal('3.16227766')
        >>> ExtendedContext.sqrt(2)
        Decimal('1.41421356')
        >>> ExtendedContext.prec
        9
        'u'Square root of a non-negative number to context precision.

        If the result must be inexact, it is rounded using the round-half-even
        algorithm.

        >>> ExtendedContext.sqrt(Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.sqrt(Decimal('-0'))
        Decimal('-0')
        >>> ExtendedContext.sqrt(Decimal('0.39'))
        Decimal('0.624499800')
        >>> ExtendedContext.sqrt(Decimal('100'))
        Decimal('10')
        >>> ExtendedContext.sqrt(Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.sqrt(Decimal('1.0'))
        Decimal('1.0')
        >>> ExtendedContext.sqrt(Decimal('1.00'))
        Decimal('1.0')
        >>> ExtendedContext.sqrt(Decimal('7'))
        Decimal('2.64575131')
        >>> ExtendedContext.sqrt(Decimal('10'))
        Decimal('3.16227766')
        >>> ExtendedContext.sqrt(2)
        Decimal('1.41421356')
        >>> ExtendedContext.prec
        9
        'b'Return the difference between the two operands.

        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.07'))
        Decimal('0.23')
        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.30'))
        Decimal('0.00')
        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('2.07'))
        Decimal('-0.77')
        >>> ExtendedContext.subtract(8, 5)
        Decimal('3')
        >>> ExtendedContext.subtract(Decimal(8), 5)
        Decimal('3')
        >>> ExtendedContext.subtract(8, Decimal(5))
        Decimal('3')
        'u'Return the difference between the two operands.

        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.07'))
        Decimal('0.23')
        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.30'))
        Decimal('0.00')
        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('2.07'))
        Decimal('-0.77')
        >>> ExtendedContext.subtract(8, 5)
        Decimal('3')
        >>> ExtendedContext.subtract(Decimal(8), 5)
        Decimal('3')
        >>> ExtendedContext.subtract(8, Decimal(5))
        Decimal('3')
        'b'Convert to a string, using engineering notation if an exponent is needed.

        Engineering notation has an exponent which is a multiple of 3.  This
        can leave up to 3 digits to the left of the decimal place and may
        require the addition of either one or two trailing zeros.

        The operation is not affected by the context.

        >>> ExtendedContext.to_eng_string(Decimal('123E+1'))
        '1.23E+3'
        >>> ExtendedContext.to_eng_string(Decimal('123E+3'))
        '123E+3'
        >>> ExtendedContext.to_eng_string(Decimal('123E-10'))
        '12.3E-9'
        >>> ExtendedContext.to_eng_string(Decimal('-123E-12'))
        '-123E-12'
        >>> ExtendedContext.to_eng_string(Decimal('7E-7'))
        '700E-9'
        >>> ExtendedContext.to_eng_string(Decimal('7E+1'))
        '70'
        >>> ExtendedContext.to_eng_string(Decimal('0E+1'))
        '0.00E+3'

        'u'Convert to a string, using engineering notation if an exponent is needed.

        Engineering notation has an exponent which is a multiple of 3.  This
        can leave up to 3 digits to the left of the decimal place and may
        require the addition of either one or two trailing zeros.

        The operation is not affected by the context.

        >>> ExtendedContext.to_eng_string(Decimal('123E+1'))
        '1.23E+3'
        >>> ExtendedContext.to_eng_string(Decimal('123E+3'))
        '123E+3'
        >>> ExtendedContext.to_eng_string(Decimal('123E-10'))
        '12.3E-9'
        >>> ExtendedContext.to_eng_string(Decimal('-123E-12'))
        '-123E-12'
        >>> ExtendedContext.to_eng_string(Decimal('7E-7'))
        '700E-9'
        >>> ExtendedContext.to_eng_string(Decimal('7E+1'))
        '70'
        >>> ExtendedContext.to_eng_string(Decimal('0E+1'))
        '0.00E+3'

        'b'Converts a number to a string, using scientific notation.

        The operation is not affected by the context.
        'u'Converts a number to a string, using scientific notation.

        The operation is not affected by the context.
        'b'Rounds to an integer.

        When the operand has a negative exponent, the result is the same
        as using the quantize() operation using the given operand as the
        left-hand-operand, 1E+0 as the right-hand-operand, and the precision
        of the operand as the precision setting; Inexact and Rounded flags
        are allowed in this operation.  The rounding mode is taken from the
        context.

        >>> ExtendedContext.to_integral_exact(Decimal('2.1'))
        Decimal('2')
        >>> ExtendedContext.to_integral_exact(Decimal('100'))
        Decimal('100')
        >>> ExtendedContext.to_integral_exact(Decimal('100.0'))
        Decimal('100')
        >>> ExtendedContext.to_integral_exact(Decimal('101.5'))
        Decimal('102')
        >>> ExtendedContext.to_integral_exact(Decimal('-101.5'))
        Decimal('-102')
        >>> ExtendedContext.to_integral_exact(Decimal('10E+5'))
        Decimal('1.0E+6')
        >>> ExtendedContext.to_integral_exact(Decimal('7.89E+77'))
        Decimal('7.89E+77')
        >>> ExtendedContext.to_integral_exact(Decimal('-Inf'))
        Decimal('-Infinity')
        'u'Rounds to an integer.

        When the operand has a negative exponent, the result is the same
        as using the quantize() operation using the given operand as the
        left-hand-operand, 1E+0 as the right-hand-operand, and the precision
        of the operand as the precision setting; Inexact and Rounded flags
        are allowed in this operation.  The rounding mode is taken from the
        context.

        >>> ExtendedContext.to_integral_exact(Decimal('2.1'))
        Decimal('2')
        >>> ExtendedContext.to_integral_exact(Decimal('100'))
        Decimal('100')
        >>> ExtendedContext.to_integral_exact(Decimal('100.0'))
        Decimal('100')
        >>> ExtendedContext.to_integral_exact(Decimal('101.5'))
        Decimal('102')
        >>> ExtendedContext.to_integral_exact(Decimal('-101.5'))
        Decimal('-102')
        >>> ExtendedContext.to_integral_exact(Decimal('10E+5'))
        Decimal('1.0E+6')
        >>> ExtendedContext.to_integral_exact(Decimal('7.89E+77'))
        Decimal('7.89E+77')
        >>> ExtendedContext.to_integral_exact(Decimal('-Inf'))
        Decimal('-Infinity')
        'b'Rounds to an integer.

        When the operand has a negative exponent, the result is the same
        as using the quantize() operation using the given operand as the
        left-hand-operand, 1E+0 as the right-hand-operand, and the precision
        of the operand as the precision setting, except that no flags will
        be set.  The rounding mode is taken from the context.

        >>> ExtendedContext.to_integral_value(Decimal('2.1'))
        Decimal('2')
        >>> ExtendedContext.to_integral_value(Decimal('100'))
        Decimal('100')
        >>> ExtendedContext.to_integral_value(Decimal('100.0'))
        Decimal('100')
        >>> ExtendedContext.to_integral_value(Decimal('101.5'))
        Decimal('102')
        >>> ExtendedContext.to_integral_value(Decimal('-101.5'))
        Decimal('-102')
        >>> ExtendedContext.to_integral_value(Decimal('10E+5'))
        Decimal('1.0E+6')
        >>> ExtendedContext.to_integral_value(Decimal('7.89E+77'))
        Decimal('7.89E+77')
        >>> ExtendedContext.to_integral_value(Decimal('-Inf'))
        Decimal('-Infinity')
        'u'Rounds to an integer.

        When the operand has a negative exponent, the result is the same
        as using the quantize() operation using the given operand as the
        left-hand-operand, 1E+0 as the right-hand-operand, and the precision
        of the operand as the precision setting, except that no flags will
        be set.  The rounding mode is taken from the context.

        >>> ExtendedContext.to_integral_value(Decimal('2.1'))
        Decimal('2')
        >>> ExtendedContext.to_integral_value(Decimal('100'))
        Decimal('100')
        >>> ExtendedContext.to_integral_value(Decimal('100.0'))
        Decimal('100')
        >>> ExtendedContext.to_integral_value(Decimal('101.5'))
        Decimal('102')
        >>> ExtendedContext.to_integral_value(Decimal('-101.5'))
        Decimal('-102')
        >>> ExtendedContext.to_integral_value(Decimal('10E+5'))
        Decimal('1.0E+6')
        >>> ExtendedContext.to_integral_value(Decimal('7.89E+77'))
        Decimal('7.89E+77')
        >>> ExtendedContext.to_integral_value(Decimal('-Inf'))
        Decimal('-Infinity')
        'b'(%r, %r, %r)'u'(%r, %r, %r)'b'Normalizes op1, op2 to have the same exp and length of coefficient.

    Done during addition.
    'u'Normalizes op1, op2 to have the same exp and length of coefficient.

    Done during addition.
    'b' Given integers n and e, return n * 10**e if it's an integer, else None.

    The computation is designed to avoid computing large powers of 10
    unnecessarily.

    >>> _decimal_lshift_exact(3, 4)
    30000
    >>> _decimal_lshift_exact(300, -999999999)  # returns None

    'u' Given integers n and e, return n * 10**e if it's an integer, else None.

    The computation is designed to avoid computing large powers of 10
    unnecessarily.

    >>> _decimal_lshift_exact(3, 4)
    30000
    >>> _decimal_lshift_exact(300, -999999999)  # returns None

    'b'Closest integer to the square root of the positive integer n.  a is
    an initial approximation to the square root.  Any positive integer
    will do for a, but the closer a is to the square root of n the
    faster convergence will be.

    'u'Closest integer to the square root of the positive integer n.  a is
    an initial approximation to the square root.  Any positive integer
    will do for a, but the closer a is to the square root of n the
    faster convergence will be.

    'b'Both arguments to _sqrt_nearest should be positive.'u'Both arguments to _sqrt_nearest should be positive.'b'Given an integer x and a nonnegative integer shift, return closest
    integer to x / 2**shift; use round-to-even in case of a tie.

    'u'Given an integer x and a nonnegative integer shift, return closest
    integer to x / 2**shift; use round-to-even in case of a tie.

    'b'Closest integer to a/b, a and b positive integers; rounds to even
    in the case of a tie.

    'u'Closest integer to a/b, a and b positive integers; rounds to even
    in the case of a tie.

    'b'Integer approximation to M*log(x/M), with absolute error boundable
    in terms only of x/M.

    Given positive integers x and M, return an integer approximation to
    M * log(x/M).  For L = 8 and 0.1 <= x/M <= 10 the difference
    between the approximation and the exact result is at most 22.  For
    L = 8 and 1.0 <= x/M <= 10.0 the difference is at most 15.  In
    both cases these are upper bounds on the error; it will usually be
    much smaller.'u'Integer approximation to M*log(x/M), with absolute error boundable
    in terms only of x/M.

    Given positive integers x and M, return an integer approximation to
    M * log(x/M).  For L = 8 and 0.1 <= x/M <= 10 the difference
    between the approximation and the exact result is at most 22.  For
    L = 8 and 1.0 <= x/M <= 10.0 the difference is at most 15.  In
    both cases these are upper bounds on the error; it will usually be
    much smaller.'b'Given integers c, e and p with c > 0, p >= 0, compute an integer
    approximation to 10**p * log10(c*10**e), with an absolute error of
    at most 1.  Assumes that c*10**e is not exactly 1.'u'Given integers c, e and p with c > 0, p >= 0, compute an integer
    approximation to 10**p * log10(c*10**e), with an absolute error of
    at most 1.  Assumes that c*10**e is not exactly 1.'b'Given integers c, e and p with c > 0, compute an integer
    approximation to 10**p * log(c*10**e), with an absolute error of
    at most 1.  Assumes that c*10**e is not exactly 1.'u'Given integers c, e and p with c > 0, compute an integer
    approximation to 10**p * log(c*10**e), with an absolute error of
    at most 1.  Assumes that c*10**e is not exactly 1.'b'Class to compute, store, and allow retrieval of, digits of the
    constant log(10) = 2.302585....  This constant is needed by
    Decimal.ln, Decimal.log10, Decimal.exp and Decimal.__pow__.'u'Class to compute, store, and allow retrieval of, digits of the
    constant log(10) = 2.302585....  This constant is needed by
    Decimal.ln, Decimal.log10, Decimal.exp and Decimal.__pow__.'b'23025850929940456840179914546843642076011014886'u'23025850929940456840179914546843642076011014886'b'Given an integer p >= 0, return floor(10**p)*log(10).

        For example, self.getdigits(3) returns 2302.
        'u'Given an integer p >= 0, return floor(10**p)*log(10).

        For example, self.getdigits(3) returns 2302.
        'b'p should be nonnegative'u'p should be nonnegative'b'Given integers x and M, M > 0, such that x/M is small in absolute
    value, compute an integer approximation to M*exp(x/M).  For 0 <=
    x/M <= 2.4, the absolute error in the result is bounded by 60 (and
    is usually much smaller).'u'Given integers x and M, M > 0, such that x/M is small in absolute
    value, compute an integer approximation to M*exp(x/M).  For 0 <=
    x/M <= 2.4, the absolute error in the result is bounded by 60 (and
    is usually much smaller).'b'Compute an approximation to exp(c*10**e), with p decimal places of
    precision.

    Returns integers d, f such that:

      10**(p-1) <= d <= 10**p, and
      (d-1)*10**f < exp(c*10**e) < (d+1)*10**f

    In other words, d*10**f is an approximation to exp(c*10**e) with p
    digits of precision, and with an error in d of at most 1.  This is
    almost, but not quite, the same as the error being < 1ulp: when d
    = 10**(p-1) the error could be up to 10 ulp.'u'Compute an approximation to exp(c*10**e), with p decimal places of
    precision.

    Returns integers d, f such that:

      10**(p-1) <= d <= 10**p, and
      (d-1)*10**f < exp(c*10**e) < (d+1)*10**f

    In other words, d*10**f is an approximation to exp(c*10**e) with p
    digits of precision, and with an error in d of at most 1.  This is
    almost, but not quite, the same as the error being < 1ulp: when d
    = 10**(p-1) the error could be up to 10 ulp.'b'Given integers xc, xe, yc and ye representing Decimals x = xc*10**xe and
    y = yc*10**ye, compute x**y.  Returns a pair of integers (c, e) such that:

      10**(p-1) <= c <= 10**p, and
      (c-1)*10**e < x**y < (c+1)*10**e

    in other words, c*10**e is an approximation to x**y with p digits
    of precision, and with an error in c of at most 1.  (This is
    almost, but not quite, the same as the error being < 1ulp: when c
    == 10**(p-1) we can only guarantee error < 10ulp.)

    We assume that: x is positive and not equal to 1, and y is nonzero.
    'u'Given integers xc, xe, yc and ye representing Decimals x = xc*10**xe and
    y = yc*10**ye, compute x**y.  Returns a pair of integers (c, e) such that:

      10**(p-1) <= c <= 10**p, and
      (c-1)*10**e < x**y < (c+1)*10**e

    in other words, c*10**e is an approximation to x**y with p digits
    of precision, and with an error in c of at most 1.  (This is
    almost, but not quite, the same as the error being < 1ulp: when c
    == 10**(p-1) we can only guarantee error < 10ulp.)

    We assume that: x is positive and not equal to 1, and y is nonzero.
    'b'Compute a lower bound for 100*log10(c) for a positive integer c.'u'Compute a lower bound for 100*log10(c) for a positive integer c.'b'The argument to _log10_lb should be nonnegative.'u'The argument to _log10_lb should be nonnegative.'b'Convert other to Decimal.

    Verifies that it's ok to use in an implicit construction.
    If allow_float is true, allow conversion from float;  this
    is used in the comparison methods (__eq__ and friends).

    'u'Convert other to Decimal.

    Verifies that it's ok to use in an implicit construction.
    If allow_float is true, allow conversion from float;  this
    is used in the comparison methods (__eq__ and friends).

    'b'Given a Decimal instance self and a Python object other, return
    a pair (s, o) of Decimal instances such that "s op o" is
    equivalent to "self op other" for any of the 6 comparison
    operators "op".

    'u'Given a Decimal instance self and a Python object other, return
    a pair (s, o) of Decimal instances such that "s op o" is
    equivalent to "self op other" for any of the 6 comparison
    operators "op".

    'b'        # A numeric string consists of:
#    \s*
    (?P<sign>[-+])?              # an optional sign, followed by either...
    (
        (?=\d|\.\d)              # ...a number (with at least one digit)
        (?P<int>\d*)             # having a (possibly empty) integer part
        (\.(?P<frac>\d*))?       # followed by an optional fractional part
        (E(?P<exp>[-+]?\d+))?    # followed by an optional exponent, or...
    |
        Inf(inity)?              # ...an infinity, or...
    |
        (?P<signal>s)?           # ...an (optionally signaling)
        NaN                      # NaN
        (?P<diag>\d*)            # with (possibly empty) diagnostic info.
    )
#    \s*
    \Z
'u'        # A numeric string consists of:
#    \s*
    (?P<sign>[-+])?              # an optional sign, followed by either...
    (
        (?=\d|\.\d)              # ...a number (with at least one digit)
        (?P<int>\d*)             # having a (possibly empty) integer part
        (\.(?P<frac>\d*))?       # followed by an optional fractional part
        (E(?P<exp>[-+]?\d+))?    # followed by an optional exponent, or...
    |
        Inf(inity)?              # ...an infinity, or...
    |
        (?P<signal>s)?           # ...an (optionally signaling)
        NaN                      # NaN
        (?P<diag>\d*)            # with (possibly empty) diagnostic info.
    )
#    \s*
    \Z
'b'0*$'u'0*$'b'50*$'u'50*$'b'\A
(?:
   (?P<fill>.)?
   (?P<align>[<>=^])
)?
(?P<sign>[-+ ])?
(?P<alt>\#)?
(?P<zeropad>0)?
(?P<minimumwidth>(?!0)\d+)?
(?P<thousands_sep>,)?
(?:\.(?P<precision>0|(?!0)\d+))?
(?P<type>[eEfFgGn%])?
\Z
'u'\A
(?:
   (?P<fill>.)?
   (?P<align>[<>=^])
)?
(?P<sign>[-+ ])?
(?P<alt>\#)?
(?P<zeropad>0)?
(?P<minimumwidth>(?!0)\d+)?
(?P<thousands_sep>,)?
(?:\.(?P<precision>0|(?!0)\d+))?
(?P<type>[eEfFgGn%])?
\Z
'b'Parse and validate a format specifier.

    Turns a standard numeric format specifier into a dict, with the
    following entries:

      fill: fill character to pad field to minimum width
      align: alignment type, either '<', '>', '=' or '^'
      sign: either '+', '-' or ' '
      minimumwidth: nonnegative integer giving minimum width
      zeropad: boolean, indicating whether to pad with zeros
      thousands_sep: string to use as thousands separator, or ''
      grouping: grouping for thousands separators, in format
        used by localeconv
      decimal_point: string to use for decimal point
      precision: nonnegative integer giving precision, or None
      type: one of the characters 'eEfFgG%', or None

    'u'Parse and validate a format specifier.

    Turns a standard numeric format specifier into a dict, with the
    following entries:

      fill: fill character to pad field to minimum width
      align: alignment type, either '<', '>', '=' or '^'
      sign: either '+', '-' or ' '
      minimumwidth: nonnegative integer giving minimum width
      zeropad: boolean, indicating whether to pad with zeros
      thousands_sep: string to use as thousands separator, or ''
      grouping: grouping for thousands separators, in format
        used by localeconv
      decimal_point: string to use for decimal point
      precision: nonnegative integer giving precision, or None
      type: one of the characters 'eEfFgG%', or None

    'b'Invalid format specifier: 'u'Invalid format specifier: 'b'fill'u'fill'b'align'u'align'b'zeropad'u'zeropad'b'Fill character conflicts with '0' in format specifier: 'u'Fill character conflicts with '0' in format specifier: 'b'Alignment conflicts with '0' in format specifier: 'u'Alignment conflicts with '0' in format specifier: 'b'minimumwidth'u'minimumwidth'b'gGn'u'gGn'b'thousands_sep'u'thousands_sep'b'Explicit thousands separator conflicts with 'n' type in format specifier: 'u'Explicit thousands separator conflicts with 'n' type in format specifier: 'b'grouping'u'grouping'b'decimal_point'u'decimal_point'b'Given an unpadded, non-aligned numeric string 'body' and sign
    string 'sign', add padding and alignment conforming to the given
    format specifier dictionary 'spec' (as produced by
    parse_format_specifier).

    'u'Given an unpadded, non-aligned numeric string 'body' and sign
    string 'sign', add padding and alignment conforming to the given
    format specifier dictionary 'spec' (as produced by
    parse_format_specifier).

    'b'^'u'^'b'Unrecognised alignment field'u'Unrecognised alignment field'b'Convert a localeconv-style grouping into a (possibly infinite)
    iterable of integers representing group lengths.

    'u'Convert a localeconv-style grouping into a (possibly infinite)
    iterable of integers representing group lengths.

    'b'unrecognised format for grouping'u'unrecognised format for grouping'b'Insert thousands separators into a digit string.

    spec is a dictionary whose keys should include 'thousands_sep' and
    'grouping'; typically it's the result of parsing the format
    specifier using _parse_format_specifier.

    The min_width keyword argument gives the minimum length of the
    result, which will be padded on the left with zeros if necessary.

    If necessary, the zero padding adds an extra '0' on the left to
    avoid a leading thousands separator.  For example, inserting
    commas every three digits in '123456', with min_width=8, gives
    '0,123,456', even though that has length 9.

    'u'Insert thousands separators into a digit string.

    spec is a dictionary whose keys should include 'thousands_sep' and
    'grouping'; typically it's the result of parsing the format
    specifier using _parse_format_specifier.

    The min_width keyword argument gives the minimum length of the
    result, which will be padded on the left with zeros if necessary.

    If necessary, the zero padding adds an extra '0' on the left to
    avoid a leading thousands separator.  For example, inserting
    commas every three digits in '123456', with min_width=8, gives
    '0,123,456', even though that has length 9.

    'b'group length should be positive'u'group length should be positive'b'Determine sign character.'u'Determine sign character.'b' +'u' +'b'Format a number, given the following data:

    is_negative: true if the number is negative, else false
    intpart: string of digits that must appear before the decimal point
    fracpart: string of digits that must come after the point
    exp: exponent, as an integer
    spec: dictionary resulting from parsing the format specifier

    This function uses the information in spec to:
      insert separators (decimal separator and thousands separators)
      format the sign
      format the exponent
      add trailing '%' for the '%' type
      zero-pad if necessary
      fill and align if necessary
    'u'Format a number, given the following data:

    is_negative: true if the number is negative, else false
    intpart: string of digits that must appear before the decimal point
    fracpart: string of digits that must come after the point
    exp: exponent, as an integer
    spec: dictionary resulting from parsing the format specifier

    This function uses the information in spec to:
      insert separators (decimal separator and thousands separators)
      format the sign
      format the exponent
      add trailing '%' for the '%' type
      zero-pad if necessary
      fill and align if necessary
    'b'alt'u'alt'b'{0}{1:+}'u'{0}{1:+}'b'Inf'u'Inf'b'-Inf'u'-Inf'u'_pydecimal'u'_queue'u'Empty.__weakref__'_queue.Emptyu'Simple, unbounded, reentrant FIFO queue.'_queue.SimpleQueueu'C implementation of the Python queue module.
This module is an implementation detail, please do not use it directly.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_queue.cpython-310-darwin.so'u'Random() -> create a random number generator with its own internal state.'u'_random'getrandbitsrandomseed_random.RandomRandomu'Module implements the Mersenne Twister random number generator.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_random.cpython-310-darwin.so'_randomu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_scproxy.cpython-310-darwin.so'u'_scproxy'_get_proxies_get_proxy_settings_scproxyu'_sha1'u'sha1.block_size'u'sha1.digest_size'u'sha1.name'_sha1.sha1SHA1Typeu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_sha1.cpython-310-darwin.so'sha1_sha1u'_sha256'u'sha224.block_size'u'sha224.name'_sha256.sha224SHA224Typeu'sha256.block_size'u'sha256.name'_sha256.sha256SHA256Typeu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_sha256.cpython-310-darwin.so'sha224sha256_sha256u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_sha3.cpython-310-darwin.so'u'_sha3'u'generic 64-bit optimized implementation (lane complementing, all rounds unrolled)'keccakoptu'sha3_224([data], *, usedforsecurity=True) -> SHA3 object

Return a new SHA3 hash object with a hashbit length of 28 bytes.'u'sha3_224._capacity_bits'_capacity_bitsu'sha3_224._rate_bits'_rate_bitsu'sha3_224._suffix'_suffixu'sha3_224.block_size'u'sha3_224.digest_size'u'sha3_224.name'_sha3.sha3_224sha3_224u'sha3_256([data], *, usedforsecurity=True) -> SHA3 object

Return a new SHA3 hash object with a hashbit length of 32 bytes.'u'sha3_256._capacity_bits'u'sha3_256._rate_bits'u'sha3_256._suffix'u'sha3_256.block_size'u'sha3_256.digest_size'u'sha3_256.name'_sha3.sha3_256sha3_256u'sha3_384([data], *, usedforsecurity=True) -> SHA3 object

Return a new SHA3 hash object with a hashbit length of 48 bytes.'u'sha3_384._capacity_bits'u'sha3_384._rate_bits'u'sha3_384._suffix'u'sha3_384.block_size'u'sha3_384.digest_size'u'sha3_384.name'_sha3.sha3_384sha3_384u'sha3_512([data], *, usedforsecurity=True) -> SHA3 object

Return a new SHA3 hash object with a hashbit length of 64 bytes.'u'sha3_512._capacity_bits'u'sha3_512._rate_bits'u'sha3_512._suffix'u'sha3_512.block_size'u'sha3_512.digest_size'u'sha3_512.name'_sha3.sha3_512sha3_512u'shake_128([data], *, usedforsecurity=True) -> SHAKE object

Return a new SHAKE hash object.'u'shake_128._capacity_bits'u'shake_128._rate_bits'u'shake_128._suffix'u'shake_128.block_size'u'shake_128.digest_size'u'shake_128.name'_sha3.shake_128shake_128u'shake_256([data], *, usedforsecurity=True) -> SHAKE object

Return a new SHAKE hash object.'u'shake_256._capacity_bits'u'shake_256._rate_bits'u'shake_256._suffix'u'shake_256.block_size'u'shake_256.digest_size'u'shake_256.name'_sha3.shake_256shake_256_sha3u'_sha512'u'sha512.block_size'u'sha512.name'_sha512.sha512SHA384Typeu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_sha512.cpython-310-darwin.so'sha384sha512_sha512ITIMER_PROFITIMER_REALITIMER_VIRTUALu'itimer_error.__weakref__'signal.itimer_errorItimerErrorNSIGSIGABRTSIGALRMSIGBUSSIGCHLDSIGCONTSIGEMTSIGFPESIGHUPSIGILLSIGINFOSIGINTSIGIOSIGIOTSIGPIPESIGPROFSIGQUITSIGSEGVSIGSYSSIGTERMSIGTRAPSIGTSTPSIGTTINSIGTTOUSIGURGSIGUSR1SIGUSR2SIGVTALRMSIGWINCHSIGXCPUSIGXFSZSIG_BLOCKSIG_DFLSIG_IGNSIG_SETMASKSIG_UNBLOCKu'This module provides mechanisms to use signal handlers in Python.

Functions:

alarm() -- cause SIGALRM after a specified time [Unix only]
setitimer() -- cause a signal (described below) after a specified
               float time and the timer may restart then [Unix only]
getitimer() -- get current value of timer [Unix only]
signal() -- set the action for a given signal
getsignal() -- get the signal action for a given signal
pause() -- wait until a signal arrives [Unix only]
default_int_handler() -- default SIGINT handler

signal constants:
SIG_DFL -- used to refer to the system default handler
SIG_IGN -- used to ignore the signal
NSIG -- number of defined signals
SIGINT, SIGTERM, etc. -- signal numbers

itimer constants:
ITIMER_REAL -- decrements in real time, and delivers SIGALRM upon
               expiration
ITIMER_VIRTUAL -- decrements only when the process is executing,
               and delivers SIGVTALRM upon expiration
ITIMER_PROF -- decrements both when the process is executing and
               when the system is executing on behalf of the process.
               Coupled with ITIMER_VIRTUAL, this timer is usually
               used to profile the time spent by the application
               in user and kernel space. SIGPROF is delivered upon
               expiration.


*** IMPORTANT NOTICE ***
A signal handler function is called with two arguments:
the first is the signal number, the second is the interrupted stack frame.'alarmdefault_int_handlergetitimerpausepthread_killpthread_sigmaskraise_signalset_wakeup_fdsetitimersiginterruptsigpendingsigwaitstrsignal_signalAF_APPLETALKAF_DECnetAF_INET6AF_IPXAF_LINKAF_ROUTEAF_SNAAF_SYSTEMAF_UNSPECAI_ADDRCONFIG256AI_ALLAI_CANONNAME1536AI_DEFAULT5127AI_MASKAI_NUMERICHOSTAI_NUMERICSERVAI_PASSIVE2048AI_V4MAPPED512AI_V4MAPPED_CFGCAPICMSG_LENCMSG_SPACEEAI_ADDRFAMILYEAI_AGAINEAI_BADFLAGSEAI_BADHINTSEAI_FAILEAI_FAMILYEAI_MAXEAI_MEMORYEAI_NODATAEAI_NONAMEEAI_OVERFLOWEAI_PROTOCOLEAI_SERVICEEAI_SOCKTYPEEAI_SYSTEM3758096385INADDR_ALLHOSTS_GROUPINADDR_ANYINADDR_BROADCAST2130706433INADDR_LOOPBACK3758096639INADDR_MAX_LOCAL_GROUPINADDR_NONE3758096384INADDR_UNSPEC_GROUPIPPORT_RESERVED5000IPPORT_USERRESERVEDIPPROTO_AHIPPROTO_DSTOPTSIPPROTO_EGPIPPROTO_EONIPPROTO_ESPIPPROTO_FRAGMENTIPPROTO_GGPIPPROTO_GREIPPROTO_HELLOIPPROTO_HOPOPTSIPPROTO_ICMP58IPPROTO_ICMPV6IPPROTO_IDPIPPROTO_IGMPIPPROTO_IP108IPPROTO_IPCOMPIPPROTO_IPIPIPPROTO_IPV4IPPROTO_IPV6IPPROTO_MAX77IPPROTO_ND59IPPROTO_NONEIPPROTO_PIMIPPROTO_PUP255IPPROTO_RAWIPPROTO_ROUTINGIPPROTO_RSVPIPPROTO_SCTPIPPROTO_TPIPPROTO_UDPIPPROTO_XTPIPV6_CHECKSUM62IPV6_DONTFRAGIPV6_DSTOPTSIPV6_HOPLIMITIPV6_HOPOPTSIPV6_JOIN_GROUPIPV6_LEAVE_GROUPIPV6_MULTICAST_HOPSIPV6_MULTICAST_IFIPV6_MULTICAST_LOOPIPV6_NEXTHOPIPV6_PATHMTUIPV6_PKTINFOIPV6_RECVDSTOPTSIPV6_RECVHOPLIMITIPV6_RECVHOPOPTSIPV6_RECVPATHMTU61IPV6_RECVPKTINFOIPV6_RECVRTHDRIPV6_RECVTCLASSIPV6_RTHDR57IPV6_RTHDRDSTOPTSIPV6_RTHDR_TYPE_0IPV6_TCLASSIPV6_UNICAST_HOPSIPV6_USE_MIN_MTUIPV6_V6ONLYIP_ADD_MEMBERSHIPIP_DEFAULT_MULTICAST_LOOPIP_DEFAULT_MULTICAST_TTLIP_DROP_MEMBERSHIPIP_HDRINCL4095IP_MAX_MEMBERSHIPSIP_MULTICAST_IFIP_MULTICAST_LOOPIP_MULTICAST_TTLIP_OPTIONSIP_RECVDSTADDRIP_RECVOPTSIP_RECVRETOPTSIP_RECVTOSIP_RETOPTSIP_TOSIP_TTLLOCAL_PEERCREDMSG_CTRUNCMSG_DONTROUTEMSG_DONTWAITMSG_EOFMSG_EORMSG_NOSIGNALMSG_OOBMSG_PEEKMSG_TRUNCMSG_WAITALLNI_DGRAM1025NI_MAXHOSTNI_MAXSERVNI_NAMEREQDNI_NOFQDNNI_NUMERICHOSTNI_NUMERICSERVPF_SYSTEMSCM_CREDSSCM_RIGHTSSHUT_RDSHUT_RDWRSOCK_RAWSOCK_RDMSOCK_SEQPACKETSOL_IPSOL_TCPSOL_UDPSOMAXCONNSO_ACCEPTCONNSO_BROADCASTSO_DEBUGSO_DONTROUTE4103SO_ERRORSO_KEEPALIVESO_LINGERSO_OOBINLINE4098SO_RCVBUF4100SO_RCVLOWAT4102SO_RCVTIMEOSO_REUSEPORT4097SO_SNDBUF4099SO_SNDLOWAT4101SO_SNDTIMEO4104SO_TYPESO_USELOOPBACKSYSPROTO_CONTROLu'socket(family=AF_INET, type=SOCK_STREAM, proto=0) -> socket object
socket(family=-1, type=-1, proto=-1, fileno=None) -> socket object

Open a socket of the given type.  The family argument specifies the
address family; it defaults to AF_INET.  The type argument specifies
whether this is a stream (SOCK_STREAM, this is the default)
or datagram (SOCK_DGRAM) socket.  The protocol argument defaults to 0,
specifying the default protocol.  Keyword arguments are accepted.
The socket is created as non-inheritable.

When a fileno is passed in, family, type and proto are auto-detected,
unless they are explicitly set.

A socket object represents one endpoint of a network connection.

Methods of socket objects (keyword arguments not allowed):

_accept() -- accept connection, returning new socket fd and client address
bind(addr) -- bind the socket to a local address
close() -- close the socket
connect(addr) -- connect the socket to a remote address
connect_ex(addr) -- connect, return an error code instead of an exception
dup() -- return a new socket fd duplicated from fileno()
fileno() -- return underlying file descriptor
getpeername() -- return remote address [*]
getsockname() -- return local address
getsockopt(level, optname[, buflen]) -- get socket options
gettimeout() -- return timeout or None
listen([n]) -- start listening for incoming connections
recv(buflen[, flags]) -- receive data
recv_into(buffer[, nbytes[, flags]]) -- receive data (into a buffer)
recvfrom(buflen[, flags]) -- receive data and sender's address
recvfrom_into(buffer[, nbytes, [, flags])
  -- receive data and sender's address (into a buffer)
sendall(data[, flags]) -- send all data
send(data[, flags]) -- send data, may not send all of it
sendto(data[, flags], addr) -- send data to a given address
setblocking(bool) -- set or clear the blocking I/O flag
getblocking() -- return True if socket is blocking, False if non-blocking
setsockopt(level, optname, value[, optlen]) -- set socket options
settimeout(None | float) -- set or clear the timeout
shutdown(how) -- shut down traffic in one or both directions

 [*] not available on all platforms!'_acceptconnect_exfamilygetblockinggetpeernamegetsockoptprotorecvrecv_intorecvfrom_intorecvmsgrecvmsg_intosendmsgsetblockingu'the socket timeout'u'socket.timeout'_socket.socket261TCP_FASTOPENTCP_KEEPALIVE258TCP_KEEPCNT257TCP_KEEPINTVLTCP_MAXSEG513TCP_NOTSENT_LOWATu'Implementation module for socket operations.

See the socket module for documentation.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_socket.cpython-310-darwin.so'u'gaierror.__weakref__'socket.gaierrorgaierrorgetaddrinfogetdefaulttimeoutgethostbyaddrgethostbynamegethostbyname_exgethostnamegetnameinfogetprotobynamegetservbynamegetservbyporthas_ipv6u'herror.__weakref__'socket.herrorherrorhtonlhtonsif_indextonameif_nameindexif_nametoindexinet_atoninet_ntoainet_ntopinet_ptonntohlntohssetdefaulttimeoutsethostnamesocketpairCODESIZE20171005MAGIC2147483647MAXGROUPSMAXREPEATascii_iscasedascii_toloweru' SRE 2.2.2 Copyright (c) 1997-2002 by Secret Labs AB 'getcodesizeunicode_iscasedunicode_tolower_sreALERT_DESCRIPTION_ACCESS_DENIEDALERT_DESCRIPTION_BAD_CERTIFICATE114ALERT_DESCRIPTION_BAD_CERTIFICATE_HASH_VALUE113ALERT_DESCRIPTION_BAD_CERTIFICATE_STATUS_RESPONSEALERT_DESCRIPTION_BAD_RECORD_MACALERT_DESCRIPTION_CERTIFICATE_EXPIREDALERT_DESCRIPTION_CERTIFICATE_REVOKEDALERT_DESCRIPTION_CERTIFICATE_UNKNOWN111ALERT_DESCRIPTION_CERTIFICATE_UNOBTAINABLEALERT_DESCRIPTION_CLOSE_NOTIFYALERT_DESCRIPTION_DECODE_ERRORALERT_DESCRIPTION_DECOMPRESSION_FAILUREALERT_DESCRIPTION_DECRYPT_ERRORALERT_DESCRIPTION_HANDSHAKE_FAILUREALERT_DESCRIPTION_ILLEGAL_PARAMETER71ALERT_DESCRIPTION_INSUFFICIENT_SECURITYALERT_DESCRIPTION_INTERNAL_ERRORALERT_DESCRIPTION_NO_RENEGOTIATIONALERT_DESCRIPTION_PROTOCOL_VERSIONALERT_DESCRIPTION_RECORD_OVERFLOWALERT_DESCRIPTION_UNEXPECTED_MESSAGEALERT_DESCRIPTION_UNKNOWN_CA115ALERT_DESCRIPTION_UNKNOWN_PSK_IDENTITY112ALERT_DESCRIPTION_UNRECOGNIZED_NAMEALERT_DESCRIPTION_UNSUPPORTED_CERTIFICATE110ALERT_DESCRIPTION_UNSUPPORTED_EXTENSION90ALERT_DESCRIPTION_USER_CANCELLEDCERT_NONECERT_OPTIONALCERT_REQUIREDu'_ssl'get_infopublic_bytes_ssl.CertificateCertificateENCODING_DERENCODING_PEMHAS_ALPNHAS_ECDHHAS_NPNHAS_SSLv2HAS_SSLv3HAS_TLS_UNIQUEHAS_TLSv1HAS_TLSv1_1HAS_TLSv1_2HAS_TLSv1_3HOSTFLAG_ALWAYS_CHECK_SUBJECTHOSTFLAG_MULTI_LABEL_WILDCARDSHOSTFLAG_NEVER_CHECK_SUBJECTHOSTFLAG_NO_PARTIAL_WILDCARDSHOSTFLAG_NO_WILDCARDSHOSTFLAG_SINGLE_LABEL_SUBDOMAINSu'Whether the memory BIO is at EOF.'u'MemoryBIO.eof'u'The number of bytes pending in the memory BIO.'u'MemoryBIO.pending'write_eof_ssl.MemoryBIOMemoryBIOu'OpenSSL 1.1.1s  1 Nov 2022'OPENSSL_VERSIONOPENSSL_VERSION_INFO269488447OPENSSL_VERSION_NUMBER2147483732OP_ALLOP_CIPHER_SERVER_PREFERENCEOP_ENABLE_MIDDLEBOX_COMPATOP_NO_COMPRESSION1073741824OP_NO_RENEGOTIATIONOP_NO_SSLv233554432OP_NO_SSLv3OP_NO_TICKET67108864OP_NO_TLSv1268435456OP_NO_TLSv1_1134217728OP_NO_TLSv1_2536870912OP_NO_TLSv1_3OP_SINGLE_DH_USEOP_SINGLE_ECDH_USEPROTOCOL_SSLv23PROTOCOL_TLS_CLIENTPROTOCOL_TLS_SERVERPROTOCOL_TLSv1PROTOCOL_TLSv1_1PROTOCOL_TLSv1_2PROTO_MAXIMUM_SUPPORTED-2PROTO_MINIMUM_SUPPORTED768PROTO_SSLv3769PROTO_TLSv1770PROTO_TLSv1_1771PROTO_TLSv1_2772PROTO_TLSv1_3RAND_addRAND_bytesRAND_pseudo_bytesRAND_statusu'A certificate could not be verified.'u'ssl'u'SSLCertVerificationError.__weakref__'u'An error occurred in the SSL implementation.'ssl.SSLErrorssl.SSLCertVerificationErrorSSLCertVerificationErroru'SSL/TLS connection terminated abruptly.'u'SSLEOFError.__weakref__'ssl.SSLEOFErrorSSLEOFErrorSSLErroru'Does the session contain a ticket?'u'SSLSession.has_ticket'has_ticketu'Session id'u'SSLSession.id'u'Ticket life time hint.'u'SSLSession.ticket_lifetime_hint'ticket_lifetime_hintu'Session creation time (seconds since epoch).'u'SSLSession.time'u'Session timeout (delta in seconds).'u'SSLSession.timeout'_ssl.SSLSessionSSLSessionu'System error when attempting SSL operation.'u'SSLSyscallError.__weakref__'ssl.SSLSyscallErrorSSLSyscallErroru'Non-blocking SSL socket needs to read more data
before the requested operation can be completed.'u'SSLWantReadError.__weakref__'ssl.SSLWantReadErrorSSLWantReadErroru'Non-blocking SSL socket needs to write more data
before the requested operation can be completed.'u'SSLWantWriteError.__weakref__'ssl.SSLWantWriteErrorSSLWantWriteErroru'SSL/TLS session closed cleanly.'u'SSLZeroReturnError.__weakref__'ssl.SSLZeroReturnErrorSSLZeroReturnErrorSSL_ERROR_EOFSSL_ERROR_INVALID_ERROR_CODESSL_ERROR_SSLSSL_ERROR_SYSCALLSSL_ERROR_WANT_CONNECTSSL_ERROR_WANT_READSSL_ERROR_WANT_WRITESSL_ERROR_WANT_X509_LOOKUPSSL_ERROR_ZERO_RETURNVERIFY_ALLOW_PROXY_CERTSVERIFY_CRL_CHECK_CHAINVERIFY_CRL_CHECK_LEAFVERIFY_DEFAULTVERIFY_X509_PARTIAL_CHAINVERIFY_X509_STRICTVERIFY_X509_TRUSTED_FIRSTu'@SECLEVEL=2:ECDH+AESGCM:ECDH+CHACHA20:ECDH+AES:DHE+AES:!aNULL:!eNULL:!aDSS:!SHA1:!AESCCM'_DEFAULT_CIPHERS_OPENSSL_API_VERSIONu'_SSLContext._host_flags'_host_flagsu'_SSLContext._msg_callback'_msg_callback_set_alpn_protocols_wrap_bio_wrap_socketcert_store_statsu'_SSLContext.check_hostname'check_hostnameget_ca_certsget_ciphersu'_SSLContext.keylog_filename'keylog_filenameload_cert_chainload_dh_paramsload_verify_locationsu'_SSLContext.maximum_version'maximum_versionu'_SSLContext.minimum_version'minimum_versionu'Control the number of TLSv1.3 session tickets'u'_SSLContext.num_tickets'num_ticketsu'_SSLContext.options'u'_SSLContext.post_handshake_auth'post_handshake_authu'_SSLContext.protocol'u'The current security level'u'_SSLContext.security_level'security_levelsession_statsset_ciphersset_default_verify_pathsset_ecdh_curveu'Set a callback that will be called when a server name is provided by the SSL/TLS client in the SNI extension.

If the argument is None then the callback is disabled. The method is called
with the SSLSocket, the server name as a string, and the SSLContext object.
See RFC 6066 for details of the SNI extension.'u'_SSLContext.sni_callback'sni_callbacku'_SSLContext.verify_flags'verify_flagsu'_SSLContext.verify_mode'verify_mode_ssl._SSLContext_SSLContextciphercompressionu'_setter_context(ctx)
This changes the context associated with the SSLSocket. This is typically
used from within a callback function set by the sni_callback
on the SSLContext to change the certificate information associated with the
SSLSocket before the cryptographic exchange handshake messages
'u'_SSLSocket.context'do_handshakeget_channel_bindingget_unverified_chainget_verified_chaingetpeercertu'The Python-level owner of this object.Passed as "self" in servername callback.'u'_SSLSocket.owner'selected_alpn_protocolu'The currently set server hostname (for SNI).'u'_SSLSocket.server_hostname'u'Whether this is a server-side socket.'u'_SSLSocket.server_side'server_sideu'_setter_session(session)
Get / set SSLSession.'u'_SSLSocket.session'u'Was the client session reused during handshake?'u'_SSLSocket.session_reused'session_reusedshared_ciphersverify_client_post_handshake_ssl._SSLSocket_SSLSocketu'Implementation module for SSL socket operations.  See the socket module
for documentation.'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_ssl.cpython-310-darwin.so'_test_decode_certerr_codes_to_nameserr_names_to_codesget_default_verify_pathslib_codes_to_namesnid2objtxt2obj_sslSF_APPENDSF_ARCHIVEDSF_IMMUTABLESF_NOUNLINKSF_SNAPSHOTST_ATIMEST_CTIMEST_DEVST_GIDST_INOST_MODEST_MTIMEST_NLINKST_SIZEST_UIDS_ENFMTS_IEXEC24576S_IFBLKS_IFCHRS_IFDIRS_IFDOORS_IFIFO40960S_IFLNKS_IFMTS_IFPORTS_IFREG49152S_IFSOCK57344S_IFWHTS_IMODES_IREADS_IRGRPS_IROTHS_IRUSRS_IRWXGS_IRWXO448S_ISBLKS_ISCHRS_ISDIRS_ISDOORS_ISFIFOS_ISGIDS_ISLNKS_ISPORTS_ISREGS_ISSOCKS_ISUIDS_ISVTXS_ISWHTS_IWGRPS_IWOTHS_IWRITES_IWUSRS_IXGRPS_IXOTHS_IXUSRUF_APPENDUF_COMPRESSEDUF_HIDDENUF_IMMUTABLEUF_NODUMPUF_NOUNLINKUF_OPAQUEu'S_IFMT_: file type bits
S_IFDIR: directory
S_IFCHR: character device
S_IFBLK: block device
S_IFREG: regular file
S_IFIFO: fifo (named pipe)
S_IFLNK: symbolic link
S_IFSOCK: socket file
S_IFDOOR: door
S_IFPORT: event port
S_IFWHT: whiteout

S_ISUID: set UID bit
S_ISGID: set GID bit
S_ENFMT: file locking enforcement
S_ISVTX: sticky bit
S_IREAD: Unix V7 synonym for S_IRUSR
S_IWRITE: Unix V7 synonym for S_IWUSR
S_IEXEC: Unix V7 synonym for S_IXUSR
S_IRWXU: mask for owner permissions
S_IRUSR: read by owner
S_IWUSR: write by owner
S_IXUSR: execute by owner
S_IRWXG: mask for group permissions
S_IRGRP: read by group
S_IWGRP: write by group
S_IXGRP: execute by group
S_IRWXO: mask for others (not in group) permissions
S_IROTH: read by others
S_IWOTH: write by others
S_IXOTH: execute by others

UF_NODUMP: do not dump file
UF_IMMUTABLE: file may not be changed
UF_APPEND: file may only be appended to
UF_OPAQUE: directory is opaque when viewed through a union stack
UF_NOUNLINK: file may not be renamed or deleted
UF_COMPRESSED: OS X: file is hfs-compressed
UF_HIDDEN: OS X: file should not be displayed
SF_ARCHIVED: file may be archived
SF_IMMUTABLE: file may not be changed
SF_APPEND: file may only be appended to
SF_NOUNLINK: file may not be renamed or deleted
SF_SNAPSHOT: file is a snapshot file

ST_MODE
ST_INO
ST_DEV
ST_NLINK
ST_UID
ST_GID
ST_SIZE
ST_ATIME
ST_MTIME
ST_CTIME

FILE_ATTRIBUTE_*: Windows file attribute constants
                   (only present on Windows)
'_statu'Accelerators for the statistics module.
'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_statistics.cpython-310-darwin.so'u'_statistics'_normal_dist_inv_cdf_statisticsu'string helper module'formatter_field_name_splitformatter_parser_stringu'Struct(fmt) --> compiled struct object

'u'_struct'u'struct format string'u'Struct.format'iter_unpackpack_intou'struct size in bytes'u'Struct.size'unpack_from_struct.StructStructu'Functions to convert between Python values and C structs.
Python bytes objects are used to hold the data representing the C struct
and also as format strings (explained below) to describe the layout of data
in the C struct.

The optional first format char indicates byte order, size and alignment:
  @: native order, size & alignment (default)
  =: native order, std. size & alignment
  <: little-endian, std. size & alignment
  >: big-endian, std. size & alignment
  !: same as >

The remaining chars indicate types of args and must match exactly;
these can be preceded by a decimal repeat count:
  x: pad byte (no data); c:char; b:signed byte; B:unsigned byte;
  ?: _Bool (requires C99; if not available, char is used instead)
  h:short; H:unsigned short; i:int; I:unsigned int;
  l:long; L:unsigned long; f:float; d:double; e:half-float.
Special cases (preceding decimal count indicates length):
  s:string (array of char); p: pascal string (with count byte).
Special cases (only available in native format):
  n:ssize_t; N:size_t;
  P:an integer type that is wide enough to hold a pointer.
Special case (not in native mode unless 'long long' in platform C):
  q:long long; Q:unsigned long long
Whitespace between formats is ignored.

The variable struct.error is an exception raised on errors.
'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_struct.cpython-310-darwin.so'_clearcacheu'struct'struct.error_struct-128CHAR_MIN_testcapi.ContainerNoGCContainerNoGCDBL_MAXDBL_MINDecodeLocaleExEncodeLocaleEx3.4028234663852886e+38FLT_MAX1.1754943508222875e-38FLT_MINGeneric__mro_entries__u'A heap type without GC, but with overridden __setattr__.

The 'value' attribute is set to 10 in __init__ and updated via attribute setting.'u'_testcapi'pvalue_testcapi.HeapCTypeSetattrHeapCTypeSetattru'Subclass of HeapCType, without GC.

__init__ sets the 'value' attribute to 10 and 'value2' to 20.'value2u'A heap type without GC, but with overridden dealloc.

The 'value' attribute is set to 10 in __init__.'_testcapi.HeapCType_testcapi.HeapCTypeSubclassHeapCTypeSubclassu'Subclass of HeapCType with a finalizer that reassigns __class__.

__class__ is set to plain HeapCTypeSubclass during finalization.
__init__ sets the 'value' attribute to 10 and 'value2' to 20.'_testcapi.HeapCTypeSubclassWithFinalizerHeapCTypeSubclassWithFinalizeru'Heap type with buffer support.

The buffer is set to [b'1', b'2', b'3', b'4']'_testcapi.HeapCTypeWithBufferHeapCTypeWithBufferu'HeapCTypeWithDict.__dict__'dictobj_testcapi.HeapCTypeWithDictHeapCTypeWithDictu'HeapCTypeWithNegativeDict.__dict__'_testcapi.HeapCTypeWithNegativeDictHeapCTypeWithNegativeDictweakreflist_testcapi.HeapCTypeWithWeakrefHeapCTypeWithWeakrefu'somedoc'_testcapi.HeapDocCTypeHeapDocCTypeu'A heap type with GC, and with overridden dealloc.

The 'value' attribute is set to 10 in __init__.'_testcapi.HeapGcCTypeHeapGcCTypeINT_MAX-2147483648INT_MINLLONG_MAX-9223372036854775808LLONG_MINLONG_MAXLONG_MINu'Class with class methods to test calling conventions'meth_fastcallmeth_fastcall_keywordsmeth_noargsmeth_ometh_varargsmeth_varargs_keywordsMethClassu'Class with normal (instance) methods to test calling conventions'MethInstanceu'Class with static methods to test calling conventions'MethStaticMethodDescriptorBaseMethodDescriptor2MethodDescriptorDerivedMethodDescriptorNopGetMyList_testcapi.NullTpDocTypeNullTpDocTypePY_SSIZE_T_MAXPY_SSIZE_T_MINPyBuffer_SizeFromFormatPyDateTime_DATE_GETPyDateTime_DELTA_GETPyDateTime_GETPyDateTime_TIME_GETPyTime_AsMicrosecondsPyTime_AsMillisecondsPyTime_AsSecondsDoublePyTime_AsTimespecPyTime_AsTimevalPyTime_FromSecondsPyTime_FromSecondsObjectPy_CompileStringu'Instantiating this exception starts infinite recursion.'RecursingInfinitelyErrorSHRT_MAX-32768SHRT_MINSIZEOF_TIME_TUCHAR_MAXUINT_MAX18446744073709551615ULLONG_MAXULONG_MAXUSHRT_MAXW_STOPCODEu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_testcapi.cpython-310-darwin.so'_pending_threadfuncT_BOOLT_BYTET_DOUBLET_FLOATT_INTT_LONGT_LONGLONGT_PYSSIZETT_SHORTT_STRING_INPLACET_UBYTET_UINTT_ULONGT_ULONGLONGT_USHORTu'Type containing all structmember types'test_structmembersType_test_structmembersType_test_thread_stateargparsingu'C level type with tp_as_async'awaitTypebad_getcall_in_temporary_c_threadcheck_pyobject_forbidden_bytes_is_freedcheck_pyobject_freed_is_freedcheck_pyobject_null_is_freedcheck_pyobject_uninitialized_is_freedcode_newemptycodec_incrementaldecodercodec_incrementalencodercrash_no_current_threadcreate_cfunctiondatetime_check_datedatetime_check_datetimedatetime_check_deltadatetime_check_timedatetime_check_tzinfodict_get_versiondict_getitem_knownhashdict_hassplittabledocstring_emptydocstring_no_signaturedocstring_with_invalid_signaturedocstring_with_invalid_signature2docstring_with_signaturedocstring_with_signature_and_extra_newlinesdocstring_with_signature_but_no_docdocstring_with_signature_with_defaults_testcapi.errorexception_printfatal_errorget_argsget_date_fromdateget_date_fromtimestampget_datetime_fromdateandtimeget_datetime_fromdateandtimeandfoldget_datetime_fromtimestampget_delta_fromdsuget_kwargsget_mapping_itemsget_mapping_keysget_mapping_valuesget_time_fromtimeget_time_fromtimeandfoldget_timezone_utc_capiget_timezones_offset_zerogetargs_Bgetargs_Cgetargs_Dgetargs_Hgetargs_Igetargs_Kgetargs_Lgetargs_Sgetargs_Ugetargs_Ygetargs_Zgetargs_Z_hashgetargs_bgetargs_cgetargs_dgetargs_esgetargs_es_hashgetargs_etgetargs_et_hashgetargs_fgetargs_hgetargs_igetargs_kgetargs_keyword_onlygetargs_keywordsgetargs_lgetargs_ngetargs_pgetargs_positional_only_and_keywordsgetargs_sgetargs_s_hashgetargs_s_hash_intgetargs_s_hash_int2getargs_s_stargetargs_tuplegetargs_ugetargs_u_hashgetargs_w_stargetargs_ygetargs_y_hashgetargs_y_stargetargs_zgetargs_z_hashgetargs_z_stargetbuffer_with_null_viewgetitem_with_errorhamtu'instancemethod.__doc__'instancemethod__ipow__ipowTypemake_exception_with_docmake_memoryview_from_NULL_pointermake_timezones_capimapping_has_keyu'C level type with matrix operations defined'__imatmul____matmul____rmatmul__matmulTypeno_docstringparse_tuple_and_keywordspymarshal_read_last_object_from_filepymarshal_read_long_from_filepymarshal_read_object_from_filepymarshal_read_short_from_filepymarshal_write_long_to_filepymarshal_write_object_to_filepymem_api_misusepymem_buffer_overflowpymem_getallocatorsnamepymem_malloc_without_gilpynumber_tobasepyobject_bytes_from_nullpyobject_fastcallpyobject_fastcalldictpyobject_malloc_without_gilpyobject_repr_from_nullpyobject_str_from_nullpyobject_vectorcallpytime_object_to_time_tpytime_object_to_timespecpytime_object_to_timevalpyvectorcall_callraise_SIGINT_then_send_Noneraise_exceptionraise_memoryerrorremove_mem_hooksreturn_null_without_errorreturn_result_with_errorsequence_getitemsequence_setitemset_exc_infoset_nomemorystack_pointertest_L_codetest_Z_codetest_buildvalue_Ntest_buildvalue_issue38913test_capsuletest_configtest_datetime_capitest_decref_doesnt_leaktest_dict_iterationtest_empty_argparsetest_from_contiguoustest_gc_controltest_get_statictype_slotstest_incref_decref_APItest_incref_doesnt_leaktest_k_codetest_lazy_hash_inheritancetest_list_apitest_long_and_overflowtest_long_apitest_long_as_doubletest_long_as_size_ttest_long_as_unsigned_long_long_masktest_long_long_and_overflowtest_long_numbitstest_longlong_apitest_mapping_has_key_stringtest_py_is_funcstest_py_is_macrostest_pymem_alloc0test_pymem_setallocatorstest_pymem_setrawallocatorstest_pyobject_setallocatorstest_pythread_tss_key_statetest_refcount_funcstest_refcount_macrostest_s_codetest_set_type_sizetest_sizeof_c_typestest_string_from_formattest_string_to_doubletest_structseq_newtype_doesnt_leaktest_structseq_newtype_null_descr_doctest_u_codetest_unicode_compare_with_asciitest_widechartest_with_docstringtest_xdecref_doesnt_leaktest_xincref_doesnt_leakthe_number_threetraceback_printtracemalloc_get_tracebacktracemalloc_tracktracemalloc_untrackunicode_asucs4unicode_asutf8unicode_asutf8andsizeunicode_aswidecharunicode_aswidecharstringunicode_copycharactersunicode_encodedecimalunicode_findcharunicode_transformdecimaltoasciiwith_tp_delwithout_gcwrite_unraisable_excu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_testinternalcapi.cpython-310-darwin.so'u'_testinternalcapi'get_configget_configsget_recursion_depthset_configtest_atomic_funcstest_bit_lengthtest_bswaptest_edit_costtest_hashtabletest_popcountu'A lock object is a synchronization primitive.  To create a lock,
call threading.Lock().  Methods are:

acquire() -- lock the lock, possibly blocking until it can be obtained
release() -- unlock of the lock
locked() -- test whether the lock is currently locked

A lock is not owned by the thread that locked it; another thread may
unlock it.  A thread attempting to lock a lock that it has already locked
will block until another thread unlocks it.  Deadlocks may ensue.'lockedlocked_lock_thread.lockLockType_acquire_restore_is_owned_release_save_thread.RLock9223372036.0TIMEOUT_MAXu'ExceptHookArgs

Type used to pass arguments to threading.excepthook.'u'exc_type'u'exc_value'u'exc_traceback'_thread._ExceptHookArgs_ExceptHookArgsu'This module provides primitive operations to write multi-threaded programs.
The 'threading' module provides a more convenient interface.'_excepthooku'Thread-local data'_thread._local_local_set_sentinelallocateexit_threadget_native_idinterrupt_mainstack_sizestart_newstart_new_threadThread-local objects.

(Note that this module provides a Python version of the threading.local
 class.  Depending on the version of Python you're using, there may be a
 faster one available.  You should always import the `local` class from
 `threading`.)

Thread-local objects support the management of thread-local data.
If you have data that you want to be local to a thread, simply create
a thread-local object and use its attributes:

  >>> mydata = local()
  >>> mydata.number = 42
  >>> mydata.number
  42

You can also access the local-object's dictionary:

  >>> mydata.__dict__
  {'number': 42}
  >>> mydata.__dict__.setdefault('widgets', [])
  []
  >>> mydata.widgets
  []

What's important about thread-local objects is that their data are
local to a thread. If we access the data in a different thread:

  >>> log = []
  >>> def f():
  ...     items = sorted(mydata.__dict__.items())
  ...     log.append(items)
  ...     mydata.number = 11
  ...     log.append(mydata.number)

  >>> import threading
  >>> thread = threading.Thread(target=f)
  >>> thread.start()
  >>> thread.join()
  >>> log
  [[], 11]

we get different data.  Furthermore, changes made in the other thread
don't affect data seen in this thread:

  >>> mydata.number
  42

Of course, values you get from a local object, including a __dict__
attribute, are for whatever thread was current at the time the
attribute was read.  For that reason, you generally don't want to save
these values across threads, as they apply only to the thread they
came from.

You can create custom local objects by subclassing the local class:

  >>> class MyLocal(local):
  ...     number = 2
  ...     def __init__(self, /, **kw):
  ...         self.__dict__.update(kw)
  ...     def squared(self):
  ...         return self.number ** 2

This can be useful to support default values, methods and
initialization.  Note that if you define an __init__ method, it will be
called each time the local object is used in a separate thread.  This
is necessary to initialize each thread's dictionary.

Now if we create a local object:

  >>> mydata = MyLocal(color='red')

Now we have a default number:

  >>> mydata.number
  2

an initial color:

  >>> mydata.color
  'red'
  >>> del mydata.color

And a method that operates on the data:

  >>> mydata.squared()
  4

As before, we can access the data in a separate thread:

  >>> log = []
  >>> thread = threading.Thread(target=f)
  >>> thread.start()
  >>> thread.join()
  >>> log
  [[('color', 'red')], 11]

without affecting this thread's data:

  >>> mydata.number
  2
  >>> mydata.color
  Traceback (most recent call last):
  ...
  AttributeError: 'MyLocal' object has no attribute 'color'

Note that subclasses can define slots, but they are not thread
local. They are shared across threads:

  >>> class MyLocal(local):
  ...     __slots__ = 'number'

  >>> mydata = MyLocal()
  >>> mydata.number = 42
  >>> mydata.color = 'red'

So, the separate thread:

  >>> thread = threading.Thread(target=f)
  >>> thread.start()
  >>> thread.join()

affects what we see:

  >>> mydata.number
  11

>>> del mydata
local_localimplA class managing thread-local dictsdictslocalargslocallock_threading_local._localimpl.get_dictReturn the dict for the current thread. Raises KeyError if none
        defined.create_dictCreate a new dict for the current thread, and return it.localdictidtlocal_deletedwrthreadthread_deletedwrlocal_patch_local__implimplInitialization arguments are not supported%r object attribute '__dict__' is read-only# We need to use objects from the threading module, but the threading# module may also want to use our `local` class, if support for locals# isn't compiled in to the `thread` module.  This creates potential problems# with circular imports.  For that reason, we don't import `threading`# until the bottom of this file (a hack sufficient to worm around the# potential problems).  Note that all platforms on CPython do have support# for locals in the `thread` module, and there is no circular import problem# then, so problems introduced by fiddling the order of imports here won't# manifest.# The key used in the Thread objects' attribute dicts.# We keep it a string for speed but make it unlikely to clash with# a "real" attribute.# { id(Thread) -> (ref(Thread), thread-local dict) }# When the localimpl is deleted, remove the thread attribute.# When the thread is deleted, remove the local dict.# Note that this is suboptimal if the thread object gets# caught in a reference loop. We would like to be called# as soon as the OS-level thread ends instead.# We need to create the thread dict in anticipation of# __init__ being called, to make sure we don't call it# again ourselves.b'Thread-local objects.

(Note that this module provides a Python version of the threading.local
 class.  Depending on the version of Python you're using, there may be a
 faster one available.  You should always import the `local` class from
 `threading`.)

Thread-local objects support the management of thread-local data.
If you have data that you want to be local to a thread, simply create
a thread-local object and use its attributes:

  >>> mydata = local()
  >>> mydata.number = 42
  >>> mydata.number
  42

You can also access the local-object's dictionary:

  >>> mydata.__dict__
  {'number': 42}
  >>> mydata.__dict__.setdefault('widgets', [])
  []
  >>> mydata.widgets
  []

What's important about thread-local objects is that their data are
local to a thread. If we access the data in a different thread:

  >>> log = []
  >>> def f():
  ...     items = sorted(mydata.__dict__.items())
  ...     log.append(items)
  ...     mydata.number = 11
  ...     log.append(mydata.number)

  >>> import threading
  >>> thread = threading.Thread(target=f)
  >>> thread.start()
  >>> thread.join()
  >>> log
  [[], 11]

we get different data.  Furthermore, changes made in the other thread
don't affect data seen in this thread:

  >>> mydata.number
  42

Of course, values you get from a local object, including a __dict__
attribute, are for whatever thread was current at the time the
attribute was read.  For that reason, you generally don't want to save
these values across threads, as they apply only to the thread they
came from.

You can create custom local objects by subclassing the local class:

  >>> class MyLocal(local):
  ...     number = 2
  ...     def __init__(self, /, **kw):
  ...         self.__dict__.update(kw)
  ...     def squared(self):
  ...         return self.number ** 2

This can be useful to support default values, methods and
initialization.  Note that if you define an __init__ method, it will be
called each time the local object is used in a separate thread.  This
is necessary to initialize each thread's dictionary.

Now if we create a local object:

  >>> mydata = MyLocal(color='red')

Now we have a default number:

  >>> mydata.number
  2

an initial color:

  >>> mydata.color
  'red'
  >>> del mydata.color

And a method that operates on the data:

  >>> mydata.squared()
  4

As before, we can access the data in a separate thread:

  >>> log = []
  >>> thread = threading.Thread(target=f)
  >>> thread.start()
  >>> thread.join()
  >>> log
  [[('color', 'red')], 11]

without affecting this thread's data:

  >>> mydata.number
  2
  >>> mydata.color
  Traceback (most recent call last):
  ...
  AttributeError: 'MyLocal' object has no attribute 'color'

Note that subclasses can define slots, but they are not thread
local. They are shared across threads:

  >>> class MyLocal(local):
  ...     __slots__ = 'number'

  >>> mydata = MyLocal()
  >>> mydata.number = 42
  >>> mydata.color = 'red'

So, the separate thread:

  >>> thread = threading.Thread(target=f)
  >>> thread.start()
  >>> thread.join()

affects what we see:

  >>> mydata.number
  11

>>> del mydata
'u'Thread-local objects.

(Note that this module provides a Python version of the threading.local
 class.  Depending on the version of Python you're using, there may be a
 faster one available.  You should always import the `local` class from
 `threading`.)

Thread-local objects support the management of thread-local data.
If you have data that you want to be local to a thread, simply create
a thread-local object and use its attributes:

  >>> mydata = local()
  >>> mydata.number = 42
  >>> mydata.number
  42

You can also access the local-object's dictionary:

  >>> mydata.__dict__
  {'number': 42}
  >>> mydata.__dict__.setdefault('widgets', [])
  []
  >>> mydata.widgets
  []

What's important about thread-local objects is that their data are
local to a thread. If we access the data in a different thread:

  >>> log = []
  >>> def f():
  ...     items = sorted(mydata.__dict__.items())
  ...     log.append(items)
  ...     mydata.number = 11
  ...     log.append(mydata.number)

  >>> import threading
  >>> thread = threading.Thread(target=f)
  >>> thread.start()
  >>> thread.join()
  >>> log
  [[], 11]

we get different data.  Furthermore, changes made in the other thread
don't affect data seen in this thread:

  >>> mydata.number
  42

Of course, values you get from a local object, including a __dict__
attribute, are for whatever thread was current at the time the
attribute was read.  For that reason, you generally don't want to save
these values across threads, as they apply only to the thread they
came from.

You can create custom local objects by subclassing the local class:

  >>> class MyLocal(local):
  ...     number = 2
  ...     def __init__(self, /, **kw):
  ...         self.__dict__.update(kw)
  ...     def squared(self):
  ...         return self.number ** 2

This can be useful to support default values, methods and
initialization.  Note that if you define an __init__ method, it will be
called each time the local object is used in a separate thread.  This
is necessary to initialize each thread's dictionary.

Now if we create a local object:

  >>> mydata = MyLocal(color='red')

Now we have a default number:

  >>> mydata.number
  2

an initial color:

  >>> mydata.color
  'red'
  >>> del mydata.color

And a method that operates on the data:

  >>> mydata.squared()
  4

As before, we can access the data in a separate thread:

  >>> log = []
  >>> thread = threading.Thread(target=f)
  >>> thread.start()
  >>> thread.join()
  >>> log
  [[('color', 'red')], 11]

without affecting this thread's data:

  >>> mydata.number
  2
  >>> mydata.color
  Traceback (most recent call last):
  ...
  AttributeError: 'MyLocal' object has no attribute 'color'

Note that subclasses can define slots, but they are not thread
local. They are shared across threads:

  >>> class MyLocal(local):
  ...     __slots__ = 'number'

  >>> mydata = MyLocal()
  >>> mydata.number = 42
  >>> mydata.color = 'red'

So, the separate thread:

  >>> thread = threading.Thread(target=f)
  >>> thread.start()
  >>> thread.join()

affects what we see:

  >>> mydata.number
  11

>>> del mydata
'b'local'u'local'b'A class managing thread-local dicts'u'A class managing thread-local dicts'b'dicts'u'dicts'b'localargs'u'localargs'b'locallock'u'locallock'b'_threading_local._localimpl.'u'_threading_local._localimpl.'b'Return the dict for the current thread. Raises KeyError if none
        defined.'u'Return the dict for the current thread. Raises KeyError if none
        defined.'b'Create a new dict for the current thread, and return it.'u'Create a new dict for the current thread, and return it.'b'_local__impl'u'_local__impl'b'Initialization arguments are not supported'u'Initialization arguments are not supported'b'%r object attribute '__dict__' is read-only'u'%r object attribute '__dict__' is read-only'u'_threading_local'u'Debug module to trace memory blocks allocated by Python.'_get_object_traceback_get_tracesclear_tracesget_traceback_limitget_traced_memoryget_tracemalloc_memoryreset_peak_tracemallocu'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/_uuid.cpython-310-darwin.so'u'_uuid'generate_time_safehas_uuid_generate_time_safe_uuid1.26.13# This file is protected via CODEOWNERSb'1.26.13'u'1.26.13'u'urllib3._version'u'_version'2.8.2version_tuple# coding: utf-8# file generated by setuptools_scm# don't change, don't track in version controlb'2.8.2'u'2.8.2'u'dateutil._version'u'_warnings provides basic warning filtering support.
It is a helper module to speed up interpreter start-up.'_defaultaction_onceregistrywarn_explicit__ifloordiv____ilshift____imod____irshift____itruediv__weakref.CallableProxyTypeCallableProxyType__bytes__weakref.ProxyTypeProxyType__callback__weakref.ReferenceTypeReferenceTypeu'Weak-reference support module.'_remove_dead_weakrefgetweakrefcountgetweakrefs_IterationGuardweakcontainer_iterating_removeselfref_pending_removalsitemrefpop from empty WeakSetnewset# Access WeakSet through the weakref module.# This code is separated-out because it is needed# by abc.py to load everything else at startup.# This context manager registers itself in the current iterators of the# weak container, such as to delay all removals until the context manager# exits.# This technique should be relatively thread-safe (since sets are).# Don't create cycles# A list of keys to be removed# Caveat: the iterator will keep a strong reference to# `item` until it is resumed or closed.b'WeakSet'u'WeakSet'b'pop from empty WeakSet'u'pop from empty WeakSet'u'abc'Abstract base classes related to import.machineryBinaryIOProtocolruntime_checkableabstract_clsfrozen_clsFinderLegacy abstract base class for import finders.

    It may be subclassed for compatibility with legacy third party
    reimplementations of the import system.  Otherwise, finder
    implementations should derive from the more specific MetaPathFinder
    or PathEntryFinder ABCs.

    Deprecated since Python 3.3
    the Finder ABC is deprecated and slated for removal in Python 3.12; use MetaPathFinder or PathEntryFinder instead"the Finder ABC is deprecated and ""slated for removal in Python 3.12; use MetaPathFinder ""or PathEntryFinder instead"An abstract method that should find a module.
        The fullname is a str and the optional path is a str or None.
        Returns a Loader object or None.
        importlib.abc.Finder along with its find_module() method are deprecated and slated for removal in Python 3.12; use MetaPathFinder.find_spec() or PathEntryFinder.find_spec() instead"importlib.abc.Finder along with its find_module() ""method are deprecated and ""slated for removal in Python 3.12; use ""MetaPathFinder.find_spec() or ""PathEntryFinder.find_spec() instead"MetaPathFinderAbstract base class for import finders on sys.meta_path.Return a loader for the module.

        If no module is found, return None.  The fullname is a str and
        the path is a list of strings or None.

        This method is deprecated since Python 3.4 in favor of
        finder.find_spec(). If find_spec() exists then backwards-compatible
        functionality is provided for this method.

        MetaPathFinder.find_module() is deprecated since Python 3.4 in favor of MetaPathFinder.find_spec() and is slated for removal in Python 3.12"MetaPathFinder.find_module() is deprecated since Python ""3.4 in favor of MetaPathFinder.find_spec() and is "An optional method for clearing the finder's cache, if any.
        This method is used by importlib.invalidate_caches().
        PathEntryFinderAbstract base class for path entry finders used by PathFinder.Return (loader, namespace portion) for the path entry.

        The fullname is a str.  The namespace portion is a sequence of
        path entries contributing to part of a namespace package. The
        sequence may be empty.  If loader is not None, the portion will
        be ignored.

        The portion will be discarded if another path entry finder
        locates the module as a normal module or package.

        This method is deprecated since Python 3.4 in favor of
        finder.find_spec(). If find_spec() is provided than backwards-compatible
        functionality is provided.
        PathEntryFinder.find_loader() is deprecated since Python 3.4 in favor of PathEntryFinder.find_spec() (available since 3.4)"PathEntryFinder.find_loader() is deprecated since Python ""3.4 in favor of PathEntryFinder.find_spec() ""(available since 3.4)"An optional method for clearing the finder's cache, if any.
        This method is used by PathFinder.invalidate_caches().
        ResourceLoaderAbstract base class for loaders which can return data from their
    back-end storage.

    This ABC represents one of the optional protocols specified by PEP 302.

    Abstract method which when implemented should return the bytes for
        the specified path.  The path must be a str.InspectLoaderAbstract base class for loaders which support inspection about the
    modules they can load.

    This ABC represents one of the optional protocols specified by PEP 302.

    Optional method which when implemented should return whether the
        module is a package.  The fullname is a str.  Returns a bool.

        Raises ImportError if the module cannot be found.
        Method which returns the code object for the module.

        The fullname is a str.  Returns a types.CodeType if possible, else
        returns None if a code object does not make sense
        (e.g. built-in module). Raises ImportError if the module cannot be
        found.
        Abstract method which should return the source code for the
        module.  The fullname is a str.  Returns a str.

        Raises ImportError if the module cannot be found.
        Compile 'data' into a code object.

        The 'data' argument can be anything that compile() can handle. The'path'
        argument should be where the data was retrieved (when applicable).ExecutionLoaderAbstract base class for loaders that wish to support the execution of
    modules as scripts.

    This ABC represents one of the optional protocols specified in PEP 302.

    Abstract method which should return the value that __file__ is to be
        set to.

        Raises ImportError if the module cannot be found.
        Method to return the code object for fullname.

        Should return None if not applicable (e.g. built-in module).
        Raise ImportError if the module cannot be found.
        Abstract base class partially implementing the ResourceLoader and
    ExecutionLoader ABCs.Abstract base class for loading source code (and optionally any
    corresponding bytecode).

    To support loading from source code, the abstractmethods inherited from
    ResourceLoader and ExecutionLoader need to be implemented. To also support
    loading from bytecode, the optional methods specified directly by this ABC
    is required.

    Inherited abstractmethods not implemented in this ABC:

        * ResourceLoader.get_data
        * ExecutionLoader.get_filename

    Return the (int) modification time for the path (str).Return a metadata dict for the source pointed to by the path (str).
        Possible keys:
        - 'mtime' (mandatory) is the numeric timestamp of last source
          code modification;
        - 'size' (optional) is the size in bytes of the source code.
        Write the bytes to the path (if possible).

        Accepts a str path and data as bytes.

        Any needed intermediary directories are to be created. If for some
        reason the file cannot be written because of permissions, fail
        silently.
        Abstract base class for loaders to provide resource reading support.open_resourceReturn an opened, file-like object for binary reading.

        The 'resource' argument is expected to represent only a file name.
        If the resource cannot be found, FileNotFoundError is raised.
        resource_pathReturn the file system path to the specified resource.

        The 'resource' argument is expected to represent only a file name.
        If the resource does not exist on the file system, raise
        FileNotFoundError.
        is_resourceReturn True if the named 'path' is a resource.

        Files are resources, directories are not.
        Return an iterable of entries in `package`.
    An object with a subset of pathlib.Path methods suitable for
    traversing directories and opening files.
    
        Yield Traversable objects in self
        
        Read contents of self as bytes
        strmread_text
        Read contents of self as text
        
        Return True if self is a dir
        
        Return True if self is a file
        
        Return Traversable child in self
        
        mode may be 'r' or 'rb' to open as text or binary. Return a handle
        suitable for reading (same as pathlib.Path.open).

        When opening as text, accepts encoding parameters such as those
        accepted by io.TextIOWrapper.
        abstractproperty
        The base name of this object without any parent references.
        TraversableResources
    The required interface for providing traversable
    resources.
    Return a Traversable object for the loaded package.# We don't define find_spec() here since that would break# This deliberately raises FileNotFoundError instead of# NotImplementedError so that if this method is accidentally called,# it'll still do the right thing.b'Abstract base classes related to import.'u'Abstract base classes related to import.'b'_frozen_importlib'b'Legacy abstract base class for import finders.

    It may be subclassed for compatibility with legacy third party
    reimplementations of the import system.  Otherwise, finder
    implementations should derive from the more specific MetaPathFinder
    or PathEntryFinder ABCs.

    Deprecated since Python 3.3
    'u'Legacy abstract base class for import finders.

    It may be subclassed for compatibility with legacy third party
    reimplementations of the import system.  Otherwise, finder
    implementations should derive from the more specific MetaPathFinder
    or PathEntryFinder ABCs.

    Deprecated since Python 3.3
    'b'the Finder ABC is deprecated and slated for removal in Python 3.12; use MetaPathFinder or PathEntryFinder instead'u'the Finder ABC is deprecated and slated for removal in Python 3.12; use MetaPathFinder or PathEntryFinder instead'b'An abstract method that should find a module.
        The fullname is a str and the optional path is a str or None.
        Returns a Loader object or None.
        'u'An abstract method that should find a module.
        The fullname is a str and the optional path is a str or None.
        Returns a Loader object or None.
        'b'importlib.abc.Finder along with its find_module() method are deprecated and slated for removal in Python 3.12; use MetaPathFinder.find_spec() or PathEntryFinder.find_spec() instead'u'importlib.abc.Finder along with its find_module() method are deprecated and slated for removal in Python 3.12; use MetaPathFinder.find_spec() or PathEntryFinder.find_spec() instead'b'Abstract base class for import finders on sys.meta_path.'u'Abstract base class for import finders on sys.meta_path.'b'Return a loader for the module.

        If no module is found, return None.  The fullname is a str and
        the path is a list of strings or None.

        This method is deprecated since Python 3.4 in favor of
        finder.find_spec(). If find_spec() exists then backwards-compatible
        functionality is provided for this method.

        'u'Return a loader for the module.

        If no module is found, return None.  The fullname is a str and
        the path is a list of strings or None.

        This method is deprecated since Python 3.4 in favor of
        finder.find_spec(). If find_spec() exists then backwards-compatible
        functionality is provided for this method.

        'b'MetaPathFinder.find_module() is deprecated since Python 3.4 in favor of MetaPathFinder.find_spec() and is slated for removal in Python 3.12'u'MetaPathFinder.find_module() is deprecated since Python 3.4 in favor of MetaPathFinder.find_spec() and is slated for removal in Python 3.12'b'An optional method for clearing the finder's cache, if any.
        This method is used by importlib.invalidate_caches().
        'u'An optional method for clearing the finder's cache, if any.
        This method is used by importlib.invalidate_caches().
        'b'Abstract base class for path entry finders used by PathFinder.'u'Abstract base class for path entry finders used by PathFinder.'b'Return (loader, namespace portion) for the path entry.

        The fullname is a str.  The namespace portion is a sequence of
        path entries contributing to part of a namespace package. The
        sequence may be empty.  If loader is not None, the portion will
        be ignored.

        The portion will be discarded if another path entry finder
        locates the module as a normal module or package.

        This method is deprecated since Python 3.4 in favor of
        finder.find_spec(). If find_spec() is provided than backwards-compatible
        functionality is provided.
        'u'Return (loader, namespace portion) for the path entry.

        The fullname is a str.  The namespace portion is a sequence of
        path entries contributing to part of a namespace package. The
        sequence may be empty.  If loader is not None, the portion will
        be ignored.

        The portion will be discarded if another path entry finder
        locates the module as a normal module or package.

        This method is deprecated since Python 3.4 in favor of
        finder.find_spec(). If find_spec() is provided than backwards-compatible
        functionality is provided.
        'b'PathEntryFinder.find_loader() is deprecated since Python 3.4 in favor of PathEntryFinder.find_spec() (available since 3.4)'u'PathEntryFinder.find_loader() is deprecated since Python 3.4 in favor of PathEntryFinder.find_spec() (available since 3.4)'b'An optional method for clearing the finder's cache, if any.
        This method is used by PathFinder.invalidate_caches().
        'u'An optional method for clearing the finder's cache, if any.
        This method is used by PathFinder.invalidate_caches().
        'b'Abstract base class for loaders which can return data from their
    back-end storage.

    This ABC represents one of the optional protocols specified by PEP 302.

    'u'Abstract base class for loaders which can return data from their
    back-end storage.

    This ABC represents one of the optional protocols specified by PEP 302.

    'b'Abstract method which when implemented should return the bytes for
        the specified path.  The path must be a str.'u'Abstract method which when implemented should return the bytes for
        the specified path.  The path must be a str.'b'Abstract base class for loaders which support inspection about the
    modules they can load.

    This ABC represents one of the optional protocols specified by PEP 302.

    'u'Abstract base class for loaders which support inspection about the
    modules they can load.

    This ABC represents one of the optional protocols specified by PEP 302.

    'b'Optional method which when implemented should return whether the
        module is a package.  The fullname is a str.  Returns a bool.

        Raises ImportError if the module cannot be found.
        'u'Optional method which when implemented should return whether the
        module is a package.  The fullname is a str.  Returns a bool.

        Raises ImportError if the module cannot be found.
        'b'Method which returns the code object for the module.

        The fullname is a str.  Returns a types.CodeType if possible, else
        returns None if a code object does not make sense
        (e.g. built-in module). Raises ImportError if the module cannot be
        found.
        'u'Method which returns the code object for the module.

        The fullname is a str.  Returns a types.CodeType if possible, else
        returns None if a code object does not make sense
        (e.g. built-in module). Raises ImportError if the module cannot be
        found.
        'b'Abstract method which should return the source code for the
        module.  The fullname is a str.  Returns a str.

        Raises ImportError if the module cannot be found.
        'u'Abstract method which should return the source code for the
        module.  The fullname is a str.  Returns a str.

        Raises ImportError if the module cannot be found.
        'b'Compile 'data' into a code object.

        The 'data' argument can be anything that compile() can handle. The'path'
        argument should be where the data was retrieved (when applicable).'u'Compile 'data' into a code object.

        The 'data' argument can be anything that compile() can handle. The'path'
        argument should be where the data was retrieved (when applicable).'b'Abstract base class for loaders that wish to support the execution of
    modules as scripts.

    This ABC represents one of the optional protocols specified in PEP 302.

    'u'Abstract base class for loaders that wish to support the execution of
    modules as scripts.

    This ABC represents one of the optional protocols specified in PEP 302.

    'b'Abstract method which should return the value that __file__ is to be
        set to.

        Raises ImportError if the module cannot be found.
        'u'Abstract method which should return the value that __file__ is to be
        set to.

        Raises ImportError if the module cannot be found.
        'b'Method to return the code object for fullname.

        Should return None if not applicable (e.g. built-in module).
        Raise ImportError if the module cannot be found.
        'u'Method to return the code object for fullname.

        Should return None if not applicable (e.g. built-in module).
        Raise ImportError if the module cannot be found.
        'b'Abstract base class partially implementing the ResourceLoader and
    ExecutionLoader ABCs.'u'Abstract base class partially implementing the ResourceLoader and
    ExecutionLoader ABCs.'b'Abstract base class for loading source code (and optionally any
    corresponding bytecode).

    To support loading from source code, the abstractmethods inherited from
    ResourceLoader and ExecutionLoader need to be implemented. To also support
    loading from bytecode, the optional methods specified directly by this ABC
    is required.

    Inherited abstractmethods not implemented in this ABC:

        * ResourceLoader.get_data
        * ExecutionLoader.get_filename

    'u'Abstract base class for loading source code (and optionally any
    corresponding bytecode).

    To support loading from source code, the abstractmethods inherited from
    ResourceLoader and ExecutionLoader need to be implemented. To also support
    loading from bytecode, the optional methods specified directly by this ABC
    is required.

    Inherited abstractmethods not implemented in this ABC:

        * ResourceLoader.get_data
        * ExecutionLoader.get_filename

    'b'Return the (int) modification time for the path (str).'u'Return the (int) modification time for the path (str).'b'Return a metadata dict for the source pointed to by the path (str).
        Possible keys:
        - 'mtime' (mandatory) is the numeric timestamp of last source
          code modification;
        - 'size' (optional) is the size in bytes of the source code.
        'u'Return a metadata dict for the source pointed to by the path (str).
        Possible keys:
        - 'mtime' (mandatory) is the numeric timestamp of last source
          code modification;
        - 'size' (optional) is the size in bytes of the source code.
        'b'Write the bytes to the path (if possible).

        Accepts a str path and data as bytes.

        Any needed intermediary directories are to be created. If for some
        reason the file cannot be written because of permissions, fail
        silently.
        'u'Write the bytes to the path (if possible).

        Accepts a str path and data as bytes.

        Any needed intermediary directories are to be created. If for some
        reason the file cannot be written because of permissions, fail
        silently.
        'b'Abstract base class for loaders to provide resource reading support.'u'Abstract base class for loaders to provide resource reading support.'b'Return an opened, file-like object for binary reading.

        The 'resource' argument is expected to represent only a file name.
        If the resource cannot be found, FileNotFoundError is raised.
        'u'Return an opened, file-like object for binary reading.

        The 'resource' argument is expected to represent only a file name.
        If the resource cannot be found, FileNotFoundError is raised.
        'b'Return the file system path to the specified resource.

        The 'resource' argument is expected to represent only a file name.
        If the resource does not exist on the file system, raise
        FileNotFoundError.
        'u'Return the file system path to the specified resource.

        The 'resource' argument is expected to represent only a file name.
        If the resource does not exist on the file system, raise
        FileNotFoundError.
        'b'Return True if the named 'path' is a resource.

        Files are resources, directories are not.
        'u'Return True if the named 'path' is a resource.

        Files are resources, directories are not.
        'b'Return an iterable of entries in `package`.'u'Return an iterable of entries in `package`.'b'
    An object with a subset of pathlib.Path methods suitable for
    traversing directories and opening files.
    'u'
    An object with a subset of pathlib.Path methods suitable for
    traversing directories and opening files.
    'b'
        Yield Traversable objects in self
        'u'
        Yield Traversable objects in self
        'b'
        Read contents of self as bytes
        'u'
        Read contents of self as bytes
        'b'
        Read contents of self as text
        'u'
        Read contents of self as text
        'b'
        Return True if self is a dir
        'u'
        Return True if self is a dir
        'b'
        Return True if self is a file
        'u'
        Return True if self is a file
        'b'
        Return Traversable child in self
        'u'
        Return Traversable child in self
        'b'
        mode may be 'r' or 'rb' to open as text or binary. Return a handle
        suitable for reading (same as pathlib.Path.open).

        When opening as text, accepts encoding parameters such as those
        accepted by io.TextIOWrapper.
        'u'
        mode may be 'r' or 'rb' to open as text or binary. Return a handle
        suitable for reading (same as pathlib.Path.open).

        When opening as text, accepts encoding parameters such as those
        accepted by io.TextIOWrapper.
        'b'
        The base name of this object without any parent references.
        'u'
        The base name of this object without any parent references.
        'b'
    The required interface for providing traversable
    resources.
    'u'
    The required interface for providing traversable
    resources.
    'b'Return a Traversable object for the loaded package.'u'Return a Traversable object for the loaded package.'u'importlib.abc'Abstract Base Classes (ABCs) according to PEP 3119.funcobjA decorator indicating abstract methods.

    Requires that the metaclass is ABCMeta or derived from it.  A
    class that has a metaclass derived from ABCMeta cannot be
    instantiated unless all of its abstract methods are overridden.
    The abstract methods can be called using any of the normal
    'super' call mechanisms.  abstractmethod() may be used to declare
    abstract methods for properties and descriptors.

    Usage:

        class C(metaclass=ABCMeta):
            @abstractmethod
            def my_abstract_method(self, ...):
                ...
    abstractclassmethodA decorator indicating abstract classmethods.

    Deprecated, use 'classmethod' with 'abstractmethod' instead:

        class C(ABC):
            @classmethod
            @abstractmethod
            def my_abstract_classmethod(cls, ...):
                ...

    abstractstaticmethodA decorator indicating abstract staticmethods.

    Deprecated, use 'staticmethod' with 'abstractmethod' instead:

        class C(ABC):
            @staticmethod
            @abstractmethod
            def my_abstract_staticmethod(...):
                ...

    A decorator indicating abstract properties.

    Deprecated, use 'property' with 'abstractmethod' instead:

        class C(ABC):
            @property
            @abstractmethod
            def my_abstract_property(self):
                ...

    Metaclass for defining Abstract Base Classes (ABCs).

        Use this metaclass to create an ABC.  An ABC can be subclassed
        directly, and then acts as a mix-in class.  You can also register
        unrelated concrete classes (even built-in classes) and unrelated
        ABCs as 'virtual subclasses' -- these and their descendants will
        be considered subclasses of the registering ABC by the built-in
        issubclass() function, but the registering ABC won't show up in
        their MRO (Method Resolution Order) nor will method
        implementations defined by the registering ABC be callable (not
        even via super()).
        Register a virtual subclass of an ABC.

            Returns the subclass, to allow usage as a class decorator.
            _abc_registry: _abc_cache: _abc_negative_cache: _abc_negative_cache_version: _py_abcupdate_abstractmethodsRecalculate the set of abstract methods of an abstract class.

    If a class has had one of its abstract methods implemented after the
    class was created, the method will not be considered implemented until
    this function is called. Alternatively, if a new abstract method has been
    added to the class, it will only be considered an abstract method of the
    class after this function is called.

    This function should be called before any use is made of the class,
    usually in class decorators that add methods to the subject class.

    Returns cls, to allow usage as a class decorator.

    If cls is not an instance of ABCMeta, does nothing.
    ABCHelper class that provides a standard way to create an ABC using
    inheritance.
    # We check for __abstractmethods__ here because cls might by a C# implementation or a python implementation (especially during# testing), and we want to handle both cases.# Check the existing abstract methods of the parents, keep only the ones# that are not implemented.# Also add any other newly added abstract methods.b'Abstract Base Classes (ABCs) according to PEP 3119.'u'Abstract Base Classes (ABCs) according to PEP 3119.'b'A decorator indicating abstract methods.

    Requires that the metaclass is ABCMeta or derived from it.  A
    class that has a metaclass derived from ABCMeta cannot be
    instantiated unless all of its abstract methods are overridden.
    The abstract methods can be called using any of the normal
    'super' call mechanisms.  abstractmethod() may be used to declare
    abstract methods for properties and descriptors.

    Usage:

        class C(metaclass=ABCMeta):
            @abstractmethod
            def my_abstract_method(self, ...):
                ...
    'u'A decorator indicating abstract methods.

    Requires that the metaclass is ABCMeta or derived from it.  A
    class that has a metaclass derived from ABCMeta cannot be
    instantiated unless all of its abstract methods are overridden.
    The abstract methods can be called using any of the normal
    'super' call mechanisms.  abstractmethod() may be used to declare
    abstract methods for properties and descriptors.

    Usage:

        class C(metaclass=ABCMeta):
            @abstractmethod
            def my_abstract_method(self, ...):
                ...
    'b'A decorator indicating abstract classmethods.

    Deprecated, use 'classmethod' with 'abstractmethod' instead:

        class C(ABC):
            @classmethod
            @abstractmethod
            def my_abstract_classmethod(cls, ...):
                ...

    'u'A decorator indicating abstract classmethods.

    Deprecated, use 'classmethod' with 'abstractmethod' instead:

        class C(ABC):
            @classmethod
            @abstractmethod
            def my_abstract_classmethod(cls, ...):
                ...

    'b'A decorator indicating abstract staticmethods.

    Deprecated, use 'staticmethod' with 'abstractmethod' instead:

        class C(ABC):
            @staticmethod
            @abstractmethod
            def my_abstract_staticmethod(...):
                ...

    'u'A decorator indicating abstract staticmethods.

    Deprecated, use 'staticmethod' with 'abstractmethod' instead:

        class C(ABC):
            @staticmethod
            @abstractmethod
            def my_abstract_staticmethod(...):
                ...

    'b'A decorator indicating abstract properties.

    Deprecated, use 'property' with 'abstractmethod' instead:

        class C(ABC):
            @property
            @abstractmethod
            def my_abstract_property(self):
                ...

    'u'A decorator indicating abstract properties.

    Deprecated, use 'property' with 'abstractmethod' instead:

        class C(ABC):
            @property
            @abstractmethod
            def my_abstract_property(self):
                ...

    'b'Metaclass for defining Abstract Base Classes (ABCs).

        Use this metaclass to create an ABC.  An ABC can be subclassed
        directly, and then acts as a mix-in class.  You can also register
        unrelated concrete classes (even built-in classes) and unrelated
        ABCs as 'virtual subclasses' -- these and their descendants will
        be considered subclasses of the registering ABC by the built-in
        issubclass() function, but the registering ABC won't show up in
        their MRO (Method Resolution Order) nor will method
        implementations defined by the registering ABC be callable (not
        even via super()).
        'u'Metaclass for defining Abstract Base Classes (ABCs).

        Use this metaclass to create an ABC.  An ABC can be subclassed
        directly, and then acts as a mix-in class.  You can also register
        unrelated concrete classes (even built-in classes) and unrelated
        ABCs as 'virtual subclasses' -- these and their descendants will
        be considered subclasses of the registering ABC by the built-in
        issubclass() function, but the registering ABC won't show up in
        their MRO (Method Resolution Order) nor will method
        implementations defined by the registering ABC be callable (not
        even via super()).
        'b'Register a virtual subclass of an ABC.

            Returns the subclass, to allow usage as a class decorator.
            'u'Register a virtual subclass of an ABC.

            Returns the subclass, to allow usage as a class decorator.
            'b'_abc_registry: 'u'_abc_registry: 'b'_abc_cache: 'u'_abc_cache: 'b'_abc_negative_cache: 'u'_abc_negative_cache: 'b'_abc_negative_cache_version: 'u'_abc_negative_cache_version: 'b'abc'b'Recalculate the set of abstract methods of an abstract class.

    If a class has had one of its abstract methods implemented after the
    class was created, the method will not be considered implemented until
    this function is called. Alternatively, if a new abstract method has been
    added to the class, it will only be considered an abstract method of the
    class after this function is called.

    This function should be called before any use is made of the class,
    usually in class decorators that add methods to the subject class.

    Returns cls, to allow usage as a class decorator.

    If cls is not an instance of ABCMeta, does nothing.
    'u'Recalculate the set of abstract methods of an abstract class.

    If a class has had one of its abstract methods implemented after the
    class was created, the method will not be considered implemented until
    this function is called. Alternatively, if a new abstract method has been
    added to the class, it will only be considered an abstract method of the
    class after this function is called.

    This function should be called before any use is made of the class,
    usually in class decorators that add methods to the subject class.

    Returns cls, to allow usage as a class decorator.

    If cls is not an instance of ABCMeta, does nothing.
    'b'Helper class that provides a standard way to create an ABC using
    inheritance.
    'u'Helper class that provides a standard way to create an ABC using
    inheritance.
    'botocore.docs.methoddocument_custom_methoddocument_model_driven_methodbotocore.modelOperationModelbotocore.utilsget_service_module_nameboto3.docs.baseBaseDocumenterboto3.docs.methoddocument_model_driven_resource_methodboto3.docs.utilsadd_resource_type_overviewget_resource_ignore_paramsget_resource_public_actionsActionDocumenterdocument_actions_resource_modelactionsmodeled_actions_listmodeled_actionsmodeled_action_resourceresource_actionsmember_mapActionsresource_typeActions call operations on resources.  They may automatically handle the passing in of arguments set from identifiers and some attributes.'Actions call operations on resources.  They may ''automatically handle the passing in of arguments set ''from identifiers and some attributes.'actions_introintro_linkaction_nameadd_new_sectionaction_sectiondocument_load_reload_action_resource_nameresource_nameevent_emitterload_model_service_modelservice_modeldocument_actionaction_modelinclude_signatureDocuments a resource action

    :param section: The section to write to

    :param resource_name: The name of the resource

    :param event_emitter: The event emitter to use to emit events

    :param action_model: The model of the action

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    operation_modeloperationignore_paramsexample_return_valueexample_resource_name{} = {}.{}example_prefixmethod_namedocumentationmethod_descriptionexclude_inputresource_action_modelDocuments the resource load action

    :param section: The section to write to

    :param action_name: The name of the loading action should be load or reload

    :param resource_name: The name of the resource

    :param event_emitter: The event emitter to use to emit events

    :param load_model: The model of the load action

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    Calls :py:meth:`{}.Client.{}` to update the attributes of the {} resource. Note that the load and reload methods are the same method and can be used interchangeably.'Calls :py:meth:`{}.Client.{}` to update the attributes of the ''{} resource. Note that the load and reload methods are ''the same method and can be used interchangeably.'b'actions'u'actions'b'Actions'u'Actions'b'Actions call operations on resources.  They may automatically handle the passing in of arguments set from identifiers and some attributes.'u'Actions call operations on resources.  They may automatically handle the passing in of arguments set from identifiers and some attributes.'b'actions_intro'u'actions_intro'b'Documents a resource action

    :param section: The section to write to

    :param resource_name: The name of the resource

    :param event_emitter: The event emitter to use to emit events

    :param action_model: The model of the action

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'u'Documents a resource action

    :param section: The section to write to

    :param resource_name: The name of the resource

    :param event_emitter: The event emitter to use to emit events

    :param action_model: The model of the action

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'b'response'u'response'b'{} = {}.{}'u'{} = {}.{}'b'Documents the resource load action

    :param section: The section to write to

    :param action_name: The name of the loading action should be load or reload

    :param resource_name: The name of the resource

    :param event_emitter: The event emitter to use to emit events

    :param load_model: The model of the load action

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'u'Documents the resource load action

    :param section: The section to write to

    :param action_name: The name of the loading action should be load or reload

    :param resource_name: The name of the resource

    :param event_emitter: The event emitter to use to emit events

    :param load_model: The model of the load action

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'b'Calls :py:meth:`{}.Client.{}` to update the attributes of the {} resource. Note that the load and reload methods are the same method and can be used interchangeably.'u'Calls :py:meth:`{}.Client.{}` to update the attributes of the {} resource. Note that the load and reload methods are the same method and can be used interchangeably.'u'boto3.docs.action'u'docs.action'u'action'boto3.docs.docstringActionDocstringboto3.utilsinject_attributeActioncreate_request_parametersRawHandlerResourceHandlerServiceAction
    A class representing a callable action on a resource, for example
    ``sqs.get_queue_by_name(...)`` or ``s3.Bucket('foo').delete()``.
    The action may construct parameters from existing resource identifiers
    and may return either a raw response or a new resource instance.

    :type action_model: :py:class`~boto3.resources.model.Action`
    :param action_model: The action model.

    :type factory: ResourceFactory
    :param factory: The factory that created the resource class to which
                    this action is attached.

    :type service_context: :py:class:`~boto3.utils.ServiceContext`
    :param service_context: Context about the AWS service
    service_context_action_modelresource_response_modelsearch_pathresource_modeloperation_name_response_handler
        Perform the action's request operation after building operation
        parameters and build any defined resources from the response.

        :type parent: :py:class:`~boto3.resources.base.ServiceResource`
        :param parent: The resource instance to which this action is attached.
        :rtype: dict or ServiceResource or list(ServiceResource)
        :return: The response, either as a raw dict or resource instance(s).
        Calling %s:%s with %rResponse: %rBatchAction
    An action which operates on a batch of items in a collection, typically
    a single page of results from the collection's underlying service
    operation call. For example, this allows you to delete up to 999
    S3 objects in a single operation rather than calling ``.delete()`` on
    each one individually.

    :type action_model: :py:class`~boto3.resources.model.Action`
    :param action_model: The action model.

    :type factory: ResourceFactory
    :param factory: The factory that created the resource class to which
                    this action is attached.

    :type service_context: :py:class:`~boto3.utils.ServiceContext`
    :param service_context: Context about the AWS service
    
        Perform the batch action's operation on every page of results
        from the collection.

        :type parent:
            :py:class:`~boto3.resources.collection.ResourceCollection`
        :param parent: The collection iterator to which this action
                       is attached.
        :rtype: list(dict)
        :return: A list of low-level response dicts from each call.
        responsespagepagesWaiterAction
    A class representing a callable waiter action on a resource, for example
    ``s3.Bucket('foo').wait_until_bucket_exists()``.
    The waiter action may construct parameters from existing resource
    identifiers.

    :type waiter_model: :py:class`~boto3.resources.model.Waiter`
    :param waiter_model: The action waiter.
    :type waiter_resource_name: string
    :param waiter_resource_name: The name of the waiter action for the
                                 resource. It usually begins with a
                                 ``wait_until_``
    waiter_modelwaiter_resource_name_waiter_model_waiter_resource_name
        Perform the wait operation after building operation
        parameters.

        :type parent: :py:class:`~boto3.resources.base.ServiceResource`
        :param parent: The resource instance to which this action is attached.
        waiter_nameclient_waiter_nameget_waiterCustomModeledActionA custom, modeled action to inject into a resource.
        :type action_name: str
        :param action_name: The name of the action to inject, e.g.
            'delete_tags'

        :type action_model: dict
        :param action_model: A JSON definition of the action, as if it were
            part of the resource model.

        :type function: function
        :param function: The function to perform when the action is called.
            The first argument should be 'self', which will be the resource
            the function is to be called on.

        :type event_emitter: :py:class:`botocore.hooks.BaseEventHooks`
        :param event_emitter: The session event emitter.
        emitterinjectclass_attributes# In the simplest case we just return the response, but if a# resource is defined, then we must create these before returning.# First, build predefined params and then update with the# user-supplied kwargs, which allows overriding the pre-built# params if needed.# Unlike the simple action above, a batch action must operate# on batches (or pages) of items. So we get each page, construct# the necessary parameters and call the batch operation.# There is no public interface to get a service name# or low-level client from a collection, so we get# these from the first resource in the collection.# There are no items, no need to make a call.b'
    A class representing a callable action on a resource, for example
    ``sqs.get_queue_by_name(...)`` or ``s3.Bucket('foo').delete()``.
    The action may construct parameters from existing resource identifiers
    and may return either a raw response or a new resource instance.

    :type action_model: :py:class`~boto3.resources.model.Action`
    :param action_model: The action model.

    :type factory: ResourceFactory
    :param factory: The factory that created the resource class to which
                    this action is attached.

    :type service_context: :py:class:`~boto3.utils.ServiceContext`
    :param service_context: Context about the AWS service
    'u'
    A class representing a callable action on a resource, for example
    ``sqs.get_queue_by_name(...)`` or ``s3.Bucket('foo').delete()``.
    The action may construct parameters from existing resource identifiers
    and may return either a raw response or a new resource instance.

    :type action_model: :py:class`~boto3.resources.model.Action`
    :param action_model: The action model.

    :type factory: ResourceFactory
    :param factory: The factory that created the resource class to which
                    this action is attached.

    :type service_context: :py:class:`~boto3.utils.ServiceContext`
    :param service_context: Context about the AWS service
    'b'
        Perform the action's request operation after building operation
        parameters and build any defined resources from the response.

        :type parent: :py:class:`~boto3.resources.base.ServiceResource`
        :param parent: The resource instance to which this action is attached.
        :rtype: dict or ServiceResource or list(ServiceResource)
        :return: The response, either as a raw dict or resource instance(s).
        'u'
        Perform the action's request operation after building operation
        parameters and build any defined resources from the response.

        :type parent: :py:class:`~boto3.resources.base.ServiceResource`
        :param parent: The resource instance to which this action is attached.
        :rtype: dict or ServiceResource or list(ServiceResource)
        :return: The response, either as a raw dict or resource instance(s).
        'b'Calling %s:%s with %r'u'Calling %s:%s with %r'b'Response: %r'u'Response: %r'b'
    An action which operates on a batch of items in a collection, typically
    a single page of results from the collection's underlying service
    operation call. For example, this allows you to delete up to 999
    S3 objects in a single operation rather than calling ``.delete()`` on
    each one individually.

    :type action_model: :py:class`~boto3.resources.model.Action`
    :param action_model: The action model.

    :type factory: ResourceFactory
    :param factory: The factory that created the resource class to which
                    this action is attached.

    :type service_context: :py:class:`~boto3.utils.ServiceContext`
    :param service_context: Context about the AWS service
    'u'
    An action which operates on a batch of items in a collection, typically
    a single page of results from the collection's underlying service
    operation call. For example, this allows you to delete up to 999
    S3 objects in a single operation rather than calling ``.delete()`` on
    each one individually.

    :type action_model: :py:class`~boto3.resources.model.Action`
    :param action_model: The action model.

    :type factory: ResourceFactory
    :param factory: The factory that created the resource class to which
                    this action is attached.

    :type service_context: :py:class:`~boto3.utils.ServiceContext`
    :param service_context: Context about the AWS service
    'b'
        Perform the batch action's operation on every page of results
        from the collection.

        :type parent:
            :py:class:`~boto3.resources.collection.ResourceCollection`
        :param parent: The collection iterator to which this action
                       is attached.
        :rtype: list(dict)
        :return: A list of low-level response dicts from each call.
        'u'
        Perform the batch action's operation on every page of results
        from the collection.

        :type parent:
            :py:class:`~boto3.resources.collection.ResourceCollection`
        :param parent: The collection iterator to which this action
                       is attached.
        :rtype: list(dict)
        :return: A list of low-level response dicts from each call.
        'b'
    A class representing a callable waiter action on a resource, for example
    ``s3.Bucket('foo').wait_until_bucket_exists()``.
    The waiter action may construct parameters from existing resource
    identifiers.

    :type waiter_model: :py:class`~boto3.resources.model.Waiter`
    :param waiter_model: The action waiter.
    :type waiter_resource_name: string
    :param waiter_resource_name: The name of the waiter action for the
                                 resource. It usually begins with a
                                 ``wait_until_``
    'u'
    A class representing a callable waiter action on a resource, for example
    ``s3.Bucket('foo').wait_until_bucket_exists()``.
    The waiter action may construct parameters from existing resource
    identifiers.

    :type waiter_model: :py:class`~boto3.resources.model.Waiter`
    :param waiter_model: The action waiter.
    :type waiter_resource_name: string
    :param waiter_resource_name: The name of the waiter action for the
                                 resource. It usually begins with a
                                 ``wait_until_``
    'b'
        Perform the wait operation after building operation
        parameters.

        :type parent: :py:class:`~boto3.resources.base.ServiceResource`
        :param parent: The resource instance to which this action is attached.
        'u'
        Perform the wait operation after building operation
        parameters.

        :type parent: :py:class:`~boto3.resources.base.ServiceResource`
        :param parent: The resource instance to which this action is attached.
        'b'A custom, modeled action to inject into a resource.'u'A custom, modeled action to inject into a resource.'b'
        :type action_name: str
        :param action_name: The name of the action to inject, e.g.
            'delete_tags'

        :type action_model: dict
        :param action_model: A JSON definition of the action, as if it were
            part of the resource model.

        :type function: function
        :param function: The function to perform when the action is called.
            The first argument should be 'self', which will be the resource
            the function is to be called on.

        :type event_emitter: :py:class:`botocore.hooks.BaseEventHooks`
        :param event_emitter: The session event emitter.
        'u'
        :type action_name: str
        :param action_name: The name of the action to inject, e.g.
            'delete_tags'

        :type action_model: dict
        :param action_model: A JSON definition of the action, as if it were
            part of the resource model.

        :type function: function
        :param function: The function to perform when the action is called.
            The first argument should be 'self', which will be the resource
            the function is to be called on.

        :type event_emitter: :py:class:`botocore.hooks.BaseEventHooks`
        :param event_emitter: The session event emitter.
        'u'boto3.resources.action'u'resources.action'
requests.adapters
~~~~~~~~~~~~~~~~~

This module contains the transport adapters that Requests uses to define
and maintain connections.
ClosedPoolErrorConnectTimeoutError_HTTPError_InvalidHeaderNewConnectionErrorProtocolErrorProxyError_ProxyErrorReadTimeoutErrorResponseError_SSLErrorurllib3.poolmanagerurllib3.responseurllib3.utilTimeoutSauceurllib3.util.retryauth_basic_auth_strcookiesextract_cookies_to_jarInvalidProxyURLInvalidSchemaInvalidURLRetryErrorstructuresCaseInsensitiveDictDEFAULT_CA_BUNDLE_PATHextract_zipped_pathsget_auth_from_urlget_encoding_from_headersprepend_scheme_if_neededselect_proxyurldefragauthurllib3.contrib.socksSOCKSProxyManagerMissing dependencies for SOCKS support.DEFAULT_POOLBLOCKDEFAULT_POOLSIZEDEFAULT_RETRIESDEFAULT_POOL_TIMEOUTBaseAdapterThe Base Transport AdapterverifycertproxiesSends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        Cleans up adapter specific items.HTTPAdapterThe built-in HTTP Adapter for urllib3.

    Provides a general-case interface for Requests sessions to contact HTTP and
    HTTPS urls by implementing the Transport Adapter interface. This class will
    usually be created by the :class:`Session <Session>` class under the
    covers.

    :param pool_connections: The number of urllib3 connection pools to cache.
    :param pool_maxsize: The maximum number of connections to save in the pool.
    :param max_retries: The maximum number of retries each connection
        should attempt. Note, this applies only to failed DNS lookups, socket
        connections and connection timeouts, never to requests where data has
        made it to the server. By default, Requests does not retry failed
        connections. If you need granular control over the conditions under
        which we retry a request, import urllib3's ``Retry`` class and pass
        that instead.
    :param pool_block: Whether the connection pool should block for connections.

    Usage::

      >>> import requests
      >>> s = requests.Session()
      >>> a = requests.adapters.HTTPAdapter(max_retries=3)
      >>> s.mount('http://', a)
    max_retries_pool_connections_pool_maxsize_pool_block__attrs__pool_connectionspool_maxsizepool_blockproxy_managerinit_poolmanagerconnectionsInitializes a urllib3 PoolManager.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param connections: The number of urllib3 connection pools to cache.
        :param maxsize: The maximum number of connections to save in the pool.
        :param block: Block when no free connections are available.
        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
        proxy_manager_forproxy_kwargsReturn urllib3 ProxyManager for the given proxy.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The proxy to return a urllib3 ProxyManager for.
        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
        :returns: ProxyManager
        :rtype: urllib3.ProxyManager
        socksusernamepasswordcert_verifyVerify a SSL certificate. This method should not be called from user
        code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param conn: The urllib3 connection object associated with the cert.
        :param url: The requested URL.
        :param verify: Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: The SSL certificate to verify.
        cert_locCould not find a suitable TLS CA certificate bundle, invalid path: "Could not find a suitable TLS CA certificate bundle, ""invalid path: "Could not find the TLS certificate file, invalid path: "Could not find the TLS certificate file, "Could not find the TLS key file, invalid path: build_responsereqrespBuilds a :class:`Response <requests.Response>` object from a urllib3
        response. This should not be called from user code, and is only exposed
        for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`

        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
        :param resp: The urllib3 response object.
        :rtype: requests.Response
        status_codeget_connectionReturns a urllib3 connection for the given URL. This should not be
        called from user code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param url: The URL to connect to.
        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
        :rtype: urllib3.ConnectionPool
        Please check proxy URL. It is malformed and could be missing the host."Please check proxy URL. It is malformed ""and could be missing the host."parsedgeturlDisposes of any internal state.

        Currently, this closes the PoolManager and any active ProxyManager,
        which closes any pooled connections.
        request_urlObtain the url to use when making the final request.

        If the message is being sent through a HTTP proxy, the full URL has to
        be used. Otherwise, we should only use the path portion of the URL.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
        :rtype: str
        is_proxied_http_requestusing_socks_proxyproxy_schemepath_urladd_headersAdd any headers needed by the connection. As of v2.0 this does
        nothing by default, but is left for overriding by users that subclass
        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
        :param kwargs: The keyword arguments from the call to send().
        Returns a dictionary of the headers to add to any request sent
        through a proxy. This works with urllib3 magic to ensure that they are
        correctly sent to the proxy, rather than in a tunnelled request if
        CONNECT is being used.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The url of the proxy being used for this request.
        :rtype: dict
        Proxy-AuthorizationSends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        Content-LengthchunkedInvalid timeout . Pass a (connect, read) timeout tuple, or a single float to set both timeouts to the same value.". Pass a (connect, read) timeout tuple, ""or a single float to set both timeouts to the same value."preload_contentdecode_contentproxy_pool_get_connlow_connskip_hostputrequestskip_accept_encodingputheaderendheaders0

getresponse# noqa: F401# Can't handle by adding 'proxy_manager' to self.__attrs__ because# self.poolmanager uses a lambda function, which isn't pickleable.# save these values for pickling# Allow self-specified cert location.# Fallback to None if there's no status_code, for whatever reason.# Make headers case-insensitive.# Set encoding.# Add new cookies from the server.# Give the Response some context.# Only scheme should be lower case# Send the request.# Receive the response from the server# If we hit any problems here, clean up the connection.# Then, raise so that we can handle the actual exception.# TODO: Remove this in 3.0.0: see #2811# This branch is for urllib3 v1.22 and later.# This branch is for urllib3 versions earlier than v1.22b'
requests.adapters
~~~~~~~~~~~~~~~~~

This module contains the transport adapters that Requests uses to define
and maintain connections.
'u'
requests.adapters
~~~~~~~~~~~~~~~~~

This module contains the transport adapters that Requests uses to define
and maintain connections.
'b'Missing dependencies for SOCKS support.'u'Missing dependencies for SOCKS support.'b'The Base Transport Adapter'u'The Base Transport Adapter'b'Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        'u'Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        'b'Cleans up adapter specific items.'u'Cleans up adapter specific items.'b'The built-in HTTP Adapter for urllib3.

    Provides a general-case interface for Requests sessions to contact HTTP and
    HTTPS urls by implementing the Transport Adapter interface. This class will
    usually be created by the :class:`Session <Session>` class under the
    covers.

    :param pool_connections: The number of urllib3 connection pools to cache.
    :param pool_maxsize: The maximum number of connections to save in the pool.
    :param max_retries: The maximum number of retries each connection
        should attempt. Note, this applies only to failed DNS lookups, socket
        connections and connection timeouts, never to requests where data has
        made it to the server. By default, Requests does not retry failed
        connections. If you need granular control over the conditions under
        which we retry a request, import urllib3's ``Retry`` class and pass
        that instead.
    :param pool_block: Whether the connection pool should block for connections.

    Usage::

      >>> import requests
      >>> s = requests.Session()
      >>> a = requests.adapters.HTTPAdapter(max_retries=3)
      >>> s.mount('http://', a)
    'u'The built-in HTTP Adapter for urllib3.

    Provides a general-case interface for Requests sessions to contact HTTP and
    HTTPS urls by implementing the Transport Adapter interface. This class will
    usually be created by the :class:`Session <Session>` class under the
    covers.

    :param pool_connections: The number of urllib3 connection pools to cache.
    :param pool_maxsize: The maximum number of connections to save in the pool.
    :param max_retries: The maximum number of retries each connection
        should attempt. Note, this applies only to failed DNS lookups, socket
        connections and connection timeouts, never to requests where data has
        made it to the server. By default, Requests does not retry failed
        connections. If you need granular control over the conditions under
        which we retry a request, import urllib3's ``Retry`` class and pass
        that instead.
    :param pool_block: Whether the connection pool should block for connections.

    Usage::

      >>> import requests
      >>> s = requests.Session()
      >>> a = requests.adapters.HTTPAdapter(max_retries=3)
      >>> s.mount('http://', a)
    'b'max_retries'u'max_retries'b'_pool_connections'u'_pool_connections'b'_pool_maxsize'u'_pool_maxsize'b'_pool_block'u'_pool_block'b'Initializes a urllib3 PoolManager.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param connections: The number of urllib3 connection pools to cache.
        :param maxsize: The maximum number of connections to save in the pool.
        :param block: Block when no free connections are available.
        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
        'u'Initializes a urllib3 PoolManager.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param connections: The number of urllib3 connection pools to cache.
        :param maxsize: The maximum number of connections to save in the pool.
        :param block: Block when no free connections are available.
        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
        'b'Return urllib3 ProxyManager for the given proxy.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The proxy to return a urllib3 ProxyManager for.
        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
        :returns: ProxyManager
        :rtype: urllib3.ProxyManager
        'u'Return urllib3 ProxyManager for the given proxy.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The proxy to return a urllib3 ProxyManager for.
        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
        :returns: ProxyManager
        :rtype: urllib3.ProxyManager
        'b'socks'u'socks'b'Verify a SSL certificate. This method should not be called from user
        code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param conn: The urllib3 connection object associated with the cert.
        :param url: The requested URL.
        :param verify: Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: The SSL certificate to verify.
        'u'Verify a SSL certificate. This method should not be called from user
        code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param conn: The urllib3 connection object associated with the cert.
        :param url: The requested URL.
        :param verify: Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: The SSL certificate to verify.
        'b'Could not find a suitable TLS CA certificate bundle, invalid path: 'u'Could not find a suitable TLS CA certificate bundle, invalid path: 'b'CERT_REQUIRED'u'CERT_REQUIRED'b'CERT_NONE'u'CERT_NONE'b'Could not find the TLS certificate file, invalid path: 'u'Could not find the TLS certificate file, invalid path: 'b'Could not find the TLS key file, invalid path: 'u'Could not find the TLS key file, invalid path: 'b'Builds a :class:`Response <requests.Response>` object from a urllib3
        response. This should not be called from user code, and is only exposed
        for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`

        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
        :param resp: The urllib3 response object.
        :rtype: requests.Response
        'u'Builds a :class:`Response <requests.Response>` object from a urllib3
        response. This should not be called from user code, and is only exposed
        for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`

        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
        :param resp: The urllib3 response object.
        :rtype: requests.Response
        'b'Returns a urllib3 connection for the given URL. This should not be
        called from user code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param url: The URL to connect to.
        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
        :rtype: urllib3.ConnectionPool
        'u'Returns a urllib3 connection for the given URL. This should not be
        called from user code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param url: The URL to connect to.
        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
        :rtype: urllib3.ConnectionPool
        'b'Please check proxy URL. It is malformed and could be missing the host.'u'Please check proxy URL. It is malformed and could be missing the host.'b'Disposes of any internal state.

        Currently, this closes the PoolManager and any active ProxyManager,
        which closes any pooled connections.
        'u'Disposes of any internal state.

        Currently, this closes the PoolManager and any active ProxyManager,
        which closes any pooled connections.
        'b'Obtain the url to use when making the final request.

        If the message is being sent through a HTTP proxy, the full URL has to
        be used. Otherwise, we should only use the path portion of the URL.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
        :rtype: str
        'u'Obtain the url to use when making the final request.

        If the message is being sent through a HTTP proxy, the full URL has to
        be used. Otherwise, we should only use the path portion of the URL.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
        :rtype: str
        'b'Add any headers needed by the connection. As of v2.0 this does
        nothing by default, but is left for overriding by users that subclass
        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
        :param kwargs: The keyword arguments from the call to send().
        'u'Add any headers needed by the connection. As of v2.0 this does
        nothing by default, but is left for overriding by users that subclass
        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
        :param kwargs: The keyword arguments from the call to send().
        'b'Returns a dictionary of the headers to add to any request sent
        through a proxy. This works with urllib3 magic to ensure that they are
        correctly sent to the proxy, rather than in a tunnelled request if
        CONNECT is being used.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The url of the proxy being used for this request.
        :rtype: dict
        'u'Returns a dictionary of the headers to add to any request sent
        through a proxy. This works with urllib3 magic to ensure that they are
        correctly sent to the proxy, rather than in a tunnelled request if
        CONNECT is being used.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The url of the proxy being used for this request.
        :rtype: dict
        'b'Proxy-Authorization'u'Proxy-Authorization'b'Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        'u'Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        'b'Content-Length'u'Content-Length'b'Invalid timeout 'u'Invalid timeout 'b'. Pass a (connect, read) timeout tuple, or a single float to set both timeouts to the same value.'u'. Pass a (connect, read) timeout tuple, or a single float to set both timeouts to the same value.'b'proxy_pool'u'proxy_pool'b'0

'u'requests.adapters'u'adapters'botocore.retriesbucketstandardthrottlingregister_retry_handlerClockclockCubicCalculatorstarting_max_ratestart_timerate_adjustorTokenBucketmax_ratetoken_bucketRateClockerrate_clockerThrottlingErrorDetectorRetryEventAdapterretry_event_adapterthrottling_detectorClientRateLimiterlimiterbefore-sendon_sending_requestneeds-retryon_receiving_response2.0_MAX_RATE_ADJUST_SCALE_rate_adjustor_rate_clocker_token_bucket_throttling_detector_clock_enabledmeasured_rateis_throttling_errorsuccess_receivednew_raterate_to_useerror_receivedThrottling response received, new send rate: %s measured rate: %s, token bucket capacity available: %s"Throttling response received, new send rate: %s ""measured rate: %s, token bucket capacity ""available: %s"available_capacityTracks the rate at which a client is sending a request.0.8_DEFAULT_SMOOTHING_TIME_BUCKET_RANGEsmoothingtime_bucket_range_measured_rate_smoothingfloor_last_bucket_time_bucket_scaleamountcurrent_rate# Hooked up to needs-retry.# Update the rate every _TIME_BUCKET_RANGE seconds.b'before-send'u'before-send'b'needs-retry'u'needs-retry'b'Throttling response received, new send rate: %s measured rate: %s, token bucket capacity available: %s'u'Throttling response received, new send rate: %s measured rate: %s, token bucket capacity available: %s'b'Tracks the rate at which a client is sending a request.'u'Tracks the rate at which a client is sending a request.'u'botocore.retries.adaptive'u'retries.adaptive'u'adaptive' Encoding Aliases Support

    This module is used by the encodings package search function to
    map encodings names to module names.

    Note that the search function normalizes the encoding names before
    doing the lookup, so the mapping will have to map normalized
    encoding names to module names.

    Contents:

        The following aliases dictionary contains mappings of all IANA
        character set names for which the Python core library provides
        codecs. In addition to these, a few Python specific codec
        aliases have also been added.

646ansi_x3.4_1968ansi_x3_4_1968ansi_x3.4_1986cp367csasciiibm367iso646_usiso_646.irv_1991iso_ir_6usus_asciibase64_codecbase_64big5big5_twcsbig5big5hkscsbig5_hkscshkscsbz2_codeccp037037csibm037ebcdic_cp_caebcdic_cp_nlebcdic_cp_usebcdic_cp_wtibm037ibm039cp10261026csibm1026ibm1026cp11251125ibm1125cp866urusciicp11401140ibm1140cp12501250windows_1250cp12511251windows_1251cp12521252windows_1252cp12531253windows_1253cp12541254windows_1254cp12551255windows_1255cp12561256windows_1256cp12571257windows_1257cp12581258windows_1258cp273273ibm273csibm273cp424csibm424ebcdic_cp_heibm424cp437437cspc8codepage437ibm437cp500csibm500ebcdic_cp_beebcdic_cp_chibm500cp775775cspc775balticibm775cp850850cspc850multilingualibm850cp852852cspcp852ibm852cp855855csibm855ibm855cp857857csibm857ibm857cp858858csibm858ibm858cp860860csibm860ibm860cp861861cp_iscsibm861ibm861cp862862cspc862latinhebrewibm862cp863863csibm863ibm863cp864864csibm864ibm864cp865865csibm865ibm865cp866866csibm866ibm866cp869869cp_grcsibm869ibm869cp932932ms932mskanjims_kanjicp949949ms949uhccp950950ms950euc_jis_2004jisx0213eucjis2004euc_jis2004euc_jisx0213eucjisx0213euc_jpeucjpujisu_jiseuc_kreuckrkoreanksc5601ks_c_5601ks_c_5601_1987ksx1001ks_x_1001gb18030gb18030_2000gb2312chinesecsiso58gb231280euc_cneuccneucgb2312_cngb2312_1980gb2312_80iso_ir_58gbk936cp936ms936hex_codechp_roman8roman8r8csHPRoman8cp1051ibm1051hzhzgbhz_gbhz_gb_2312iso2022_jpcsiso2022jpiso2022jpiso_2022_jpiso2022_jp_1iso2022jp_1iso_2022_jp_1iso2022_jp_2iso2022jp_2iso_2022_jp_2iso2022_jp_2004iso_2022_jp_2004iso2022jp_2004iso2022_jp_3iso2022jp_3iso_2022_jp_3iso2022_jp_extiso2022jp_extiso_2022_jp_extiso2022_krcsiso2022kriso2022kriso_2022_kriso8859_10csisolatin6iso_8859_10iso_8859_10_1992iso_ir_157l6latin6iso8859_11thaiiso_8859_11iso_8859_11_2001iso8859_13iso_8859_13l7latin7iso8859_14iso_8859_14iso_8859_14_1998iso_celticiso_ir_199l8latin8iso8859_15iso_8859_15l9latin9iso8859_16iso_8859_16iso_8859_16_2001iso_ir_226l10latin10iso8859_2csisolatin2iso_8859_2iso_8859_2_1987iso_ir_101l2latin2iso8859_3csisolatin3iso_8859_3iso_8859_3_1988iso_ir_109l3latin3iso8859_4csisolatin4iso_8859_4iso_8859_4_1988iso_ir_110l4latin4iso8859_5csisolatincyrilliccyrilliciso_8859_5iso_8859_5_1988iso_ir_144iso8859_6arabicasmo_708csisolatinarabicecma_114iso_8859_6iso_8859_6_1987iso_ir_127iso8859_7csisolatingreekecma_118elot_928greekgreek8iso_8859_7iso_8859_7_1987iso_ir_126iso8859_8csisolatinhebrewhebrewiso_8859_8iso_8859_8_1988iso_ir_138iso8859_9csisolatin5iso_8859_9iso_8859_9_1989iso_ir_148l5latin5johabcp1361ms1361koi8_rcskoi8rkz1048kz_1048rk1048strk1048_2002latin_18859cp819csisolatin1ibm819iso8859iso8859_1iso_8859_1iso_8859_1_1987iso_ir_100l1latinlatin1mac_cyrillicmaccyrillicmac_greekmacgreekmac_icelandmacicelandmac_latin2maccentraleuropemac_centeuromaclatin2mac_romanmacintoshmacromanmac_turkishmacturkishansidbcsptcp154csptcp154pt154cp154cyrillic_asianquopri_codecquopriquoted_printablequotedprintablerot_13rot13shift_jiscsshiftjisshiftjissjiss_jisshift_jis_2004shiftjis2004sjis_2004s_jis_2004shift_jisx0213shiftjisx0213sjisx0213s_jisx0213tis_620tis620tis_620_0tis_620_2529_0tis_620_2529_1iso_ir_166utf_16u16utf16utf_16_beunicodebigunmarkedutf_16beutf_16_leunicodelittleunmarkedutf_16leutf_32u32utf32utf_32_beutf_32beutf_32_leutf_32leutf_7u7utf7unicode_1_1_utf_7utf_8u8utfutf8_ucs2utf8_ucs4uu_codecuuzlib_codecx_mac_japanesex_mac_koreanx_mac_simp_chinesex_mac_trad_chinese# Please keep this list sorted alphabetically by value !# ascii codec# some email headers use this non-standard name# base64_codec codec# big5 codec# big5hkscs codec# bz2_codec codec# cp037 codec# cp1026 codec# cp1125 codec# cp1140 codec# cp1250 codec# cp1251 codec# cp1252 codec# cp1253 codec# cp1254 codec# cp1255 codec# cp1256 codec# cp1257 codec# cp1258 codec# cp273 codec# cp424 codec# cp437 codec# cp500 codec# cp775 codec# cp850 codec# cp852 codec# cp855 codec# cp857 codec# cp858 codec# cp860 codec# cp861 codec# cp862 codec# cp863 codec# cp864 codec# cp865 codec# cp866 codec# cp869 codec# cp932 codec# cp949 codec# cp950 codec# euc_jis_2004 codec# euc_jisx0213 codec# euc_jp codec# euc_kr codec# gb18030 codec# gb2312 codec# gbk codec# hex_codec codec# hp_roman8 codec# hz codec# iso2022_jp codec# iso2022_jp_1 codec# iso2022_jp_2 codec# iso2022_jp_2004 codec# iso2022_jp_3 codec# iso2022_jp_ext codec# iso2022_kr codec# iso8859_10 codec# iso8859_11 codec# iso8859_13 codec# iso8859_14 codec# iso8859_15 codec# iso8859_16 codec# iso8859_2 codec# iso8859_3 codec# iso8859_4 codec# iso8859_5 codec# iso8859_6 codec# iso8859_7 codec# iso8859_8 codec# iso8859_9 codec# johab codec# koi8_r codec# kz1048 codec# latin_1 codec# Note that the latin_1 codec is implemented internally in C and a# lot faster than the charmap codec iso8859_1 which uses the same# encoding. This is why we discourage the use of the iso8859_1# codec and alias it to latin_1 instead.# mac_cyrillic codec# mac_greek codec# mac_iceland codec# mac_latin2 codec# mac_roman codec# mac_turkish codec# mbcs codec# ptcp154 codec# quopri_codec codec# rot_13 codec# shift_jis codec# shift_jis_2004 codec# shift_jisx0213 codec# tis_620 codec# utf_16 codec# utf_16_be codec# utf_16_le codec# utf_32 codec# utf_32_be codec# utf_32_le codec# utf_7 codec# utf_8 codec# uu_codec codec# zlib_codec codec# temporary mac CJK aliases, will be replaced by proper codecs in 3.1b' Encoding Aliases Support

    This module is used by the encodings package search function to
    map encodings names to module names.

    Note that the search function normalizes the encoding names before
    doing the lookup, so the mapping will have to map normalized
    encoding names to module names.

    Contents:

        The following aliases dictionary contains mappings of all IANA
        character set names for which the Python core library provides
        codecs. In addition to these, a few Python specific codec
        aliases have also been added.

'u' Encoding Aliases Support

    This module is used by the encodings package search function to
    map encodings names to module names.

    Note that the search function normalizes the encoding names before
    doing the lookup, so the mapping will have to map normalized
    encoding names to module names.

    Contents:

        The following aliases dictionary contains mappings of all IANA
        character set names for which the Python core library provides
        codecs. In addition to these, a few Python specific codec
        aliases have also been added.

'b'646'u'646'b'ansi_x3.4_1968'u'ansi_x3.4_1968'b'ansi_x3_4_1968'u'ansi_x3_4_1968'b'ansi_x3.4_1986'u'ansi_x3.4_1986'b'cp367'u'cp367'b'csascii'u'csascii'b'ibm367'u'ibm367'b'iso646_us'u'iso646_us'b'iso_646.irv_1991'u'iso_646.irv_1991'b'iso_ir_6'u'iso_ir_6'b'us'u'us'b'us_ascii'u'us_ascii'b'base64_codec'u'base64_codec'b'base64'u'base64'b'base_64'u'base_64'b'big5'u'big5'b'big5_tw'u'big5_tw'b'csbig5'u'csbig5'b'big5hkscs'u'big5hkscs'b'big5_hkscs'u'big5_hkscs'b'hkscs'u'hkscs'b'bz2_codec'u'bz2_codec'b'cp037'u'cp037'b'037'u'037'b'csibm037'u'csibm037'b'ebcdic_cp_ca'u'ebcdic_cp_ca'b'ebcdic_cp_nl'u'ebcdic_cp_nl'b'ebcdic_cp_us'u'ebcdic_cp_us'b'ebcdic_cp_wt'u'ebcdic_cp_wt'b'ibm037'u'ibm037'b'ibm039'u'ibm039'b'cp1026'u'cp1026'b'1026'u'1026'b'csibm1026'u'csibm1026'b'ibm1026'u'ibm1026'b'cp1125'u'cp1125'b'1125'u'1125'b'ibm1125'u'ibm1125'b'cp866u'u'cp866u'b'ruscii'u'ruscii'b'cp1140'u'cp1140'b'1140'u'1140'b'ibm1140'u'ibm1140'b'cp1250'u'cp1250'b'1250'u'1250'b'windows_1250'u'windows_1250'b'cp1251'u'cp1251'b'1251'u'1251'b'windows_1251'u'windows_1251'b'cp1252'u'cp1252'b'1252'u'1252'b'windows_1252'u'windows_1252'b'cp1253'u'cp1253'b'1253'u'1253'b'windows_1253'u'windows_1253'b'cp1254'u'cp1254'b'1254'u'1254'b'windows_1254'u'windows_1254'b'cp1255'u'cp1255'b'1255'u'1255'b'windows_1255'u'windows_1255'b'cp1256'u'cp1256'b'1256'u'1256'b'windows_1256'u'windows_1256'b'cp1257'u'cp1257'b'1257'u'1257'b'windows_1257'u'windows_1257'b'cp1258'u'cp1258'b'1258'u'1258'b'windows_1258'u'windows_1258'b'cp273'u'cp273'b'273'u'273'b'ibm273'u'ibm273'b'csibm273'u'csibm273'b'cp424'u'cp424'b'424'u'424'b'csibm424'u'csibm424'b'ebcdic_cp_he'u'ebcdic_cp_he'b'ibm424'u'ibm424'b'cp437'u'cp437'b'437'u'437'b'cspc8codepage437'u'cspc8codepage437'b'ibm437'u'ibm437'b'cp500'u'cp500'b'500'u'500'b'csibm500'u'csibm500'b'ebcdic_cp_be'u'ebcdic_cp_be'b'ebcdic_cp_ch'u'ebcdic_cp_ch'b'ibm500'u'ibm500'b'cp775'u'cp775'b'775'u'775'b'cspc775baltic'u'cspc775baltic'b'ibm775'u'ibm775'b'cp850'u'cp850'b'850'u'850'b'cspc850multilingual'u'cspc850multilingual'b'ibm850'u'ibm850'b'cp852'u'cp852'b'852'u'852'b'cspcp852'u'cspcp852'b'ibm852'u'ibm852'b'cp855'u'cp855'b'855'u'855'b'csibm855'u'csibm855'b'ibm855'u'ibm855'b'cp857'u'cp857'b'857'u'857'b'csibm857'u'csibm857'b'ibm857'u'ibm857'b'cp858'u'cp858'b'858'u'858'b'csibm858'u'csibm858'b'ibm858'u'ibm858'b'cp860'u'cp860'b'860'u'860'b'csibm860'u'csibm860'b'ibm860'u'ibm860'b'cp861'u'cp861'b'861'u'861'b'cp_is'u'cp_is'b'csibm861'u'csibm861'b'ibm861'u'ibm861'b'cp862'u'cp862'b'862'u'862'b'cspc862latinhebrew'u'cspc862latinhebrew'b'ibm862'u'ibm862'b'cp863'u'cp863'b'863'u'863'b'csibm863'u'csibm863'b'ibm863'u'ibm863'b'cp864'u'cp864'b'864'u'864'b'csibm864'u'csibm864'b'ibm864'u'ibm864'b'cp865'u'cp865'b'865'u'865'b'csibm865'u'csibm865'b'ibm865'u'ibm865'b'cp866'u'cp866'b'866'u'866'b'csibm866'u'csibm866'b'ibm866'u'ibm866'b'cp869'u'cp869'b'869'u'869'b'cp_gr'u'cp_gr'b'csibm869'u'csibm869'b'ibm869'u'ibm869'b'cp932'u'cp932'b'932'u'932'b'ms932'u'ms932'b'mskanji'u'mskanji'b'ms_kanji'u'ms_kanji'b'cp949'u'cp949'b'949'u'949'b'ms949'u'ms949'b'uhc'u'uhc'b'cp950'u'cp950'b'950'u'950'b'ms950'u'ms950'b'euc_jis_2004'u'euc_jis_2004'b'jisx0213'u'jisx0213'b'eucjis2004'u'eucjis2004'b'euc_jis2004'u'euc_jis2004'b'euc_jisx0213'u'euc_jisx0213'b'eucjisx0213'u'eucjisx0213'b'euc_jp'u'euc_jp'b'eucjp'u'eucjp'b'ujis'u'ujis'b'u_jis'u'u_jis'b'euc_kr'u'euc_kr'b'euckr'u'euckr'b'korean'u'korean'b'ksc5601'u'ksc5601'b'ks_c_5601'u'ks_c_5601'b'ks_c_5601_1987'u'ks_c_5601_1987'b'ksx1001'u'ksx1001'b'ks_x_1001'u'ks_x_1001'b'gb18030'u'gb18030'b'gb18030_2000'u'gb18030_2000'b'gb2312'u'gb2312'b'chinese'u'chinese'b'csiso58gb231280'u'csiso58gb231280'b'euc_cn'u'euc_cn'b'euccn'u'euccn'b'eucgb2312_cn'u'eucgb2312_cn'b'gb2312_1980'u'gb2312_1980'b'gb2312_80'u'gb2312_80'b'iso_ir_58'u'iso_ir_58'b'gbk'u'gbk'b'936'u'936'b'cp936'u'cp936'b'ms936'u'ms936'b'hex_codec'u'hex_codec'b'hex'u'hex'b'hp_roman8'u'hp_roman8'b'roman8'u'roman8'b'r8'u'r8'b'csHPRoman8'u'csHPRoman8'b'cp1051'u'cp1051'b'ibm1051'u'ibm1051'b'hz'u'hz'b'hzgb'u'hzgb'b'hz_gb'u'hz_gb'b'hz_gb_2312'u'hz_gb_2312'b'iso2022_jp'u'iso2022_jp'b'csiso2022jp'u'csiso2022jp'b'iso2022jp'u'iso2022jp'b'iso_2022_jp'u'iso_2022_jp'b'iso2022_jp_1'u'iso2022_jp_1'b'iso2022jp_1'u'iso2022jp_1'b'iso_2022_jp_1'u'iso_2022_jp_1'b'iso2022_jp_2'u'iso2022_jp_2'b'iso2022jp_2'u'iso2022jp_2'b'iso_2022_jp_2'u'iso_2022_jp_2'b'iso2022_jp_2004'u'iso2022_jp_2004'b'iso_2022_jp_2004'u'iso_2022_jp_2004'b'iso2022jp_2004'u'iso2022jp_2004'b'iso2022_jp_3'u'iso2022_jp_3'b'iso2022jp_3'u'iso2022jp_3'b'iso_2022_jp_3'u'iso_2022_jp_3'b'iso2022_jp_ext'u'iso2022_jp_ext'b'iso2022jp_ext'u'iso2022jp_ext'b'iso_2022_jp_ext'u'iso_2022_jp_ext'b'iso2022_kr'u'iso2022_kr'b'csiso2022kr'u'csiso2022kr'b'iso2022kr'u'iso2022kr'b'iso_2022_kr'u'iso_2022_kr'b'iso8859_10'u'iso8859_10'b'csisolatin6'u'csisolatin6'b'iso_8859_10'u'iso_8859_10'b'iso_8859_10_1992'u'iso_8859_10_1992'b'iso_ir_157'u'iso_ir_157'b'l6'u'l6'b'latin6'u'latin6'b'iso8859_11'u'iso8859_11'b'thai'u'thai'b'iso_8859_11'u'iso_8859_11'b'iso_8859_11_2001'u'iso_8859_11_2001'b'iso8859_13'u'iso8859_13'b'iso_8859_13'u'iso_8859_13'b'l7'u'l7'b'latin7'u'latin7'b'iso8859_14'u'iso8859_14'b'iso_8859_14'u'iso_8859_14'b'iso_8859_14_1998'u'iso_8859_14_1998'b'iso_celtic'u'iso_celtic'b'iso_ir_199'u'iso_ir_199'b'l8'u'l8'b'latin8'u'latin8'b'iso8859_15'u'iso8859_15'b'iso_8859_15'u'iso_8859_15'b'l9'u'l9'b'latin9'u'latin9'b'iso8859_16'u'iso8859_16'b'iso_8859_16'u'iso_8859_16'b'iso_8859_16_2001'u'iso_8859_16_2001'b'iso_ir_226'u'iso_ir_226'b'l10'u'l10'b'latin10'u'latin10'b'iso8859_2'u'iso8859_2'b'csisolatin2'u'csisolatin2'b'iso_8859_2'u'iso_8859_2'b'iso_8859_2_1987'u'iso_8859_2_1987'b'iso_ir_101'u'iso_ir_101'b'l2'u'l2'b'latin2'u'latin2'b'iso8859_3'u'iso8859_3'b'csisolatin3'u'csisolatin3'b'iso_8859_3'u'iso_8859_3'b'iso_8859_3_1988'u'iso_8859_3_1988'b'iso_ir_109'u'iso_ir_109'b'l3'u'l3'b'latin3'u'latin3'b'iso8859_4'u'iso8859_4'b'csisolatin4'u'csisolatin4'b'iso_8859_4'u'iso_8859_4'b'iso_8859_4_1988'u'iso_8859_4_1988'b'iso_ir_110'u'iso_ir_110'b'l4'u'l4'b'latin4'u'latin4'b'iso8859_5'u'iso8859_5'b'csisolatincyrillic'u'csisolatincyrillic'b'cyrillic'u'cyrillic'b'iso_8859_5'u'iso_8859_5'b'iso_8859_5_1988'u'iso_8859_5_1988'b'iso_ir_144'u'iso_ir_144'b'iso8859_6'u'iso8859_6'b'arabic'u'arabic'b'asmo_708'u'asmo_708'b'csisolatinarabic'u'csisolatinarabic'b'ecma_114'u'ecma_114'b'iso_8859_6'u'iso_8859_6'b'iso_8859_6_1987'u'iso_8859_6_1987'b'iso_ir_127'u'iso_ir_127'b'iso8859_7'u'iso8859_7'b'csisolatingreek'u'csisolatingreek'b'ecma_118'u'ecma_118'b'elot_928'u'elot_928'b'greek'u'greek'b'greek8'u'greek8'b'iso_8859_7'u'iso_8859_7'b'iso_8859_7_1987'u'iso_8859_7_1987'b'iso_ir_126'u'iso_ir_126'b'iso8859_8'u'iso8859_8'b'csisolatinhebrew'u'csisolatinhebrew'b'hebrew'u'hebrew'b'iso_8859_8'u'iso_8859_8'b'iso_8859_8_1988'u'iso_8859_8_1988'b'iso_ir_138'u'iso_ir_138'b'iso8859_9'u'iso8859_9'b'csisolatin5'u'csisolatin5'b'iso_8859_9'u'iso_8859_9'b'iso_8859_9_1989'u'iso_8859_9_1989'b'iso_ir_148'u'iso_ir_148'b'l5'u'l5'b'latin5'u'latin5'b'johab'u'johab'b'cp1361'u'cp1361'b'ms1361'u'ms1361'b'koi8_r'u'koi8_r'b'cskoi8r'u'cskoi8r'b'kz1048'u'kz1048'b'kz_1048'u'kz_1048'b'rk1048'u'rk1048'b'strk1048_2002'u'strk1048_2002'b'latin_1'u'latin_1'b'8859'u'8859'b'cp819'u'cp819'b'csisolatin1'u'csisolatin1'b'ibm819'u'ibm819'b'iso8859'u'iso8859'b'iso8859_1'u'iso8859_1'b'iso_8859_1'u'iso_8859_1'b'iso_8859_1_1987'u'iso_8859_1_1987'b'iso_ir_100'u'iso_ir_100'b'l1'u'l1'b'latin'u'latin'b'latin1'u'latin1'b'mac_cyrillic'u'mac_cyrillic'b'maccyrillic'u'maccyrillic'b'mac_greek'u'mac_greek'b'macgreek'u'macgreek'b'mac_iceland'u'mac_iceland'b'maciceland'u'maciceland'b'mac_latin2'u'mac_latin2'b'maccentraleurope'u'maccentraleurope'b'mac_centeuro'u'mac_centeuro'b'maclatin2'u'maclatin2'b'mac_roman'u'mac_roman'b'macintosh'u'macintosh'b'macroman'u'macroman'b'mac_turkish'u'mac_turkish'b'macturkish'u'macturkish'b'mbcs'u'mbcs'b'ansi'u'ansi'b'dbcs'u'dbcs'b'ptcp154'u'ptcp154'b'csptcp154'u'csptcp154'b'pt154'u'pt154'b'cp154'u'cp154'b'cyrillic_asian'u'cyrillic_asian'b'quopri_codec'u'quopri_codec'b'quopri'u'quopri'b'quoted_printable'u'quoted_printable'b'quotedprintable'u'quotedprintable'b'rot_13'u'rot_13'b'rot13'u'rot13'b'shift_jis'u'shift_jis'b'csshiftjis'u'csshiftjis'b'shiftjis'u'shiftjis'b'sjis'u'sjis'b's_jis'u's_jis'b'shift_jis_2004'u'shift_jis_2004'b'shiftjis2004'u'shiftjis2004'b'sjis_2004'u'sjis_2004'b's_jis_2004'u's_jis_2004'b'shift_jisx0213'u'shift_jisx0213'b'shiftjisx0213'u'shiftjisx0213'b'sjisx0213'u'sjisx0213'b's_jisx0213'u's_jisx0213'b'tis_620'u'tis_620'b'tis620'u'tis620'b'tis_620_0'u'tis_620_0'b'tis_620_2529_0'u'tis_620_2529_0'b'tis_620_2529_1'u'tis_620_2529_1'b'iso_ir_166'u'iso_ir_166'b'utf_16'u'utf_16'b'u16'u'u16'b'utf16'u'utf16'b'utf_16_be'u'utf_16_be'b'unicodebigunmarked'u'unicodebigunmarked'b'utf_16be'u'utf_16be'b'utf_16_le'u'utf_16_le'b'unicodelittleunmarked'u'unicodelittleunmarked'b'utf_16le'u'utf_16le'b'utf_32'u'utf_32'b'u32'u'u32'b'utf32'u'utf32'b'utf_32_be'u'utf_32_be'b'utf_32be'u'utf_32be'b'utf_32_le'u'utf_32_le'b'utf_32le'u'utf_32le'b'utf_7'u'utf_7'b'u7'u'u7'b'utf7'u'utf7'b'unicode_1_1_utf_7'u'unicode_1_1_utf_7'b'utf_8'u'utf_8'b'u8'u'u8'b'utf'u'utf'b'utf8'u'utf8'b'utf8_ucs2'u'utf8_ucs2'b'utf8_ucs4'u'utf8_ucs4'b'uu_codec'u'uu_codec'b'uu'u'uu'b'zlib_codec'u'zlib_codec'b'zlib'u'zlib'b'x_mac_japanese'u'x_mac_japanese'b'x_mac_korean'u'x_mac_korean'b'x_mac_simp_chinese'u'x_mac_simp_chinese'b'x_mac_trad_chinese'u'x_mac_trad_chinese'u'encodings.aliases'u'aliases'cdcoherence_ratioencoding_languagesmb_encoding_languagesmerge_coherence_ratiosconstantIANA_SUPPORTEDTOO_BIG_SEQUENCETOO_SMALL_SEQUENCETRACEmdmess_ratioany_specified_encodingcut_sequence_chunksiana_nameidentify_sig_or_bomis_cp_similaris_multi_byte_encodingshould_strip_sig_or_bomexplain_handler%(asctime)s | %(levelname)s | %(message)s0.2stepschunk_sizethresholdcp_isolationcp_exclusionpreemptive_behaviourexplainlanguage_threshold
    Given a raw bytes sequence, return the best possibles charset usable to render str objects.
    If there is no results, it is a strong indicator that the source is binary/not text.
    By default, the process will extract 5 blocks of 512o each to assess the mess and coherence of a given sequence.
    And will give up a particular code page after 20% of measured mess. Those criteria are customizable at will.

    The preemptive behavior DOES NOT replace the traditional detection workflow, it prioritize a particular code page
    but never take it for granted. Can improve the performance.

    You may want to focus your attention to some code page or/and not others, use cp_isolation and cp_exclusion for that
    purpose.

    This function will strip the SIG in the payload/sequence every time except on UTF-16, UTF-32.
    By default the library does not setup any handler other than the NullHandler, if you choose to set the 'explain'
    toggle to True it will alter the logger configuration to add a StreamHandler that is suitable for debugging.
    Custom logging format and handler can be set manually.
    Expected object of type bytes or bytearray, got: {0}previous_logger_levellengthEncoding detection on empty bytes, assuming utf_8 intention.cp_isolation is set. use this flag for debugging purpose. limited list of encoding allowed : %s."cp_isolation is set. use this flag for debugging purpose. ""limited list of encoding allowed : %s."cpcp_exclusion is set. use this flag for debugging purpose. limited list of encoding excluded : %s."cp_exclusion is set. use this flag for debugging purpose. ""limited list of encoding excluded : %s."override steps (%i) and chunk_size (%i) as content does not fit (%i byte(s) given) parameters.is_too_small_sequenceis_too_large_sequenceTrying to detect encoding from a tiny portion of ({}) byte(s).Using lazy str decoding because the payload is quite large, ({}) byte(s).prioritized_encodingsspecified_encodingDetected declarative mark in sequence. Priority +1 given for %s.testedtested_but_hard_failuretested_but_soft_failurefallback_asciifallback_u8fallback_specifiedresultssig_encodingsig_payloadDetected a SIG or BOM mark on first %i byte(s). Priority +1 given for %s.encoding_ianadecoded_payloadbom_or_sig_availablestrip_sig_or_bomEncoding %s won't be tested as-is because it require a BOM. Will try some sub-encoder LE/BE.Encoding %s won't be tested as-is because detection is unreliable without BOM/SIG.is_multi_byte_decoderEncoding %s does not provide an IncrementalDecoder500000.050e4Code page %s does not fit given bytes sequence at ALL. %ssimilar_soft_failure_testencoding_soft_failed%s is deemed too similar to code page %s and was consider unsuited already. Continuing!r_multi_byte_bonusCode page %s is a multi byte encoding table and it appear that at least one character was encoded using n-bytes."Code page %s is a multi byte encoding table and it appear that at least one character ""was encoded using n-bytes."max_chunk_gave_upearly_stop_countlazy_str_hard_failuremd_chunksmd_ratiosLazyStr Loading: After MD chunk decode, code page %s does not fit given bytes sequence at ALL. %s50000.050e3LazyStr Loading: After final lookup, code page %s does not fit given bytes sequence at ALL. %smean_mess_ratio%s was excluded because of initial chaos probing. Gave up %i time(s). Computed mean chaos is %f %%."%s was excluded because of initial chaos probing. Gave up %i time(s). ""Computed mean chaos is %f %%."ndigitsfallback_entry%s passed initial chaos probing. Mean measured chaos is %f %%target_languages{} should target any language(s) of {}cd_ratioschunk_languagescd_ratios_mergedWe detected language {} using {}Encoding detection: %s is most likely the one.Encoding detection: %s is most likely the one as we detected a BOM or SIG within the beginning of the sequence."Encoding detection: %s is most likely the one as we detected a BOM or SIG within ""the beginning of the sequence."Nothing got out of the detection process. Using ASCII/UTF-8/Specified fallback.Encoding detection: %s will be used as a fallback matchfingerprintEncoding detection: utf_8 will be used as a fallback matchEncoding detection: ascii will be used as a fallback matchEncoding detection: Found %s as plausible (best-candidate) for content. With %i alternatives.bestEncoding detection: Unable to determine any suitable charset.0.20
    Same thing than the function from_bytes but using a file pointer that is already ready.
    Will not close the file pointer.
    PathLike[Any]
    Same thing than the function from_bytes but with one extra step. Opening and reading given file path in binary mode.
    Can raise IOError.
    # Will most likely be controversial# logging.addLevelName(TRACE, "TRACE")# Lazy str loading may have missed something there# We might want to check the sequence again with the whole content# Only if initial MD tests passes# Preparing those fallbacks in case we got nothing.# We shall skip the CD when its about ASCII# Most of the time its not relevant to run "language-detection" on it.b'%(asctime)s | %(levelname)s | %(message)s'u'%(asctime)s | %(levelname)s | %(message)s'b'
    Given a raw bytes sequence, return the best possibles charset usable to render str objects.
    If there is no results, it is a strong indicator that the source is binary/not text.
    By default, the process will extract 5 blocks of 512o each to assess the mess and coherence of a given sequence.
    And will give up a particular code page after 20% of measured mess. Those criteria are customizable at will.

    The preemptive behavior DOES NOT replace the traditional detection workflow, it prioritize a particular code page
    but never take it for granted. Can improve the performance.

    You may want to focus your attention to some code page or/and not others, use cp_isolation and cp_exclusion for that
    purpose.

    This function will strip the SIG in the payload/sequence every time except on UTF-16, UTF-32.
    By default the library does not setup any handler other than the NullHandler, if you choose to set the 'explain'
    toggle to True it will alter the logger configuration to add a StreamHandler that is suitable for debugging.
    Custom logging format and handler can be set manually.
    'u'
    Given a raw bytes sequence, return the best possibles charset usable to render str objects.
    If there is no results, it is a strong indicator that the source is binary/not text.
    By default, the process will extract 5 blocks of 512o each to assess the mess and coherence of a given sequence.
    And will give up a particular code page after 20% of measured mess. Those criteria are customizable at will.

    The preemptive behavior DOES NOT replace the traditional detection workflow, it prioritize a particular code page
    but never take it for granted. Can improve the performance.

    You may want to focus your attention to some code page or/and not others, use cp_isolation and cp_exclusion for that
    purpose.

    This function will strip the SIG in the payload/sequence every time except on UTF-16, UTF-32.
    By default the library does not setup any handler other than the NullHandler, if you choose to set the 'explain'
    toggle to True it will alter the logger configuration to add a StreamHandler that is suitable for debugging.
    Custom logging format and handler can be set manually.
    'b'Expected object of type bytes or bytearray, got: {0}'u'Expected object of type bytes or bytearray, got: {0}'b'Encoding detection on empty bytes, assuming utf_8 intention.'u'Encoding detection on empty bytes, assuming utf_8 intention.'b'cp_isolation is set. use this flag for debugging purpose. limited list of encoding allowed : %s.'u'cp_isolation is set. use this flag for debugging purpose. limited list of encoding allowed : %s.'b'cp_exclusion is set. use this flag for debugging purpose. limited list of encoding excluded : %s.'u'cp_exclusion is set. use this flag for debugging purpose. limited list of encoding excluded : %s.'b'override steps (%i) and chunk_size (%i) as content does not fit (%i byte(s) given) parameters.'u'override steps (%i) and chunk_size (%i) as content does not fit (%i byte(s) given) parameters.'b'Trying to detect encoding from a tiny portion of ({}) byte(s).'u'Trying to detect encoding from a tiny portion of ({}) byte(s).'b'Using lazy str decoding because the payload is quite large, ({}) byte(s).'u'Using lazy str decoding because the payload is quite large, ({}) byte(s).'b'Detected declarative mark in sequence. Priority +1 given for %s.'u'Detected declarative mark in sequence. Priority +1 given for %s.'b'Detected a SIG or BOM mark on first %i byte(s). Priority +1 given for %s.'u'Detected a SIG or BOM mark on first %i byte(s). Priority +1 given for %s.'b'Encoding %s won't be tested as-is because it require a BOM. Will try some sub-encoder LE/BE.'u'Encoding %s won't be tested as-is because it require a BOM. Will try some sub-encoder LE/BE.'b'Encoding %s won't be tested as-is because detection is unreliable without BOM/SIG.'u'Encoding %s won't be tested as-is because detection is unreliable without BOM/SIG.'b'Encoding %s does not provide an IncrementalDecoder'u'Encoding %s does not provide an IncrementalDecoder'b'Code page %s does not fit given bytes sequence at ALL. %s'u'Code page %s does not fit given bytes sequence at ALL. %s'b'%s is deemed too similar to code page %s and was consider unsuited already. Continuing!'u'%s is deemed too similar to code page %s and was consider unsuited already. Continuing!'b'Code page %s is a multi byte encoding table and it appear that at least one character was encoded using n-bytes.'u'Code page %s is a multi byte encoding table and it appear that at least one character was encoded using n-bytes.'b'LazyStr Loading: After MD chunk decode, code page %s does not fit given bytes sequence at ALL. %s'u'LazyStr Loading: After MD chunk decode, code page %s does not fit given bytes sequence at ALL. %s'b'LazyStr Loading: After final lookup, code page %s does not fit given bytes sequence at ALL. %s'u'LazyStr Loading: After final lookup, code page %s does not fit given bytes sequence at ALL. %s'b'%s was excluded because of initial chaos probing. Gave up %i time(s). Computed mean chaos is %f %%.'u'%s was excluded because of initial chaos probing. Gave up %i time(s). Computed mean chaos is %f %%.'b'%s passed initial chaos probing. Mean measured chaos is %f %%'u'%s passed initial chaos probing. Mean measured chaos is %f %%'b'{} should target any language(s) of {}'u'{} should target any language(s) of {}'b'We detected language {} using {}'u'We detected language {} using {}'b'Encoding detection: %s is most likely the one.'u'Encoding detection: %s is most likely the one.'b'Encoding detection: %s is most likely the one as we detected a BOM or SIG within the beginning of the sequence.'u'Encoding detection: %s is most likely the one as we detected a BOM or SIG within the beginning of the sequence.'b'Nothing got out of the detection process. Using ASCII/UTF-8/Specified fallback.'u'Nothing got out of the detection process. Using ASCII/UTF-8/Specified fallback.'b'Encoding detection: %s will be used as a fallback match'u'Encoding detection: %s will be used as a fallback match'b'Encoding detection: utf_8 will be used as a fallback match'u'Encoding detection: utf_8 will be used as a fallback match'b'Encoding detection: ascii will be used as a fallback match'u'Encoding detection: ascii will be used as a fallback match'b'Encoding detection: Found %s as plausible (best-candidate) for content. With %i alternatives.'u'Encoding detection: Found %s as plausible (best-candidate) for content. With %i alternatives.'b'Encoding detection: Unable to determine any suitable charset.'u'Encoding detection: Unable to determine any suitable charset.'b'
    Same thing than the function from_bytes but using a file pointer that is already ready.
    Will not close the file pointer.
    'u'
    Same thing than the function from_bytes but using a file pointer that is already ready.
    Will not close the file pointer.
    'b'PathLike[Any]'u'PathLike[Any]'b'
    Same thing than the function from_bytes but with one extra step. Opening and reading given file path in binary mode.
    Can raise IOError.
    'u'
    Same thing than the function from_bytes but with one extra step. Opening and reading given file path in binary mode.
    Can raise IOError.
    'u'charset_normalizer.api'u'api'
requests.api
~~~~~~~~~~~~

This module implements the Requests API.

:copyright: (c) 2012 by Kenneth Reitz.
:license: Apache2, see LICENSE for more details.
Constructs and sends a :class:`Request <Request>`.

    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
        to add for the file.
    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
    :param timeout: (optional) How many seconds to wait for the server to send data
        before giving up, as a float, or a :ref:`(connect timeout, read
        timeout) <timeouts>` tuple.
    :type timeout: float or tuple
    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
    :type allow_redirects: bool
    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
    :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
    :param stream: (optional) if ``False``, the response content will be immediately downloaded.
    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response

    Usage::

      >>> import requests
      >>> req = requests.request('GET', 'https://httpbin.org/get')
      >>> req
      <Response [200]>
    Sends a GET request.

    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    Sends an OPTIONS request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    Sends a HEAD request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes. If
        `allow_redirects` is not provided, it will be set to `False` (as
        opposed to the default :meth:`request` behavior).
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    allow_redirectsjsonSends a POST request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    Sends a PUT request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    Sends a PATCH request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    Sends a DELETE request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    # By using the 'with' statement we are sure the session is closed, thus we# avoid leaving sockets open which can trigger a ResourceWarning in some# cases, and look like a memory leak in others.b'
requests.api
~~~~~~~~~~~~

This module implements the Requests API.

:copyright: (c) 2012 by Kenneth Reitz.
:license: Apache2, see LICENSE for more details.
'u'
requests.api
~~~~~~~~~~~~

This module implements the Requests API.

:copyright: (c) 2012 by Kenneth Reitz.
:license: Apache2, see LICENSE for more details.
'b'Constructs and sends a :class:`Request <Request>`.

    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
        to add for the file.
    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
    :param timeout: (optional) How many seconds to wait for the server to send data
        before giving up, as a float, or a :ref:`(connect timeout, read
        timeout) <timeouts>` tuple.
    :type timeout: float or tuple
    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
    :type allow_redirects: bool
    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
    :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
    :param stream: (optional) if ``False``, the response content will be immediately downloaded.
    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response

    Usage::

      >>> import requests
      >>> req = requests.request('GET', 'https://httpbin.org/get')
      >>> req
      <Response [200]>
    'u'Constructs and sends a :class:`Request <Request>`.

    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
        to add for the file.
    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
    :param timeout: (optional) How many seconds to wait for the server to send data
        before giving up, as a float, or a :ref:`(connect timeout, read
        timeout) <timeouts>` tuple.
    :type timeout: float or tuple
    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
    :type allow_redirects: bool
    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
    :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
    :param stream: (optional) if ``False``, the response content will be immediately downloaded.
    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response

    Usage::

      >>> import requests
      >>> req = requests.request('GET', 'https://httpbin.org/get')
      >>> req
      <Response [200]>
    'b'Sends a GET request.

    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'u'Sends a GET request.

    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'b'Sends an OPTIONS request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'u'Sends an OPTIONS request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'b'options'u'options'b'Sends a HEAD request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes. If
        `allow_redirects` is not provided, it will be set to `False` (as
        opposed to the default :meth:`request` behavior).
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'u'Sends a HEAD request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes. If
        `allow_redirects` is not provided, it will be set to `False` (as
        opposed to the default :meth:`request` behavior).
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'b'allow_redirects'u'allow_redirects'b'head'u'head'b'Sends a POST request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'u'Sends a POST request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'b'Sends a PUT request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'u'Sends a PUT request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'b'Sends a PATCH request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'u'Sends a PATCH request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'b'patch'u'patch'b'Sends a DELETE request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'u'Sends a DELETE request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    'u'requests.api'Command-line parsing library

This module is an optparse-inspired command-line parsing library that:

    - handles both optional and positional arguments
    - produces highly informative usage messages
    - supports parsers that dispatch to sub-parsers

The following is a simple usage example that sums integers from the
command-line and writes the result to a file::

    parser = argparse.ArgumentParser(
        description='sum the integers at the command line')
    parser.add_argument(
        'integers', metavar='int', nargs='+', type=int,
        help='an integer to be summed')
    parser.add_argument(
        '--log', default=sys.stdout, type=argparse.FileType('w'),
        help='the file where the sum should be written')
    args = parser.parse_args()
    args.log.write('%s' % sum(args.integers))
    args.log.close()

The module contains the following public classes:

    - ArgumentParser -- The main entry point for command-line parsing. As the
        example above shows, the add_argument() method is used to populate
        the parser with actions for optional and positional arguments. Then
        the parse_args() method is invoked to convert the args at the
        command-line into an object with attributes.

    - ArgumentError -- The exception raised by ArgumentParser objects when
        there are errors with the parser's actions. Errors raised while
        parsing the command-line are caught by ArgumentParser and emitted
        as command-line messages.

    - FileType -- A factory for defining types of files to be created. As the
        example above shows, instances of FileType are typically passed as
        the type= argument of add_argument() calls.

    - Action -- The base class for parser actions. Typically actions are
        selected by passing strings like 'store_true' or 'append_const' to
        the action= argument of add_argument(). However, for greater
        customization of ArgumentParser actions, subclasses of Action may
        be defined and passed as the action= argument.

    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,
        ArgumentDefaultsHelpFormatter -- Formatter classes which
        may be passed as the formatter_class= argument to the
        ArgumentParser constructor. HelpFormatter is the default,
        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser
        not to change the formatting for help text, and
        ArgumentDefaultsHelpFormatter adds information about argument defaults
        to the help.

All other classes in this module are considered implementation details.
(Also note that HelpFormatter and RawDescriptionHelpFormatter are only
considered public as object names -- the API of the formatter objects is
still considered an implementation detail.)
1.1ArgumentParserArgumentTypeErrorBooleanOptionalActionFileTypeHelpFormatterArgumentDefaultsHelpFormatterRawDescriptionHelpFormatterRawTextHelpFormatterMetavarTypeHelpFormatterNamespaceONE_OR_MOREOPTIONALPARSERREMAINDERSUPPRESSZERO_OR_MOREgettextngettext==SUPPRESS==A..._unrecognized_args_UNRECOGNIZED_ARGS_ATTR_AttributeHolderAbstract base class that provides __repr__.

    The __repr__ method returns a string in the format::
        ClassName(attr=name, attr=name, ...)
    The attributes are determined either by a class-level attribute,
    '_kwarg_names', or by inspecting the instance __dict__.
    type_namearg_stringsstar_args_get_args_get_kwargs%s=%r**%s_copy_itemsFormatter for generating usage messages and argument help strings.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    progindent_incrementmax_help_positioncolumns_prog_indent_increment_max_help_position_width_current_indent_level_action_max_length_Section_root_section_current_section\s+_whitespace_matcher\n\n\n+_long_break_matcher_indent_dedentIndent decreased below 0.headingformat_help_join_partsitem_helpcurrent_indent%*s%s:
_add_itemstart_sectionend_sectionadd_text_format_textadd_usageusage_format_usageadd_argumenthelp_format_action_invocationget_invocationinvocationssubaction_iter_indented_subactionsinvocation_lengthaction_length_format_actionadd_arguments

part_stringsusage: %(prog)soptionalspositionalsoption_strings_format_actions_usageaction_usagetext_width\(.*?\)+(?=\s|$)|\[.*?\]+(?=\s|$)|\S+r'\(.*?\)+(?=\s|$)|'r'\[.*?\]+(?=\s|$)|'r'\S+'part_regexpopt_usagepos_usageopt_partspos_partsget_linesline_len0.75%s%s

group_actionsinserts_group_actionsempty group  [_get_default_metavar_for_positional_format_argsoption_stringnargsformat_usage_get_default_metavar_for_optionalargs_string%s %s[\[(][\])](%s)  (%s)%s *%s\(([^|]*)\)%(prog)_fill_texthelp_positionhelp_widthaction_widthaction_headertup%*s%s
%*s%-*s  indent_first_expand_helphelp_text_split_lineshelp_lines_metavar_formattermetavardefault_metavarchoiceschoicechoice_strstuple_sizeget_metavar[%s [%s ...]][%s ...]%s [%s ...]%s ...formatsinvalid nargs valuechoices_str_get_help_string_get_subactionsget_subactionstextwrapwrapinitial_indentsubsequent_indentdestHelp message formatter which retains any formatting in descriptions.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    Help message formatter which retains formatting of all help text.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    Help message formatter which adds default values to argument help.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    %(default)defaulting_nargs (default: %(default)s)Help message formatter which uses the argument 'type' as the default
    metavar value (instead of the argument 'dest')

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    _get_action_nameargumentAn error from creating or using an argument (optional or positional).

    The string value of this exception is the message, augmented with
    information about the argument that caused it.
    argument_nameargument %(argument_name)s: %(message)sAn error from trying to convert a command line string to a type.Information about how to convert command line strings to Python objects.

    Action objects are used by an ArgumentParser to represent the information
    needed to parse a single argument from one or more strings from the
    command line. The keyword arguments to the Action constructor are also
    all attributes of Action instances.

    Keyword Arguments:

        - option_strings -- A list of command-line option strings which
            should be associated with this action.

        - dest -- The name of the attribute to hold the created object(s)

        - nargs -- The number of command-line arguments that should be
            consumed. By default, one argument will be consumed and a single
            value will be produced.  Other values include:
                - N (an integer) consumes N arguments (and produces a list)
                - '?' consumes zero or one arguments
                - '*' consumes zero or more arguments (and produces a list)
                - '+' consumes one or more arguments (and produces a list)
            Note that the difference between the default and nargs=1 is that
            with the default, a single value will be produced, while with
            nargs=1, a list containing a single value will be produced.

        - const -- The value to be produced if the option is specified and the
            option uses an action that takes no values.

        - default -- The value to be produced if the option is not specified.

        - type -- A callable that accepts a single string argument, and
            returns the converted value.  The standard Python types str, int,
            float, and complex are useful examples of such callables.  If None,
            str is used.

        - choices -- A container of values that should be allowed. If not None,
            after a command-line argument has been converted to the appropriate
            type, an exception will be raised if it is not a member of this
            collection.

        - required -- True if the action must always be specified at the
            command line. This is only meaningful for optional command-line
            arguments.

        - help -- The help string describing the argument.

        - metavar -- The name to be used for the option's argument with the
            help string. If None, the 'dest' value will be used as the name.
    const.__call__() not defined_option_strings--no- | _StoreActionnargs for store actions must be != 0; if you have nothing to store, actions such as store true or store const may be more appropriate'nargs for store actions must be != 0; if you ''have nothing to store, actions such as store ''true or store const may be more appropriate'nargs must be %r to supply const_StoreConstAction_StoreTrueAction_StoreFalseAction_AppendActionnargs for append actions must be != 0; if arg strings are not supplying the value to append, the append const action may be more appropriate'nargs for append actions must be != 0; if arg ''strings are not supplying the value to append, ''the append const action may be more appropriate'_AppendConstAction_CountAction_HelpActionprint_help_VersionActionshow program's version number and exit_get_formatter_print_message_SubParsersAction_ChoicesPseudoActionsupparser_class_prog_prefix_parser_class_name_parser_map_choices_actionsadd_parserchoice_actionparser_nameunknown parser %(parser_name)r (choices: %(choices)s)parse_known_argssubnamespace_ExtendActionFactory for creating file object types

    Instances of FileType are typically passed as type= arguments to the
    ArgumentParser add_argument() method.

    Keyword Arguments:
        - mode -- A string indicating how the file is to be opened. Accepts the
            same values as the builtin open() function.
        - bufsize -- The file's desired buffer size. Accepts the same values as
            the builtin open() function.
        - encoding -- The file's encoding. Accepts the same values as the
            builtin open() function.
        - errors -- A string indicating how encoding and decoding errors are to
            be handled. Accepts the same value as the builtin open() function.
    bufsize_bufsize_encoding_errorswaxargument "-" with mode %rcan't open '%(filename)s': %(error)sargs_strSimple object for storing attributes.

    Implements equality by attribute names and values, and provides a simple
    string representation.
    _ActionsContainerprefix_charsargument_defaultconflict_handler_registriesstorestore_conststore_truestore_falseappend_const_get_handler_actions_option_string_actions_action_groups_mutually_exclusive_groups^-\d+$|^-\d*\.\d+$_negative_number_matcher_has_negative_number_optionalsregistry_nameregistry_registry_getset_defaultsget_default
        add_argument(dest, ..., name=value, ...)
        add_argument(option_string, option_string, ..., name=value, ...)
        dest supplied twice for positional argument_get_positional_kwargs_get_optional_kwargs_pop_action_classaction_classunknown action "%s"type_func%r is not callable%r is a FileType class object, instance of it must be passed'%r is a FileType class object, instance of it'' must be passed'length of metavar tuple does not match nargs_add_actionadd_argument_group_ArgumentGroupadd_mutually_exclusive_group_MutuallyExclusiveGroup_check_conflictcontainer_remove_action_add_container_actionstitle_group_mapcannot merge actions - two groups are named %rgroup_mapmutex_group'required' is an invalid argument for positionalslong_option_stringsinvalid option string %(option)r: must start with a character %(prefix_chars)r'invalid option string %(option)r: ''must start with a character %(prefix_chars)r'dest_option_stringdest= is required for options like %r_handle_conflict_%shandler_func_nameinvalid conflict_resolution value: %rconfl_optionalsconfl_optional_handle_conflict_errorconflicting_actionsconflicting option string: %sconflicting option strings: %sconflict_string_handle_conflict_resolvesuper_initmutually exclusive arguments must be optionalObject for parsing command line strings into Python objects.

    Keyword Arguments:
        - prog -- The name of the program (default:
            ``os.path.basename(sys.argv[0])``)
        - usage -- A usage message (default: auto-generated from arguments)
        - description -- A description of what the program does
        - epilog -- Text following the argument descriptions
        - parents -- Parsers whose arguments should be copied into this one
        - formatter_class -- HelpFormatter class for printing help messages
        - prefix_chars -- Characters that prefix optional arguments
        - fromfile_prefix_chars -- Characters that prefix files containing
            additional arguments
        - argument_default -- The default value for all arguments
        - conflict_handler -- String indicating how to handle conflicts
        - add_help -- Add a -h/-help option
        - allow_abbrev -- Allow long options to be abbreviated unambiguously
        - exit_on_error -- Determines whether or not ArgumentParser exits with
            error info when an error occurs
    epilogformatter_classfromfile_prefix_charsadd_helpallow_abbrevexit_on_errorsuperinitadd_grouppositional arguments_positionals_optionals_subparsersidentitydefault_prefixshow this help message and exitadd_subparserscannot have multiple subparser argumentssubcommands_get_positional_actionsparsers_class_get_optional_actionsparse_argsunrecognized arguments: %s_parse_known_args_read_args_from_filesaction_conflictsmutex_actionconflictsoption_string_indicesarg_string_pattern_partsarg_strings_iterarg_string_parse_optionaloption_tuplearg_strings_patternseen_actionsseen_non_default_actionstake_actionargument_strings_get_valuesargument_valuesconflict_actionnot allowed with argument %sconsume_optionalstart_indexexplicit_arg_match_argumentmatch_argumentaction_tuplesextrasarg_countnew_explicit_argoptionals_mapignored explicit argument %rselected_patternsconsume_positionals_match_arguments_partialmatch_partialselected_patternarg_countsmax_option_string_indexnext_option_string_indexpositionals_end_indexstringsstop_indexrequired_actionsthe following arguments are required: %sone of the arguments %s is requirednew_arg_stringsargs_filearg_lineconvert_arg_line_to_args_get_nargs_patternnargs_patternexpected one argumentexpected at most one argumentexpected at least one argumentnargs_errorsexpected %s argumentexpected %s argumentsactions_slice_get_option_tuplesoption_tuplesambiguous option: %(option)s could match %(matches)soption_prefixshort_option_prefixshort_explicit_argunexpected option string: %s(-*A-*)(-*A?-*)(-*[A-]*)(-*A[A-]*)([-AO]*)(-*A[-AO]*)(-*-*)(-*%s-*)-*parse_intermixed_argsparse_known_intermixed_argsparse_intermixed_args: positional arg with nargs=%s'parse_intermixed_args: positional arg'' with nargs=%s'parse_intermixed_args: positional in mutuallyExclusiveGroup'parse_intermixed_args: positional in'' mutuallyExclusiveGroup'save_usagesave_nargssave_defaultremaining_argsDo not expect %s in %ssave_required_check_valueinvalid %(type)s value: %(value)rinvalid choice: %(value)r (choose from %(choices)s)action_groupprint_usageerror(message: string)

        Prints a usage message incorporating the message to stderr and
        exits.

        If you override this in a subclass, it should not return -- it
        should either exit or raise an exception.
        %(prog)s: error: %(message)s
# Author: Steven J. Bethard <steven.bethard@gmail.com>.# New maintainer as of 29 August 2019:  Raymond Hettinger <raymond.hettinger@gmail.com># =============================# Utility functions and classes# The copy module is used only in the 'append' and 'append_const'# actions, and it is needed only when the default value isn't a list.# Delay its import for speeding up the common case.# ===============# Formatting Help# default setting for width# ===============================# Section and indentation methods# format the indented section# return nothing if the section was empty# add the heading if the section was non-empty# join the section-initial newline, the heading and the help# ========================# Message building methods# find all invocations# update the maximum item length# add the item to the list# =======================# Help-formatting methods# if usage is specified, use that# if no optionals or positionals are available, usage is just prog# if optionals and positionals are available, calculate usage# split optionals from positionals# build full usage string# wrap the usage parts if it's too long# break usage into wrappable parts# helper for wrapping lines# if prog is short, follow it with optionals or positionals# if prog is long, put it on its own line# join lines into usage# prefix with 'usage:'# find group indices and identify actions in groups# collect all actions format strings# suppressed arguments are marked with None# remove | separators for suppressed arguments# produce all arg strings# if it's in a group, strip the outer []# add the action string to the list# produce the first way to invoke the option in brackets# if the Optional doesn't take a value, format is:#    -s or --long# if the Optional takes a value, format is:#    -s ARGS or --long ARGS# make it look optional if it's not required or in a group# insert things at the necessary indices# join all the action items with spaces# clean up separators for mutually exclusive groups# return the text# determine the required width and the entry label# no help; start on same line and add a final newline# short action name; start on the same line and pad two spaces# long action name; start on the next line# collect the pieces of the action help# if there was help for the action, add lines of help text# or add a newline if the description doesn't end with one# if there are any sub-actions, add their help as well# return a single string#    -s, --long#    -s ARGS, --long ARGS# The textwrap module is used only for formatting help.# Delay its import for speeding up the common usage of argparse.# =====================# Options and Arguments# ==============# Action classes# set prog from the existing prefix# create a pseudo-action to hold the choice help# create the parser and add it to the map# make parser available under aliases also# set the parser name if requested# select the parser# parse all the remaining options into the namespace# store any unrecognized options on the object, so that the top# level parser can decide what to do with them# In case this subparser defines new defaults, we parse them# in a new namespace object and then update the original# namespace for the relevant parts.# Type classes# the special argument "-" means sys.std{in,out}# all other arguments are used as file names# ===========================# Optional and Positional Parsing# set up registries# register actions# raise an exception if the conflict handler is invalid# action storage# groups# defaults storage# determines whether an "option" looks like a negative number# whether or not there are any optionals that look like negative# numbers -- uses a list so it can be shared and edited# ====================# Registration methods# ==================================# Namespace default accessor methods# if these defaults match any existing arguments, replace# the previous default on the object with the new one# Adding argument actions# if no positional args are supplied or only one is supplied and# it doesn't look like an option string, parse a positional# argument# otherwise, we're adding an optional argument# if no default was supplied, use the parser-level default# create the action object, and add it to the parser# raise an error if the action type is not callable# raise an error if the metavar does not match the type# resolve any conflicts# add to actions list# index the action by any option strings it has# set the flag if any option strings look like negative numbers# return the created action# collect groups by titles# map each action to its group# if a group with the title exists, use that, otherwise# create a new group matching the container's group# map the actions to their new group# add container's mutually exclusive groups# NOTE: if add_mutually_exclusive_group ever gains title= and# description= then this code will need to be expanded as above# map the actions to their new mutex group# add all actions to this container or their group# make sure required is not specified# mark positional arguments as required if at least one is# always required# return the keyword arguments with no option strings# determine short and long option strings# error on strings that don't start with an appropriate prefix# strings starting with two prefix characters are long options# infer destination, '--foo-bar' -> 'foo_bar' and '-x' -> 'x'# return the updated keyword arguments# determine function from conflict handler string# find all options that conflict with this option# remove all conflicting options# remove the conflicting option# if the option now has no option string, remove it from the# container holding it# add any missing keyword arguments by checking the container# group attributes# share most attributes with the container# default setting for prog# register types# add help argument if necessary# (using explicit default to override global argument_default)# add parent arguments and defaults# Pretty __repr__ methods# Optional/Positional adding methods# add the parser class to the arguments if it's not present# prog defaults to the usage message of this parser, skipping# optional arguments and with no "usage:" prefix# create the parsers action and add it to the positionals list# return the created parsers action# =====================================# Command line argument parsing methods# args default to the system args# make sure that args are mutable# default Namespace built from parser defaults# add any action defaults that aren't present# add any parser defaults that aren't present# parse the arguments and exit if there are any errors# replace arg strings that are file references# map all mutually exclusive arguments to the other arguments# they can't occur with# find all option indices, and determine the arg_string_pattern# which has an 'O' if there is an option at an index,# an 'A' if there is an argument, or a '-' if there is a '--'# all args after -- are non-options# otherwise, add the arg to the arg strings# and note the index if it was an option# join the pieces together to form the pattern# converts arg strings to the appropriate and then takes the action# error if this argument is not allowed with other previously# seen arguments, assuming that actions that use the default# value don't really count as "present"# take the action if we didn't receive a SUPPRESS value# (e.g. from a default)# function to convert arg_strings into an optional action# get the optional identified at this index# identify additional optionals in the same arg string# (e.g. -xyz is the same as -x -y -z if no args are required)# if we found no optional action, skip it# if there is an explicit argument, try to match the# optional's string arguments to only this# if the action is a single-dash option and takes no# arguments, try to parse more single-dash options out# of the tail of the option string# if the action expect exactly one argument, we've# successfully matched the option; exit the loop# error if a double-dash option did not use the# explicit argument# if there is no explicit argument, try to match the# optional's string arguments with the following strings# if successful, exit the loop# add the Optional to the list and return the index at which# the Optional's string args stopped# the list of Positionals left to be parsed; this is modified# by consume_positionals()# function to convert arg_strings into positional actions# match as many Positionals as possible# slice off the appropriate arg strings for each Positional# and add the Positional and its args to the list# slice off the Positionals that we just parsed and return the# index at which the Positionals' string args stopped# consume Positionals and Optionals alternately, until we have# passed the last option string# consume any Positionals preceding the next option# only try to parse the next optional if we didn't consume# the option string during the positionals parsing# if we consumed all the positionals we could and we're not# at the index of an option string, there were extra arguments# consume the next optional and any arguments for it# consume any positionals following the last Optional# if we didn't consume all the argument strings, there were extras# make sure all required actions were present and also convert# action defaults which were not given as arguments# Convert action default now instead of doing it before# parsing arguments to avoid calling convert functions# twice (which may fail) if the argument was given, but# only if it was defined already in the namespace# make sure all required groups had one option present# if no actions were used, report the error# return the updated namespace and the extra arguments# expand arguments referencing files# for regular arguments, just add them back into the list# replace arguments referencing files with the file content# return the modified argument list# match the pattern for this action to the arg strings# raise an exception if we weren't able to find a match# return the number of arguments matched# progressively shorten the actions list by slicing off the# final actions until we find a match# return the list of arg string counts# if it's an empty string, it was meant to be a positional# if it doesn't start with a prefix, it was meant to be positional# if the option string is present in the parser, return the action# if it's just a single character, it was meant to be positional# if the option string before the "=" is present, return the action# search through all possible prefixes of the option string# and all actions in the parser for possible interpretations# if multiple actions match, the option string was ambiguous# if exactly one action matched, this segmentation is good,# so return the parsed action# if it was not found as an option, but it looks like a negative# number, it was meant to be positional# unless there are negative-number-like options# if it contains a space, it was meant to be a positional# it was meant to be an optional but there is no such option# in this parser (though it might be a valid option in a subparser)# option strings starting with two prefix characters are only# split at the '='# single character options can be concatenated with their arguments# but multiple character options always have to have their argument# separate# shouldn't ever get here# return the collected option tuples# in all examples below, we have to allow for '--' args# which are represented as '-' in the pattern# the default (None) is assumed to be a single argument# allow zero or one arguments# allow zero or more arguments# allow one or more arguments# allow any number of options or arguments# allow one argument followed by any number of options or arguments# suppress action, like nargs=0# all others should be integers# if this is an optional action, -- is not allowed# return the pattern# Alt command line argument parsing, allowing free intermix# returns a namespace and list of extras# positional can be freely intermixed with optionals.  optionals are# first parsed with all positional arguments deactivated.  The 'extras'# are then parsed.  If the parser definition is incompatible with the# intermixed assumptions (e.g. use of REMAINDER, subparsers) a# TypeError is raised.# positionals are 'deactivated' by setting nargs and default to# SUPPRESS.  This blocks the addition of that positional to the# namespace# capture the full usage for use in error messages# deactivate positionals# action.nargs = 0# remove the empty positional values from namespace# restore nargs and usage before exiting# parse positionals.  optionals aren't normally required, but# they could be, so make sure they aren't.# restore parser values before exiting# Value conversion methods# for everything but PARSER, REMAINDER args, strip out first '--'# optional argument produces a default when not present# when nargs='*' on a positional, if there were no command-line# args, use the default if it is anything other than None# single argument or optional argument produces a single value# REMAINDER arguments convert all values, checking none# PARSER arguments convert all values, but check only the first# SUPPRESS argument does not put anything in the namespace# all other types of nargs produce a list# return the converted value# convert the value to the appropriate type# ArgumentTypeErrors indicate errors# TypeErrors or ValueErrors also indicate errors# converted value must be one of the choices (if specified)# usage# description# positionals, optionals and user-defined groups# epilog# determine help from format above# Help-printing methods# Exiting methodsb'Command-line parsing library

This module is an optparse-inspired command-line parsing library that:

    - handles both optional and positional arguments
    - produces highly informative usage messages
    - supports parsers that dispatch to sub-parsers

The following is a simple usage example that sums integers from the
command-line and writes the result to a file::

    parser = argparse.ArgumentParser(
        description='sum the integers at the command line')
    parser.add_argument(
        'integers', metavar='int', nargs='+', type=int,
        help='an integer to be summed')
    parser.add_argument(
        '--log', default=sys.stdout, type=argparse.FileType('w'),
        help='the file where the sum should be written')
    args = parser.parse_args()
    args.log.write('%s' % sum(args.integers))
    args.log.close()

The module contains the following public classes:

    - ArgumentParser -- The main entry point for command-line parsing. As the
        example above shows, the add_argument() method is used to populate
        the parser with actions for optional and positional arguments. Then
        the parse_args() method is invoked to convert the args at the
        command-line into an object with attributes.

    - ArgumentError -- The exception raised by ArgumentParser objects when
        there are errors with the parser's actions. Errors raised while
        parsing the command-line are caught by ArgumentParser and emitted
        as command-line messages.

    - FileType -- A factory for defining types of files to be created. As the
        example above shows, instances of FileType are typically passed as
        the type= argument of add_argument() calls.

    - Action -- The base class for parser actions. Typically actions are
        selected by passing strings like 'store_true' or 'append_const' to
        the action= argument of add_argument(). However, for greater
        customization of ArgumentParser actions, subclasses of Action may
        be defined and passed as the action= argument.

    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,
        ArgumentDefaultsHelpFormatter -- Formatter classes which
        may be passed as the formatter_class= argument to the
        ArgumentParser constructor. HelpFormatter is the default,
        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser
        not to change the formatting for help text, and
        ArgumentDefaultsHelpFormatter adds information about argument defaults
        to the help.

All other classes in this module are considered implementation details.
(Also note that HelpFormatter and RawDescriptionHelpFormatter are only
considered public as object names -- the API of the formatter objects is
still considered an implementation detail.)
'u'Command-line parsing library

This module is an optparse-inspired command-line parsing library that:

    - handles both optional and positional arguments
    - produces highly informative usage messages
    - supports parsers that dispatch to sub-parsers

The following is a simple usage example that sums integers from the
command-line and writes the result to a file::

    parser = argparse.ArgumentParser(
        description='sum the integers at the command line')
    parser.add_argument(
        'integers', metavar='int', nargs='+', type=int,
        help='an integer to be summed')
    parser.add_argument(
        '--log', default=sys.stdout, type=argparse.FileType('w'),
        help='the file where the sum should be written')
    args = parser.parse_args()
    args.log.write('%s' % sum(args.integers))
    args.log.close()

The module contains the following public classes:

    - ArgumentParser -- The main entry point for command-line parsing. As the
        example above shows, the add_argument() method is used to populate
        the parser with actions for optional and positional arguments. Then
        the parse_args() method is invoked to convert the args at the
        command-line into an object with attributes.

    - ArgumentError -- The exception raised by ArgumentParser objects when
        there are errors with the parser's actions. Errors raised while
        parsing the command-line are caught by ArgumentParser and emitted
        as command-line messages.

    - FileType -- A factory for defining types of files to be created. As the
        example above shows, instances of FileType are typically passed as
        the type= argument of add_argument() calls.

    - Action -- The base class for parser actions. Typically actions are
        selected by passing strings like 'store_true' or 'append_const' to
        the action= argument of add_argument(). However, for greater
        customization of ArgumentParser actions, subclasses of Action may
        be defined and passed as the action= argument.

    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,
        ArgumentDefaultsHelpFormatter -- Formatter classes which
        may be passed as the formatter_class= argument to the
        ArgumentParser constructor. HelpFormatter is the default,
        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser
        not to change the formatting for help text, and
        ArgumentDefaultsHelpFormatter adds information about argument defaults
        to the help.

All other classes in this module are considered implementation details.
(Also note that HelpFormatter and RawDescriptionHelpFormatter are only
considered public as object names -- the API of the formatter objects is
still considered an implementation detail.)
'b'1.1'u'1.1'b'ArgumentParser'u'ArgumentParser'b'ArgumentError'u'ArgumentError'b'ArgumentTypeError'u'ArgumentTypeError'b'BooleanOptionalAction'u'BooleanOptionalAction'b'FileType'u'FileType'b'HelpFormatter'u'HelpFormatter'b'ArgumentDefaultsHelpFormatter'u'ArgumentDefaultsHelpFormatter'b'RawDescriptionHelpFormatter'u'RawDescriptionHelpFormatter'b'RawTextHelpFormatter'u'RawTextHelpFormatter'b'MetavarTypeHelpFormatter'u'MetavarTypeHelpFormatter'b'Namespace'u'Namespace'b'Action'u'Action'b'ONE_OR_MORE'u'ONE_OR_MORE'b'OPTIONAL'u'OPTIONAL'b'PARSER'u'PARSER'b'REMAINDER'u'REMAINDER'b'SUPPRESS'u'SUPPRESS'b'ZERO_OR_MORE'u'ZERO_OR_MORE'b'==SUPPRESS=='u'==SUPPRESS=='b'A...'u'A...'b'_unrecognized_args'u'_unrecognized_args'b'Abstract base class that provides __repr__.

    The __repr__ method returns a string in the format::
        ClassName(attr=name, attr=name, ...)
    The attributes are determined either by a class-level attribute,
    '_kwarg_names', or by inspecting the instance __dict__.
    'u'Abstract base class that provides __repr__.

    The __repr__ method returns a string in the format::
        ClassName(attr=name, attr=name, ...)
    The attributes are determined either by a class-level attribute,
    '_kwarg_names', or by inspecting the instance __dict__.
    'b'%s=%r'u'%s=%r'b'**%s'u'**%s'b'Formatter for generating usage messages and argument help strings.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Formatter for generating usage messages and argument help strings.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'\s+'u'\s+'b'\n\n\n+'u'\n\n\n+'b'Indent decreased below 0.'u'Indent decreased below 0.'b'%*s%s:
'u'%*s%s:
'b'

'u'

'b'usage: 'u'usage: 'b'%(prog)s'u'%(prog)s'b'\(.*?\)+(?=\s|$)|\[.*?\]+(?=\s|$)|\S+'u'\(.*?\)+(?=\s|$)|\[.*?\]+(?=\s|$)|\S+'b'%s%s

'u'%s%s

'b'empty group 'u'empty group 'b' ['u' ['b'%s %s'u'%s %s'b'[\[(]'u'[\[(]'b'[\])]'u'[\])]'b'(%s) 'u'(%s) 'b' (%s)'u' (%s)'b'%s *%s'u'%s *%s'b'\(([^|]*)\)'u'\(([^|]*)\)'b'%(prog)'u'%(prog)'b'%*s%s
'u'%*s%s
'b'%*s%-*s  'u'%*s%-*s  'b'[%s [%s ...]]'u'[%s [%s ...]]'b'[%s ...]'u'[%s ...]'b'%s [%s ...]'u'%s [%s ...]'b'%s ...'u'%s ...'b'invalid nargs value'u'invalid nargs value'b'choices'u'choices'b'Help message formatter which retains any formatting in descriptions.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Help message formatter which retains any formatting in descriptions.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'Help message formatter which retains formatting of all help text.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Help message formatter which retains formatting of all help text.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'Help message formatter which adds default values to argument help.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Help message formatter which adds default values to argument help.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'%(default)'u'%(default)'b' (default: %(default)s)'u' (default: %(default)s)'b'Help message formatter which uses the argument 'type' as the default
    metavar value (instead of the argument 'dest')

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'u'Help message formatter which uses the argument 'type' as the default
    metavar value (instead of the argument 'dest')

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    'b'An error from creating or using an argument (optional or positional).

    The string value of this exception is the message, augmented with
    information about the argument that caused it.
    'u'An error from creating or using an argument (optional or positional).

    The string value of this exception is the message, augmented with
    information about the argument that caused it.
    'b'argument %(argument_name)s: %(message)s'u'argument %(argument_name)s: %(message)s'b'An error from trying to convert a command line string to a type.'u'An error from trying to convert a command line string to a type.'b'Information about how to convert command line strings to Python objects.

    Action objects are used by an ArgumentParser to represent the information
    needed to parse a single argument from one or more strings from the
    command line. The keyword arguments to the Action constructor are also
    all attributes of Action instances.

    Keyword Arguments:

        - option_strings -- A list of command-line option strings which
            should be associated with this action.

        - dest -- The name of the attribute to hold the created object(s)

        - nargs -- The number of command-line arguments that should be
            consumed. By default, one argument will be consumed and a single
            value will be produced.  Other values include:
                - N (an integer) consumes N arguments (and produces a list)
                - '?' consumes zero or one arguments
                - '*' consumes zero or more arguments (and produces a list)
                - '+' consumes one or more arguments (and produces a list)
            Note that the difference between the default and nargs=1 is that
            with the default, a single value will be produced, while with
            nargs=1, a list containing a single value will be produced.

        - const -- The value to be produced if the option is specified and the
            option uses an action that takes no values.

        - default -- The value to be produced if the option is not specified.

        - type -- A callable that accepts a single string argument, and
            returns the converted value.  The standard Python types str, int,
            float, and complex are useful examples of such callables.  If None,
            str is used.

        - choices -- A container of values that should be allowed. If not None,
            after a command-line argument has been converted to the appropriate
            type, an exception will be raised if it is not a member of this
            collection.

        - required -- True if the action must always be specified at the
            command line. This is only meaningful for optional command-line
            arguments.

        - help -- The help string describing the argument.

        - metavar -- The name to be used for the option's argument with the
            help string. If None, the 'dest' value will be used as the name.
    'u'Information about how to convert command line strings to Python objects.

    Action objects are used by an ArgumentParser to represent the information
    needed to parse a single argument from one or more strings from the
    command line. The keyword arguments to the Action constructor are also
    all attributes of Action instances.

    Keyword Arguments:

        - option_strings -- A list of command-line option strings which
            should be associated with this action.

        - dest -- The name of the attribute to hold the created object(s)

        - nargs -- The number of command-line arguments that should be
            consumed. By default, one argument will be consumed and a single
            value will be produced.  Other values include:
                - N (an integer) consumes N arguments (and produces a list)
                - '?' consumes zero or one arguments
                - '*' consumes zero or more arguments (and produces a list)
                - '+' consumes one or more arguments (and produces a list)
            Note that the difference between the default and nargs=1 is that
            with the default, a single value will be produced, while with
            nargs=1, a list containing a single value will be produced.

        - const -- The value to be produced if the option is specified and the
            option uses an action that takes no values.

        - default -- The value to be produced if the option is not specified.

        - type -- A callable that accepts a single string argument, and
            returns the converted value.  The standard Python types str, int,
            float, and complex are useful examples of such callables.  If None,
            str is used.

        - choices -- A container of values that should be allowed. If not None,
            after a command-line argument has been converted to the appropriate
            type, an exception will be raised if it is not a member of this
            collection.

        - required -- True if the action must always be specified at the
            command line. This is only meaningful for optional command-line
            arguments.

        - help -- The help string describing the argument.

        - metavar -- The name to be used for the option's argument with the
            help string. If None, the 'dest' value will be used as the name.
    'b'option_strings'u'option_strings'b'dest'u'dest'b'nargs'u'nargs'b'const'u'const'b'required'u'required'b'help'u'help'b'metavar'u'metavar'b'.__call__() not defined'u'.__call__() not defined'b'--no-'u'--no-'b' | 'u' | 'b'nargs for store actions must be != 0; if you have nothing to store, actions such as store true or store const may be more appropriate'u'nargs for store actions must be != 0; if you have nothing to store, actions such as store true or store const may be more appropriate'b'nargs must be %r to supply const'u'nargs must be %r to supply const'b'nargs for append actions must be != 0; if arg strings are not supplying the value to append, the append const action may be more appropriate'u'nargs for append actions must be != 0; if arg strings are not supplying the value to append, the append const action may be more appropriate'b'show program's version number and exit'u'show program's version number and exit'b'prog'u'prog'b'aliases'b'parser_name'u'parser_name'b'unknown parser %(parser_name)r (choices: %(choices)s)'u'unknown parser %(parser_name)r (choices: %(choices)s)'b'Factory for creating file object types

    Instances of FileType are typically passed as type= arguments to the
    ArgumentParser add_argument() method.

    Keyword Arguments:
        - mode -- A string indicating how the file is to be opened. Accepts the
            same values as the builtin open() function.
        - bufsize -- The file's desired buffer size. Accepts the same values as
            the builtin open() function.
        - encoding -- The file's encoding. Accepts the same values as the
            builtin open() function.
        - errors -- A string indicating how encoding and decoding errors are to
            be handled. Accepts the same value as the builtin open() function.
    'u'Factory for creating file object types

    Instances of FileType are typically passed as type= arguments to the
    ArgumentParser add_argument() method.

    Keyword Arguments:
        - mode -- A string indicating how the file is to be opened. Accepts the
            same values as the builtin open() function.
        - bufsize -- The file's desired buffer size. Accepts the same values as
            the builtin open() function.
        - encoding -- The file's encoding. Accepts the same values as the
            builtin open() function.
        - errors -- A string indicating how encoding and decoding errors are to
            be handled. Accepts the same value as the builtin open() function.
    'b'wax'u'wax'b'argument "-" with mode %r'u'argument "-" with mode %r'b'can't open '%(filename)s': %(error)s'u'can't open '%(filename)s': %(error)s'b'Simple object for storing attributes.

    Implements equality by attribute names and values, and provides a simple
    string representation.
    'u'Simple object for storing attributes.

    Implements equality by attribute names and values, and provides a simple
    string representation.
    'b'action'b'store'u'store'b'store_const'u'store_const'b'store_true'u'store_true'b'store_false'u'store_false'b'append_const'u'append_const'b'version'b'extend'u'extend'b'^-\d+$|^-\d*\.\d+$'u'^-\d+$|^-\d*\.\d+$'b'
        add_argument(dest, ..., name=value, ...)
        add_argument(option_string, option_string, ..., name=value, ...)
        'u'
        add_argument(dest, ..., name=value, ...)
        add_argument(option_string, option_string, ..., name=value, ...)
        'b'dest supplied twice for positional argument'u'dest supplied twice for positional argument'b'unknown action "%s"'u'unknown action "%s"'b'%r is not callable'u'%r is not callable'b'%r is a FileType class object, instance of it must be passed'u'%r is a FileType class object, instance of it must be passed'b'_get_formatter'u'_get_formatter'b'length of metavar tuple does not match nargs'u'length of metavar tuple does not match nargs'b'cannot merge actions - two groups are named %r'u'cannot merge actions - two groups are named %r'b''required' is an invalid argument for positionals'u''required' is an invalid argument for positionals'b'prefix_chars'u'prefix_chars'b'invalid option string %(option)r: must start with a character %(prefix_chars)r'u'invalid option string %(option)r: must start with a character %(prefix_chars)r'b'dest= is required for options like %r'u'dest= is required for options like %r'b'_handle_conflict_%s'u'_handle_conflict_%s'b'invalid conflict_resolution value: %r'u'invalid conflict_resolution value: %r'b'conflicting option string: %s'u'conflicting option string: %s'b'conflicting option strings: %s'u'conflicting option strings: %s'b'conflict_handler'u'conflict_handler'b'argument_default'u'argument_default'b'mutually exclusive arguments must be optional'u'mutually exclusive arguments must be optional'b'Object for parsing command line strings into Python objects.

    Keyword Arguments:
        - prog -- The name of the program (default:
            ``os.path.basename(sys.argv[0])``)
        - usage -- A usage message (default: auto-generated from arguments)
        - description -- A description of what the program does
        - epilog -- Text following the argument descriptions
        - parents -- Parsers whose arguments should be copied into this one
        - formatter_class -- HelpFormatter class for printing help messages
        - prefix_chars -- Characters that prefix optional arguments
        - fromfile_prefix_chars -- Characters that prefix files containing
            additional arguments
        - argument_default -- The default value for all arguments
        - conflict_handler -- String indicating how to handle conflicts
        - add_help -- Add a -h/-help option
        - allow_abbrev -- Allow long options to be abbreviated unambiguously
        - exit_on_error -- Determines whether or not ArgumentParser exits with
            error info when an error occurs
    'u'Object for parsing command line strings into Python objects.

    Keyword Arguments:
        - prog -- The name of the program (default:
            ``os.path.basename(sys.argv[0])``)
        - usage -- A usage message (default: auto-generated from arguments)
        - description -- A description of what the program does
        - epilog -- Text following the argument descriptions
        - parents -- Parsers whose arguments should be copied into this one
        - formatter_class -- HelpFormatter class for printing help messages
        - prefix_chars -- Characters that prefix optional arguments
        - fromfile_prefix_chars -- Characters that prefix files containing
            additional arguments
        - argument_default -- The default value for all arguments
        - conflict_handler -- String indicating how to handle conflicts
        - add_help -- Add a -h/-help option
        - allow_abbrev -- Allow long options to be abbreviated unambiguously
        - exit_on_error -- Determines whether or not ArgumentParser exits with
            error info when an error occurs
    'b'positional arguments'u'positional arguments'b'show this help message and exit'u'show this help message and exit'b'usage'u'usage'b'description'u'description'b'formatter_class'u'formatter_class'b'add_help'u'add_help'b'cannot have multiple subparser arguments'u'cannot have multiple subparser arguments'b'parser_class'u'parser_class'b'subcommands'u'subcommands'b'unrecognized arguments: %s'u'unrecognized arguments: %s'b'not allowed with argument %s'u'not allowed with argument %s'b'ignored explicit argument %r'u'ignored explicit argument %r'b'the following arguments are required: %s'u'the following arguments are required: %s'b'one of the arguments %s is required'u'one of the arguments %s is required'b'expected one argument'u'expected one argument'b'expected at most one argument'u'expected at most one argument'b'expected at least one argument'u'expected at least one argument'b'expected %s argument'u'expected %s argument'b'expected %s arguments'u'expected %s arguments'b'matches'u'matches'b'ambiguous option: %(option)s could match %(matches)s'u'ambiguous option: %(option)s could match %(matches)s'b'unexpected option string: %s'u'unexpected option string: %s'b'(-*A-*)'u'(-*A-*)'b'(-*A?-*)'u'(-*A?-*)'b'(-*[A-]*)'u'(-*[A-]*)'b'(-*A[A-]*)'u'(-*A[A-]*)'b'([-AO]*)'u'([-AO]*)'b'(-*A[-AO]*)'u'(-*A[-AO]*)'b'(-*-*)'u'(-*-*)'b'(-*%s-*)'u'(-*%s-*)'b'-*'u'-*'b'parse_intermixed_args: positional arg with nargs=%s'u'parse_intermixed_args: positional arg with nargs=%s'b'parse_intermixed_args: positional in mutuallyExclusiveGroup'u'parse_intermixed_args: positional in mutuallyExclusiveGroup'b'Do not expect %s in %s'u'Do not expect %s in %s'b'invalid %(type)s value: %(value)r'u'invalid %(type)s value: %(value)r'b'invalid choice: %(value)r (choose from %(choices)s)'u'invalid choice: %(value)r (choose from %(choices)s)'b'error(message: string)

        Prints a usage message incorporating the message to stderr and
        exits.

        If you override this in a subclass, it should not return -- it
        should either exit or raise an exception.
        'u'error(message: string)

        Prints a usage message incorporating the message to stderr and
        exits.

        If you override this in a subclass, it should not return -- it
        should either exit or raise an exception.
        'b'%(prog)s: error: %(message)s
'u'%(prog)s: error: %(message)s
'u'argparse'Internal module to help with normalizing botocore client args.

This module (and all function/classes within this module) should be
considered internal, and *not* a public API.

botocore.exceptionsbotocore.parsersbotocore.serializebotocore.configConfigbotocore.endpointEndpointCreatorbotocore.regionsEndpointResolverBuiltinsEPRBuiltinsEndpointRulesetResolverbotocore.signersRequestSignerensure_booleanis_s3_accelerate_urlregionalVALID_REGIONAL_ENDPOINTS_CONFIGap-northeast-1ap-south-1ap-southeast-1ap-southeast-2aws-globalca-central-1eu-central-1eu-north-1eu-west-1eu-west-2eu-west-3sa-east-1us-east-1us-east-2us-west-1us-west-2LEGACY_GLOBAL_STS_REGIONSClientArgsCreatoruser_agentresponse_parser_factoryexceptions_factoryconfig_store_event_emitter_user_agent_response_parser_factory_loader_exceptions_factory_config_storeget_client_argsregion_nameis_secureendpoint_urlcredentialsscoped_configclient_configendpoint_bridgeauth_tokenendpoints_ruleset_datapartition_datacompute_client_argsfinal_argsparameter_validationendpoint_configconfig_kwargss3_configmetadatasigning_regionendpoint_region_nameservice_idsigning_namesignature_versionsigners3new_configendpoint_creatorcreate_endpointmax_pool_connectionsclient_certproxies_configendpointcreate_serializerserializercreate_parserresponse_parser_build_endpoint_resolverruleset_resolverrequest_signerendpoint_ruleset_resolverendpoint_prefixraw_valueuser_agent_extra %scompute_s3_config_compute_endpoint_configtagsendpoint_variant_tagsdualstackuse_dualstack_endpointfipsuse_fips_endpointinject_host_prefixtcp_keepalive_compute_retry_config_compute_connect_timeout_is_s3_serviceis_s3_service_compute_socket_optionsget_config_variables3_configurationWhether the service is S3 or S3 Control.

        Note that throughout this class, service_name refers to the endpoint
        prefix, not the folder name of the service in botocore/data. For
        S3 Control, the folder name is 's3control' but the endpoint prefix is
        's3-control'.
        s3-controlresolve_endpoint_kwargs_compute_s3_endpoint_configsts_compute_sts_endpoint_config_resolve_endpoint_should_force_s3_globalforce_s3_global_set_region_if_custom_s3_endpoints3_regional_configus_east_1_regional_endpoint_validate_s3_regional_configis_global_regionconfig_valInvalidS3UsEast1RegionalEndpointConfigErrors3_us_east_1_regional_endpoint_config_should_set_global_sts_endpoint_set_global_sts_endpointhas_variant_tags_get_sts_regional_endpoints_configsts_regional_endpointssts_regional_endpoints_configInvalidSTSRegionalEndpointsConfigError%s://sts.amazonaws.comclient_keepalive_ensure_booleanscoped_keepalive_compute_retry_max_attempts_compute_retry_modetotal_max_attemptsmax_attemptsretry_modes3_config_rawservice_name_raweprv2_region_namecompute_endpoint_resolver_builtin_defaultsclient_endpoint_urllegacy_endpoint_urlresolver_builtinsclient_contextsig_versionendpoint_ruleset_datause_sslrequested_auth_schemegiven_endpointresolver_uses_builtin_datause_accelerate_endpointforce_path_styleaddressing_styleAWS_REGION_resolve_endpoint_variant_config_varAWS_USE_FIPS_resolve_use_dualstack_endpointAWS_USE_DUALSTACKAWS_STS_USE_GLOBAL_ENDPOINTAWS_S3_USE_GLOBAL_ENDPOINTAWS_S3_ACCELERATEAWS_S3_FORCE_PATH_STYLEuse_arn_regionAWS_S3_USE_ARN_REGIONAWS_S3CONTROL_USE_ARN_REGIONs3_disable_multiregion_access_pointsAWS_S3_DISABLE_MRAPSDK_ENDPOINT# Copyright 2016 Amazon.com, Inc. or its affiliates. All Rights Reserved.# noqa# Override the user agent if specified in the client config.# Create a new client config to be passed to the client based# on the final values. We do not want the user to be able# to try to modify an existing client with a client config.# Next specific client config values takes precedence over# specific values in the scoped config.# The current s3_configuration dictionary may be# from a source that only should be read from so# we want to be safe and just make a copy of it to modify# before it actually gets updated.# For backwards compatibility reasons, we want to make sure the# client.meta.region_name will remain us-east-1 if we forced the# endpoint to be the global region. Specifically, if this value# changes to aws-global, it breaks logic where a user is checking# for us-east-1 as the global endpoint such as in creating buckets.# If a user is providing a custom URL, the endpoint resolver will# refuse to infer a signing region. If we want to default to s3v4,# we have to account for this.# This disables Nagle's algorithm and is the default socket options# in urllib3.# Enables TCP Keepalive if specified in client config object or shared config file.# There's a pre-existing max_attempts client config value that actually# means max *retry* attempts.  There's also a `max_attempts` we pull# from the config store that means *total attempts*, which includes the# intitial request.  We can't change what `max_attempts` means in# client config so we try to normalize everything to a new# "total_max_attempts" variable.  We ensure that after this, the only# configuration for "max attempts" is the 'total_max_attempts' key.# An explicitly provided max_attempts in the client config# overrides everything.# client config max_attempts means total retries so we# have to add one for 'total_max_attempts' to account# for the initial request.# Otherwise we'll check the config store which checks env vars,# config files, etc.  There is no default value for max_attempts# so if this returns None and we don't set a default value here.# If there's a retry mode explicitly set in the client config# that overrides everything.# Checking if connect_timeout is set on the client config.# If it is not, we check the config_store in case a# non legacy default mode has been configured.# The legacy EndpointResolver is global to the session, but# EndpointRulesetResolver is service-specific. Builtins for# EndpointRulesetResolver must not be derived from the legacy# endpoint resolver's output, including final_args, s3_config,# etc.# Maintain complex logic for s3 and sts endpoints for backwards# compatibility.# botocore does not support client context parameters generically# for every service. Instead, the s3 config section entries are# available as client context parameters. In the future, endpoint# rulesets of services other than s3/s3control may require client# context parameters.# EndpointRulesetResolver rulesets may accept an "SDK::Endpoint" as# input. If the endpoint_url argument of create_client() is set, it# always takes priority.# If an endpoints.json data file other than the one bundled within# the botocore/data directory is used, the output of legacy# endpoint resolution is provided to EndpointRulesetResolver.# The endpoint rulesets differ from legacy botocore behavior in whether# forcing path style addressing in incompatible situations raises an# exception or silently ignores the config setting. The# AWS_S3_FORCE_PATH_STYLE parameter is adjusted both here and for each# operation so that the ruleset behavior is backwards compatible.# SDK_ENDPOINT cannot be combined with AWS_USE_FIPS# use legacy resolver's _resolve_endpoint_variant_config_var()# or default to False if it returns None# SDK_ENDPOINT cannot be combined with AWS_USE_DUALSTACK# use legacy resolver's _resolve_use_dualstack_endpoint() andb'Internal module to help with normalizing botocore client args.

This module (and all function/classes within this module) should be
considered internal, and *not* a public API.

'u'Internal module to help with normalizing botocore client args.

This module (and all function/classes within this module) should be
considered internal, and *not* a public API.

'b'legacy'u'legacy'b'regional'u'regional'b'ap-northeast-1'u'ap-northeast-1'b'ap-south-1'u'ap-south-1'b'ap-southeast-1'u'ap-southeast-1'b'ap-southeast-2'u'ap-southeast-2'b'aws-global'u'aws-global'b'ca-central-1'u'ca-central-1'b'eu-central-1'u'eu-central-1'b'eu-north-1'u'eu-north-1'b'eu-west-1'u'eu-west-1'b'eu-west-2'u'eu-west-2'b'eu-west-3'u'eu-west-3'b'sa-east-1'u'sa-east-1'b'us-east-1'u'us-east-1'b'us-east-2'u'us-east-2'b'us-west-1'u'us-west-1'b'us-west-2'u'us-west-2'b'service_name'u'service_name'b'parameter_validation'u'parameter_validation'b'endpoint_config'u'endpoint_config'b'config_kwargs'u'config_kwargs'b's3_config'u's3_config'b'metadata'u'metadata'b'partition'u'partition'b'signing_region'u'signing_region'b'region_name'u'region_name'b'signing_name'u'signing_name'b'signature_version'u'signature_version'b's3'u's3'b'endpoint_url'u'endpoint_url'b'serializer'u'serializer'b'endpoint'u'endpoint'b'response_parser'u'response_parser'b'event_emitter'u'event_emitter'b'request_signer'u'request_signer'b'service_model'u'service_model'b'loader'u'loader'b'client_config'u'client_config'b'exceptions_factory'u'exceptions_factory'b'endpoint_ruleset_resolver'u'endpoint_ruleset_resolver'b' %s'u' %s'b'tags'u'tags'b'dualstack'u'dualstack'b'fips'u'fips'b'use_dualstack_endpoint'u'use_dualstack_endpoint'b'user_agent'u'user_agent'b'Whether the service is S3 or S3 Control.

        Note that throughout this class, service_name refers to the endpoint
        prefix, not the folder name of the service in botocore/data. For
        S3 Control, the folder name is 's3control' but the endpoint prefix is
        's3-control'.
        'u'Whether the service is S3 or S3 Control.

        Note that throughout this class, service_name refers to the endpoint
        prefix, not the folder name of the service in botocore/data. For
        S3 Control, the folder name is 's3control' but the endpoint prefix is
        's3-control'.
        'b's3-control'u's3-control'b'is_secure'u'is_secure'b'endpoint_bridge'u'endpoint_bridge'b'sts'u'sts'b'us_east_1_regional_endpoint'u'us_east_1_regional_endpoint'b'sts_regional_endpoints'u'sts_regional_endpoints'b'%s://sts.amazonaws.com'u'%s://sts.amazonaws.com'b'tcp_keepalive'u'tcp_keepalive'b'total_max_attempts'u'total_max_attempts'b'max_attempts'u'max_attempts'b'mode'u'mode'b'retry_mode'u'retry_mode'b'connect_timeout'u'connect_timeout'b'use_accelerate_endpoint'u'use_accelerate_endpoint'b'addressing_style'u'addressing_style'b'virtual'u'virtual'b'use_fips_endpoint'u'use_fips_endpoint'b'use_arn_region'u'use_arn_region'b's3_disable_multiregion_access_points'u's3_disable_multiregion_access_points'u'botocore.args'u'array(typecode [, initializer]) -> array

Return a new array whose items are restricted by typecode, and
initialized from the optional initializer value, which must be a list,
string or iterable over elements of the appropriate type.

Arrays represent basic values and behave very much like lists, except
the type of objects stored in them is constrained. The type is specified
at object creation time by using a type code, which is a single character.
The following type codes are defined:

    Type code   C Type             Minimum size in bytes
    'b'         signed integer     1
    'B'         unsigned integer   1
    'u'         Unicode character  2 (see note)
    'h'         signed integer     2
    'H'         unsigned integer   2
    'i'         signed integer     2
    'I'         unsigned integer   2
    'l'         signed integer     4
    'L'         unsigned integer   4
    'q'         signed integer     8 (see note)
    'Q'         unsigned integer   8 (see note)
    'f'         floating point     4
    'd'         floating point     8

NOTE: The 'u' typecode corresponds to Python's unicode character. On
narrow builds this is 2-bytes on wide builds this is 4-bytes.

NOTE: The 'q' and 'Q' type codes are only available if the platform
C compiler used to build Python supports 'long long', or, on Windows,
'__int64'.

Methods:

append() -- append a new item to the end of the array
buffer_info() -- return information giving the current memory info
byteswap() -- byteswap all the items of the array
count() -- return number of occurrences of an object
extend() -- extend array by appending multiple elements from an iterable
fromfile() -- read items from a file object
fromlist() -- append items from the list
frombytes() -- append items from the string
index() -- return index of first occurrence of an object
insert() -- insert a new item into the array at a provided position
pop() -- remove and return item (default last)
remove() -- remove first occurrence of an object
reverse() -- reverse the order of the items in the array
tofile() -- write all items to a file object
tolist() -- return the array converted to an ordinary list
tobytes() -- return the array converted to a string

Attributes:

typecode -- the typecode character used to create the array
itemsize -- the length in bytes of one array item
'u'array'byteswapfrombytesfromfilefromunicodeu'the size, in bytes, of one array item'u'array.itemsize'tofiletounicodeu'the typecode character used to create the array'u'array.typecode'array.arrayArrayTypeu'This module defines an object type which can efficiently represent
an array of basic values: characters, integers, floating point
numbers.  Arrays are sequence types and behave very much like lists,
except that the type of objects stored in them is constrained.
'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/array.cpython-310-darwin.so'_array_reconstructorarrayu'bBuhHiIlLqQfd'typecodescomparatorcurrent_nodeexpreffunction_expressionfilter_projectionleftrightflattennodeindex_expressionkey_val_pairkey_nameliteralliteral_valuemulti_select_dictnodesmulti_select_listor_expressionand_expressionnot_expressionpipeprojectionsubexpressionvalue_projection# AST nodes have this structure:# {"type": <node type>", children: [], "value": ""}b'comparator'u'comparator'b'expref'u'expref'b'function_expression'u'function_expression'b'field'u'field'b'filter_projection'u'filter_projection'b'flatten'u'flatten'b'identity'u'identity'b'index_expression'u'index_expression'b'key_val_pair'u'key_val_pair'b'literal'u'literal'b'multi_select_dict'u'multi_select_dict'b'multi_select_list'u'multi_select_list'b'or_expression'u'or_expression'b'and_expression'u'and_expression'b'not_expression'u'not_expression'b'pipe'u'pipe'b'projection'u'projection'b'subexpression'u'subexpression'b'slice'b'value_projection'u'value_projection'u'jmespath.ast'
    ast
    ~~~

    The `ast` module helps Python applications to process trees of the Python
    abstract syntax grammar.  The abstract syntax itself might change with
    each Python release; this module helps to find out programmatically what
    the current grammar looks like and allows modifications of it.

    An abstract syntax tree can be generated by passing `ast.PyCF_ONLY_AST` as
    a flag to the `compile()` builtin function or by using the `parse()`
    function from this module.  The result will be a tree of objects whose
    classes all inherit from `ast.AST`.

    A modified abstract syntax tree can be compiled into a Python code object
    using the built-in `compile()` function.

    Additionally various helper functions are provided that make working with
    the trees simpler.  The main intention of the helper functions and this
    module in general is to provide an easy to use interface for libraries
    that work tightly with the python syntax (template engines for example).


    :copyright: Copyright 2008 by Armin Ronacher.
    :license: Python License.
nullcontextautotype_commentsfeature_version
    Parse the source into an AST node.
    Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
    Pass type_comments=True to get back type comments where the syntax allows.
    _feature_versionliteral_evalnode_or_string
    Evaluate an expression node or a string containing only a Python
    expression.  The string or node provided may only consist of the following
    Python literal structures: strings, bytes, numbers, tuples, lists, dicts,
    sets, booleans, and None.

    Caution: A complex expression can overflow the C stack and cause a crash.
    _raise_malformed_nodemalformed node or string on line _convert_num_convert_signed_numoperandeltsannotate_fieldsinclude_attributes
    Return a formatted dump of the tree in node.  This is mainly useful for
    debugging purposes.  If annotate_fields is true (by default),
    the returned string will show the names and the values for fields.
    If annotate_fields is false, the result string will be more compact by
    omitting unambiguous field names.  Attributes such as line
    numbers and column offsets are not dumped by default.  If this is wanted,
    include_attributes can be set to true.  If indent is a non-negative
    integer or string, then the tree will be pretty-printed with that indent
    level. None (the default) selects the single line representation.
    ,
allsimplesimple%s(%s%s)[%s%s]expected AST, got %rcopy_locationnew_nodeold_node
    Copy source location (`lineno`, `col_offset`, `end_lineno`, and `end_col_offset`
    attributes) from *old_node* to *new_node* if possible, and return *new_node*.
    col_offsetend_fix_missing_locations
    When you compile a node tree with compile(), the compiler expects lineno and
    col_offset attributes for every node that supports them.  This is rather
    tedious to fill in for generated nodes, so this helper adds these attributes
    recursively where not already set, by setting them to the values of the
    parent node.  It works recursively starting at *node*.
    iter_child_nodesincrement_lineno
    Increment the line number and end line number of each node in the tree
    starting at *node* by *n*. This is useful to "move code" to a different
    location in a file.
    walkiter_fields
    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``
    that is present on *node*.
    
    Yield all direct child nodes of *node*, that is, all fields that are nodes
    and all items of fields that are lists of nodes.
    get_docstringclean
    Return the docstring for the given node or None if no docstring can
    be found.  If the node provided does not have docstrings a TypeError
    will be raised.

    If *clean* is `True`, all tabs are expanded to spaces and any whitespace
    that can be uniformly removed from the second line onwards is removed.
    %r can't have docstringsStrcleandoc_splitlines_no_ffSplit a string into lines ignoring form feed and other chars.

    This mimics how the Python parser splits source code.
    next_line_pad_whitespaceReplace all chars except '\f\t' in a line with spaces.	get_source_segmentpaddedGet source code segment of the *source* that generated *node*.

    If some location information (`lineno`, `end_lineno`, `col_offset`,
    or `end_col_offset`) is missing, return None.

    If *padded* is `True`, the first line of a multi-line statement will
    be padded with spaces to match its original position.
    
    Recursively yield all descendant nodes in the tree starting at *node*
    (including *node* itself), in no specified order.  This is useful if you
    only want to modify nodes in place and don't care about the context.
    todoNodeVisitor
    A node visitor base class that walks the abstract syntax tree and calls a
    visitor function for every node found.  This function may return a value
    which is forwarded by the `visit` method.

    This class is meant to be subclassed, with the subclass adding visitor
    methods.

    Per default the visitor functions for the nodes are ``'visit_'`` +
    class name of the node.  So a `TryFinally` node visit function would
    be `visit_TryFinally`.  This behavior can be changed by overriding
    the `visit` method.  If no visitor function exists for a node
    (return value `None`) the `generic_visit` visitor is used instead.

    Don't use the `NodeVisitor` if you want to apply changes to nodes during
    traversing.  For this a special visitor exists (`NodeTransformer`) that
    allows modifications.
    visitVisit a node.visit_generic_visitvisitorCalled if no explicit visitor function exists for a node.visit_Constant_const_node_type_names is deprecated; add visit_ConstantNodeTransformer
    A :class:`NodeVisitor` subclass that walks the abstract syntax tree and
    allows modification of nodes.

    The `NodeTransformer` will walk the AST and use the return value of the
    visitor methods to replace or remove the old node.  If the return value of
    the visitor method is ``None``, the node will be removed from its location,
    otherwise it is replaced with the return value.  The return value may be the
    original node in which case no replacement takes place.

    Here is an example transformer that rewrites all occurrences of name lookups
    (``foo``) to ``data['foo']``::

       class RewriteName(NodeTransformer):

           def visit_Name(self, node):
               return Subscript(
                   value=Name(id='data', ctx=Load()),
                   slice=Constant(value=node.id),
                   ctx=node.ctx
               )

    Keep in mind that if the node you're operating on has child nodes you must
    either transform the child nodes yourself or call the :meth:`generic_visit`
    method for the node first.

    For nodes that were part of a collection of statements (that applies to all
    statement nodes), the visitor may also return a list of nodes rather than
    just a single node.

    Usually you use the transformer like this::

       node = YourTransformer().visit(node)
    new_values_getterDeprecated. Use value instead._setter_ABCDeprecated AST node class. Use ast.Constant instead_const_types_const_types_not_new got multiple values for argument NumBytesNameConstantDeprecated AST node class.IndexDeprecated AST node class. Use the index value directly instead.ExtSliceDeprecated AST node class. Use ast.Tuple instead._dims_getterDeprecated. Use elts instead._dims_setterSuiteDeprecated AST node class.  Unused in Python 3.AugLoadAugStoreParam1e_INFSTR_PrecedencePrecedence table that originated from python grammar.TUPLEYIELDTESTORANDNOTCMPEXPRBORBXORBANDSHIFTARITHTERMFACTORPOWERAWAITATOM_SINGLE_QUOTES_MULTI_QUOTES_ALL_QUOTES_UnparserMethods in this class recursively traverse an AST and
    output source code for the abstract syntax; original formatting
    is disregarded._avoid_backslashes_source_buffer_precedences_type_ignoresinterleaveinterCall f on each item in seq, calling inter() in between.items_viewtraverserTraverse and separate the given *items* with a comma and append it to
        the buffer. If *items* is a single item sequence, a trailing comma
        will be added.maybe_newlineAdds a newline if it isn't the start of generated sourceIndent a piece of text and append it, according to the current
        indentation levelAppend a piece of textbuffer_writerA context manager for preparing the source for blocks. It adds
        the character':', increases the indentation on enter and decreases
        the indentation on exit. If *extra* is given, it will be directly
        appended after the colon character.
        delimitA context manager for preparing the source for expressions. It adds
        *start* to the buffer and enters, after exit it adds *end*.delimit_ifrequire_parensprecedenceShortcut to adding precedence related parensget_precedenceset_precedenceget_raw_docstringIf a docstring node is found in the body of the *node* parameter,
        return that docstring node, None otherwise.

        Logic mirrored from ``_PyAST_GetDocString``.get_type_comment # type: traverseOutputs a source code string that, if converted back to an ast
        (using ast.parse) will generate an AST equivalent to *node*_write_docstring_and_traverse_bodydocstring_write_docstringvisit_Moduletype_ignoresvisit_FunctionType -> visit_Exprvisit_NamedExpr := visit_Importvisit_ImportFromfrom  import visit_Assigntargets = visit_AugAssignbinop= visit_AnnAssignvisit_Returnreturnvisit_Passpassvisit_Breakbreakvisit_Continuecontinuevisit_Deletedel visit_Assertassert visit_Globalglobal visit_Nonlocalnonlocal visit_Awaitawaitvisit_Yieldyieldvisit_YieldFromyield from Node can't be used without a value attribute.visit_RaiseNode can't use cause without an exception. from visit_Trytryorelsefinalbodyfinallyvisit_ExceptHandlerexcept as visit_ClassDefdecodecorator_listclass commavisit_FunctionDef_function_helperdefvisit_AsyncFunctionDefasync deffill_suffixdef_strvisit_For_for_helperfor visit_AsyncForasync for visit_Ifif elif visit_Whilewhile visit_Withwith visit_AsyncWithasync with _str_literal_helperquote_typesescape_special_whitespaceHelper for writing string literals, minimizing escapes.
        Returns the tuple (string literal to write, possible quote types).
        escape_charunicode_escapeescaped_stringpossible_quotes_write_str_avoiding_backslashesWrite string literal value with a best effort attempt to avoid backslashes.quote_typevisit_JoinedStr_fstring_JoinedStr_fstring_new_bufferis_constantvisit_FormattedValue_fstring_FormattedValue_fstring_ConstantConstants inside JoinedStr should be a string.unparserUnable to avoid backslash in f-string expression partsraUnknown f-string conversion.visit_Name_write_constantvisit_Listvisit_ListCompgenvisit_GeneratorExpvisit_SetCompvisit_DictCompvisit_comprehensionis_async async for  for ifsif_clause if visit_IfExp else visit_Set{*()}visit_Dictwrite_key_value_pairwrite_item**visit_Tuple~notunopunop_precedencevisit_UnaryOpoperator_precedence<<>>binop_precedencebinop_rassocvisit_BinOpleft_precedenceright_precedence<=>=isis notnot incmpopsvisit_Comparecomparatorsorboolopsboolop_precedencevisit_BoolOpincreasing_level_traversevisit_Attributevisit_Callvisit_Subscriptis_simple_tupleslice_valuevisit_Starredvisit_Ellipsisvisit_Slicevisit_Matchmatch subjectcasesvisit_argvisit_argumentsposonlyargsall_args, /kwonlyargskw_defaultsvisit_keywordvisit_Lambdalambda visit_aliasvisit_withitemcontext_exprvisit_match_casecase visit_MatchValuevisit_MatchSingletonvisit_MatchSequencevisit_MatchStarvisit_MatchMappingwrite_key_pattern_pairvisit_MatchClasskwd_attrswrite_attr_patternkwd_patternsvisit_MatchAsvisit_MatchOrunparseast_objargparsepython -m astinfilethe file to parse; defaults to stdin-m--modesinglefunc_typespecify what kind of code must be parsed--no-type-commentsdon't add information about type comments-a--include-attributesinclude attributes such as line numbers and column offsets'include attributes such as line numbers and ''column offsets'-i--indentindentation of nodes (number of spaces)no_type_comments# Should be a 2-tuple.# Else it should be an int giving the minor version for 3.x.# end_lineno and end_col_offset are optional attributes, and they# should be copied whether the value is None or not.# TypeIgnore is a special case where lineno is not an attribute# but rather a field of the node itself.# Keep \r\n together# If the ast module is loaded more than once, only add deprecated methods once# The following code is for backward compatibility.# It will be removed in future.# arbitrary keyword arguments are accepted# should be before int# Large float and imaginary literals get turned into infinities in the AST.# We unparse those infinities to INFSTR.# 'yield', 'yield from'# 'if'-'else', 'lambda'# 'or'# 'and'# 'not'# '<', '>', '==', '>=', '<=', '!=',# 'in', 'not in', 'is', 'is not'# '|'# '^'# '&'# '<<', '>>'# '+', '-'# '*', '@', '/', '%', '//'# unary '+', '-', '~'# '**'# 'await'# Note: as visit() resets the output text, do NOT rely on# NodeVisitor.generic_visit to handle any nodes (as it calls back in to# the subclass visit() method, which resets self._source to an empty list)# collapse nested ifs into equivalent elifs.# final else# \n and \t are non-printable, but we only escape them if# escape_special_whitespace is True# Always escape backslashes and other non-printable characters# If there aren't any possible_quotes, fallback to using repr# on the original string. Try to use a quote from quote_types,# e.g., so that we use triple quotes for docstrings.# Sort so that we prefer '''"''' over """\""""# If we're using triple quotes and we'd need to escape a final# quote, escape it# If we don't need to avoid backslashes globally (i.e., we only need# to avoid them inside FormattedValues), it's cosmetically preferred# to use escaped whitespace. That is, it's preferred to use backslashes# for cases like: f"{x}\n". To accomplish this, we keep track of what# in our buffer corresponds to FormattedValues and what corresponds to# Constant parts of the f-string, and allow escapes accordingly.# Repeatedly narrow down the list of possible quote_types# Separate pair of opening brackets as "{ {"# Substitute overflowing decimal literal for AST infinities,# and inf - inf for NaNs.# `{}` would be interpreted as a dictionary literal, and# `set` might be shadowed. Thus:# for dictionary unpacking operator in dicts {**{'y': 2}}# see PEP 448 for details# factor prefixes (+, -, ~) shouldn't be seperated# from the value they belong, (e.g: +1 instead of + 1)# Special case: 3.__abs__() is a syntax error, so if node.value# is an integer literal then we need to either parenthesize# it or add an extra space to get 3 .__abs__().# when unparsing a non-empty tuple, the parentheses can be safely# omitted if there aren't any elements that explicitly requires# parentheses (such as starred expressions).# normal arguments# varargs, or bare '*' if no varargs but keyword-only arguments present# keyword-only arguments# kwargsb'
    ast
    ~~~

    The `ast` module helps Python applications to process trees of the Python
    abstract syntax grammar.  The abstract syntax itself might change with
    each Python release; this module helps to find out programmatically what
    the current grammar looks like and allows modifications of it.

    An abstract syntax tree can be generated by passing `ast.PyCF_ONLY_AST` as
    a flag to the `compile()` builtin function or by using the `parse()`
    function from this module.  The result will be a tree of objects whose
    classes all inherit from `ast.AST`.

    A modified abstract syntax tree can be compiled into a Python code object
    using the built-in `compile()` function.

    Additionally various helper functions are provided that make working with
    the trees simpler.  The main intention of the helper functions and this
    module in general is to provide an easy to use interface for libraries
    that work tightly with the python syntax (template engines for example).


    :copyright: Copyright 2008 by Armin Ronacher.
    :license: Python License.
'u'
    ast
    ~~~

    The `ast` module helps Python applications to process trees of the Python
    abstract syntax grammar.  The abstract syntax itself might change with
    each Python release; this module helps to find out programmatically what
    the current grammar looks like and allows modifications of it.

    An abstract syntax tree can be generated by passing `ast.PyCF_ONLY_AST` as
    a flag to the `compile()` builtin function or by using the `parse()`
    function from this module.  The result will be a tree of objects whose
    classes all inherit from `ast.AST`.

    A modified abstract syntax tree can be compiled into a Python code object
    using the built-in `compile()` function.

    Additionally various helper functions are provided that make working with
    the trees simpler.  The main intention of the helper functions and this
    module in general is to provide an easy to use interface for libraries
    that work tightly with the python syntax (template engines for example).


    :copyright: Copyright 2008 by Armin Ronacher.
    :license: Python License.
'b'
    Parse the source into an AST node.
    Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
    Pass type_comments=True to get back type comments where the syntax allows.
    'u'
    Parse the source into an AST node.
    Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
    Pass type_comments=True to get back type comments where the syntax allows.
    'b'
    Evaluate an expression node or a string containing only a Python
    expression.  The string or node provided may only consist of the following
    Python literal structures: strings, bytes, numbers, tuples, lists, dicts,
    sets, booleans, and None.

    Caution: A complex expression can overflow the C stack and cause a crash.
    'u'
    Evaluate an expression node or a string containing only a Python
    expression.  The string or node provided may only consist of the following
    Python literal structures: strings, bytes, numbers, tuples, lists, dicts,
    sets, booleans, and None.

    Caution: A complex expression can overflow the C stack and cause a crash.
    'b'eval'u'eval'b'malformed node or string'u'malformed node or string'b'lineno'b' on line 'u' on line 'b'
    Return a formatted dump of the tree in node.  This is mainly useful for
    debugging purposes.  If annotate_fields is true (by default),
    the returned string will show the names and the values for fields.
    If annotate_fields is false, the result string will be more compact by
    omitting unambiguous field names.  Attributes such as line
    numbers and column offsets are not dumped by default.  If this is wanted,
    include_attributes can be set to true.  If indent is a non-negative
    integer or string, then the tree will be pretty-printed with that indent
    level. None (the default) selects the single line representation.
    'u'
    Return a formatted dump of the tree in node.  This is mainly useful for
    debugging purposes.  If annotate_fields is true (by default),
    the returned string will show the names and the values for fields.
    If annotate_fields is false, the result string will be more compact by
    omitting unambiguous field names.  Attributes such as line
    numbers and column offsets are not dumped by default.  If this is wanted,
    include_attributes can be set to true.  If indent is a non-negative
    integer or string, then the tree will be pretty-printed with that indent
    level. None (the default) selects the single line representation.
    'b',
'u',
'b'%s(%s%s)'u'%s(%s%s)'b'[%s%s]'u'[%s%s]'b'expected AST, got %r'u'expected AST, got %r'b'
    Copy source location (`lineno`, `col_offset`, `end_lineno`, and `end_col_offset`
    attributes) from *old_node* to *new_node* if possible, and return *new_node*.
    'u'
    Copy source location (`lineno`, `col_offset`, `end_lineno`, and `end_col_offset`
    attributes) from *old_node* to *new_node* if possible, and return *new_node*.
    'b'col_offset'b'end_lineno'b'end_col_offset'b'end_'u'end_'b'
    When you compile a node tree with compile(), the compiler expects lineno and
    col_offset attributes for every node that supports them.  This is rather
    tedious to fill in for generated nodes, so this helper adds these attributes
    recursively where not already set, by setting them to the values of the
    parent node.  It works recursively starting at *node*.
    'u'
    When you compile a node tree with compile(), the compiler expects lineno and
    col_offset attributes for every node that supports them.  This is rather
    tedious to fill in for generated nodes, so this helper adds these attributes
    recursively where not already set, by setting them to the values of the
    parent node.  It works recursively starting at *node*.
    'b'
    Increment the line number and end line number of each node in the tree
    starting at *node* by *n*. This is useful to "move code" to a different
    location in a file.
    'u'
    Increment the line number and end line number of each node in the tree
    starting at *node* by *n*. This is useful to "move code" to a different
    location in a file.
    'b'
    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``
    that is present on *node*.
    'u'
    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``
    that is present on *node*.
    'b'
    Yield all direct child nodes of *node*, that is, all fields that are nodes
    and all items of fields that are lists of nodes.
    'u'
    Yield all direct child nodes of *node*, that is, all fields that are nodes
    and all items of fields that are lists of nodes.
    'b'
    Return the docstring for the given node or None if no docstring can
    be found.  If the node provided does not have docstrings a TypeError
    will be raised.

    If *clean* is `True`, all tabs are expanded to spaces and any whitespace
    that can be uniformly removed from the second line onwards is removed.
    'u'
    Return the docstring for the given node or None if no docstring can
    be found.  If the node provided does not have docstrings a TypeError
    will be raised.

    If *clean* is `True`, all tabs are expanded to spaces and any whitespace
    that can be uniformly removed from the second line onwards is removed.
    'b'%r can't have docstrings'u'%r can't have docstrings'b'Split a string into lines ignoring form feed and other chars.

    This mimics how the Python parser splits source code.
    'u'Split a string into lines ignoring form feed and other chars.

    This mimics how the Python parser splits source code.
    'b'Replace all chars except '\f\t' in a line with spaces.'u'Replace all chars except '\f\t' in a line with spaces.'b'	'u'	'b'Get source code segment of the *source* that generated *node*.

    If some location information (`lineno`, `end_lineno`, `col_offset`,
    or `end_col_offset`) is missing, return None.

    If *padded* is `True`, the first line of a multi-line statement will
    be padded with spaces to match its original position.
    'u'Get source code segment of the *source* that generated *node*.

    If some location information (`lineno`, `end_lineno`, `col_offset`,
    or `end_col_offset`) is missing, return None.

    If *padded* is `True`, the first line of a multi-line statement will
    be padded with spaces to match its original position.
    'b'
    Recursively yield all descendant nodes in the tree starting at *node*
    (including *node* itself), in no specified order.  This is useful if you
    only want to modify nodes in place and don't care about the context.
    'u'
    Recursively yield all descendant nodes in the tree starting at *node*
    (including *node* itself), in no specified order.  This is useful if you
    only want to modify nodes in place and don't care about the context.
    'b'
    A node visitor base class that walks the abstract syntax tree and calls a
    visitor function for every node found.  This function may return a value
    which is forwarded by the `visit` method.

    This class is meant to be subclassed, with the subclass adding visitor
    methods.

    Per default the visitor functions for the nodes are ``'visit_'`` +
    class name of the node.  So a `TryFinally` node visit function would
    be `visit_TryFinally`.  This behavior can be changed by overriding
    the `visit` method.  If no visitor function exists for a node
    (return value `None`) the `generic_visit` visitor is used instead.

    Don't use the `NodeVisitor` if you want to apply changes to nodes during
    traversing.  For this a special visitor exists (`NodeTransformer`) that
    allows modifications.
    'u'
    A node visitor base class that walks the abstract syntax tree and calls a
    visitor function for every node found.  This function may return a value
    which is forwarded by the `visit` method.

    This class is meant to be subclassed, with the subclass adding visitor
    methods.

    Per default the visitor functions for the nodes are ``'visit_'`` +
    class name of the node.  So a `TryFinally` node visit function would
    be `visit_TryFinally`.  This behavior can be changed by overriding
    the `visit` method.  If no visitor function exists for a node
    (return value `None`) the `generic_visit` visitor is used instead.

    Don't use the `NodeVisitor` if you want to apply changes to nodes during
    traversing.  For this a special visitor exists (`NodeTransformer`) that
    allows modifications.
    'b'Visit a node.'u'Visit a node.'b'visit_'u'visit_'b'Called if no explicit visitor function exists for a node.'u'Called if no explicit visitor function exists for a node.'b' is deprecated; add visit_Constant'u' is deprecated; add visit_Constant'b'
    A :class:`NodeVisitor` subclass that walks the abstract syntax tree and
    allows modification of nodes.

    The `NodeTransformer` will walk the AST and use the return value of the
    visitor methods to replace or remove the old node.  If the return value of
    the visitor method is ``None``, the node will be removed from its location,
    otherwise it is replaced with the return value.  The return value may be the
    original node in which case no replacement takes place.

    Here is an example transformer that rewrites all occurrences of name lookups
    (``foo``) to ``data['foo']``::

       class RewriteName(NodeTransformer):

           def visit_Name(self, node):
               return Subscript(
                   value=Name(id='data', ctx=Load()),
                   slice=Constant(value=node.id),
                   ctx=node.ctx
               )

    Keep in mind that if the node you're operating on has child nodes you must
    either transform the child nodes yourself or call the :meth:`generic_visit`
    method for the node first.

    For nodes that were part of a collection of statements (that applies to all
    statement nodes), the visitor may also return a list of nodes rather than
    just a single node.

    Usually you use the transformer like this::

       node = YourTransformer().visit(node)
    'u'
    A :class:`NodeVisitor` subclass that walks the abstract syntax tree and
    allows modification of nodes.

    The `NodeTransformer` will walk the AST and use the return value of the
    visitor methods to replace or remove the old node.  If the return value of
    the visitor method is ``None``, the node will be removed from its location,
    otherwise it is replaced with the return value.  The return value may be the
    original node in which case no replacement takes place.

    Here is an example transformer that rewrites all occurrences of name lookups
    (``foo``) to ``data['foo']``::

       class RewriteName(NodeTransformer):

           def visit_Name(self, node):
               return Subscript(
                   value=Name(id='data', ctx=Load()),
                   slice=Constant(value=node.id),
                   ctx=node.ctx
               )

    Keep in mind that if the node you're operating on has child nodes you must
    either transform the child nodes yourself or call the :meth:`generic_visit`
    method for the node first.

    For nodes that were part of a collection of statements (that applies to all
    statement nodes), the visitor may also return a list of nodes rather than
    just a single node.

    Usually you use the transformer like this::

       node = YourTransformer().visit(node)
    'b'Deprecated. Use value instead.'u'Deprecated. Use value instead.'b'Deprecated AST node class. Use ast.Constant instead'u'Deprecated AST node class. Use ast.Constant instead'b' got multiple values for argument 'u' got multiple values for argument 'b'NameConstant'u'NameConstant'b'Num'u'Num'b'Str'u'Str'b'Bytes'u'Bytes'b'Ellipsis'u'Ellipsis'b'Deprecated AST node class.'u'Deprecated AST node class.'b'Deprecated AST node class. Use the index value directly instead.'u'Deprecated AST node class. Use the index value directly instead.'b'Deprecated AST node class. Use ast.Tuple instead.'u'Deprecated AST node class. Use ast.Tuple instead.'b'dims'u'dims'b'Deprecated. Use elts instead.'u'Deprecated. Use elts instead.'b'Deprecated AST node class.  Unused in Python 3.'u'Deprecated AST node class.  Unused in Python 3.'b'1e'u'1e'b'Precedence table that originated from python grammar.'u'Precedence table that originated from python grammar.'b'"""'u'"""'b'''''u'''''b'Methods in this class recursively traverse an AST and
    output source code for the abstract syntax; original formatting
    is disregarded.'u'Methods in this class recursively traverse an AST and
    output source code for the abstract syntax; original formatting
    is disregarded.'b'Call f on each item in seq, calling inter() in between.'u'Call f on each item in seq, calling inter() in between.'b'Traverse and separate the given *items* with a comma and append it to
        the buffer. If *items* is a single item sequence, a trailing comma
        will be added.'u'Traverse and separate the given *items* with a comma and append it to
        the buffer. If *items* is a single item sequence, a trailing comma
        will be added.'b'Adds a newline if it isn't the start of generated source'u'Adds a newline if it isn't the start of generated source'b'Indent a piece of text and append it, according to the current
        indentation level'u'Indent a piece of text and append it, according to the current
        indentation level'b'Append a piece of text'u'Append a piece of text'b'A context manager for preparing the source for blocks. It adds
        the character':', increases the indentation on enter and decreases
        the indentation on exit. If *extra* is given, it will be directly
        appended after the colon character.
        'u'A context manager for preparing the source for blocks. It adds
        the character':', increases the indentation on enter and decreases
        the indentation on exit. If *extra* is given, it will be directly
        appended after the colon character.
        'b'A context manager for preparing the source for expressions. It adds
        *start* to the buffer and enters, after exit it adds *end*.'u'A context manager for preparing the source for expressions. It adds
        *start* to the buffer and enters, after exit it adds *end*.'b'Shortcut to adding precedence related parens'u'Shortcut to adding precedence related parens'b'If a docstring node is found in the body of the *node* parameter,
        return that docstring node, None otherwise.

        Logic mirrored from ``_PyAST_GetDocString``.'u'If a docstring node is found in the body of the *node* parameter,
        return that docstring node, None otherwise.

        Logic mirrored from ``_PyAST_GetDocString``.'b' # type: 'u' # type: 'b'Outputs a source code string that, if converted back to an ast
        (using ast.parse) will generate an AST equivalent to *node*'u'Outputs a source code string that, if converted back to an ast
        (using ast.parse) will generate an AST equivalent to *node*'b' -> 'u' -> 'b' := 'u' := 'b'from 'u'from 'b' import 'u' import 'b' = 'u' = 'b'= 'u'= 'b'return'u'return'b'pass'u'pass'b'break'u'break'b'continue'u'continue'b'del 'u'del 'b'assert 'u'assert 'b'global 'u'global 'b'nonlocal 'u'nonlocal 'b'await'u'await'b'yield'u'yield'b'yield from 'u'yield from 'b'Node can't be used without a value attribute.'u'Node can't be used without a value attribute.'b'Node can't use cause without an exception.'u'Node can't use cause without an exception.'b' from 'u' from 'b'try'u'try'b'finally'u'finally'b'except'u'except'b' as 'u' as 'b'class 'u'class 'b'def'u'def'b'async def'u'async def'b'for 'u'for 'b'async for 'u'async for 'b'if 'u'if 'b'elif 'u'elif 'b'while 'u'while 'b'with 'u'with 'b'async with 'u'async with 'b'Helper for writing string literals, minimizing escapes.
        Returns the tuple (string literal to write, possible quote types).
        'u'Helper for writing string literals, minimizing escapes.
        Returns the tuple (string literal to write, possible quote types).
        'b'unicode_escape'u'unicode_escape'b'Write string literal value with a best effort attempt to avoid backslashes.'u'Write string literal value with a best effort attempt to avoid backslashes.'b'_fstring_'u'_fstring_'b'Constants inside JoinedStr should be a string.'u'Constants inside JoinedStr should be a string.'b'Unable to avoid backslash in f-string expression part'u'Unable to avoid backslash in f-string expression part'b'sra'u'sra'b'Unknown f-string conversion.'u'Unknown f-string conversion.'b' async for 'u' async for 'b' for 'u' for 'b' if 'u' if 'b' else 'u' else 'b'{*()}'u'{*()}'b'**'u'**'b'~'u'~'b'Invert'b'not'u'not'b'Not'b'UAdd'b'USub'b'Add'b'Sub'b'Mult'b'MatMult'b'Div'b'Mod'b'<<'u'<<'b'LShift'b'>>'u'>>'b'RShift'b'BitOr'b'BitXor'b'BitAnd'b'FloorDiv'b'Pow'u'=='b'Eq'b'NotEq'b'Lt'b'<='u'<='b'LtE'b'Gt'b'>='u'>='b'GtE'b'is'u'is'b'Is'b'is not'u'is not'b'IsNot'b'In'b'not in'u'not in'b'NotIn'b'And'b'or'u'or'b'Or'b'match 'u'match 'b', /'u', /'b'lambda 'u'lambda 'b'case 'u'case 'b'python -m ast'u'python -m ast'b'infile'u'infile'b'the file to parse; defaults to stdin'u'the file to parse; defaults to stdin'b'-m'u'-m'b'--mode'u'--mode'b'single'u'single'b'func_type'u'func_type'b'specify what kind of code must be parsed'u'specify what kind of code must be parsed'b'--no-type-comments'u'--no-type-comments'b'don't add information about type comments'u'don't add information about type comments'b'-a'u'-a'b'--include-attributes'u'--include-attributes'b'include attributes such as line numbers and column offsets'u'include attributes such as line numbers and column offsets'b'-i'u'-i'b'--indent'u'--indent'b'indentation of nodes (number of spaces)'u'indentation of nodes (number of spaces)'runTestmethodName_asyncioTestLoop_asyncioCallsQueueasyncSetUpasyncTearDownaddAsyncCleanup_callSetUpsetUp_callAsync_callTestMethod_callMaybeAsync_callTearDowntearDown_callCleanupasyncio test loop is not initializedisawaitable returned non-awaitablecreate_futurerun_until_complete_asyncioLoopRunnerqueryawaitable_setupAsyncioLoopasyncio test loop already initializednew_event_looploopset_event_loopset_debugcreate_task_asyncioCallsTask_tearDownAsyncioLoopall_tasksto_canceltaskgatherreturn_exceptionscall_exception_handlerunhandled exception during test shutdownshutdown_asyncgensshutdown_default_executor# Names intentionally have a long prefix# to reduce a chance of clashing with user-defined attributes# from inherited test case# The class doesn't call loop.run_until_complete(self.setUp()) and family# but uses a different approach:# 1. create a long-running task that reads self.setUp()#    awaitable from queue along with a future# 2. await the awaitable object passing in and set the result#    into the future object# 3. Outer code puts the awaitable and the future object into a queue#    with waiting for the future# The trick is necessary because every run_until_complete() call# creates a new task with embedded ContextVar context.# To share contextvars between setUp(), test and tearDown() we need to execute# them inside the same task.# Note: the test case modifies event loop policy if the policy was not instantiated# yet.# asyncio.get_event_loop_policy() creates a default policy on demand but never# returns None# I believe this is not an issue in user level tests but python itself for testing# should reset a policy in every test module# by calling asyncio.set_event_loop_policy(None) in tearDownModule()# A trivial trampoline to addCleanup()# the function exists because it has a different semantics# and signature:# addCleanup() accepts regular functions# but addAsyncCleanup() accepts coroutines# We intentionally don't add inspect.iscoroutinefunction() check# for func argument because there is no way# to check for async function reliably:# 1. It can be "async def func()" itself# 2. Class can implement "async def __call__()" method# 3. Regular "def func()" that returns awaitable object# cancel all tasks# shutdown asyncgens# Prevent our executor environment from leaking to future tests.b'runTest'u'runTest'b'asyncio test loop is not initialized'u'asyncio test loop is not initialized'b' returned non-awaitable'u' returned non-awaitable'b'asyncio test loop already initialized'u'asyncio test loop already initialized'b'unhandled exception during test shutdown'u'unhandled exception during test shutdown'b'task'u'task'u'unittest.async_case'u'async_case'u'allow programmer to define multiple exit functions to be executed
upon normal program termination.

Two public functions, register and unregister, are defined.
'_clear_ncallbacks_run_exitfuncsbotocore.docs.paramsResponseParamsDocumenterget_identifier_descriptionResourceShapeDocumenterresource-shapeEVENT_NAMEdocument_attributeattr_modelstart_sphinx_py_attrdocument_paramsdocument_identifieridentifier_model*(string)* document_referencereference_model(:py:class:``) reference_typeinclude_doc_stringThe related  if set, otherwise ``None``.# Note that an attribute may have one, may have many, or may have no# operations that back the resource's shape. So we just set the# operation_name to the resource name if we ever to hook in and modify# a particular attribute.b'resource-shape'u'resource-shape'b'*(string)* 'u'*(string)* 'b'(:py:class:`'u'(:py:class:`'b'`) 'u'`) 'b'The related 'u'The related 'b' if set, otherwise ``None``.'u' if set, otherwise ``None``.'u'boto3.docs.attr'u'docs.attr'hmacformatdatehashlibbotocore.compatHAS_CRTHTTPHeadersencodebytesensure_unicodeparse_qsurlspliturlunsplitNoAuthTokenErrorNoCredentialsErroris_valid_ipv6_endpoint_urlnormalize_url_pathpercent_encode_sequenceMD5_AVAILABLEe3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855EMPTY_SHA256_HASHPAYLOAD_BUFFER%Y-%m-%dT%H:%M:%SZISO8601%Y%m%dT%H%M%SZSIGV4_TIMESTAMPexpectuser-agentx-amzn-trace-idSIGNED_HEADERS_BLACKLISTUNSIGNED-PAYLOADUNSIGNED_PAYLOADSTREAMING-UNSIGNED-PAYLOAD-TRAILERSTREAMING_UNSIGNED_PAYLOAD_TRAILER_host_from_urlurl_partshostname443default_ports%s:%d_get_body_as_dictBaseSignerREQUIRES_REGIONREQUIRES_TOKENadd_authTokenSigner
    Signers that expect an authorization token to perform the authorization
    SigV2Auth
    Sign a request with Signature V2.
    calc_signatureCalculating signature using v2 auth.string_to_signsecret_keydigestmodlhmacpairsSignaturequoted_key-_~qsString to sign: %sb64access_keyAWSAccessKeyIdSignatureVersionHmacSHA256SignatureMethodgmtimeTimestampSecurityTokenSigV3AuthDateusegmtX-Amz-Security-Tokennew_hmacencoded_signatureAWS3-HTTPS AWSAccessKeyId=,Algorithm=HmacSHA256,Signature=",""Algorithm=HmacSHA256,Signature="X-Amzn-AuthorizationSigV4Auth
    Sign a request with Signature V4.
    _region_name_service_nameheaders_to_sign
        Select the headers from the request that need to be included
        in the StringToSign.
        header_maplnamecanonical_query_string_canonical_query_string_params_canonical_query_string_urlkey_val_pairs-_.~sorted_key_valscanonical_headers
        Return the headers that need to be included in the StringToSign
        in their canonical form by converting all header keys to lower
        case, sorting them in alphabetical order and then joining
        them into a string, separated by newlines.
        sorted_header_names_header_valuesigned_headers_is_streaming_checksum_payloadchecksumchecksum_contextrequest_algorithmtrailer_should_sha256_sign_payloadrequest_bodyread_chunksizehex_checksumpayload_signing_enabledcanonical_requestcr_normalize_url_pathX-Amz-Content-SHA256body_checksum/~normalized_pathscopeaws4_requestcredential_scope
        Return the canonical StringToSign as well as a dict
        containing the original version of all headers that
        were included in the StringToSign.
        AWS4-HMAC-SHA256AWS4k_datek_regionk_servicek_signingdatetime_now_modify_request_before_signingCalculating signature using v4 auth.CanonicalRequest:
%sStringToSign:
%sSignature:
%s_inject_signature_to_requestAWS4-HMAC-SHA256 Credential=%sauth_strSignedHeaders=Signature=%sAuthorization_set_necessary_date_headersdatetime_timestampX-Amz-DateS3SigV4Authsign_payloadContent-MD5checksum_headerhas_streaming_inputSigV4QueryAuthDEFAULT_EXPIRESexpires_expirescontent_typeapplication/x-www-form-urlencoded; charset=utf-8blacklisted_content_typeX-Amz-AlgorithmX-Amz-CredentialX-Amz-ExpiresX-Amz-SignedHeadersauth_paramskeep_blank_valuesquery_string_partsquery_dictoperation_paramsnew_query_stringnew_url_parts&X-Amz-Signature=%sS3SigV4QueryAuthS3 SigV4 auth using query parameters.

    This signer will sign a request using query parameters and signature
    version 4, i.e a "presigned url" signer.

    Based off of:

    http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html

    S3SigV4PostAuth
    Presigns a s3 post

    Implementation doc here:
    http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-UsingHTTPPOST.html
    s3-presign-post-fieldsconditionss3-presign-post-policyx-amz-algorithmx-amz-credentialx-amz-datex-amz-security-tokenx-amz-signatureHmacV1AuthaccelerateaclcorsdefaultObjectAclpartNumberrequestPaymenttorrentversioningversionIdwebsiteuploadsuploadIdresponse-content-typeresponse-content-languageresponse-expiresresponse-cache-controlresponse-content-dispositionresponse-content-encodinglifecycletaggingstorageClassnotificationreplicationanalyticsmetricsinventoryselect-typeobject-lockQSAOfInterestsign_stringcanonical_standard_headerscontent-md5interesting_headershoi_get_dateihlkcanonical_custom_headerscustom_headersx-amz-sorted_header_keysunquote_v
        TODO: Do we need this?
        canonical_resourceauth_pathqsacanonical_stringcsget_signatureCalculating signature using hmacv1 auth.HTTP request method: %s_inject_signatureAWS auth_headerHmacV1QueryAuth
    Generates a presigned request for s3.

    Spec from this document:

    http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html
    #RESTAuthenticationQueryStringAuth

    header_keyExpiresHmacV1PostAuth
    Generates a presigned post for s3.

    Spec from this document:

    http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingHTTPPOST.html
    BearerAuth
    Performs bearer token authorization by placing the bearer token in the
    Authorization header as specified by Section 2.1 of RFC 6750.

    https://datatracker.ietf.org/doc/html/rfc6750#section-2.1
    Bearer v2v3v3httpss3-querys3-presign-posts3v4-presign-postbearerAUTH_TYPE_MAPSbotocore.crt.authCRT_AUTH_TYPE_MAPS# Imports for backwards compatibility# This is the buffer size used when calculating sha256 checksums.# Experimenting with various buffer sizes showed that this value generally# gave the best result (in terms of performance).# Given URL, derive value for host header. Ensure that value:# 1) is lowercase# 2) excludes port, if it was the default port# 3) excludes userinfo# urlsplit's hostname is always lowercase# For query services, request.data is form-encoded and is already a# dict, but for other services such as rest-json it could be a json# string or bytes. In those cases we attempt to load the data as a# dict.# Any previous signature should not be a part of this# one, so we skip that particular key. This prevents# issues during retries.# The auth handler is the last thing called in the# preparation phase of a prepared request.# Because of this we have to parse the query params# from the request body so we can update them with# the sigv2 auth params.# POST# GET# We initialize these value here so the unit tests can have# valid values.  But these will get overriden in ``add_auth``# later for real requests.# TODO: We should set the host ourselves, instead of relying on our# HTTP client to set it for us.# The query string can come from two parts.  One is the# params attribute of the request.  The other is from the request# url (in which case we have to re-split the url into its components# and parse out the query string component).# [(key, value), (key2, value2)]# Sort by the URI-encoded key names, and in the case of# repeated keys, then sort by the value.# From the sigv4 docs:# Lowercase(HeaderName) + ':' + Trimall(HeaderValue)# The Trimall function removes excess white space before and after# values, and converts sequential spaces to a single space.# When payload signing is disabled, we use this static string in# place of the payload checksum.# The request serialization has ensured that# request.body is a bytes() type.# Payloads will always be signed over insecure connections.# Certain operations may have payload signing disabled by default.# Since we don't have access to the operation model, we pass in this# bit of metadata through the request context.# This could be a retry.  Make sure the previous# authorization header is removed first.# The spec allows for either the Date _or_ the X-Amz-Date value to be# used so we check both.  If there's a Date header, we use the date# header.  Otherwise we use the X-Amz-Date header.# S3 allows optional body signing, so to minimize the performance# impact, we opt to not SHA256 sign the body on streaming uploads,# provided that we're on https.# The config could be None if it isn't set, or if the customer sets it# to None.# The explicit configuration takes precedence over any implicit# configuration.# We require that both a checksum be present and https be enabled# to implicitly disable body signing. The combination of TLS and# a checksum is sufficiently secure and durable for us to be# confident in the request without body signing.# If the input is streaming we disable body signing by default.# If the S3-specific checks had no results, delegate to the generic# checks.# For S3, we do not normalize the path.# We automatically set this header, so if it's the auto-set value we# want to get rid of it since it doesn't make sense for presigned urls.# Note that we're not including X-Amz-Signature.# From the docs: "The Canonical Query String must include all the query# parameters from the preceding table except for X-Amz-Signature.# Now parse the original query string to a dict, inject our new query# params, and serialize back to a query string.# parse_qs makes each value a list, but in our case we know we won't# have repeated keys so we know we have single element lists which we# can convert back to scalar values.# The spec is particular about this.  It *has* to be:# https://<endpoint>?<operation params>&<auth params># You can't mix the two types of params together, i.e just keep doing# new_query_params.update(op_params)# new_query_params.update(auth_params)# percent_encode_sequence(new_query_params)# We also need to move the body params into the query string. To# do this, we first have to convert it to a dict.# url_parts is a tuple (and therefore immutable) so we need to create# a new url_parts with the new query string.# <part>   - <index># scheme   - 0# netloc   - 1# path     - 2# query    - 3  <-- we're replacing this.# fragment - 4# Rather than calculating an "Authorization" header, for the query# param quth, we just append an 'X-Amz-Signature' param to the end# of the query string.# From the doc link above:# "You don't include a payload hash in the Canonical Request, because# when you create a presigned URL, you don't know anything about the# payload. Instead, you use a constant string "UNSIGNED-PAYLOAD".# Dump the base64 encoded policy into the fields dictionary.# List of Query String Arguments of Interest# don't include anything after the first ? in the resource...# unless it is one of the QSA of interest, defined above# NOTE:# The path in the canonical resource should always be the# full path including the bucket name, even for virtual-hosting# style addressing.  The ``auth_path`` keeps track of the full# path for the canonical resource and would be passed in if# the client was using virtual-hosting style.# We have to do this because request.headers is not# normal dictionary.  It has the (unintuitive) behavior# of aggregating repeated setattr calls for the same# key value.  For example:# headers['foo'] = 'a'; headers['foo'] = 'b'# list(headers) will print ['foo', 'foo'].# For query string requests, Expires is used instead of the# Date header.# We only want to include relevant headers in the query string.# These can be anything that starts with x-amz, is Content-MD5,# or is Content-Type.# Combine all of the identified headers into an encoded# query string# Create a new url with the presigned url.# If there was a pre-existing query string, we should# add that back before injecting the new query string.# Define v4 signers depending on if CRT is presentb'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'u'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855'b'%Y-%m-%dT%H:%M:%SZ'u'%Y-%m-%dT%H:%M:%SZ'b'%Y%m%dT%H%M%SZ'u'%Y%m%dT%H%M%SZ'b'expect'u'expect'b'user-agent'u'user-agent'b'x-amzn-trace-id'u'x-amzn-trace-id'b'UNSIGNED-PAYLOAD'u'UNSIGNED-PAYLOAD'b'STREAMING-UNSIGNED-PAYLOAD-TRAILER'u'STREAMING-UNSIGNED-PAYLOAD-TRAILER'b'%s:%d'u'%s:%d'b'add_auth'u'add_auth'b'
    Signers that expect an authorization token to perform the authorization
    'u'
    Signers that expect an authorization token to perform the authorization
    'b'
    Sign a request with Signature V2.
    'u'
    Sign a request with Signature V2.
    'b'Calculating signature using v2 auth.'u'Calculating signature using v2 auth.'b'Signature'u'Signature'b'-_~'u'-_~'b'String to sign: %s'u'String to sign: %s'b'AWSAccessKeyId'u'AWSAccessKeyId'b'SignatureVersion'u'SignatureVersion'b'HmacSHA256'u'HmacSHA256'b'SignatureMethod'u'SignatureMethod'b'Timestamp'u'Timestamp'b'SecurityToken'u'SecurityToken'b'Date'u'Date'b'X-Amz-Security-Token'u'X-Amz-Security-Token'b'AWS3-HTTPS AWSAccessKeyId='u'AWS3-HTTPS AWSAccessKeyId='b',Algorithm=HmacSHA256,Signature='u',Algorithm=HmacSHA256,Signature='b'X-Amzn-Authorization'u'X-Amzn-Authorization'b'
    Sign a request with Signature V4.
    'u'
    Sign a request with Signature V4.
    'b'
        Select the headers from the request that need to be included
        in the StringToSign.
        'u'
        Select the headers from the request that need to be included
        in the StringToSign.
        'b'-_.~'u'-_.~'b'
        Return the headers that need to be included in the StringToSign
        in their canonical form by converting all header keys to lower
        case, sorting them in alphabetical order and then joining
        them into a string, separated by newlines.
        'u'
        Return the headers that need to be included in the StringToSign
        in their canonical form by converting all header keys to lower
        case, sorting them in alphabetical order and then joining
        them into a string, separated by newlines.
        'b'checksum'u'checksum'b'request_algorithm'u'request_algorithm'b'trailer'u'trailer'b'seek'u'seek'b'payload_signing_enabled'u'payload_signing_enabled'b'X-Amz-Content-SHA256'u'X-Amz-Content-SHA256'b'/~'u'/~'b'aws4_request'u'aws4_request'b'
        Return the canonical StringToSign as well as a dict
        containing the original version of all headers that
        were included in the StringToSign.
        'u'
        Return the canonical StringToSign as well as a dict
        containing the original version of all headers that
        were included in the StringToSign.
        'b'AWS4-HMAC-SHA256'u'AWS4-HMAC-SHA256'b'AWS4'u'AWS4'b'Calculating signature using v4 auth.'u'Calculating signature using v4 auth.'b'CanonicalRequest:
%s'u'CanonicalRequest:
%s'b'StringToSign:
%s'u'StringToSign:
%s'b'Signature:
%s'u'Signature:
%s'b'AWS4-HMAC-SHA256 Credential=%s'u'AWS4-HMAC-SHA256 Credential=%s'b'SignedHeaders='u'SignedHeaders='b'Signature=%s'u'Signature=%s'b'Authorization'u'Authorization'b'X-Amz-Date'u'X-Amz-Date'b'Content-MD5'u'Content-MD5'b'has_streaming_input'u'has_streaming_input'b'application/x-www-form-urlencoded; charset=utf-8'u'application/x-www-form-urlencoded; charset=utf-8'b'X-Amz-Algorithm'u'X-Amz-Algorithm'b'X-Amz-Credential'u'X-Amz-Credential'b'X-Amz-Expires'u'X-Amz-Expires'b'X-Amz-SignedHeaders'u'X-Amz-SignedHeaders'b'&X-Amz-Signature=%s'u'&X-Amz-Signature=%s'b'S3 SigV4 auth using query parameters.

    This signer will sign a request using query parameters and signature
    version 4, i.e a "presigned url" signer.

    Based off of:

    http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html

    'u'S3 SigV4 auth using query parameters.

    This signer will sign a request using query parameters and signature
    version 4, i.e a "presigned url" signer.

    Based off of:

    http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html

    'b'
    Presigns a s3 post

    Implementation doc here:
    http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-UsingHTTPPOST.html
    'u'
    Presigns a s3 post

    Implementation doc here:
    http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-UsingHTTPPOST.html
    'b's3-presign-post-fields'u's3-presign-post-fields'b's3-presign-post-policy'u's3-presign-post-policy'b'conditions'u'conditions'b'x-amz-algorithm'u'x-amz-algorithm'b'x-amz-credential'u'x-amz-credential'b'x-amz-date'u'x-amz-date'b'x-amz-security-token'u'x-amz-security-token'b'policy'u'policy'b'x-amz-signature'u'x-amz-signature'b'accelerate'u'accelerate'b'acl'u'acl'b'cors'u'cors'b'defaultObjectAcl'u'defaultObjectAcl'b'logging'b'partNumber'u'partNumber'b'requestPayment'u'requestPayment'b'torrent'u'torrent'b'versioning'u'versioning'b'versionId'u'versionId'b'versions'u'versions'b'website'u'website'b'uploads'u'uploads'b'uploadId'u'uploadId'b'response-content-type'u'response-content-type'b'response-content-language'u'response-content-language'b'response-expires'u'response-expires'b'response-cache-control'u'response-cache-control'b'response-content-disposition'u'response-content-disposition'b'response-content-encoding'u'response-content-encoding'b'lifecycle'u'lifecycle'b'tagging'u'tagging'b'restore'u'restore'b'storageClass'u'storageClass'b'notification'u'notification'b'replication'u'replication'b'analytics'u'analytics'b'metrics'u'metrics'b'inventory'u'inventory'b'select-type'u'select-type'b'object-lock'u'object-lock'b'content-md5'u'content-md5'b'date'u'date'b'x-amz-'u'x-amz-'b'
        TODO: Do we need this?
        'u'
        TODO: Do we need this?
        'b'Calculating signature using hmacv1 auth.'u'Calculating signature using hmacv1 auth.'b'HTTP request method: %s'u'HTTP request method: %s'b'AWS 'u'AWS 'b'
    Generates a presigned request for s3.

    Spec from this document:

    http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html
    #RESTAuthenticationQueryStringAuth

    'u'
    Generates a presigned request for s3.

    Spec from this document:

    http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html
    #RESTAuthenticationQueryStringAuth

    'b'Expires'u'Expires'b'
    Generates a presigned post for s3.

    Spec from this document:

    http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingHTTPPOST.html
    'u'
    Generates a presigned post for s3.

    Spec from this document:

    http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingHTTPPOST.html
    'b'signature'u'signature'b'
    Performs bearer token authorization by placing the bearer token in the
    Authorization header as specified by Section 2.1 of RFC 6750.

    https://datatracker.ietf.org/doc/html/rfc6750#section-2.1
    'u'
    Performs bearer token authorization by placing the bearer token in the
    Authorization header as specified by Section 2.1 of RFC 6750.

    https://datatracker.ietf.org/doc/html/rfc6750#section-2.1
    'b'Bearer 'u'Bearer 'b'v2'u'v2'b'v3'u'v3'b'v3https'u'v3https'b's3-query'u's3-query'b's3-presign-post'u's3-presign-post'b's3v4-presign-post'u's3v4-presign-post'b'bearer'u'bearer'u'botocore.auth'u'auth'
requests.auth
~~~~~~~~~~~~~

This module contains the authentication handlers for Requests.
_internal_utilsparse_dict_headerapplication/x-www-form-urlencodedCONTENT_TYPE_FORM_URLENCODEDmultipart/form-dataCONTENT_TYPE_MULTI_PARTReturns a Basic Auth string.Non-string usernames will no longer be supported in Requests 3.0.0. Please convert the object you've passed in ({!r}) to a string or bytes object in the near future to avoid problems."Non-string usernames will no longer be supported in Requests ""3.0.0. Please convert the object you've passed in ({!r}) to ""a string or bytes object in the near future to avoid ""problems."Non-string passwords will no longer be supported in Requests 3.0.0. Please convert the object you've passed in ({!r}) to a string or bytes object in the near future to avoid problems."Non-string passwords will no longer be supported in Requests "Basic authstrAuthBaseBase class that all auth implementations derive fromAuth hooks must be callable.HTTPBasicAuthAttaches HTTP Basic Authentication to the given Request object.HTTPProxyAuthAttaches HTTP Proxy Authentication to a given Request object.HTTPDigestAuthAttaches HTTP Digest Authentication to the given Request object._thread_localinit_per_thread_statelast_noncenonce_countchalnum_401_callsbuild_digest_header
        :rtype: str
        realmnonceqopopaquehash_utf8MD5_algorithmMD5-SESSmd5_utf8SHAsha_utf8SHA-256sha256_utf8SHA-512sha512_utf8KDentdigp_parsedA1A2HA1HA2ncvalueurandomcnoncerespdig:auth:noncebitusername="", realm="", nonce="", uri="'", ''uri="'", response=", opaque=", algorithm=", digest=", qop="auth", nc=, cnonce="Digest handle_redirectReset num_401_calls counter on redirects.is_redirecthandle_401
        Takes the given response and tries digest-auth, if needed.

        :rtype: requests.Response
        www-authenticates_authdigest patprep_cookiesprepare_cookies_rhistoryregister_hook# "I want us to put a big-ol' comment on top of it that# says that this behaviour is dumb but we need to preserve# it because people are relying on it."#    - Lukasa# These are here solely to maintain backwards compatibility# for things like ints. This will be removed in 3.0.0.# -- End Removal --# Keep state in per-thread local storage# Ensure state is initialized just once per-thread# lambdas assume digest modules are imported at the top level# noqa:E731# XXX not implemented yet#: path is request-uri defined in RFC 2616 which should not be empty# XXX handle auth-int.# XXX should the partial digests be encoded too?# If response is not 4xx, do not auth# See https://github.com/psf/requests/issues/3772# Rewind the file position indicator of the body to where# it was to resend the request.# Consume content and release the original connection# to allow our new request to reuse the same one.# Initialize per-thread state, if needed# If we have a saved nonce, skip the 401# In the case of HTTPDigestAuth being reused and the body of# the previous request was a file-like object, pos has the# file position of the previous body. Ensure it's set to# None.b'
requests.auth
~~~~~~~~~~~~~

This module contains the authentication handlers for Requests.
'u'
requests.auth
~~~~~~~~~~~~~

This module contains the authentication handlers for Requests.
'b'application/x-www-form-urlencoded'u'application/x-www-form-urlencoded'b'multipart/form-data'u'multipart/form-data'b'Returns a Basic Auth string.'u'Returns a Basic Auth string.'b'Non-string usernames will no longer be supported in Requests 3.0.0. Please convert the object you've passed in ({!r}) to a string or bytes object in the near future to avoid problems.'u'Non-string usernames will no longer be supported in Requests 3.0.0. Please convert the object you've passed in ({!r}) to a string or bytes object in the near future to avoid problems.'b'Non-string passwords will no longer be supported in Requests 3.0.0. Please convert the object you've passed in ({!r}) to a string or bytes object in the near future to avoid problems.'u'Non-string passwords will no longer be supported in Requests 3.0.0. Please convert the object you've passed in ({!r}) to a string or bytes object in the near future to avoid problems.'b'Basic 'u'Basic 'b'Base class that all auth implementations derive from'u'Base class that all auth implementations derive from'b'Auth hooks must be callable.'u'Auth hooks must be callable.'b'Attaches HTTP Basic Authentication to the given Request object.'u'Attaches HTTP Basic Authentication to the given Request object.'b'username'u'username'b'password'u'password'b'Attaches HTTP Proxy Authentication to a given Request object.'u'Attaches HTTP Proxy Authentication to a given Request object.'b'Attaches HTTP Digest Authentication to the given Request object.'u'Attaches HTTP Digest Authentication to the given Request object.'b'init'u'init'b'
        :rtype: str
        'u'
        :rtype: str
        'b'realm'u'realm'b'nonce'u'nonce'b'qop'u'qop'b'algorithm'b'opaque'u'opaque'b'MD5'u'MD5'b'MD5-SESS'u'MD5-SESS'b'SHA'u'SHA'b'SHA-256'u'SHA-256'b'SHA-512'u'SHA-512'b'auth'b':auth:'u':auth:'b'username="'u'username="'b'", realm="'u'", realm="'b'", nonce="'u'", nonce="'b'", uri="'u'", uri="'b'", response="'u'", response="'b', opaque="'u', opaque="'b', algorithm="'u', algorithm="'b', digest="'u', digest="'b', qop="auth", nc='u', qop="auth", nc='b', cnonce="'u', cnonce="'b'Digest 'u'Digest 'b'Reset num_401_calls counter on redirects.'u'Reset num_401_calls counter on redirects.'b'
        Takes the given response and tries digest-auth, if needed.

        :rtype: requests.Response
        'u'
        Takes the given response and tries digest-auth, if needed.

        :rtype: requests.Response
        'b'www-authenticate'u'www-authenticate'b'digest'u'digest'b'digest 'u'digest 'u'requests.auth'botocore.authawscrtCrtSigV4Auth_PRESIGNED_HEADERS_BLOCKLISTAwsSignatureTypeHTTP_REQUEST_HEADERS_SIGNATURE_TYPE_USE_DOUBLE_URI_ENCODE_SHOULD_NORMALIZE_URI_PATH_expiration_in_seconds_get_existing_sha256existing_sha256AwsCredentialsProvidernew_staticaccess_key_idsecret_access_keysession_tokencredentials_providerexplicit_payload_should_add_content_sha256_headerAwsSignedBodyHeaderTypeX_AMZ_CONTENT_SHA_256body_headerNONEAwsSigningConfigAwsSigningAlgorithmV4signature_typeregionservice_should_sign_headershould_sign_headeruse_double_uri_encodeshould_normalize_uri_pathsigned_body_valuesigned_body_header_typeexpiration_in_secondssigning_config_crt_request_from_aws_requestcrt_requestaws_sign_request_apply_signing_changesaws_requestcrt_pathHttpHeaderscrt_headerscrt_body_streamHttpRequestbody_streamsigned_crt_requestfrom_pairsCrtS3SigV4AuthCrtSigV4AsymAuthV4_ASYMMETRICCrtS3SigV4AsymAuthCrtSigV4AsymQueryAuthHTTP_REQUEST_QUERY_PARAMSsigned_queryCrtS3SigV4AsymQueryAuthS3 SigV4A auth using query parameters.
    This signer will sign a request using query parameters and signature
    version 4A, i.e a "presigned url" signer.
    CrtSigV4QueryAuthCrtS3SigV4QueryAuthS3 SigV4 auth using query parameters.
    This signer will sign a request using query parameters and signature
    version 4, i.e a "presigned url" signer.
    Based off of:
    http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html
    # Use utcnow() because that's what gets mocked by tests, but set# timezone because CRT assumes naive datetime is local time.# Use existing 'X-Amz-Content-SHA256' header if able# to be calculated during signing# CRT requires body (if it exists) to be an I/O stream.# Apply changes from signed CRT request to the AWSRequest# This could be a retry. Make sure the previous# authorization headers are removed first.# If necessary, add the host header# only add X-Amz-Content-SHA256 header if payload is explicitly set# always recalculate# Always add X-Amz-Content-SHA256 header# We require that both content-md5 be present and https be enabled# content-md5 is sufficiently secure and durable for us to be# urlsplit() returns a tuple (and therefore immutable) so we# need to create new url with the new query string.# Never add X-Amz-Content-SHA256 header# Defined at the bottom of module to ensure all Auth# classes are defined.b'S3 SigV4A auth using query parameters.
    This signer will sign a request using query parameters and signature
    version 4A, i.e a "presigned url" signer.
    'u'S3 SigV4A auth using query parameters.
    This signer will sign a request using query parameters and signature
    version 4A, i.e a "presigned url" signer.
    'b'S3 SigV4 auth using query parameters.
    This signer will sign a request using query parameters and signature
    version 4, i.e a "presigned url" signer.
    Based off of:
    http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html
    'u'S3 SigV4 auth using query parameters.
    This signer will sign a request using query parameters and signature
    version 4, i.e a "presigned url" signer.
    Based off of:
    http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html
    'u'botocore.crt.auth'u'crt.auth'urllib3.connectionHTTPConnectionVerifiedHTTPSConnectionurllib3.connectionpoolUnseekableStreamErrorAWSHTTPResponsestatus_tuple_status_tuple_read_statusAWSConnectionMixin for HTTPConnection that supports Expect 100-continue.

    This when mixed with a subclass of httplib.HTTPConnection (though
    technically we subclass from urllib3, which subclasses
    httplib.HTTPConnection) and we only override this class to support Expect
    100-continue, which we need for S3.  As far as I can tell, this is
    general purpose enough to not be specific to S3, but I'm being
    tentative and keeping it in botocore because I've only tested
    this against AWS services.

    response_class_original_response_cls_response_received_expect_header_set_send_requestExpect100-continuerval_convert_to_bytesmixed_bufferbytes_buffer_send_outputmessage_bodyWaiting for 100 Continue response.util_handle_expect_responseNo response seen from server, continuing to send the response body."No response seen from server, continuing to ""send the response body."_consume_headersmaybe_status_line_is_100_continue_status100 Continue response seen, now sending request body._send_message_bodyHTTP/Received a non 100 Continue response from the server, NOT sending request body."Received a non 100 Continue response ""from the server, NOT sending request body."send() called, but reseponse already received. Not sending data."send() called, but reseponse already received. ""Not sending data."AWSHTTPConnectionAn HTTPConnection that supports 100 Continue behavior.AWSHTTPSConnectionAn HTTPSConnection that supports 100 Continue behavior.AWSHTTPConnectionPoolConnectionClsAWSHTTPSConnectionPoolprepare_request_dictrequest_dict
    This method prepares a request dict to be created into an
    AWSRequestObject. This prepares the request dict by adding the
    url and the user agent to the request dict.

    :type request_dict: dict
    :param request_dict:  The request dict (created from the
        ``serialize`` module).

    :type user_agent: string
    :param user_agent: The user agent to use for this request.

    :type endpoint_url: string
    :param endpoint_url: The full endpoint url, which contains at least
        the scheme, the hostname, and optionally any path components.
    User-Agenthost_prefix_urljoinurl_pathquery_stringencoded_query_string?%s&%screate_request_object
    This method takes a request dict and creates an AWSRequest object
    from it.

    :type request_dict: dict
    :param request_dict:  The request dict (created from the
        ``prepare_request_dict`` method).

    :rtype: ``botocore.awsrequest.AWSRequest``
    :return: An AWSRequest object based on the request_dict.

    AWSRequestrequest_objectnew_pathnew_netlocreconstructedAWSRequestPreparer
    This class performs preparation on AWSRequest objects similar to that of
    the PreparedRequest class does in the requests library. However, the logic
    has been boiled down to meet the specific use cases in botocore. Of note
    there are the following differences:
        This class does not heavily prepare the URL. Requests performed many
        validations and corrections to ensure the URL is properly formatted.
        Botocore either performs these validations elsewhere or otherwise
        consistently provides well formatted URLs.

        This class does not heavily prepare the body. Body preperation is
        simple and supports only the cases that we document: bytes and
        file-like objects to determine the content-length. This will also
        additionally prepare a body that is a dict to be url encoded params
        string as some signers rely on this. Finally, this class does not
        support multipart file uploads.

        This class does not prepare the method, auth or cookies.
    prepareoriginal_prepare_url_prepare_body_prepare_headersstream_outputAWSPreparedRequestparams_to_encodedoseqprepared_bodyHeadersDictTransfer-EncodingHEADOPTIONS_determine_content_lengthbody_typeFailed to determine length of %s_to_utf8Prepares the given HTTP body data.determine_content_lengthRepresents the elements of an HTTP request.

    This class was originally inspired by requests.models.Request, but has been
    boiled down to meet the specific use cases in botocore. That being said this
    class (even in requests) is effectively a named-tuple.
    _REQUEST_PREPARER_CLS_request_preparerConstructs a :class:`AWSPreparedRequest <AWSPreparedRequest>`.A data class representing a finalized request to be sent over the wire.

    Requests at this stage should be treated as final, and the properties of
    the request should not be modified.

    :ivar method: The HTTP Method
    :ivar url: The full url
    :ivar headers: The HTTP headers to send.
    :ivar body: The HTTP body.
    :ivar stream_output: If the response for this request should be streamed.
    <AWSPreparedRequest stream_output=%s, method=%s, url=%s, headers=%s>'<AWSPreparedRequest stream_output=%s, method=%s, url=%s, ''headers=%s>'reset_streamResets the streaming body to it's initial position.

        If the request contains a streaming body (a streamable file-like object)
        seek to the object's initial position to ensure the entire contents of
        the object is sent. This is a no-op for static bytes-like body types.
        non_seekable_typesRewinding stream: %sUnable to rewind stream: %sstream_objectAWSResponseA data class representing an HTTP response.

    This class was originally inspired by requests.models.Response, but has
    been boiled down to meet the specific use cases in botocore. This has
    effectively been reduced to a named tuple.

    :ivar url: The full url.
    :ivar status_code: The status code of the HTTP response.
    :ivar headers: The HTTP headers received.
    :ivar body: The HTTP response body.
    _contentContent of the response as bytes.Content of the response as a proper text type.

        Uses the encoding type provided in the reponse headers to decode the
        response content into a proper text type. If the encoding is not
        present in the headers, UTF-8 is used as a default.
        _HeaderKey_lowerA case-insenseitive dictionary to represent HTTP headers.# The *args, **kwargs is used because the args are slightly# different in py2.6 than in py2.7/py3.# We'd ideally hook into httplib's states, but they're all# __mangled_vars so we use our own state var.  This variable is set# when we receive an early response from the server.  If this value is# set to True, any calls to send() are noops.  This value is reset to# false every time _send_request is called.  This is to workaround the# fact that py2.6 (and only py2.6) has a separate send() call for the# body in _send_request, as opposed to endheaders(), which is where the# body is sent in all versions > 2.6.# Reset all of our instance state we were tracking.# Take a list of mixed str/bytes and convert it# all into a single bytestring.# Any str will be encoded as utf-8.# If msg and message_body are sent in a single send() call,# it will avoid performance problems caused by the interaction# between delayed ack and the Nagle algorithm.# This is our custom behavior.  If the Expect header was# set, it will trigger this custom behavior.# Wait for 1 second for the server to send a response.# From the RFC:# Because of the presence of older implementations, the# protocol allows ambiguous situations in which a client may# send "Expect: 100-continue" without receiving either a 417# (Expectation Failed) status or a 100 (Continue) status.# Therefore, when a client sends this header field to an origin# server (possibly via a proxy) from which it has never seen a# 100 (Continue) status, the client SHOULD NOT wait for an# indefinite period before sending the request body.# message_body was not a string (i.e. it is a file), and# we must run the risk of Nagle.# Most servers (including S3) will just return# the CLRF after the 100 continue response.  However,# some servers (I've specifically seen this for squid when# used as a straight HTTP proxy) will also inject a# Connection: keep-alive header.  To account for this# we'll read until we read '\r\n', and ignore any headers# that come immediately after the 100 continue response.# This is called when we sent the request headers containing# an Expect: 100-continue header and received a response.# We now need to figure out what to do.# Requirements for HTTP/1.1 origin servers:# - Upon receiving a request which includes an Expect#   request-header field with the "100-continue"#   expectation, an origin server MUST either respond with#   100 (Continue) status and continue to read from the#   input stream, or respond with a final status code.# So if we don't get a 100 Continue response, then# whatever the server has sent back is the final response# and don't send the message_body.# Check for HTTP/<version> 100 Continue\r\n# NOTE: This is to avoid circular import with utils. This is being# done to avoid moving classes to different modules as to not cause# breaking chainges.# scheme   - p[0]# netloc   - p[1]# path     - p[2]# query    - p[3]# fragment - p[4]# If there's no path component, ensure the URL ends with# a '/' for backwards compatibility.# If the transfer encoding or content length is already set, use that# Ensure we set the content length when it is expected# Failed to determine content length, using chunked# NOTE: This shouldn't ever happen in practice# Default empty dicts for dict params.# This is a dictionary to hold information that is used when# processing the request. What is inside of ``context`` is open-ended.# For example, it may have a timestamp key that is used for holding# what the timestamp is when signing the request. Note that none# of the information that is inside of ``context`` is directly# sent over the wire; the information is only used to assist in# creating what is sent over the wire.# Trying to reset a stream when there is a no stream will# just immediately return.  It's not an error, it will produce# the same result as if we had actually reset the stream (we'll send# the entire body contents again if we need to).# Same case if the body is a string/bytes/bytearray type.# Read the contents.# NOTE: requests would attempt to call stream and fall back# to a custom generator that would call read in a loop, but# we don't rely on this behaviorb'status_tuple'u'status_tuple'b'Mixin for HTTPConnection that supports Expect 100-continue.

    This when mixed with a subclass of httplib.HTTPConnection (though
    technically we subclass from urllib3, which subclasses
    httplib.HTTPConnection) and we only override this class to support Expect
    100-continue, which we need for S3.  As far as I can tell, this is
    general purpose enough to not be specific to S3, but I'm being
    tentative and keeping it in botocore because I've only tested
    this against AWS services.

    'u'Mixin for HTTPConnection that supports Expect 100-continue.

    This when mixed with a subclass of httplib.HTTPConnection (though
    technically we subclass from urllib3, which subclasses
    httplib.HTTPConnection) and we only override this class to support Expect
    100-continue, which we need for S3.  As far as I can tell, this is
    general purpose enough to not be specific to S3, but I'm being
    tentative and keeping it in botocore because I've only tested
    this against AWS services.

    'b'Expect'u'Expect'b'100-continue'b'Waiting for 100 Continue response.'u'Waiting for 100 Continue response.'b'No response seen from server, continuing to send the response body.'u'No response seen from server, continuing to send the response body.'b'100 Continue response seen, now sending request body.'u'100 Continue response seen, now sending request body.'b'HTTP/'b'Received a non 100 Continue response from the server, NOT sending request body.'u'Received a non 100 Continue response from the server, NOT sending request body.'b'send() called, but reseponse already received. Not sending data.'u'send() called, but reseponse already received. Not sending data.'b'100'b'An HTTPConnection that supports 100 Continue behavior.'u'An HTTPConnection that supports 100 Continue behavior.'b'An HTTPSConnection that supports 100 Continue behavior.'u'An HTTPSConnection that supports 100 Continue behavior.'b'
    This method prepares a request dict to be created into an
    AWSRequestObject. This prepares the request dict by adding the
    url and the user agent to the request dict.

    :type request_dict: dict
    :param request_dict:  The request dict (created from the
        ``serialize`` module).

    :type user_agent: string
    :param user_agent: The user agent to use for this request.

    :type endpoint_url: string
    :param endpoint_url: The full endpoint url, which contains at least
        the scheme, the hostname, and optionally any path components.
    'u'
    This method prepares a request dict to be created into an
    AWSRequestObject. This prepares the request dict by adding the
    url and the user agent to the request dict.

    :type request_dict: dict
    :param request_dict:  The request dict (created from the
        ``serialize`` module).

    :type user_agent: string
    :param user_agent: The user agent to use for this request.

    :type endpoint_url: string
    :param endpoint_url: The full endpoint url, which contains at least
        the scheme, the hostname, and optionally any path components.
    'b'User-Agent'u'User-Agent'b'host_prefix'u'host_prefix'b'url_path'u'url_path'b'query_string'u'query_string'b'?%s'u'?%s'b'&%s'u'&%s'b'url'u'url'b'context'u'context'b'
    This method takes a request dict and creates an AWSRequest object
    from it.

    :type request_dict: dict
    :param request_dict:  The request dict (created from the
        ``prepare_request_dict`` method).

    :rtype: ``botocore.awsrequest.AWSRequest``
    :return: An AWSRequest object based on the request_dict.

    'u'
    This method takes a request dict and creates an AWSRequest object
    from it.

    :type request_dict: dict
    :param request_dict:  The request dict (created from the
        ``prepare_request_dict`` method).

    :rtype: ``botocore.awsrequest.AWSRequest``
    :return: An AWSRequest object based on the request_dict.

    'b'method'u'method'b'body'b'auth_path'u'auth_path'b'
    This class performs preparation on AWSRequest objects similar to that of
    the PreparedRequest class does in the requests library. However, the logic
    has been boiled down to meet the specific use cases in botocore. Of note
    there are the following differences:
        This class does not heavily prepare the URL. Requests performed many
        validations and corrections to ensure the URL is properly formatted.
        Botocore either performs these validations elsewhere or otherwise
        consistently provides well formatted URLs.

        This class does not heavily prepare the body. Body preperation is
        simple and supports only the cases that we document: bytes and
        file-like objects to determine the content-length. This will also
        additionally prepare a body that is a dict to be url encoded params
        string as some signers rely on this. Finally, this class does not
        support multipart file uploads.

        This class does not prepare the method, auth or cookies.
    'u'
    This class performs preparation on AWSRequest objects similar to that of
    the PreparedRequest class does in the requests library. However, the logic
    has been boiled down to meet the specific use cases in botocore. Of note
    there are the following differences:
        This class does not heavily prepare the URL. Requests performed many
        validations and corrections to ensure the URL is properly formatted.
        Botocore either performs these validations elsewhere or otherwise
        consistently provides well formatted URLs.

        This class does not heavily prepare the body. Body preperation is
        simple and supports only the cases that we document: bytes and
        file-like objects to determine the content-length. This will also
        additionally prepare a body that is a dict to be url encoded params
        string as some signers rely on this. Finally, this class does not
        support multipart file uploads.

        This class does not prepare the method, auth or cookies.
    'b'Transfer-Encoding'u'Transfer-Encoding'b'HEAD'u'HEAD'b'OPTIONS'u'OPTIONS'b'Failed to determine length of %s'u'Failed to determine length of %s'b'chunked'u'chunked'b'Prepares the given HTTP body data.'u'Prepares the given HTTP body data.'b'Represents the elements of an HTTP request.

    This class was originally inspired by requests.models.Request, but has been
    boiled down to meet the specific use cases in botocore. That being said this
    class (even in requests) is effectively a named-tuple.
    'u'Represents the elements of an HTTP request.

    This class was originally inspired by requests.models.Request, but has been
    boiled down to meet the specific use cases in botocore. That being said this
    class (even in requests) is effectively a named-tuple.
    'b'Constructs a :class:`AWSPreparedRequest <AWSPreparedRequest>`.'u'Constructs a :class:`AWSPreparedRequest <AWSPreparedRequest>`.'b'A data class representing a finalized request to be sent over the wire.

    Requests at this stage should be treated as final, and the properties of
    the request should not be modified.

    :ivar method: The HTTP Method
    :ivar url: The full url
    :ivar headers: The HTTP headers to send.
    :ivar body: The HTTP body.
    :ivar stream_output: If the response for this request should be streamed.
    'u'A data class representing a finalized request to be sent over the wire.

    Requests at this stage should be treated as final, and the properties of
    the request should not be modified.

    :ivar method: The HTTP Method
    :ivar url: The full url
    :ivar headers: The HTTP headers to send.
    :ivar body: The HTTP body.
    :ivar stream_output: If the response for this request should be streamed.
    'b'<AWSPreparedRequest stream_output=%s, method=%s, url=%s, headers=%s>'u'<AWSPreparedRequest stream_output=%s, method=%s, url=%s, headers=%s>'b'Resets the streaming body to it's initial position.

        If the request contains a streaming body (a streamable file-like object)
        seek to the object's initial position to ensure the entire contents of
        the object is sent. This is a no-op for static bytes-like body types.
        'u'Resets the streaming body to it's initial position.

        If the request contains a streaming body (a streamable file-like object)
        seek to the object's initial position to ensure the entire contents of
        the object is sent. This is a no-op for static bytes-like body types.
        'b'Rewinding stream: %s'u'Rewinding stream: %s'b'Unable to rewind stream: %s'u'Unable to rewind stream: %s'b'A data class representing an HTTP response.

    This class was originally inspired by requests.models.Response, but has
    been boiled down to meet the specific use cases in botocore. This has
    effectively been reduced to a named tuple.

    :ivar url: The full url.
    :ivar status_code: The status code of the HTTP response.
    :ivar headers: The HTTP headers received.
    :ivar body: The HTTP response body.
    'u'A data class representing an HTTP response.

    This class was originally inspired by requests.models.Response, but has
    been boiled down to meet the specific use cases in botocore. This has
    effectively been reduced to a named tuple.

    :ivar url: The full url.
    :ivar status_code: The status code of the HTTP response.
    :ivar headers: The HTTP headers received.
    :ivar body: The HTTP response body.
    'b'Content of the response as bytes.'u'Content of the response as bytes.'b'Content of the response as a proper text type.

        Uses the encoding type provided in the reponse headers to decode the
        response content into a proper text type. If the encoding is not
        present in the headers, UTF-8 is used as a default.
        'u'Content of the response as a proper text type.

        Uses the encoding type provided in the reponse headers to decode the
        response content into a proper text type. If the encoding is not
        present in the headers, UTF-8 is used as a default.
        'b'A case-insenseitive dictionary to represent HTTP headers.'u'A case-insenseitive dictionary to represent HTTP headers.'u'botocore.awsrequest'u'awsrequest'Base class for MIME specializations.MIMEBaseemail.policy_maintype_subtype_paramsThis constructor adds a Content-Type: and a MIME-Version: header.

        The Content-Type: header is taken from the _maintype and _subtype
        arguments.  Additional parameters for this header are taken from the
        keyword arguments.
        %s/%sadd_headerContent-TypeMIME-Version# Copyright (C) 2001-2006 Python Software Foundationb'Base class for MIME specializations.'u'Base class for MIME specializations.'b'MIMEBase'u'MIMEBase'b'This constructor adds a Content-Type: and a MIME-Version: header.

        The Content-Type: header is taken from the _maintype and _subtype
        arguments.  Additional parameters for this header are taken from the
        keyword arguments.
        'u'This constructor adds a Content-Type: and a MIME-Version: header.

        The Content-Type: header is taken from the _maintype and _subtype
        arguments.  Additional parameters for this header are taken from the
        keyword arguments.
        'b'%s/%s'u'%s/%s'b'Content-Type'u'Content-Type'b'MIME-Version'u'MIME-Version'u'email.mime.base'u'mime.base'_client_service_docs_namerepresents_service_resourceclass_nameu'boto3.docs.base'u'docs.base'BaseRetryBackoffdelay_amountCalculate how long we should delay before retrying.

        :type context: RetryContext

        BaseRetryableCheckerBase class for determining if a retry should happen.

    This base class checks for specific retryable conditions.
    A single retryable checker doesn't necessarily indicate a retry
    will happen.  It's up to the ``RetryPolicy`` to use its
    ``BaseRetryableCheckers`` to make the final decision on whether a retry
    should happen.
    is_retryableReturns True if retryable, False if not.

        :type context: RetryContext
        b'Calculate how long we should delay before retrying.

        :type context: RetryContext

        'u'Calculate how long we should delay before retrying.

        :type context: RetryContext

        'b'delay_amount'u'delay_amount'b'Base class for determining if a retry should happen.

    This base class checks for specific retryable conditions.
    A single retryable checker doesn't necessarily indicate a retry
    will happen.  It's up to the ``RetryPolicy`` to use its
    ``BaseRetryableCheckers`` to make the final decision on whether a retry
    should happen.
    'u'Base class for determining if a retry should happen.

    This base class checks for specific retryable conditions.
    A single retryable checker doesn't necessarily indicate a retry
    will happen.  It's up to the ``RetryPolicy`` to use its
    ``BaseRetryableCheckers`` to make the final decision on whether a retry
    should happen.
    'b'Returns True if retryable, False if not.

        :type context: RetryContext
        'u'Returns True if retryable, False if not.

        :type context: RetryContext
        'b'is_retryable'u'is_retryable'u'botocore.retries.base'u'retries.base'ResourceMeta
    An object containing metadata about a resource.
    identifiersResourceMeta('{}', identifiers={})
        Create a copy of this metadata object.
        ServiceResource
    A base class for resources.

    :type client: botocore.client
    :param client: A low-level Botocore client instance
    
    Stores metadata about this resource instance, such as the
    ``service_name``, the low-level ``client`` and any cached ``data``
    from when the instance was hydrated. For example::

        # Get a low-level client from a resource instance
        client = resource.meta.client
        response = client.operation(Param='foo')

        # Print the resource instance's service short name
        print(resource.meta.service_name)

    See :py:class:`ResourceMeta` for more information.
    Unknown keyword argument: identifierRequired parameter  not set#: (``string``) The service name, e.g. 's3'#: (``list``) List of identifier names#: (:py:class:`~botocore.client.BaseClient`) Low-level Botocore client#: (``dict``) Loaded resource data attributes# The resource model for that resource# Two metas are equal if their components are all equal# Always work on a copy of meta, otherwise we would affect other# instances of the same subclass.# Create a default client if none was passed# Allow setting identifiers as positional arguments in the order# in which they were defined in the ResourceJSON.# Allow setting identifiers via keyword arguments. Here we need# extra logic to ignore other keyword arguments like ``client``.# Validate that all identifiers have been set.# Should be instances of the same resource class# Each of the identifiers should have the same value in both# instances, e.g. two buckets need the same name to be equal.b'
    An object containing metadata about a resource.
    'u'
    An object containing metadata about a resource.
    'b'ResourceMeta('{}', identifiers={})'u'ResourceMeta('{}', identifiers={})'b'
        Create a copy of this metadata object.
        'u'
        Create a copy of this metadata object.
        'b'
    A base class for resources.

    :type client: botocore.client
    :param client: A low-level Botocore client instance
    'u'
    A base class for resources.

    :type client: botocore.client
    :param client: A low-level Botocore client instance
    'b'
    Stores metadata about this resource instance, such as the
    ``service_name``, the low-level ``client`` and any cached ``data``
    from when the instance was hydrated. For example::

        # Get a low-level client from a resource instance
        client = resource.meta.client
        response = client.operation(Param='foo')

        # Print the resource instance's service short name
        print(resource.meta.service_name)

    See :py:class:`ResourceMeta` for more information.
    'u'
    Stores metadata about this resource instance, such as the
    ``service_name``, the low-level ``client`` and any cached ``data``
    from when the instance was hydrated. For example::

        # Get a low-level client from a resource instance
        client = resource.meta.client
        response = client.operation(Param='foo')

        # Print the resource instance's service short name
        print(resource.meta.service_name)

    See :py:class:`ResourceMeta` for more information.
    'b'Unknown keyword argument: 'u'Unknown keyword argument: 'b'Required parameter 'u'Required parameter 'b' not set'u' not set'u'boto3.resources.base'u'resources.base'Base16, Base32, Base64 (RFC 3548), Base85 and Ascii85 data encodingsdecodebytesb32encodeb32decodeb32hexencodeb32hexdecodeb16encodeb16decodeb85encodeb85decodea85encodea85decodestandard_b64encodestandard_b64decodeurlsafe_b64encodeurlsafe_b64decodebytes_types_bytes_from_decode_datastring argument should contain only ASCII charactersargument should be a bytes-like object or ASCII string, not %r"argument should be a bytes-like object or ASCII ""string, not %r"altcharsEncode the bytes-like object s using Base64 and return a bytes object.

    Optional altchars should be a byte string of length 2 which specifies an
    alternative alphabet for the '+' and '/' characters.  This allows an
    application to e.g. generate url or filesystem safe Base64 strings.
    b2a_base64+/Decode the Base64 encoded bytes-like object or ASCII string s.

    Optional altchars must be a bytes-like object or ASCII string of length 2
    which specifies the alternative alphabet used instead of the '+' and '/'
    characters.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded.

    If validate is False (the default), characters that are neither in the
    normal base-64 alphabet nor the alternative alphabet are discarded prior
    to the padding check.  If validate is True, these non-alphabet characters
    in the input result in a binascii.Error.
    fullmatch[A-Za-z0-9+/]*={0,2}Non-base64 digit founda2b_base64Encode bytes-like object s using the standard Base64 alphabet.

    The result is returned as a bytes object.
    Decode bytes encoded with the standard Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the standard alphabet
    are discarded prior to the padding check.
    -__urlsafe_encode_translation_urlsafe_decode_translationEncode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object to encode.  The result is returned as a
    bytes object.  The alphabet uses '-' instead of '+' and '_' instead of
    '/'.
    Decode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the URL-safe base-64
    alphabet, and are not a plus '+' or slash '/', are discarded prior to the
    padding check.

    The alphabet uses '-' instead of '+' and '_' instead of '/'.
    
Encode the bytes-like objects using {encoding} and return a bytes object.
_B32_ENCODE_DOCSTRING
Decode the {encoding} encoded bytes-like object or ASCII string s.

Optional casefold is a flag specifying whether a lowercase alphabet is
acceptable as input.  For security purposes, the default is False.
{extra_args}
The result is returned as a bytes object.  A binascii.Error is raised if
the input is incorrectly padded or if there are non-alphabet
characters present in the input.
_B32_DECODE_DOCSTRING
RFC 3548 allows for optional mapping of the digit 0 (zero) to the
letter O (oh), and for optional mapping of the digit 1 (one) to
either the letter I (eye) or letter L (el).  The optional argument
map01 when not None, specifies which letter the digit 1 should be
mapped to (when map01 is not None, the digit 0 is always mapped to
the letter O).  For security purposes the default is None, so that
0 and 1 are not allowed in the input.
_B32_DECODE_MAP01_DOCSTRINGABCDEFGHIJKLMNOPQRSTUVWXYZ234567_b32alphabet0123456789ABCDEFGHIJKLMNOPQRSTUV_b32hexalphabet_b32tab2_b32rev_b32encodealphabetb32tabb32tab210230x3ff==========_b32decodemap01Incorrect paddingpadcharsdecodedb32revquantaaccNon-base32 digit foundbase32extra_argsbase32hexEncode the bytes-like object s using Base16 and return a bytes object.
    hexlifyDecode the Base16 encoded bytes-like object or ASCII string s.

    Optional casefold is a flag specifying whether a lowercase alphabet is
    acceptable as input.  For security purposes, the default is False.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded or if there are non-alphabet characters present
    in the input.
    [^0-9A-F]Non-base16 digit foundunhexlify_a85chars_a85chars2<~_A85START~>_A85END_85encodechars2padfoldnulsfoldspaces!%dIwords5389762880x20202020614125857225wrapcoladobeEncode bytes-like object b using Ascii85 and return a bytes object.

    foldspaces is an optional flag that uses the special short sequence 'y'
    instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This
    feature is not supported by the "standard" Adobe encoding.

    wrapcol controls whether the output should have newline (b'\n') characters
    added to it. If this is non-zero, each output line will be at most this
    many characters long.

    pad controls whether the input is padded to a multiple of 4 before
    encoding. Note that the btoa implementation always pads.

    adobe controls whether the encoded byte sequence is framed with <~ and ~>,
    which is used by the Adobe implementation.
    118 	
ignorecharsDecode the Ascii85 encoded bytes-like object or ASCII string b.

    foldspaces is a flag that specifies whether the 'y' short sequence should be
    accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is
    not supported by the "standard" Adobe encoding.

    adobe controls whether the input sequence is in Adobe Ascii85 format (i.e.
    is framed with <~ and ~>).

    ignorechars should be a byte string containing characters to ignore from the
    input. This should only contain whitespace characters, and by default
    contains all whitespace characters in ASCII.

    The result is returned as a bytes object.
    Ascii85 encoded byte sequences must end with {!r}"Ascii85 encoded byte sequences must end ""with {!r}"!IpackIdecoded_appendcurr_appendcurr_clearAscii85 overflowz inside Ascii85 5-tuple    y inside Ascii85 5-tupleNon-Ascii85 digit found: %c0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!#$%&()*+-;<=>?@^_`{|}~b"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"b"abcdefghijklmnopqrstuvwxyz!#$%&()*+-;<=>?@^_`{|}~"_b85alphabet_b85chars_b85chars2_b85decEncode bytes-like object b in base85 format and return a bytes object.

    If pad is true, the input is padded with b'\0' so its length is a multiple of
    4 bytes before encoding.
    Decode the base85-encoded bytes-like object or ASCII string b

    The result is returned as a bytes object.
    bad base85 character at position %dbase85 overflow in hunk starting at byte %d76MAXLINESIZEMAXBINSIZEoutputEncode a file; input and output are binary files.Decode a file; input and output are binary files._input_type_checkexpected bytes-like object, not %sexpected single byte elements, not %r from %sexpected 1-D data, not %d-D data from %sEncode a bytestring into a bytes object containing multiple lines
    of base-64 data.piecesDecode a bytestring of base-64 data into a bytes object.Small main programgetoptdeutusage: %s [-d|-e|-u|-t] [file|-]
        -d, -u: decode
        -e: encode (default)
        -t: encode and decode string 'Aladdin:open sesame'-e-d-u-tAladdin:open sesames0s2Script#! /usr/bin/env python3# Modified 04-Oct-1995 by Jack Jansen to use binascii module# Modified 30-Dec-2003 by Barry Warsaw to add full RFC 3548 support# Modified 22-May-2007 by Guido van Rossum to use bytes everywhere# Legacy interface exports traditional RFC 2045 Base64 encodings# Generalized interface for other encodings# Base85 and Ascii85 encodings# Standard Base64 encoding# Some common Base64 alternatives.  As referenced by RFC 3458, see thread# starting at:# http://zgp.org/pipermail/p2p-hackers/2001-September/000316.html# Types acceptable as binary data# Base64 encoding/decoding uses binascii# Base32 encoding/decoding must be done in Python# Delay the initialization of the table to not waste memory# if the function is never called# Pad the last quantum with zero bits if necessary# Don't use += !# bits 1 - 10# bits 11 - 20# bits 21 - 30# bits 31 - 40# Adjust for any leftover partial quanta# Handle section 2.4 zero and one mapping.  The flag map01 will be either# False, or the character to map the digit 1 (one) to.  It should be# either L (el) or I (eye).# Strip off pad characters from the right.  We need to count the pad# characters because this will tell us how many null bytes to remove from# the end of the decoded string.# Now decode the full quanta# Process the last, partial quanta# 1: 4, 3: 3, 4: 2, 6: 1# base32hex does not have the 01 mapping# RFC 3548, Base 16 Alphabet specifies uppercase, but hexlify() returns# lowercase.  The RFC also recommends against accepting input case# insensitively.# Ascii85 encoding/decoding# Helper function for a85encode and b85encode# Delay the initialization of tables to not waste memory# Strip off start/end markers# We have to go through this stepwise, so as to ignore spaces and handle# special short sequences# Skip whitespace# Throw away the extra padding# The following code is originally taken (with permission) from Mercurial# Legacy interface.  This code could be cleaned up since I don't believe# binascii has any line length limitations.  It just doesn't seem worth it# though.  The files should be opened in binary mode.# Excluding the CRLF# Usable as a script...b'Base16, Base32, Base64 (RFC 3548), Base85 and Ascii85 data encodings'u'Base16, Base32, Base64 (RFC 3548), Base85 and Ascii85 data encodings'b'encodebytes'u'encodebytes'b'decodebytes'u'decodebytes'b'b64encode'u'b64encode'b'b64decode'u'b64decode'b'b32encode'u'b32encode'b'b32decode'u'b32decode'b'b32hexencode'u'b32hexencode'b'b32hexdecode'u'b32hexdecode'b'b16encode'u'b16encode'b'b16decode'u'b16decode'b'b85encode'u'b85encode'b'b85decode'u'b85decode'b'a85encode'u'a85encode'b'a85decode'u'a85decode'b'standard_b64encode'u'standard_b64encode'b'standard_b64decode'u'standard_b64decode'b'urlsafe_b64encode'u'urlsafe_b64encode'b'urlsafe_b64decode'u'urlsafe_b64decode'b'string argument should contain only ASCII characters'u'string argument should contain only ASCII characters'b'argument should be a bytes-like object or ASCII string, not %r'u'argument should be a bytes-like object or ASCII string, not %r'b'Encode the bytes-like object s using Base64 and return a bytes object.

    Optional altchars should be a byte string of length 2 which specifies an
    alternative alphabet for the '+' and '/' characters.  This allows an
    application to e.g. generate url or filesystem safe Base64 strings.
    'u'Encode the bytes-like object s using Base64 and return a bytes object.

    Optional altchars should be a byte string of length 2 which specifies an
    alternative alphabet for the '+' and '/' characters.  This allows an
    application to e.g. generate url or filesystem safe Base64 strings.
    'b'+/'b'Decode the Base64 encoded bytes-like object or ASCII string s.

    Optional altchars must be a bytes-like object or ASCII string of length 2
    which specifies the alternative alphabet used instead of the '+' and '/'
    characters.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded.

    If validate is False (the default), characters that are neither in the
    normal base-64 alphabet nor the alternative alphabet are discarded prior
    to the padding check.  If validate is True, these non-alphabet characters
    in the input result in a binascii.Error.
    'u'Decode the Base64 encoded bytes-like object or ASCII string s.

    Optional altchars must be a bytes-like object or ASCII string of length 2
    which specifies the alternative alphabet used instead of the '+' and '/'
    characters.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded.

    If validate is False (the default), characters that are neither in the
    normal base-64 alphabet nor the alternative alphabet are discarded prior
    to the padding check.  If validate is True, these non-alphabet characters
    in the input result in a binascii.Error.
    'b'[A-Za-z0-9+/]*={0,2}'b'Non-base64 digit found'u'Non-base64 digit found'b'Encode bytes-like object s using the standard Base64 alphabet.

    The result is returned as a bytes object.
    'u'Encode bytes-like object s using the standard Base64 alphabet.

    The result is returned as a bytes object.
    'b'Decode bytes encoded with the standard Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the standard alphabet
    are discarded prior to the padding check.
    'u'Decode bytes encoded with the standard Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the standard alphabet
    are discarded prior to the padding check.
    'b'-_'b'Encode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object to encode.  The result is returned as a
    bytes object.  The alphabet uses '-' instead of '+' and '_' instead of
    '/'.
    'u'Encode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object to encode.  The result is returned as a
    bytes object.  The alphabet uses '-' instead of '+' and '_' instead of
    '/'.
    'b'Decode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the URL-safe base-64
    alphabet, and are not a plus '+' or slash '/', are discarded prior to the
    padding check.

    The alphabet uses '-' instead of '+' and '_' instead of '/'.
    'u'Decode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the URL-safe base-64
    alphabet, and are not a plus '+' or slash '/', are discarded prior to the
    padding check.

    The alphabet uses '-' instead of '+' and '_' instead of '/'.
    'b'
Encode the bytes-like objects using {encoding} and return a bytes object.
'u'
Encode the bytes-like objects using {encoding} and return a bytes object.
'b'
Decode the {encoding} encoded bytes-like object or ASCII string s.

Optional casefold is a flag specifying whether a lowercase alphabet is
acceptable as input.  For security purposes, the default is False.
{extra_args}
The result is returned as a bytes object.  A binascii.Error is raised if
the input is incorrectly padded or if there are non-alphabet
characters present in the input.
'u'
Decode the {encoding} encoded bytes-like object or ASCII string s.

Optional casefold is a flag specifying whether a lowercase alphabet is
acceptable as input.  For security purposes, the default is False.
{extra_args}
The result is returned as a bytes object.  A binascii.Error is raised if
the input is incorrectly padded or if there are non-alphabet
characters present in the input.
'b'
RFC 3548 allows for optional mapping of the digit 0 (zero) to the
letter O (oh), and for optional mapping of the digit 1 (one) to
either the letter I (eye) or letter L (el).  The optional argument
map01 when not None, specifies which letter the digit 1 should be
mapped to (when map01 is not None, the digit 0 is always mapped to
the letter O).  For security purposes the default is None, so that
0 and 1 are not allowed in the input.
'u'
RFC 3548 allows for optional mapping of the digit 0 (zero) to the
letter O (oh), and for optional mapping of the digit 1 (one) to
either the letter I (eye) or letter L (el).  The optional argument
map01 when not None, specifies which letter the digit 1 should be
mapped to (when map01 is not None, the digit 0 is always mapped to
the letter O).  For security purposes the default is None, so that
0 and 1 are not allowed in the input.
'b'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'b'0123456789ABCDEFGHIJKLMNOPQRSTUV'b'======'b'===='b'Incorrect padding'u'Incorrect padding'b'Non-base32 digit found'u'Non-base32 digit found'b'base32'u'base32'b'base32hex'u'base32hex'b'Encode the bytes-like object s using Base16 and return a bytes object.
    'u'Encode the bytes-like object s using Base16 and return a bytes object.
    'b'Decode the Base16 encoded bytes-like object or ASCII string s.

    Optional casefold is a flag specifying whether a lowercase alphabet is
    acceptable as input.  For security purposes, the default is False.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded or if there are non-alphabet characters present
    in the input.
    'u'Decode the Base16 encoded bytes-like object or ASCII string s.

    Optional casefold is a flag specifying whether a lowercase alphabet is
    acceptable as input.  For security purposes, the default is False.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded or if there are non-alphabet characters present
    in the input.
    'b'[^0-9A-F]'b'Non-base16 digit found'u'Non-base16 digit found'b'<~'b'~>'b'!%dI'u'!%dI'b'Encode bytes-like object b using Ascii85 and return a bytes object.

    foldspaces is an optional flag that uses the special short sequence 'y'
    instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This
    feature is not supported by the "standard" Adobe encoding.

    wrapcol controls whether the output should have newline (b'\n') characters
    added to it. If this is non-zero, each output line will be at most this
    many characters long.

    pad controls whether the input is padded to a multiple of 4 before
    encoding. Note that the btoa implementation always pads.

    adobe controls whether the encoded byte sequence is framed with <~ and ~>,
    which is used by the Adobe implementation.
    'u'Encode bytes-like object b using Ascii85 and return a bytes object.

    foldspaces is an optional flag that uses the special short sequence 'y'
    instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This
    feature is not supported by the "standard" Adobe encoding.

    wrapcol controls whether the output should have newline (b'\n') characters
    added to it. If this is non-zero, each output line will be at most this
    many characters long.

    pad controls whether the input is padded to a multiple of 4 before
    encoding. Note that the btoa implementation always pads.

    adobe controls whether the encoded byte sequence is framed with <~ and ~>,
    which is used by the Adobe implementation.
    'b' 	
'b'Decode the Ascii85 encoded bytes-like object or ASCII string b.

    foldspaces is a flag that specifies whether the 'y' short sequence should be
    accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is
    not supported by the "standard" Adobe encoding.

    adobe controls whether the input sequence is in Adobe Ascii85 format (i.e.
    is framed with <~ and ~>).

    ignorechars should be a byte string containing characters to ignore from the
    input. This should only contain whitespace characters, and by default
    contains all whitespace characters in ASCII.

    The result is returned as a bytes object.
    'u'Decode the Ascii85 encoded bytes-like object or ASCII string b.

    foldspaces is a flag that specifies whether the 'y' short sequence should be
    accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is
    not supported by the "standard" Adobe encoding.

    adobe controls whether the input sequence is in Adobe Ascii85 format (i.e.
    is framed with <~ and ~>).

    ignorechars should be a byte string containing characters to ignore from the
    input. This should only contain whitespace characters, and by default
    contains all whitespace characters in ASCII.

    The result is returned as a bytes object.
    'b'Ascii85 encoded byte sequences must end with {!r}'u'Ascii85 encoded byte sequences must end with {!r}'b'!I'u'!I'b'Ascii85 overflow'u'Ascii85 overflow'b'z inside Ascii85 5-tuple'u'z inside Ascii85 5-tuple'b'    'b'y inside Ascii85 5-tuple'u'y inside Ascii85 5-tuple'b'Non-Ascii85 digit found: %c'u'Non-Ascii85 digit found: %c'b'0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!#$%&()*+-;<=>?@^_`{|}~'b'Encode bytes-like object b in base85 format and return a bytes object.

    If pad is true, the input is padded with b'\0' so its length is a multiple of
    4 bytes before encoding.
    'u'Encode bytes-like object b in base85 format and return a bytes object.

    If pad is true, the input is padded with b'\0' so its length is a multiple of
    4 bytes before encoding.
    'b'Decode the base85-encoded bytes-like object or ASCII string b

    The result is returned as a bytes object.
    'u'Decode the base85-encoded bytes-like object or ASCII string b

    The result is returned as a bytes object.
    'b'bad base85 character at position %d'u'bad base85 character at position %d'b'base85 overflow in hunk starting at byte %d'u'base85 overflow in hunk starting at byte %d'b'Encode a file; input and output are binary files.'u'Encode a file; input and output are binary files.'b'Decode a file; input and output are binary files.'u'Decode a file; input and output are binary files.'b'expected bytes-like object, not %s'u'expected bytes-like object, not %s'b'expected single byte elements, not %r from %s'u'expected single byte elements, not %r from %s'b'expected 1-D data, not %d-D data from %s'u'expected 1-D data, not %d-D data from %s'b'Encode a bytestring into a bytes object containing multiple lines
    of base-64 data.'u'Encode a bytestring into a bytes object containing multiple lines
    of base-64 data.'b'Decode a bytestring of base-64 data into a bytes object.'u'Decode a bytestring of base-64 data into a bytes object.'b'Small main program'u'Small main program'b'deut'u'deut'b'usage: %s [-d|-e|-u|-t] [file|-]
        -d, -u: decode
        -e: encode (default)
        -t: encode and decode string 'Aladdin:open sesame''u'usage: %s [-d|-e|-u|-t] [file|-]
        -d, -u: decode
        -e: encode (default)
        -t: encode and decode string 'Aladdin:open sesame''b'-e'u'-e'b'-d'u'-d'b'-u'u'-u'b'-t'u'-t'b'Aladdin:open sesame'Base64 content transfer encoding per RFCs 2045-2047.

This module handles the content transfer encoding method defined in RFC 2045
to encode arbitrary 8-bit data using the three 8-bit bytes in four 7-bit
characters encoding known as Base64.

It is used in the MIME standards for email to attach images, audio, and text
using some 8-bit character sets to messages.

This module provides an interface to encode and decode both headers and bodies
with Base64 encoding.

RFC 2045 defines a method for including character set information in an
`encoded-word' in a header.  This method is commonly used for 8-bit real names
in To:, From:, Cc:, etc. fields, as well as Subject: lines.

This module does not do the line wrapping or end-of-line character conversion
necessary for proper internationalized headers; it only does dumb encoding and
decoding.  To deal with the various line wrapping issues, use the email.header
module.
body_decodebody_encodedecodestringheader_encodeheader_lengthCRLFNLMISC_LENReturn the length of s when it is encoded with base64.iso-8859-1header_bytesEncode a single header line with Base64 encoding in a given charset.

    charset names the character set to use to encode the header.  It defaults
    to iso-8859-1.  Base64 encoding is defined in RFC 2045.
    =?%s?b?%s?=eolEncode a string with base64.

    Each line will be wrapped at, at most, maxlinelen characters (defaults to
    76 characters).

    Each line of encoded text will end with eol, which defaults to "\n".  Set
    this to "\r\n" if you will be using the result of this function directly
    in an email.
    encvecmax_unencodedencDecode a raw base64 string, returning a bytes object.

    This function does not parse a full MIME header value encoded with
    base64 (like =?iso-8859-1?b?bmloISBuaWgh?=) -- please use the high
    level email.header class for that functionality.
    raw-unicode-escape# Author: Ben Gertzfield# See also Charset.py# Helpers# BAW: should encode() inherit b2a_base64()'s dubious behavior in# adding a newline to the encoded string?# For convenience and backwards compatibility w/ standard base64 moduleb'Base64 content transfer encoding per RFCs 2045-2047.

This module handles the content transfer encoding method defined in RFC 2045
to encode arbitrary 8-bit data using the three 8-bit bytes in four 7-bit
characters encoding known as Base64.

It is used in the MIME standards for email to attach images, audio, and text
using some 8-bit character sets to messages.

This module provides an interface to encode and decode both headers and bodies
with Base64 encoding.

RFC 2045 defines a method for including character set information in an
`encoded-word' in a header.  This method is commonly used for 8-bit real names
in To:, From:, Cc:, etc. fields, as well as Subject: lines.

This module does not do the line wrapping or end-of-line character conversion
necessary for proper internationalized headers; it only does dumb encoding and
decoding.  To deal with the various line wrapping issues, use the email.header
module.
'u'Base64 content transfer encoding per RFCs 2045-2047.

This module handles the content transfer encoding method defined in RFC 2045
to encode arbitrary 8-bit data using the three 8-bit bytes in four 7-bit
characters encoding known as Base64.

It is used in the MIME standards for email to attach images, audio, and text
using some 8-bit character sets to messages.

This module provides an interface to encode and decode both headers and bodies
with Base64 encoding.

RFC 2045 defines a method for including character set information in an
`encoded-word' in a header.  This method is commonly used for 8-bit real names
in To:, From:, Cc:, etc. fields, as well as Subject: lines.

This module does not do the line wrapping or end-of-line character conversion
necessary for proper internationalized headers; it only does dumb encoding and
decoding.  To deal with the various line wrapping issues, use the email.header
module.
'b'body_decode'u'body_decode'b'body_encode'u'body_encode'b'decodestring'u'decodestring'b'header_encode'u'header_encode'b'header_length'u'header_length'b'Return the length of s when it is encoded with base64.'u'Return the length of s when it is encoded with base64.'b'iso-8859-1'u'iso-8859-1'b'Encode a single header line with Base64 encoding in a given charset.

    charset names the character set to use to encode the header.  It defaults
    to iso-8859-1.  Base64 encoding is defined in RFC 2045.
    'u'Encode a single header line with Base64 encoding in a given charset.

    charset names the character set to use to encode the header.  It defaults
    to iso-8859-1.  Base64 encoding is defined in RFC 2045.
    'b'=?%s?b?%s?='u'=?%s?b?%s?='b'Encode a string with base64.

    Each line will be wrapped at, at most, maxlinelen characters (defaults to
    76 characters).

    Each line of encoded text will end with eol, which defaults to "\n".  Set
    this to "\r\n" if you will be using the result of this function directly
    in an email.
    'u'Encode a string with base64.

    Each line will be wrapped at, at most, maxlinelen characters (defaults to
    76 characters).

    Each line of encoded text will end with eol, which defaults to "\n".  Set
    this to "\r\n" if you will be using the result of this function directly
    in an email.
    'b'Decode a raw base64 string, returning a bytes object.

    This function does not parse a full MIME header value encoded with
    base64 (like =?iso-8859-1?b?bmloISBuaWgh?=) -- please use the high
    level email.header class for that functionality.
    'u'Decode a raw base64 string, returning a bytes object.

    This function does not parse a full MIME header value encoded with
    base64 (like =?iso-8859-1?b?bmloISBuaWgh?=) -- please use the high
    level email.header class for that functionality.
    'b'raw-unicode-escape'u'raw-unicode-escape'u'email.base64mime'Base implementation of event loop.

The event loop can be broken up into a multiplexer (the part
responsible for notifying us of I/O events) and the event loop proper,
which wraps a multiplexer with functionality for scheduling callbacks,
immediately or at a given time in the future.

Whenever a public API takes a callback, subsequent positional
arguments will be passed to the callback if/when it is called.  This
avoids the proliferation of trivial lambdas implementing closures.
Keyword arguments for the callback are not supported; this is a
conscious design decision, leaving the door open for keyword arguments
to modify the meaning of the API call itself.
concurrentconstantssslprotostaggeredtrsockBaseEventLoopServer_MIN_SCHEDULED_TIMER_HANDLES_MIN_CANCELLED_TIMER_HANDLES_FRACTION_HAS_IPv6MAXIMUM_SELECT_TIMEOUT_unset_format_handle_callback_format_pipe<pipe>STDOUT<stdout>_set_reuseportreuse_port not supported by socket modulereuse_port not supported by socket module, SO_REUSEPORT defined but not implemented.'reuse_port not supported by socket module, ''SO_REUSEPORT defined but not implemented.'_ipaddr_infoflowinfoscopeidafsidnaaf_interleave_addrinfosaddrinfosfirst_address_family_countInterleave list of addrinfo tuples by family.addrinfos_by_familyaddraddrinfos_listsreordered_run_until_complete_cb_get_loop_set_nodelay_check_ssl_socketSSLSocketSocket cannot be of type SSLSocket_SendfileFallbackProtocoltransp_FlowControlMixintransport should be _FlowControlMixin instance_transportget_protocol_protois_reading_should_resume_reading_protocol_paused_should_resume_writingpause_readingset_protocol_write_ready_futdrainis_closingConnection closed by peerconnection_madetransportInvalid state: connection should have been established already."Invalid state: ""connection should have been established already."connection_lostConnection is closed by peerpause_writingresume_writingdata_receivedInvalid state: reading should be pausedeof_receivedresume_readingAbstractServersocketsprotocol_factorybacklogssl_handshake_timeout_sockets_active_count_protocol_factory_backlog_ssl_context_ssl_handshake_timeout_serving_serving_forever_fut sockets=_attach_detach_wakeup_start_servingis_servingTransportSocket_stop_servingstart_servingserver  is already being awaited on serve_forever() is closedwait_closedAbstractEventLoop_timer_cancelled_count_stopping_ready_scheduled_default_executor_internal_fds_thread_idget_clock_info_clock_resolution_exception_handler_is_debug_modeslow_callback_duration_current_handle_task_factory_coroutine_origin_tracking_enabled_coroutine_origin_tracking_saved_depth_asyncgens_asyncgens_shutdown_called_executor_shutdown_called running=is_running closed=' ''closed='is_closed debug=get_debugCreate a Future object attached to the loop.coroSchedule a coroutine object.

        Return a task object.
        _check_closed_set_task_nameset_task_factorySet a task factory that will be used by loop.create_task().

        If factory is None the default task factory will be set.

        If factory is a callable, it should have a signature matching
        '(loop, coro)', where 'loop' will be a reference to the active
        event loop, 'coro' will be a coroutine object.  The callable
        must return a Future.
        task factory must be a callable or Noneget_task_factoryReturn a task factory, or None if the default one is in use._make_socket_transportCreate socket transport._make_ssl_transportrawsocksslcontextcall_connection_madeCreate SSL transport._make_datagram_transportCreate datagram transport._make_read_pipe_transportCreate read pipe transport._make_write_pipe_transportCreate write pipe transport._make_subprocess_transportshellCreate subprocess transport._write_to_selfWrite a byte to self-pipe, to wake up the event loop.

        This may be called from a different thread.

        The subclass is responsible for implementing the self-pipe.
        _process_eventsevent_listProcess selector events.Event loop is closed_check_default_executorExecutor shutdown has been called_asyncgen_finalizer_hookagencall_soon_threadsafe_asyncgen_firstiter_hookasynchronous generator  was scheduled after loop.shutdown_asyncgens() call" was scheduled after ""loop.shutdown_asyncgens() call"Shutdown all active asynchronous generators.closing_agensagan error occurred during closing of asynchronous generator 'an error occurred during closing of ''asynchronous generator 'asyncgenSchedule the shutdown of the default executor._do_shutdown_check_runningThis event loop is already runningCannot run the event loop while another loop is runningrun_foreverRun until stop() is called._set_coroutine_origin_tracking_debugold_agen_hooksfirstiterfinalizer_run_onceRun until the Future is done.

        If the argument is a coroutine, it is wrapped in a Task.

        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.

        Return the Future's result, or raise its exception.
        isfuturenew_taskensure_futureEvent loop stopped before Future completed.Stop running the event loop.

        Every callback already scheduled will still run.  This simply informs
        run_forever to stop looping after a complete iteration.
        Close the event loop.

        This clears the queues and shuts down the executor,
        but does not wait for the executor to finish.

        The event loop must not be running.
        Cannot close a running event loopClose %rexecutorReturns True if the event loop was closed._warnunclosed event loop Returns True if the event loop is running.Return the time according to the event loop's clock.

        This is a float expressed in seconds since an epoch, but the
        epoch, precision, accuracy and drift are unspecified and may
        differ per event loop.
        call_laterArrange for a callback to be called at a given time.

        Return a Handle: an opaque object with a cancel() method that
        can be used to cancel the call.

        The delay can be an int or float, expressed in seconds.  It is
        always relative to the current time.

        Each callback will be called exactly once.  If two callbacks
        are scheduled for exactly the same time, it undefined which
        will be called first.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        call_attimerwhenLike call_later(), but uses an absolute time.

        Absolute time corresponds to the event loop's time() method.
        _check_thread_check_callbackTimerHandlecall_soonArrange for a callback to be called as soon as possible.

        This operates as a FIFO queue: callbacks are called in the
        order in which they are registered.  Each callback will be
        called exactly once.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        _call_sooniscoroutineiscoroutinefunctioncoroutines cannot be used with a callable object was expected by (), got '(), ''got 'HandleCheck that the current thread is the thread running the event loop.

        Non-thread-safe methods of this class make this assumption and will
        likely behave incorrectly when the assumption is violated.

        Should only be called when (self._debug == True).  The caller is
        responsible for checking this condition for performance reasons.
        thread_idNon-thread-safe operation invoked on an event loop other than the current one"Non-thread-safe operation invoked on an event loop other ""than the current one"Like call_soon(), but thread-safe.run_in_executorthread_name_prefixwrap_futureset_default_executorUsing the default executor that is not an instance of ThreadPoolExecutor is deprecated and will be prohibited in Python 3.9'Using the default executor that is not an instance of ''ThreadPoolExecutor is deprecated and will be prohibited ''in Python 3.9'_getaddrinfo_debugfamily=type=proto=flags=Get address info %saddrinfoGetting address info  took 1000.01e3ms: getaddr_funcsockaddrsock_sendfilethe socket must be non-blocking_check_sendfile_params_sock_sendfile_nativeSendfileNotAvailableError_sock_sendfile_fallbacksyscall sendfile is not available for socket  and file "and file " combinationSENDFILE_FALLBACK_READBUFFER_SIZEblocksizetotal_sentsock_sendallfile should be opened in binary modeonly SOCK_STREAM type sockets are supportedcount must be a positive integer (got {!r})offset must be a non-negative integer (got {!r})_connect_sockaddr_infolocal_addr_infosCreate, bind and connect one socket.my_exceptionstype_laddrerror while attempting to bind on address 'error while attempting to bind on ''address '': 'sock_connectcreate_connectionlocal_addrhappy_eyeballs_delayConnect to a TCP server.

        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.

        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        server_hostname is only meaningful with sslYou must set server_hostname when using ssl without a host'You must set server_hostname ''when using ssl without a host'ssl_handshake_timeout is only meaningful with sslhost/port and sock can not be specified at the same time_ensure_resolvedinfosgetaddrinfo() returned empty listladdr_infosstaggered_raceMultiple exceptions: {}host and port was not specified and no sock specifiedA Stream Socket was expected, got _create_connection_transportget_extra_info%r connected to %s:%r: (%r, %r)sendfileSend a file to transport.

        Return the total number of bytes which were sent.

        The method uses high-performance os.sendfile if available.

        file must be a regular file object opened in binary mode.

        offset tells from where to start reading the file. If specified,
        count is the total number of bytes to transmit as opposed to
        sending the file until EOF is reached. File position is updated on
        return or also in case of error in which case file.tell()
        can be used to figure out the number of bytes
        which were sent.

        fallback set to True makes asyncio to manually read and send
        the file when the platform does not support the sendfile syscall
        (e.g. Windows or SSL socket on Unix).

        Raise SendfileNotAvailableError if the system does not support
        sendfile syscall and fallback is False.
        Transport is closing_sendfile_compatible_SendfileModeUNSUPPORTEDsendfile is not supported for transport TRY_NATIVE_sendfile_nativefallback is disabled and native sendfile is not supported for transport "fallback is disabled and native sendfile is not ""supported for transport "_sendfile_fallbacksendfile syscall is not supportedstart_tlsUpgrade transport to TLS.

        Return a new transport that *protocol* should start using
        immediately.
        Python ssl module is not availablesslcontext is expected to be an instance of ssl.SSLContext, got 'sslcontext is expected to be an instance of ssl.SSLContext, '_start_tls_compatibletransport  is not supported by start_tls()SSLProtocolssl_protocolconmade_cbresume_cb_app_transportcreate_datagram_endpointremote_addrreuse_addressreuse_portallow_broadcastCreate datagram connection.A UDP Socket was expected, got problemssocket modifier keyword arguments can not be used when sock is specified. ('socket modifier keyword arguments can not be used ''when sock is specified. ('r_addrunexpected address familyaddr_pairs_infostring is expectedUnable to check or remove stale UNIX socket %r: %r'Unable to check or remove stale UNIX ''socket %r: %r'addr_infos2-tuple is expectedfamproaddr_paircan not get address informationPassing `reuse_address=True` is no longer supported, as the usage of SO_REUSEPORT in UDP poses a significant security concern."Passing `reuse_address=True` is no ""longer supported, as the usage of ""SO_REUSEPORT in UDP poses a significant ""security concern."The *reuse_address* parameter has been deprecated as of 3.5.10 and is scheduled for removal in 3.11."The *reuse_address* parameter has been ""deprecated as of 3.5.10 and is scheduled ""for removal in 3.11."local_addressremote_addressDatagram endpoint local_addr=%r remote_addr=%r created: (%r, %r)"Datagram endpoint local_addr=%r remote_addr=%r ""created: (%r, %r)"Datagram endpoint remote_addr=%r created: (%r, %r)"Datagram endpoint remote_addr=%r created: ""(%r, %r)"_create_server_getaddrinfogetaddrinfo() returned empty listcreate_serverCreate a TCP server.

        The host parameter can be a string, in that case the TCP server is
        bound to host and port.

        The host parameter can also be a sequence of strings and in that case
        the TCP server is bound to all hosts of the sequence. If a host
        appears multiple times (possibly indirectly e.g. when hostnames
        resolve to the same IP address), the server is only bound once to that
        host.

        Return a Server object which can be used to stop the service.

        This method is a coroutine.
        ssl argument must be an SSLContext or Nonehostscompletedsocktypecanonnamesacreate_server() failed to create socket.socket(%r, %r, %r)'create_server() failed to create ''socket.socket(%r, %r, %r)'error while attempting to bind on address %r: %s'error while attempting ''to bind on address %r: %s'Neither host/port nor sock were specified%r is servingconnect_accepted_socket%r handled: (%r, %r)connect_read_pipeRead pipe %r connected: (%r, %r)connect_write_pipeWrite pipe %r connected: (%r, %r)_log_subprocessstdin=stdout=stderr=stdout=stderr=subprocess_shellcmd must be a stringuniversal_newlines must be Falseshell must be Truebufsize must be 0text must be Falseencoding must be Noneerrors must be Nonedebug_logrun shell command %r%s: %rsubprocess_execprogramshell must be Falsepopen_argsexecute program get_exception_handlerReturn an exception handler, or None if the default one is in use.
        set_exception_handlerSet handler as the new event loop exception handler.

        If handler is None, the default exception handler will
        be set.

        If handler is a callable object, it should have a
        signature matching '(loop, context)', where 'loop'
        will be a reference to the active event loop, 'context'
        will be a dict object (see `call_exception_handler()`
        documentation for details about context).
        A callable object or None is expected, got 'A callable object or None is expected, 'default_exception_handlerDefault exception handler.

        This is called when an exception occurs and no exception
        handler is set, and can be called by a custom exception
        handler that wants to defer to the default behavior.

        This default handler logs the error message and other
        context-dependent information.  In debug mode, a truncated
        stack trace is also appended showing where the given object
        (e.g. a handle or future or task) was created, if any.

        The context parameter has the same meaning as in
        `call_exception_handler()`.
        Unhandled exception in event loopsource_tracebackhandle_tracebacklog_linesformat_listObject created at (most recent call last):
Handle created at (most recent call last):
Call the current event loop's exception handler.

        The context argument is a dict containing the following keys:

        - 'message': Error message;
        - 'exception' (optional): Exception object;
        - 'future' (optional): Future instance;
        - 'task' (optional): Task instance;
        - 'handle' (optional): Handle instance;
        - 'protocol' (optional): Protocol instance;
        - 'transport' (optional): Transport instance;
        - 'socket' (optional): Socket instance;
        - 'asyncgen' (optional): Asynchronous generator that caused
                                 the exception.

        New keys maybe introduced in the future.

        Note: do not overload this method in an event loop subclass.
        For custom exception handling, use the
        `set_exception_handler()` method.
        Exception in default exception handlerUnhandled error in exception handlerException in default exception handler while handling an unexpected error in custom exception handler'Exception in default exception handler ''while handling an unexpected error ''in custom exception handler'_add_callbackAdd a Handle to _scheduled (TimerHandle) or _ready.A Handle is required here_cancelled_add_callback_signalsafeLike _add_callback() but called from a signal handler._timer_handle_cancelledNotification that a TimerHandle has been cancelled.Run one full iteration of the event loop.

        This calls all currently ready callbacks, polls for I/O,
        schedules the resulting callbacks, and finally schedules
        'call_later' callbacks.
        sched_countnew_scheduled_when_selectorntodo_runExecuting %s took %.3f secondsenabledDEBUG_STACK_DEPTH# Minimum number of _scheduled timer handles before cleanup of# cancelled handles is performed.# Minimum fraction of _scheduled timer handles that are cancelled# before cleanup of cancelled handles is performed.# Maximum timeout passed to select to avoid OS limitations# Used for deprecation and removal of `loop.create_datagram_endpoint()`'s# *reuse_address* parameter# format the task# Try to skip getaddrinfo if "host" is already an IP. Users might have# handled name resolution in their own code and pass in resolved IPs.# If port's a service name like "http", don't skip getaddrinfo.# Linux's inet_pton doesn't accept an IPv6 zone index after host,# like '::1%lo0'.# The host has already been resolved.# "host" is not an IP address.# Group addresses by family# Issue #22429: run_forever() already finished, no need to# stop it.# Never happens if peer disconnects after sending the whole content# Thus disconnection is always an exception from user perspective# Cancel the future.# Basically it has no effect because protocol is switched back,# no code should wait for it anymore.# Skip one loop iteration so that all 'loop.add_reader'# go through.# Identifier of the thread running the event loop, or None if the# event loop is not running# In debug mode, if the execution of a callback or a step of a task# exceed this duration in seconds, the slow callback/task is logged.# A weak set of all asynchronous generators that are# being iterated by the loop.# Set to True when `loop.shutdown_asyncgens` is called.# Set to True when `loop.shutdown_default_executor` is called.# If Python version is <3.6 or we don't have any asynchronous# generators alive.# An exception is raised if the future didn't complete, so there# is no need to log the "destroy pending task" message# The coroutine raised a BaseException. Consume the exception# to not log a warning, the caller doesn't have access to the# local task.# Only check when the default executor is being used# NB: sendfile syscall is not supported for SSL sockets and# non-mmap files even if sendfile is supported by OS# EOF# all bind attempts failed# Use host as default for server_hostname.  It is an error# if host is empty or not set, e.g. when an# already-connected socket was passed or when only a port# is given.  To avoid this error, you can pass# server_hostname='' -- this will bypass the hostname# check.  (This also means that if host is a numeric# IP/IPv6 address, we will attempt to verify that exact# address; this will probably fail, but it is possible to# create a certificate for a specific IP address, so we# don't judge it here.)# If using happy eyeballs, default to interleave addresses by family# not using happy eyeballs# using happy eyeballs# If they all have the same str(), raise one.# Raise a combined exception so the user can see all# the various error messages.# We allow AF_INET, AF_INET6, AF_UNIX as long as they# are SOCK_STREAM.# We support passing AF_UNIX sockets even though we have# a dedicated API for that: create_unix_connection.# Disallowing AF_UNIX in this method, breaks backwards# Get the socket from the transport because SSL transport closes# the old socket and creates a new SSL socket# Pause early so that "ssl_protocol.data_received()" doesn't# have a chance to get called before "ssl_protocol.connection_made()".# show the problematic kwargs in exception msg# Directory may have permissions only to create socket.# join address by (family, protocol)# Using order preserving dict# each addr has to have info for each (family, proto) pair# bpo-37228# "host" is already a resolved IP.# Assume it's a bad family/type/protocol combination.# Disable IPv4/IPv6 dual stack support (enabled by# default on Linux) which makes a single socket# listen on both address families.# don't log parameters: they may contain sensitive information# (password) and may be too long# Second protection layer for unexpected errors# in the default implementation, as well as for subclassed# event loops with overloaded "default_exception_handler".# Exception in the user set custom exception handler.# Let's try default handler.# Guard 'default_exception_handler' in case it is# overloaded.# Remove delayed calls that were cancelled if their number# is too high# Remove delayed calls that were cancelled from head of queue.# Compute the desired timeout.# Needed to break cycles when an exception occurs.# Handle 'later' callbacks that are ready.# This is the only place where callbacks are actually *called*.# All other places just add them to ready.# Note: We run all currently scheduled callbacks, but not any# callbacks scheduled by callbacks run this time around --# they will be run the next time (after another I/O poll).# Use an idiom that is thread-safe without using locks.b'Base implementation of event loop.

The event loop can be broken up into a multiplexer (the part
responsible for notifying us of I/O events) and the event loop proper,
which wraps a multiplexer with functionality for scheduling callbacks,
immediately or at a given time in the future.

Whenever a public API takes a callback, subsequent positional
arguments will be passed to the callback if/when it is called.  This
avoids the proliferation of trivial lambdas implementing closures.
Keyword arguments for the callback are not supported; this is a
conscious design decision, leaving the door open for keyword arguments
to modify the meaning of the API call itself.
'u'Base implementation of event loop.

The event loop can be broken up into a multiplexer (the part
responsible for notifying us of I/O events) and the event loop proper,
which wraps a multiplexer with functionality for scheduling callbacks,
immediately or at a given time in the future.

Whenever a public API takes a callback, subsequent positional
arguments will be passed to the callback if/when it is called.  This
avoids the proliferation of trivial lambdas implementing closures.
Keyword arguments for the callback are not supported; this is a
conscious design decision, leaving the door open for keyword arguments
to modify the meaning of the API call itself.
'b'BaseEventLoop'u'BaseEventLoop'b'Server'u'Server'b'AF_INET6'u'AF_INET6'b'<pipe>'u'<pipe>'b'<stdout>'u'<stdout>'b'SO_REUSEPORT'u'SO_REUSEPORT'b'reuse_port not supported by socket module'u'reuse_port not supported by socket module'b'reuse_port not supported by socket module, SO_REUSEPORT defined but not implemented.'u'reuse_port not supported by socket module, SO_REUSEPORT defined but not implemented.'b'inet_pton'u'inet_pton'b'idna'b'Interleave list of addrinfo tuples by family.'u'Interleave list of addrinfo tuples by family.'b'TCP_NODELAY'u'TCP_NODELAY'b'Socket cannot be of type SSLSocket'u'Socket cannot be of type SSLSocket'b'transport should be _FlowControlMixin instance'u'transport should be _FlowControlMixin instance'b'Connection closed by peer'u'Connection closed by peer'b'Invalid state: connection should have been established already.'u'Invalid state: connection should have been established already.'b'Connection is closed by peer'u'Connection is closed by peer'b'Invalid state: reading should be paused'u'Invalid state: reading should be paused'b' sockets='u' sockets='b'server 'u'server 'b' is already being awaited on serve_forever()'u' is already being awaited on serve_forever()'b' is closed'u' is closed'b' running='u' running='b' closed='u' closed='b' debug='u' debug='b'Create a Future object attached to the loop.'u'Create a Future object attached to the loop.'b'Schedule a coroutine object.

        Return a task object.
        'u'Schedule a coroutine object.

        Return a task object.
        'b'Set a task factory that will be used by loop.create_task().

        If factory is None the default task factory will be set.

        If factory is a callable, it should have a signature matching
        '(loop, coro)', where 'loop' will be a reference to the active
        event loop, 'coro' will be a coroutine object.  The callable
        must return a Future.
        'u'Set a task factory that will be used by loop.create_task().

        If factory is None the default task factory will be set.

        If factory is a callable, it should have a signature matching
        '(loop, coro)', where 'loop' will be a reference to the active
        event loop, 'coro' will be a coroutine object.  The callable
        must return a Future.
        'b'task factory must be a callable or None'u'task factory must be a callable or None'b'Return a task factory, or None if the default one is in use.'u'Return a task factory, or None if the default one is in use.'b'Create socket transport.'u'Create socket transport.'b'Create SSL transport.'u'Create SSL transport.'b'Create datagram transport.'u'Create datagram transport.'b'Create read pipe transport.'u'Create read pipe transport.'b'Create write pipe transport.'u'Create write pipe transport.'b'Create subprocess transport.'u'Create subprocess transport.'b'Write a byte to self-pipe, to wake up the event loop.

        This may be called from a different thread.

        The subclass is responsible for implementing the self-pipe.
        'u'Write a byte to self-pipe, to wake up the event loop.

        This may be called from a different thread.

        The subclass is responsible for implementing the self-pipe.
        'b'Process selector events.'u'Process selector events.'b'Event loop is closed'u'Event loop is closed'b'Executor shutdown has been called'u'Executor shutdown has been called'b'asynchronous generator 'u'asynchronous generator 'b' was scheduled after loop.shutdown_asyncgens() call'u' was scheduled after loop.shutdown_asyncgens() call'b'Shutdown all active asynchronous generators.'u'Shutdown all active asynchronous generators.'b'an error occurred during closing of asynchronous generator 'u'an error occurred during closing of asynchronous generator 'b'asyncgen'u'asyncgen'b'Schedule the shutdown of the default executor.'u'Schedule the shutdown of the default executor.'b'This event loop is already running'u'This event loop is already running'b'Cannot run the event loop while another loop is running'u'Cannot run the event loop while another loop is running'b'Run until stop() is called.'u'Run until stop() is called.'b'Run until the Future is done.

        If the argument is a coroutine, it is wrapped in a Task.

        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.

        Return the Future's result, or raise its exception.
        'u'Run until the Future is done.

        If the argument is a coroutine, it is wrapped in a Task.

        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.

        Return the Future's result, or raise its exception.
        'b'Event loop stopped before Future completed.'u'Event loop stopped before Future completed.'b'Stop running the event loop.

        Every callback already scheduled will still run.  This simply informs
        run_forever to stop looping after a complete iteration.
        'u'Stop running the event loop.

        Every callback already scheduled will still run.  This simply informs
        run_forever to stop looping after a complete iteration.
        'b'Close the event loop.

        This clears the queues and shuts down the executor,
        but does not wait for the executor to finish.

        The event loop must not be running.
        'u'Close the event loop.

        This clears the queues and shuts down the executor,
        but does not wait for the executor to finish.

        The event loop must not be running.
        'b'Cannot close a running event loop'u'Cannot close a running event loop'b'Close %r'u'Close %r'b'Returns True if the event loop was closed.'u'Returns True if the event loop was closed.'b'unclosed event loop 'u'unclosed event loop 'b'Returns True if the event loop is running.'u'Returns True if the event loop is running.'b'Return the time according to the event loop's clock.

        This is a float expressed in seconds since an epoch, but the
        epoch, precision, accuracy and drift are unspecified and may
        differ per event loop.
        'u'Return the time according to the event loop's clock.

        This is a float expressed in seconds since an epoch, but the
        epoch, precision, accuracy and drift are unspecified and may
        differ per event loop.
        'b'Arrange for a callback to be called at a given time.

        Return a Handle: an opaque object with a cancel() method that
        can be used to cancel the call.

        The delay can be an int or float, expressed in seconds.  It is
        always relative to the current time.

        Each callback will be called exactly once.  If two callbacks
        are scheduled for exactly the same time, it undefined which
        will be called first.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        'u'Arrange for a callback to be called at a given time.

        Return a Handle: an opaque object with a cancel() method that
        can be used to cancel the call.

        The delay can be an int or float, expressed in seconds.  It is
        always relative to the current time.

        Each callback will be called exactly once.  If two callbacks
        are scheduled for exactly the same time, it undefined which
        will be called first.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        'b'Like call_later(), but uses an absolute time.

        Absolute time corresponds to the event loop's time() method.
        'u'Like call_later(), but uses an absolute time.

        Absolute time corresponds to the event loop's time() method.
        'b'call_at'u'call_at'b'Arrange for a callback to be called as soon as possible.

        This operates as a FIFO queue: callbacks are called in the
        order in which they are registered.  Each callback will be
        called exactly once.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        'u'Arrange for a callback to be called as soon as possible.

        This operates as a FIFO queue: callbacks are called in the
        order in which they are registered.  Each callback will be
        called exactly once.

        Any positional arguments after the callback will be passed to
        the callback when it is called.
        'b'call_soon'u'call_soon'b'coroutines cannot be used with 'u'coroutines cannot be used with 'b'a callable object was expected by 'u'a callable object was expected by 'b'(), got 'u'(), got 'b'Check that the current thread is the thread running the event loop.

        Non-thread-safe methods of this class make this assumption and will
        likely behave incorrectly when the assumption is violated.

        Should only be called when (self._debug == True).  The caller is
        responsible for checking this condition for performance reasons.
        'u'Check that the current thread is the thread running the event loop.

        Non-thread-safe methods of this class make this assumption and will
        likely behave incorrectly when the assumption is violated.

        Should only be called when (self._debug == True).  The caller is
        responsible for checking this condition for performance reasons.
        'b'Non-thread-safe operation invoked on an event loop other than the current one'u'Non-thread-safe operation invoked on an event loop other than the current one'b'Like call_soon(), but thread-safe.'u'Like call_soon(), but thread-safe.'b'call_soon_threadsafe'u'call_soon_threadsafe'b'run_in_executor'u'run_in_executor'b'asyncio'b'Using the default executor that is not an instance of ThreadPoolExecutor is deprecated and will be prohibited in Python 3.9'u'Using the default executor that is not an instance of ThreadPoolExecutor is deprecated and will be prohibited in Python 3.9'b'family='u'family='b'type='u'type='b'proto='u'proto='b'flags='u'flags='b'Get address info %s'u'Get address info %s'b'Getting address info 'u'Getting address info 'b' took 'u' took 'b'ms: 'u'ms: 'b'the socket must be non-blocking'u'the socket must be non-blocking'b'syscall sendfile is not available for socket 'u'syscall sendfile is not available for socket 'b' and file 'u' and file 'b' combination'u' combination'b'file should be opened in binary mode'u'file should be opened in binary mode'b'only SOCK_STREAM type sockets are supported'u'only SOCK_STREAM type sockets are supported'b'count must be a positive integer (got {!r})'u'count must be a positive integer (got {!r})'b'offset must be a non-negative integer (got {!r})'u'offset must be a non-negative integer (got {!r})'b'Create, bind and connect one socket.'u'Create, bind and connect one socket.'b'error while attempting to bind on address 'u'error while attempting to bind on address 'b'Connect to a TCP server.

        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.

        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        'u'Connect to a TCP server.

        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.

        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        'b'server_hostname is only meaningful with ssl'u'server_hostname is only meaningful with ssl'b'You must set server_hostname when using ssl without a host'u'You must set server_hostname when using ssl without a host'b'ssl_handshake_timeout is only meaningful with ssl'u'ssl_handshake_timeout is only meaningful with ssl'b'host/port and sock can not be specified at the same time'u'host/port and sock can not be specified at the same time'b'getaddrinfo() returned empty list'u'getaddrinfo() returned empty list'b'Multiple exceptions: {}'u'Multiple exceptions: {}'b'host and port was not specified and no sock specified'u'host and port was not specified and no sock specified'b'A Stream Socket was expected, got 'u'A Stream Socket was expected, got 'b'%r connected to %s:%r: (%r, %r)'u'%r connected to %s:%r: (%r, %r)'b'Send a file to transport.

        Return the total number of bytes which were sent.

        The method uses high-performance os.sendfile if available.

        file must be a regular file object opened in binary mode.

        offset tells from where to start reading the file. If specified,
        count is the total number of bytes to transmit as opposed to
        sending the file until EOF is reached. File position is updated on
        return or also in case of error in which case file.tell()
        can be used to figure out the number of bytes
        which were sent.

        fallback set to True makes asyncio to manually read and send
        the file when the platform does not support the sendfile syscall
        (e.g. Windows or SSL socket on Unix).

        Raise SendfileNotAvailableError if the system does not support
        sendfile syscall and fallback is False.
        'u'Send a file to transport.

        Return the total number of bytes which were sent.

        The method uses high-performance os.sendfile if available.

        file must be a regular file object opened in binary mode.

        offset tells from where to start reading the file. If specified,
        count is the total number of bytes to transmit as opposed to
        sending the file until EOF is reached. File position is updated on
        return or also in case of error in which case file.tell()
        can be used to figure out the number of bytes
        which were sent.

        fallback set to True makes asyncio to manually read and send
        the file when the platform does not support the sendfile syscall
        (e.g. Windows or SSL socket on Unix).

        Raise SendfileNotAvailableError if the system does not support
        sendfile syscall and fallback is False.
        'b'Transport is closing'u'Transport is closing'b'_sendfile_compatible'u'_sendfile_compatible'b'sendfile is not supported for transport 'u'sendfile is not supported for transport 'b'fallback is disabled and native sendfile is not supported for transport 'u'fallback is disabled and native sendfile is not supported for transport 'b'sendfile syscall is not supported'u'sendfile syscall is not supported'b'Upgrade transport to TLS.

        Return a new transport that *protocol* should start using
        immediately.
        'u'Upgrade transport to TLS.

        Return a new transport that *protocol* should start using
        immediately.
        'b'Python ssl module is not available'u'Python ssl module is not available'b'sslcontext is expected to be an instance of ssl.SSLContext, got 'u'sslcontext is expected to be an instance of ssl.SSLContext, got 'b'_start_tls_compatible'u'_start_tls_compatible'b'transport 'u'transport 'b' is not supported by start_tls()'u' is not supported by start_tls()'b'Create datagram connection.'u'Create datagram connection.'b'A UDP Socket was expected, got 'u'A UDP Socket was expected, got 'b'socket modifier keyword arguments can not be used when sock is specified. ('u'socket modifier keyword arguments can not be used when sock is specified. ('b'unexpected address family'u'unexpected address family'b'string is expected'u'string is expected'b'Unable to check or remove stale UNIX socket %r: %r'u'Unable to check or remove stale UNIX socket %r: %r'b'2-tuple is expected'u'2-tuple is expected'b'can not get address information'u'can not get address information'b'Passing `reuse_address=True` is no longer supported, as the usage of SO_REUSEPORT in UDP poses a significant security concern.'u'Passing `reuse_address=True` is no longer supported, as the usage of SO_REUSEPORT in UDP poses a significant security concern.'b'The *reuse_address* parameter has been deprecated as of 3.5.10 and is scheduled for removal in 3.11.'u'The *reuse_address* parameter has been deprecated as of 3.5.10 and is scheduled for removal in 3.11.'b'Datagram endpoint local_addr=%r remote_addr=%r created: (%r, %r)'u'Datagram endpoint local_addr=%r remote_addr=%r created: (%r, %r)'b'Datagram endpoint remote_addr=%r created: (%r, %r)'u'Datagram endpoint remote_addr=%r created: (%r, %r)'b'getaddrinfo('u'getaddrinfo('b') returned empty list'u') returned empty list'b'Create a TCP server.

        The host parameter can be a string, in that case the TCP server is
        bound to host and port.

        The host parameter can also be a sequence of strings and in that case
        the TCP server is bound to all hosts of the sequence. If a host
        appears multiple times (possibly indirectly e.g. when hostnames
        resolve to the same IP address), the server is only bound once to that
        host.

        Return a Server object which can be used to stop the service.

        This method is a coroutine.
        'u'Create a TCP server.

        The host parameter can be a string, in that case the TCP server is
        bound to host and port.

        The host parameter can also be a sequence of strings and in that case
        the TCP server is bound to all hosts of the sequence. If a host
        appears multiple times (possibly indirectly e.g. when hostnames
        resolve to the same IP address), the server is only bound once to that
        host.

        Return a Server object which can be used to stop the service.

        This method is a coroutine.
        'b'ssl argument must be an SSLContext or None'u'ssl argument must be an SSLContext or None'b'create_server() failed to create socket.socket(%r, %r, %r)'u'create_server() failed to create socket.socket(%r, %r, %r)'b'IPPROTO_IPV6'u'IPPROTO_IPV6'b'error while attempting to bind on address %r: %s'u'error while attempting to bind on address %r: %s'b'Neither host/port nor sock were specified'u'Neither host/port nor sock were specified'b'%r is serving'u'%r is serving'b'%r handled: (%r, %r)'u'%r handled: (%r, %r)'b'Read pipe %r connected: (%r, %r)'u'Read pipe %r connected: (%r, %r)'b'Write pipe %r connected: (%r, %r)'u'Write pipe %r connected: (%r, %r)'b'stdin='u'stdin='b'stdout=stderr='u'stdout=stderr='b'stdout='u'stdout='b'stderr='u'stderr='b'cmd must be a string'u'cmd must be a string'b'universal_newlines must be False'u'universal_newlines must be False'b'shell must be True'u'shell must be True'b'bufsize must be 0'u'bufsize must be 0'b'text must be False'u'text must be False'b'encoding must be None'u'encoding must be None'b'errors must be None'u'errors must be None'b'run shell command %r'u'run shell command %r'b'%s: %r'u'%s: %r'b'shell must be False'u'shell must be False'b'execute program 'u'execute program 'b'Return an exception handler, or None if the default one is in use.
        'u'Return an exception handler, or None if the default one is in use.
        'b'Set handler as the new event loop exception handler.

        If handler is None, the default exception handler will
        be set.

        If handler is a callable object, it should have a
        signature matching '(loop, context)', where 'loop'
        will be a reference to the active event loop, 'context'
        will be a dict object (see `call_exception_handler()`
        documentation for details about context).
        'u'Set handler as the new event loop exception handler.

        If handler is None, the default exception handler will
        be set.

        If handler is a callable object, it should have a
        signature matching '(loop, context)', where 'loop'
        will be a reference to the active event loop, 'context'
        will be a dict object (see `call_exception_handler()`
        documentation for details about context).
        'b'A callable object or None is expected, got 'u'A callable object or None is expected, got 'b'Default exception handler.

        This is called when an exception occurs and no exception
        handler is set, and can be called by a custom exception
        handler that wants to defer to the default behavior.

        This default handler logs the error message and other
        context-dependent information.  In debug mode, a truncated
        stack trace is also appended showing where the given object
        (e.g. a handle or future or task) was created, if any.

        The context parameter has the same meaning as in
        `call_exception_handler()`.
        'u'Default exception handler.

        This is called when an exception occurs and no exception
        handler is set, and can be called by a custom exception
        handler that wants to defer to the default behavior.

        This default handler logs the error message and other
        context-dependent information.  In debug mode, a truncated
        stack trace is also appended showing where the given object
        (e.g. a handle or future or task) was created, if any.

        The context parameter has the same meaning as in
        `call_exception_handler()`.
        'b'Unhandled exception in event loop'u'Unhandled exception in event loop'b'source_traceback'u'source_traceback'b'handle_traceback'u'handle_traceback'b'Object created at (most recent call last):
'u'Object created at (most recent call last):
'b'Handle created at (most recent call last):
'u'Handle created at (most recent call last):
'b'Call the current event loop's exception handler.

        The context argument is a dict containing the following keys:

        - 'message': Error message;
        - 'exception' (optional): Exception object;
        - 'future' (optional): Future instance;
        - 'task' (optional): Task instance;
        - 'handle' (optional): Handle instance;
        - 'protocol' (optional): Protocol instance;
        - 'transport' (optional): Transport instance;
        - 'socket' (optional): Socket instance;
        - 'asyncgen' (optional): Asynchronous generator that caused
                                 the exception.

        New keys maybe introduced in the future.

        Note: do not overload this method in an event loop subclass.
        For custom exception handling, use the
        `set_exception_handler()` method.
        'u'Call the current event loop's exception handler.

        The context argument is a dict containing the following keys:

        - 'message': Error message;
        - 'exception' (optional): Exception object;
        - 'future' (optional): Future instance;
        - 'task' (optional): Task instance;
        - 'handle' (optional): Handle instance;
        - 'protocol' (optional): Protocol instance;
        - 'transport' (optional): Transport instance;
        - 'socket' (optional): Socket instance;
        - 'asyncgen' (optional): Asynchronous generator that caused
                                 the exception.

        New keys maybe introduced in the future.

        Note: do not overload this method in an event loop subclass.
        For custom exception handling, use the
        `set_exception_handler()` method.
        'b'Exception in default exception handler'u'Exception in default exception handler'b'Unhandled error in exception handler'u'Unhandled error in exception handler'b'Exception in default exception handler while handling an unexpected error in custom exception handler'u'Exception in default exception handler while handling an unexpected error in custom exception handler'b'Add a Handle to _scheduled (TimerHandle) or _ready.'u'Add a Handle to _scheduled (TimerHandle) or _ready.'b'A Handle is required here'u'A Handle is required here'b'Like _add_callback() but called from a signal handler.'u'Like _add_callback() but called from a signal handler.'b'Notification that a TimerHandle has been cancelled.'u'Notification that a TimerHandle has been cancelled.'b'Run one full iteration of the event loop.

        This calls all currently ready callbacks, polls for I/O,
        schedules the resulting callbacks, and finally schedules
        'call_later' callbacks.
        'u'Run one full iteration of the event loop.

        This calls all currently ready callbacks, polls for I/O,
        schedules the resulting callbacks, and finally schedules
        'call_later' callbacks.
        'b'Executing %s took %.3f seconds'u'Executing %s took %.3f seconds'u'asyncio.base_events'u'base_events'format_helpers_PENDING_CANCELLED_FINISHEDCheck for a Future.

    This returns True when obj is a Future instance or is advertising
    itself as duck-type compatible by setting _asyncio_future_blocking.
    See comment in Future for more details.
    _format_callbackshelper function for Future.__repr__format_cb_format_callback_source{}, {}{}, <{} more>, {}cb=[_repr_running_future_repr_infoexception=result=created at # States for Future.# bpo-42183: _repr_running is needed for repr protection# when a Future or Task result contains itself directly or indirectly.# The logic is borrowed from @reprlib.recursive_repr decorator.# Unfortunately, the direct decorator usage is impossible because of# AttributeError: '_asyncio.Task' object has no attribute '__module__' error.# After fixing this thing we can return to the decorator based approach.# (Future) -> str# use reprlib to limit the length of the output, especially# for very long stringsb'Check for a Future.

    This returns True when obj is a Future instance or is advertising
    itself as duck-type compatible by setting _asyncio_future_blocking.
    See comment in Future for more details.
    'u'Check for a Future.

    This returns True when obj is a Future instance or is advertising
    itself as duck-type compatible by setting _asyncio_future_blocking.
    See comment in Future for more details.
    'b'_asyncio_future_blocking'u'_asyncio_future_blocking'b'helper function for Future.__repr__'u'helper function for Future.__repr__'b'{}, {}'u'{}, {}'b'{}, <{} more>, {}'u'{}, <{} more>, {}'b'cb=['u'cb=['b'exception='u'exception='b'result='u'result='b'created at 'u'created at 'u'asyncio.base_futures'u'base_futures'BaseSubprocessTransportSubprocessTransport_protocol_proc_pid_returncode_exit_waiters_pending_calls_pipes_finished_extraprocess %r created: pid %s_connect_pipespid=returncode=not started<{}>pollClose running child process: kill %runclosed transport get_pidget_returncodeget_pipe_transport_check_procsend_signalWriteSubprocessPipeProtoReadSubprocessPipeProto_pipe_connection_lostpipe_connection_lost_try_finish_pipe_data_receivedpipe_data_received_process_exited%r exited with return code %rprocess_exited_waitWait until the process exit and return the process return code.

        This method is a coroutine.disconnected_call_connection_lostBaseProtocol fd= pipe=# Create the child process: set the _proc attribute# has the child process finished?# the child process has finished, but the# transport hasn't been notified yet?# Don't clear the _proc reference yet: _post_init() may still run# asyncio uses a child watcher: copy the status into the Popen# object. On Python 3.6, it is required to avoid a ResourceWarning.# wake up futures waiting for wait()b'process %r created: pid %s'u'process %r created: pid %s'b'closed'u'closed'b'pid='u'pid='b'returncode='u'returncode='b'not started'u'not started'b'<{}>'u'<{}>'b'Close running child process: kill %r'u'Close running child process: kill %r'b'unclosed transport 'u'unclosed transport 'b'%r exited with return code %r'u'%r exited with return code %r'b'Wait until the process exit and return the process return code.

        This method is a coroutine.'u'Wait until the process exit and return the process return code.

        This method is a coroutine.'b' fd='u' fd='b' pipe='u' pipe='u'asyncio.base_subprocess'u'base_subprocess'linecachebase_futures_task_repr_infocancellingname=%r_format_coroutinecoro=<wait_for=_task_get_stackframescr_frameag_frametb_next_task_print_stackextracted_listcheckcachegetlineNo stack for Traceback for  (most recent call last):Stack for print_listformat_exception_only# replace status# case 1: 'async def' coroutines# case 2: legacy coroutines# case 3: async generators# case 4: unknown objectsb'cancelling'u'cancelling'b'name=%r'u'name=%r'b'coro=<'u'coro=<'b'wait_for='u'wait_for='b'cr_frame'u'cr_frame'b'gi_frame'u'gi_frame'b'ag_frame'u'ag_frame'b'No stack for 'u'No stack for 'b'Traceback for 'u'Traceback for 'b' (most recent call last):'u' (most recent call last):'b'Stack for 'u'Stack for 'u'asyncio.base_tasks'u'base_tasks'Debugger basicsCO_GENERATORCO_COROUTINECO_ASYNC_GENERATORBdbQuitBdbBreakpointGENERATOR_AND_COROUTINE_FLAGSException to give up completely.Generic Python debugger base class.

    This class takes care of details of the trace facility;
    a derived class should implement user interaction.
    The standard debugger class (pdb.Pdb) is an example.

    The optional skip argument must be an iterable of glob-style
    module name patterns.  The debugger will not step into frames
    that originate in a module that matches one of these patterns.
    Whether a frame is considered to originate in a certain module
    is determined by the __name__ in the frame globals.
    breaksfncacheframe_returning_load_breakscanonicReturn canonical form of filename.

        For real filenames, the canonical form is a case-normalized (on
        case insensitive filesystems) absolute path.  'Filenames' with
        angle brackets, such as "<stdin>", generated in interactive
        mode, are returned unchanged.
        Set values of attributes as ready to start debugging.botframe_set_stopinfotrace_dispatchDispatch a trace function for debugged frames based on the event.

        This function is installed as the trace function for debugged
        frames. Its return value is the new trace function, which is
        usually itself. The default implementation decides how to
        dispatch a frame, depending on the type of event (passed in as a
        string) that is about to be executed.

        The event can be one of the following:
            line: A new line of code is going to be executed.
            call: A function is about to be called or another code block
                  is entered.
            return: A function or other code block is about to return.
            exception: An exception has occurred.
            c_call: A C function is about to be called.
            c_return: A C function has returned.
            c_exception: A C function has raised an exception.

        For the Python events, specialized functions (see the dispatch_*()
        methods) are called.  For the C events, no action is taken.

        The arg parameter depends on the previous event.
        quittingdispatch_linedispatch_calldispatch_returndispatch_exceptionc_callc_exceptionc_returnbdb.Bdb.dispatch: unknown debugging event:Invoke user function and return trace function for line event.

        If the debugger stops on the current line, invoke
        self.user_line(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        stop_herebreak_hereuser_lineInvoke user function and return trace function for call event.

        If the debugger stops on this function call, invoke
        self.user_call(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        break_anywherestopframeco_flagsuser_callInvoke user function and return trace function for return event.

        If the debugger stops on this function return, invoke
        self.user_return(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        returnframeuser_returnstoplinenoInvoke user function and return trace function for exception event.

        If the debugger stops on this exception, invoke
        self.user_exception(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        user_exceptionis_skipped_modulemodule_nameReturn True if module_name matches any skip pattern.Return True if frame is below the starting frame in the stack.Return True if there is an effective breakpoint for this line.

        Check for line or function breakpoint and if in effect.
        Delete temporary breakpoints if effective() says to.
        co_firstlinenoeffectivebpcurrentbptemporarydo_clearRemove temporary breakpoint.

        Must implement in derived classes or get NotImplementedError.
        subclass of bdb must implement do_clear()Return True if there is any breakpoint for frame's filename.
        argument_listCalled if we might stop in a function.Called when we stop or break at a line.return_valueCalled when a return trap is set here.Called when we stop on an exception.Set the attributes for stopping.

        If stoplineno is greater than or equal to 0, then stop at line
        greater than or equal to the stopline.  If stoplineno is -1, then
        don't stop at all.
        set_untilStop when the line with the lineno greater than the current one is
        reached or when returning from current frame.set_stepStop after one line of code.caller_framef_traceset_nextStop on the next line in or below the given frame.set_returnStop when returning from the given frame.set_traceStart debugging from frame.

        If frame is not specified, debugging starts from caller's frame.
        set_continueStop only at breakpoints or when finished.

        If there are no breakpoints, set the system trace function to None.
        set_quitSet quitting attribute to True.

        Raises BdbQuit exception in the next call to a dispatch_*() method.
        _add_to_breaksAdd breakpoint to breaks, if not already there.bp_linenosset_breakcondfuncnameSet a new breakpoint for filename:lineno.

        If lineno doesn't exist for the filename, return an error message.
        The filename should be in canonical form.
        Line %s:%d does not existApply all breakpoints (set in other instances) to this one.

        Populates this instance's breaks list from the Breakpoint class's
        list, which can have breakpoints set by another Bdb instance. This
        is necessary for interactive sessions to keep the breakpoints
        active across multiple calls to run().
        bplist_prune_breaksPrune breakpoints for filename:lineno.

        A list of breakpoints is maintained in the Bdb instance and in
        the Breakpoint class.  If a breakpoint in the Bdb instance no
        longer exists in the Breakpoint class, then it's removed from the
        Bdb instance.
        clear_breakDelete breakpoints for filename:lineno.

        If no breakpoints were set, return an error message.
        There are no breakpoints in %sThere is no breakpoint at %s:%ddeleteMeclear_bpbynumberDelete a breakpoint by its index in Breakpoint.bpbynumber.

        If arg is invalid, return an error message.
        get_bpbynumberclear_all_file_breaksDelete all breakpoints in filename.

        If none were set, return an error message.
        blistclear_all_breaksDelete all existing breakpoints.

        If none were set, return an error message.
        There are no breakpointsbpbynumberReturn a breakpoint by its index in Breakpoint.bybpnumber.

        For invalid arg values or if the breakpoint doesn't exist,
        raise a ValueError.
        Breakpoint number expectedNon-numeric breakpoint number %sBreakpoint number %d out of rangeBreakpoint %d already deletedget_breakReturn True if there is a breakpoint for filename:lineno.get_breaksReturn all breakpoints for filename:lineno.

        If no breakpoints are set, return an empty list.
        get_file_breaksReturn all lines with breakpoints for filename.

        If no breakpoints are set, return an empty list.
        get_all_breaksReturn all breakpoints that are set.Return a list of (frame, lineno) in a stack trace and a size.

        List starts with original calling frame, if there is one.
        Size may be number of frames above or below f.
        tb_linenoformat_stack_entryframe_linenolprefixReturn a string with information about a stack entry.

        The stack entry frame_lineno is a (frame, lineno) tuple.  The
        return string contains the canonical filename, the function name
        or '<lambda>', the input arguments, the return value, and the
        line of code (if it exists).

        <lambda>__return__f_locals->Debug a statement executed via the exec() function.

        globals defaults to __main__.dict; locals defaults to globals.
        runevalDebug an expression executed via the eval() function.

        globals defaults to __main__.dict; locals defaults to globals.
        runctxFor backwards-compatibility.  Defers to run().runcallDebug a single function call.

        Return the result of the function call.
        Start debugging with a Bdb instance from the caller's frame.Breakpoint class.

    Implements temporary breakpoints, ignore counts, disabling and
    (re)-enabling, and conditionals.

    Breakpoints are indexed by number through bpbynumber and by
    the (file, line) tuple using bplist.  The former points to a
    single instance of class Breakpoint.  The latter points to a
    list of such instances since there may be more than one
    breakpoint per line.

    When creating a breakpoint, its associated filename should be
    in canonical form.  If funcname is defined, a breakpoint hit will be
    counted when the first line of that function is executed.  A
    conditional breakpoint always counts a hit.
    func_first_executable_linehitsclearBreakpointsDelete the breakpoint from the list associated to a file:line.

        If it is the last breakpoint in that position, it also deletes
        the entry for the file:line.
        Mark the breakpoint as enabled.Mark the breakpoint as disabled.bpprintPrint the output of bpformat().

        The optional out argument directs where the output is sent
        and defaults to standard output.
        bpformatReturn a string with information about the breakpoint.

        The information includes the breakpoint number, temporary
        status, file:line position, break condition, number of times to
        ignore, and number of times hit.

        del  dispkeep yes  no   %-4dbreakpoint   %s at %s:%d
	stop only if %s
	ignore next %d hitsss
	breakpoint already hit %d time%sReturn a condensed description of the breakpoint.breakpoint %s at %s:%scheckfuncnameReturn True if break should happen here.

    Whether a break should happen depends on the way that b (the breakpoint)
    was set.  If it was set via line number, check if b.line is the same as
    the one in the frame.  If it was set via function name, check if this is
    the right function and if it is on the first executable line.
    Return (active breakpoint, delete temporary flag) or (None, None) as
       breakpoint to act upon.

       The "active breakpoint" is the first entry in bplist[line, file] (which
       must exist) that is enabled, for which checkfuncname is True, and that
       has neither a False condition nor a positive ignore count.  The flag,
       meaning that a temporary breakpoint should be deleted, is False only
       when the condiion cannot be evaluated (in which case, ignore count is
       ignored).

       If no such entry exists, then (None, None) is returned.
    possiblesTdb???+++ call+++retval+++ returnexc_stuff+++ exceptionfoofoo(barbar returnedbar(import bdb; bdb.foo(10)# None# XXX 'arg' is no longer used# First call of dispatch since reset()# (CT) Note that this may also be None!# No need to trace this function# Ignore call events in generator except when stepping.# Ignore return events in generator except when stepping.# The user issued a 'next' or 'until' command.# When stepping with next/until/return in a generator frame, skip# the internal StopIteration exception (with no traceback)# triggered by a subiterator run with the 'yield from' statement.# Stop at the StopIteration or GeneratorExit exception when the user# has set stopframe in a generator by issuing a return command, or a# next/until command at the last statement in the generator before the# exception.# Normally derived classes don't override the following# methods, but they may if they want to redefine the# definition of stopping and breakpoints.# some modules do not have names# (CT) stopframe may now also be None, see dispatch_call.# (CT) the former test for None is therefore removed from here.# The line itself has no breakpoint, but maybe the line is the# first line of a function with breakpoint set by function name.# flag says ok to delete temp. bp# Derived classes should override the user_* methods# to gain control.# stoplineno >= 0 means: stop at line >= the stoplineno# stoplineno -1 means: don't stop at all# Derived classes and clients can call the following methods# to affect the stepping state.# the name "until" is borrowed from gdb# Issue #13183: pdb skips frames after hitting a breakpoint and running# step commands.# Restore the trace function in the caller (that may not have been set# for performance reasons) when returning from the current frame.# Don't stop except at breakpoints or when finished# no breakpoints; run without debugger overhead# to manipulate breakpoints.  These methods return an# error message if something went wrong, None if all is well.# Set_break prints out the breakpoint line and file:lineno.# Call self.get_*break*() to see the breakpoints or better# for bp in Breakpoint.bpbynumber: if bp: bp.bpprint().# Import as late as possible# If there's only one bp in the list for that file,line# pair, then remove the breaks entry# Derived classes and clients can call the following method# to get a data structure representing a stack trace.# The following methods can be called by clients to use# a debugger to debug a statement or an expression.# Both can be given as a string, or a code object.# B/W compatibility# This method is more useful to debug a single function call.# XXX Keeping state in the class is a mistake -- this means# you cannot have more than one active Bdb instance.# Next bp to be assigned# indexed by (file, lineno) tuple# Each entry is None or an instance of Bpt# index 0 is unused, except for marking an# effective break .... see effective()# Needed if funcname is not None.# This better be in canonical form!# Build the two lists# No longer in list# No more bp for this f:l combo# -----------end of Breakpoint class----------# Breakpoint was set via line number.# Breakpoint was set at a line with a def statement and the function# defined is called: don't break.# Breakpoint set via function name.# It's not a function call, but rather execution of def statement.# We are in the right frame.# The function is entered for the 1st time.# But we are not at the first line number: don't break.# Count every hit when bp is enabled# If unconditional, and ignoring go on to next, else break# breakpoint and marker that it's ok to delete if temporary# Conditional bp.# Ignore count applies only to those bpt hits where the# condition evaluates to true.# continue# else:#   continue# if eval fails, most conservative thing is to stop on# breakpoint regardless of ignore count.  Don't delete# temporary, as another hint to user.# -------------------- testing --------------------b'Debugger basics'u'Debugger basics'b'BdbQuit'u'BdbQuit'b'Bdb'u'Bdb'b'Breakpoint'u'Breakpoint'b'Exception to give up completely.'u'Exception to give up completely.'b'Generic Python debugger base class.

    This class takes care of details of the trace facility;
    a derived class should implement user interaction.
    The standard debugger class (pdb.Pdb) is an example.

    The optional skip argument must be an iterable of glob-style
    module name patterns.  The debugger will not step into frames
    that originate in a module that matches one of these patterns.
    Whether a frame is considered to originate in a certain module
    is determined by the __name__ in the frame globals.
    'u'Generic Python debugger base class.

    This class takes care of details of the trace facility;
    a derived class should implement user interaction.
    The standard debugger class (pdb.Pdb) is an example.

    The optional skip argument must be an iterable of glob-style
    module name patterns.  The debugger will not step into frames
    that originate in a module that matches one of these patterns.
    Whether a frame is considered to originate in a certain module
    is determined by the __name__ in the frame globals.
    'b'Return canonical form of filename.

        For real filenames, the canonical form is a case-normalized (on
        case insensitive filesystems) absolute path.  'Filenames' with
        angle brackets, such as "<stdin>", generated in interactive
        mode, are returned unchanged.
        'u'Return canonical form of filename.

        For real filenames, the canonical form is a case-normalized (on
        case insensitive filesystems) absolute path.  'Filenames' with
        angle brackets, such as "<stdin>", generated in interactive
        mode, are returned unchanged.
        'b'Set values of attributes as ready to start debugging.'u'Set values of attributes as ready to start debugging.'b'Dispatch a trace function for debugged frames based on the event.

        This function is installed as the trace function for debugged
        frames. Its return value is the new trace function, which is
        usually itself. The default implementation decides how to
        dispatch a frame, depending on the type of event (passed in as a
        string) that is about to be executed.

        The event can be one of the following:
            line: A new line of code is going to be executed.
            call: A function is about to be called or another code block
                  is entered.
            return: A function or other code block is about to return.
            exception: An exception has occurred.
            c_call: A C function is about to be called.
            c_return: A C function has returned.
            c_exception: A C function has raised an exception.

        For the Python events, specialized functions (see the dispatch_*()
        methods) are called.  For the C events, no action is taken.

        The arg parameter depends on the previous event.
        'u'Dispatch a trace function for debugged frames based on the event.

        This function is installed as the trace function for debugged
        frames. Its return value is the new trace function, which is
        usually itself. The default implementation decides how to
        dispatch a frame, depending on the type of event (passed in as a
        string) that is about to be executed.

        The event can be one of the following:
            line: A new line of code is going to be executed.
            call: A function is about to be called or another code block
                  is entered.
            return: A function or other code block is about to return.
            exception: An exception has occurred.
            c_call: A C function is about to be called.
            c_return: A C function has returned.
            c_exception: A C function has raised an exception.

        For the Python events, specialized functions (see the dispatch_*()
        methods) are called.  For the C events, no action is taken.

        The arg parameter depends on the previous event.
        'b'call'u'call'b'c_call'u'c_call'b'c_exception'u'c_exception'b'c_return'u'c_return'b'bdb.Bdb.dispatch: unknown debugging event:'u'bdb.Bdb.dispatch: unknown debugging event:'b'Invoke user function and return trace function for line event.

        If the debugger stops on the current line, invoke
        self.user_line(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'u'Invoke user function and return trace function for line event.

        If the debugger stops on the current line, invoke
        self.user_line(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'b'Invoke user function and return trace function for call event.

        If the debugger stops on this function call, invoke
        self.user_call(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'u'Invoke user function and return trace function for call event.

        If the debugger stops on this function call, invoke
        self.user_call(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'b'Invoke user function and return trace function for return event.

        If the debugger stops on this function return, invoke
        self.user_return(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'u'Invoke user function and return trace function for return event.

        If the debugger stops on this function return, invoke
        self.user_return(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'b'Invoke user function and return trace function for exception event.

        If the debugger stops on this exception, invoke
        self.user_exception(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'u'Invoke user function and return trace function for exception event.

        If the debugger stops on this exception, invoke
        self.user_exception(). Raise BdbQuit if self.quitting is set.
        Return self.trace_dispatch to continue tracing in this scope.
        'b'Return True if module_name matches any skip pattern.'u'Return True if module_name matches any skip pattern.'b'Return True if frame is below the starting frame in the stack.'u'Return True if frame is below the starting frame in the stack.'b'Return True if there is an effective breakpoint for this line.

        Check for line or function breakpoint and if in effect.
        Delete temporary breakpoints if effective() says to.
        'u'Return True if there is an effective breakpoint for this line.

        Check for line or function breakpoint and if in effect.
        Delete temporary breakpoints if effective() says to.
        'b'Remove temporary breakpoint.

        Must implement in derived classes or get NotImplementedError.
        'u'Remove temporary breakpoint.

        Must implement in derived classes or get NotImplementedError.
        'b'subclass of bdb must implement do_clear()'u'subclass of bdb must implement do_clear()'b'Return True if there is any breakpoint for frame's filename.
        'u'Return True if there is any breakpoint for frame's filename.
        'b'Called if we might stop in a function.'u'Called if we might stop in a function.'b'Called when we stop or break at a line.'u'Called when we stop or break at a line.'b'Called when a return trap is set here.'u'Called when a return trap is set here.'b'Called when we stop on an exception.'u'Called when we stop on an exception.'b'Set the attributes for stopping.

        If stoplineno is greater than or equal to 0, then stop at line
        greater than or equal to the stopline.  If stoplineno is -1, then
        don't stop at all.
        'u'Set the attributes for stopping.

        If stoplineno is greater than or equal to 0, then stop at line
        greater than or equal to the stopline.  If stoplineno is -1, then
        don't stop at all.
        'b'Stop when the line with the lineno greater than the current one is
        reached or when returning from current frame.'u'Stop when the line with the lineno greater than the current one is
        reached or when returning from current frame.'b'Stop after one line of code.'u'Stop after one line of code.'b'Stop on the next line in or below the given frame.'u'Stop on the next line in or below the given frame.'b'Stop when returning from the given frame.'u'Stop when returning from the given frame.'b'Start debugging from frame.

        If frame is not specified, debugging starts from caller's frame.
        'u'Start debugging from frame.

        If frame is not specified, debugging starts from caller's frame.
        'b'Stop only at breakpoints or when finished.

        If there are no breakpoints, set the system trace function to None.
        'u'Stop only at breakpoints or when finished.

        If there are no breakpoints, set the system trace function to None.
        'b'Set quitting attribute to True.

        Raises BdbQuit exception in the next call to a dispatch_*() method.
        'u'Set quitting attribute to True.

        Raises BdbQuit exception in the next call to a dispatch_*() method.
        'b'Add breakpoint to breaks, if not already there.'u'Add breakpoint to breaks, if not already there.'b'Set a new breakpoint for filename:lineno.

        If lineno doesn't exist for the filename, return an error message.
        The filename should be in canonical form.
        'u'Set a new breakpoint for filename:lineno.

        If lineno doesn't exist for the filename, return an error message.
        The filename should be in canonical form.
        'b'Line %s:%d does not exist'u'Line %s:%d does not exist'b'Apply all breakpoints (set in other instances) to this one.

        Populates this instance's breaks list from the Breakpoint class's
        list, which can have breakpoints set by another Bdb instance. This
        is necessary for interactive sessions to keep the breakpoints
        active across multiple calls to run().
        'u'Apply all breakpoints (set in other instances) to this one.

        Populates this instance's breaks list from the Breakpoint class's
        list, which can have breakpoints set by another Bdb instance. This
        is necessary for interactive sessions to keep the breakpoints
        active across multiple calls to run().
        'b'Prune breakpoints for filename:lineno.

        A list of breakpoints is maintained in the Bdb instance and in
        the Breakpoint class.  If a breakpoint in the Bdb instance no
        longer exists in the Breakpoint class, then it's removed from the
        Bdb instance.
        'u'Prune breakpoints for filename:lineno.

        A list of breakpoints is maintained in the Bdb instance and in
        the Breakpoint class.  If a breakpoint in the Bdb instance no
        longer exists in the Breakpoint class, then it's removed from the
        Bdb instance.
        'b'Delete breakpoints for filename:lineno.

        If no breakpoints were set, return an error message.
        'u'Delete breakpoints for filename:lineno.

        If no breakpoints were set, return an error message.
        'b'There are no breakpoints in %s'u'There are no breakpoints in %s'b'There is no breakpoint at %s:%d'u'There is no breakpoint at %s:%d'b'Delete a breakpoint by its index in Breakpoint.bpbynumber.

        If arg is invalid, return an error message.
        'u'Delete a breakpoint by its index in Breakpoint.bpbynumber.

        If arg is invalid, return an error message.
        'b'Delete all breakpoints in filename.

        If none were set, return an error message.
        'u'Delete all breakpoints in filename.

        If none were set, return an error message.
        'b'Delete all existing breakpoints.

        If none were set, return an error message.
        'u'Delete all existing breakpoints.

        If none were set, return an error message.
        'b'There are no breakpoints'u'There are no breakpoints'b'Return a breakpoint by its index in Breakpoint.bybpnumber.

        For invalid arg values or if the breakpoint doesn't exist,
        raise a ValueError.
        'u'Return a breakpoint by its index in Breakpoint.bybpnumber.

        For invalid arg values or if the breakpoint doesn't exist,
        raise a ValueError.
        'b'Breakpoint number expected'u'Breakpoint number expected'b'Non-numeric breakpoint number %s'u'Non-numeric breakpoint number %s'b'Breakpoint number %d out of range'u'Breakpoint number %d out of range'b'Breakpoint %d already deleted'u'Breakpoint %d already deleted'b'Return True if there is a breakpoint for filename:lineno.'u'Return True if there is a breakpoint for filename:lineno.'b'Return all breakpoints for filename:lineno.

        If no breakpoints are set, return an empty list.
        'u'Return all breakpoints for filename:lineno.

        If no breakpoints are set, return an empty list.
        'b'Return all lines with breakpoints for filename.

        If no breakpoints are set, return an empty list.
        'u'Return all lines with breakpoints for filename.

        If no breakpoints are set, return an empty list.
        'b'Return all breakpoints that are set.'u'Return all breakpoints that are set.'b'Return a list of (frame, lineno) in a stack trace and a size.

        List starts with original calling frame, if there is one.
        Size may be number of frames above or below f.
        'u'Return a list of (frame, lineno) in a stack trace and a size.

        List starts with original calling frame, if there is one.
        Size may be number of frames above or below f.
        'b'Return a string with information about a stack entry.

        The stack entry frame_lineno is a (frame, lineno) tuple.  The
        return string contains the canonical filename, the function name
        or '<lambda>', the input arguments, the return value, and the
        line of code (if it exists).

        'u'Return a string with information about a stack entry.

        The stack entry frame_lineno is a (frame, lineno) tuple.  The
        return string contains the canonical filename, the function name
        or '<lambda>', the input arguments, the return value, and the
        line of code (if it exists).

        'b'<lambda>'u'<lambda>'b'__return__'u'__return__'b'->'u'->'b'Debug a statement executed via the exec() function.

        globals defaults to __main__.dict; locals defaults to globals.
        'u'Debug a statement executed via the exec() function.

        globals defaults to __main__.dict; locals defaults to globals.
        'b'Debug an expression executed via the eval() function.

        globals defaults to __main__.dict; locals defaults to globals.
        'u'Debug an expression executed via the eval() function.

        globals defaults to __main__.dict; locals defaults to globals.
        'b'For backwards-compatibility.  Defers to run().'u'For backwards-compatibility.  Defers to run().'b'Debug a single function call.

        Return the result of the function call.
        'u'Debug a single function call.

        Return the result of the function call.
        'b'Start debugging with a Bdb instance from the caller's frame.'u'Start debugging with a Bdb instance from the caller's frame.'b'Breakpoint class.

    Implements temporary breakpoints, ignore counts, disabling and
    (re)-enabling, and conditionals.

    Breakpoints are indexed by number through bpbynumber and by
    the (file, line) tuple using bplist.  The former points to a
    single instance of class Breakpoint.  The latter points to a
    list of such instances since there may be more than one
    breakpoint per line.

    When creating a breakpoint, its associated filename should be
    in canonical form.  If funcname is defined, a breakpoint hit will be
    counted when the first line of that function is executed.  A
    conditional breakpoint always counts a hit.
    'u'Breakpoint class.

    Implements temporary breakpoints, ignore counts, disabling and
    (re)-enabling, and conditionals.

    Breakpoints are indexed by number through bpbynumber and by
    the (file, line) tuple using bplist.  The former points to a
    single instance of class Breakpoint.  The latter points to a
    list of such instances since there may be more than one
    breakpoint per line.

    When creating a breakpoint, its associated filename should be
    in canonical form.  If funcname is defined, a breakpoint hit will be
    counted when the first line of that function is executed.  A
    conditional breakpoint always counts a hit.
    'b'Delete the breakpoint from the list associated to a file:line.

        If it is the last breakpoint in that position, it also deletes
        the entry for the file:line.
        'u'Delete the breakpoint from the list associated to a file:line.

        If it is the last breakpoint in that position, it also deletes
        the entry for the file:line.
        'b'Mark the breakpoint as enabled.'u'Mark the breakpoint as enabled.'b'Mark the breakpoint as disabled.'u'Mark the breakpoint as disabled.'b'Print the output of bpformat().

        The optional out argument directs where the output is sent
        and defaults to standard output.
        'u'Print the output of bpformat().

        The optional out argument directs where the output is sent
        and defaults to standard output.
        'b'Return a string with information about the breakpoint.

        The information includes the breakpoint number, temporary
        status, file:line position, break condition, number of times to
        ignore, and number of times hit.

        'u'Return a string with information about the breakpoint.

        The information includes the breakpoint number, temporary
        status, file:line position, break condition, number of times to
        ignore, and number of times hit.

        'b'del  'u'del  'b'keep 'u'keep 'b'yes  'u'yes  'b'no   'u'no   'b'%-4dbreakpoint   %s at %s:%d'u'%-4dbreakpoint   %s at %s:%d'b'
	stop only if %s'u'
	stop only if %s'b'
	ignore next %d hits'u'
	ignore next %d hits'b'
	breakpoint already hit %d time%s'u'
	breakpoint already hit %d time%s'b'Return a condensed description of the breakpoint.'u'Return a condensed description of the breakpoint.'b'breakpoint %s at %s:%s'u'breakpoint %s at %s:%s'b'Return True if break should happen here.

    Whether a break should happen depends on the way that b (the breakpoint)
    was set.  If it was set via line number, check if b.line is the same as
    the one in the frame.  If it was set via function name, check if this is
    the right function and if it is on the first executable line.
    'u'Return True if break should happen here.

    Whether a break should happen depends on the way that b (the breakpoint)
    was set.  If it was set via line number, check if b.line is the same as
    the one in the frame.  If it was set via function name, check if this is
    the right function and if it is on the first executable line.
    'b'Return (active breakpoint, delete temporary flag) or (None, None) as
       breakpoint to act upon.

       The "active breakpoint" is the first entry in bplist[line, file] (which
       must exist) that is enabled, for which checkfuncname is True, and that
       has neither a False condition nor a positive ignore count.  The flag,
       meaning that a temporary breakpoint should be deleted, is False only
       when the condiion cannot be evaluated (in which case, ignore count is
       ignored).

       If no such entry exists, then (None, None) is returned.
    'u'Return (active breakpoint, delete temporary flag) or (None, None) as
       breakpoint to act upon.

       The "active breakpoint" is the first entry in bplist[line, file] (which
       must exist) that is enabled, for which checkfuncname is True, and that
       has neither a False condition nor a positive ignore count.  The flag,
       meaning that a temporary breakpoint should be deleted, is False only
       when the condiion cannot be evaluated (in which case, ignore count is
       ignored).

       If no such entry exists, then (None, None) is returned.
    'b'???'u'???'b'+++ call'u'+++ call'b'+++'u'+++'b'+++ return'u'+++ return'b'+++ exception'u'+++ exception'b'foo('u'foo('b'bar returned'u'bar returned'b'bar('u'bar('b'import bdb; bdb.foo(10)'u'import bdb; bdb.foo(10)'u'bdb'u'binascii'binascii.Erroru'Incomplete.__weakref__'binascii.IncompleteIncompleteu'Conversion between binary data and ASCII'u'/opt/homebrew/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/lib-dynload/binascii.cpython-310-darwin.so'a2b_hexa2b_hqxa2b_qpa2b_uub2a_hexb2a_hqxb2a_qpb2a_uucrc32crc_hqxrlecode_hqxrledecode_hqxBisection algorithms.lohiInsert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the right of the rightmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e <= x, and all e in
    a[i:] have e > x.  So if x already appears in the list, a.insert(i, x) will
    insert just after the rightmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    lo must be non-negativemidInsert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the left of the leftmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e < x, and all e in
    a[i:] have e >= x.  So if x already appears in the list, a.insert(i, x) will
    insert just before the leftmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    bisectinsort# Note, the comparison uses "<" to match the# __lt__() logic in list.sort() and in heapq.# Overwrite above definitions with a fast C implementation# Create aliasesb'Bisection algorithms.'u'Bisection algorithms.'b'Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the right of the rightmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    'u'Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the right of the rightmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    'b'Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e <= x, and all e in
    a[i:] have e > x.  So if x already appears in the list, a.insert(i, x) will
    insert just after the rightmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    'u'Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e <= x, and all e in
    a[i:] have e > x.  So if x already appears in the list, a.insert(i, x) will
    insert just after the rightmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    'b'lo must be non-negative'u'lo must be non-negative'b'Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the left of the leftmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    'u'Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the left of the leftmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    'b'Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e < x, and all e in
    a[i:] have e >= x.  So if x already appears in the list, a.insert(i, x) will
    insert just before the leftmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    'u'Return the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e < x, and all e in
    a[i:] have e >= x.  So if x already appears in the list, a.insert(i, x) will
    insert just before the leftmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    'u'bisect'A bottom-up tree matching algorithm implementation meant to speed
up 2to3's matching process. After the tree patterns are reduced to
their rarest linear path, a linear Aho-Corasick automaton is
created. The linear automaton traverses the linear paths from the
leaves to the root of the AST and returns a set of nodes for further
matching. This reduces significantly the number of candidate nodes.George Boutsioukis <gboutsioukis@gmail.com>pytreebtm_utilsreduce_treeBMNodeClass for a node of the Aho-Corasick automaton used in matchingtransition_tablefixersBottomMatcherThe main matcher class. After instantiating the patterns should
    be added using the add_fixer methodRefactoringTooladd_fixerfixerReduces a fixer's pattern tree to a linear path and adds it
        to the matcher(a common Aho-Corasick automaton). The fixer is
        appended on the matching states and called when they are
        reachedpattern_treeget_linear_subpatternlinearmatch_nodesmatch_nodeRecursively adds a linear pattern to the AC automatonalternativeend_nodesnext_nodeleavesThe main interface with the bottom matcher. The tree is
        traversed from the bottom using the constructed
        automaton. Nodes are only checked once as the tree is
        retraversed. When the automaton fails, we give it one more
        shot(in case the above tree matches as a whole with the
        rejected leaf), then we break for the next leaf. There is the
        special case of multiple arguments(see code comments) where we
        recheck the nodes

        Args:
           The leaves of the AST tree to be matched

        Returns:
           A dictionary of node matches with fixers as the keys
        current_ac_nodeleafcurrent_ast_nodewas_checkedLeafnode_tokenprint_acPrints a graphviz diagram of the BM automaton(for debugging)digraph g{print_nodesubnode_keysubnode%d -> %d [label=%s] //%stype_repr_type_reprstype_numpygrampython_symbols#print("adding pattern", pattern, "to", start)#print("empty pattern")#alternatives#print("alternatives")#add all alternatives, and add the rest of the pattern#to each end node#single token#not last#transition did not exist, create new#transition exists already, follow# multiple statements, recheck#name#token matches#matching failed, reset automaton#the rest of the tree upwards has been checked, next leaf#recheck the rejected node once from the root# taken from pytree.py for debugging; only used by print_ac# printing tokens is possible but not as useful# from .pgen2 import token // token.__dict__.items():b'A bottom-up tree matching algorithm implementation meant to speed
up 2to3's matching process. After the tree patterns are reduced to
their rarest linear path, a linear Aho-Corasick automaton is
created. The linear automaton traverses the linear paths from the
leaves to the root of the AST and returns a set of nodes for further
matching. This reduces significantly the number of candidate nodes.'u'A bottom-up tree matching algorithm implementation meant to speed
up 2to3's matching process. After the tree patterns are reduced to
their rarest linear path, a linear Aho-Corasick automaton is
created. The linear automaton traverses the linear paths from the
leaves to the root of the AST and returns a set of nodes for further
matching. This reduces significantly the number of candidate nodes.'b'George Boutsioukis <gboutsioukis@gmail.com>'u'George Boutsioukis <gboutsioukis@gmail.com>'b'Class for a node of the Aho-Corasick automaton used in matching'u'Class for a node of the Aho-Corasick automaton used in matching'b'The main matcher class. After instantiating the patterns should
    be added using the add_fixer method'u'The main matcher class. After instantiating the patterns should
    be added using the add_fixer method'b'RefactoringTool'u'RefactoringTool'b'Reduces a fixer's pattern tree to a linear path and adds it
        to the matcher(a common Aho-Corasick automaton). The fixer is
        appended on the matching states and called when they are
        reached'u'Reduces a fixer's pattern tree to a linear path and adds it
        to the matcher(a common Aho-Corasick automaton). The fixer is
        appended on the matching states and called when they are
        reached'b'Recursively adds a linear pattern to the AC automaton'u'Recursively adds a linear pattern to the AC automaton'b'The main interface with the bottom matcher. The tree is
        traversed from the bottom using the constructed
        automaton. Nodes are only checked once as the tree is
        retraversed. When the automaton fails, we give it one more
        shot(in case the above tree matches as a whole with the
        rejected leaf), then we break for the next leaf. There is the
        special case of multiple arguments(see code comments) where we
        recheck the nodes

        Args:
           The leaves of the AST tree to be matched

        Returns:
           A dictionary of node matches with fixers as the keys
        'u'The main interface with the bottom matcher. The tree is
        traversed from the bottom using the constructed
        automaton. Nodes are only checked once as the tree is
        retraversed. When the automaton fails, we give it one more
        shot(in case the above tree matches as a whole with the
        rejected leaf), then we break for the next leaf. There is the
        special case of multiple arguments(see code comments) where we
        recheck the nodes

        Args:
           The leaves of the AST tree to be matched

        Returns:
           A dictionary of node matches with fixers as the keys
        'b'Prints a graphviz diagram of the BM automaton(for debugging)'u'Prints a graphviz diagram of the BM automaton(for debugging)'b'digraph g{'u'digraph g{'b'%d -> %d [label=%s] //%s'u'%d -> %d [label=%s] //%s'u'lib2to3.btm_matcher'u'btm_matcher'Utility functions used by the btm_matcher modulepgen2grammarpattern_symbolssymspysymsopmaptoken_labelsTYPE_ANYTYPE_ALTERNATIVESTYPE_GROUPMinNodeThis class serves as an intermediate representation of the
    pattern tree during the conversion to sets of leaf-to-root
    subpatternsalternativesleaf_to_rootInternal method. Returns a characteristic path of the
        pattern tree. This method must be run for all leaves until the
        linear subpatterns are merged into a singlesubpget_characteristic_subpatternNAMEDrives the leaf_to_root method. The reason that
        leaf_to_root must be run multiple times is because we need to
        reject 'group' matches; for example the alternative form
        (a | b c) creates a group [b c] that needs to be matched. Since
        matching multiple linear patterns overcomes the automaton's
        capabilities, leaf_to_root merges each group into a single
        choice based on 'characteristic'ity,

        i.e. (a|b c) -> (a|b) if b more characteristic than c

        Returns: The most 'characteristic'(as defined by
          get_characteristic_subpattern) path for the compiled pattern
          tree.
        Generator that returns the leaves of the tree
    Internal function. Reduces a compiled pattern tree to an
    intermediate representation suitable for feeding the
    automaton. This also trims off any optional pattern elements(like
    [a], a*).
    AlternativesreducedAlternativeUnitdetails_nodealternatives_nodehas_repeaterrepeater_nodehas_variable_nameDetailsRepeatername_leafSTRINGsubpatternsPicks the most characteristic from a list of linear patterns
    Current order used is:
    names > common_names > common_chars
    subpatterns_with_namessubpatterns_with_common_namesforcommon_namessubpatterns_with_common_chars[]().,:common_charssubpatternrec_testtest_funcTests test_func on all items of sequence and items of included
    sub-iterables#last alternative#probably should check the number of leaves#in case of type=name, use the name instead#switch on the node type#skip#2 cases#just a single 'Alternative', skip this node#real alternatives#skip odd children('|' tokens)# delete the group if all of the children were reduced to None#skip parentheses#skip whole unit if its optional# variable name#skip variable name#skip variable name, '='# skip parenthesis#set node type#(python) non-name or wildcard#(python) name or character; remove the apostrophes from#the string value#handle repeaters#reduce to None#reduce to a single occurrence i.e. do nothing#TODO: handle {min, max} repeaters#add children#skip '<', '>' markers# first pick out the ones containing variable names# of the remaining subpatterns pick out the longest oneb'Utility functions used by the btm_matcher module'u'Utility functions used by the btm_matcher module'b'This class serves as an intermediate representation of the
    pattern tree during the conversion to sets of leaf-to-root
    subpatterns'u'This class serves as an intermediate representation of the
    pattern tree during the conversion to sets of leaf-to-root
    subpatterns'b'Internal method. Returns a characteristic path of the
        pattern tree. This method must be run for all leaves until the
        linear subpatterns are merged into a single'u'Internal method. Returns a characteristic path of the
        pattern tree. This method must be run for all leaves until the
        linear subpatterns are merged into a single'b'Drives the leaf_to_root method. The reason that
        leaf_to_root must be run multiple times is because we need to
        reject 'group' matches; for example the alternative form
        (a | b c) creates a group [b c] that needs to be matched. Since
        matching multiple linear patterns overcomes the automaton's
        capabilities, leaf_to_root merges each group into a single
        choice based on 'characteristic'ity,

        i.e. (a|b c) -> (a|b) if b more characteristic than c

        Returns: The most 'characteristic'(as defined by
          get_characteristic_subpattern) path for the compiled pattern
          tree.
        'u'Drives the leaf_to_root method. The reason that
        leaf_to_root must be run multiple times is because we need to
        reject 'group' matches; for example the alternative form
        (a | b c) creates a group [b c] that needs to be matched. Since
        matching multiple linear patterns overcomes the automaton's
        capabilities, leaf_to_root merges each group into a single
        choice based on 'characteristic'ity,

        i.e. (a|b c) -> (a|b) if b more characteristic than c

        Returns: The most 'characteristic'(as defined by
          get_characteristic_subpattern) path for the compiled pattern
          tree.
        'b'Generator that returns the leaves of the tree'u'Generator that returns the leaves of the tree'b'
    Internal function. Reduces a compiled pattern tree to an
    intermediate representation suitable for feeding the
    automaton. This also trims off any optional pattern elements(like
    [a], a*).
    'u'
    Internal function. Reduces a compiled pattern tree to an
    intermediate representation suitable for feeding the
    automaton. This also trims off any optional pattern elements(like
    [a], a*).
    'b'any'u'any'b'Picks the most characteristic from a list of linear patterns
    Current order used is:
    names > common_names > common_chars
    'u'Picks the most characteristic from a list of linear patterns
    Current order used is:
    names > common_names > common_chars
    'b'for'u'for'b'None'u'None'b'[]().,:'u'[]().,:'b'Tests test_func on all items of sequence and items of included
    sub-iterables'u'Tests test_func on all items of sequence and items of included
    sub-iterables'u'lib2to3.btm_utils'u'btm_utils'This module implements token buckets used for client side throttling.CapacityNotAvailableError_MIN_RATEmin_rate_fill_rate_max_capacity_current_capacity_last_timestamp_min_rate_new_fill_rate_condition_refillmax_capacityAcquire token or return amount of time until next token available.

        If block is True, then this method will block until there's sufficient
        capacity to acquire the desired amount.

        If block is False, then this method will return True is capacity
        was successfully acquired, False otherwise.

        _acquire_sleep_amountsleep_amountcurrent_capacityfill_amountnew_capacity# Before we can change the rate we need to fill any pending# tokens we might have based on the current rate.  If we don't# do this it means everything since the last recorded timestamp# will accumulate at the rate we're about to set which isn't# correct.# If we're scaling down, we also can't have a capacity that's# more than our max_capacity.# Not enough capacity.# Until python3.2, wait() always returned None so we can't# tell if a timeout occurred waiting on the cond var.# Because of this we'll unconditionally call _refill().# The downside to this is that we were waken up via# a notify(), we're calling unnecessarily calling _refill() an# extra time.b'This module implements token buckets used for client side throttling.'u'This module implements token buckets used for client side throttling.'b'Acquire token or return amount of time until next token available.

        If block is True, then this method will block until there's sufficient
        capacity to acquire the desired amount.

        If block is False, then this method will return True is capacity
        was successfully acquired, False otherwise.

        'u'Acquire token or return amount of time until next token available.

        If block is True, then this method will block until there's sufficient
        capacity to acquire the desired amount.

        If block is False, then this method will return True is capacity
        was successfully acquired, False otherwise.

        'u'botocore.retries.bucket'u'retries.bucket'u'bucket'Interface to the libbzip2 compression library.

This module provides a file interface, classes for incremental
(de)compression, and functions for one-shot (de)compression.
BZ2FileNadeem Vawda <nadeem.vawda@gmail.com>_compression_MODE_CLOSED_MODE_READ_MODE_WRITEA file object providing transparent bzip2 (de)compression.

    A BZ2File can act as a wrapper for an existing file object, or refer
    directly to a named file on disk.

    Note that BZ2File provides a *binary* file interface - data read is
    returned as bytes, and data to be written should be given as bytes.
    compresslevelOpen a bzip2-compressed file.

        If filename is a str, bytes, or PathLike object, it gives the
        name of the file to be opened. Otherwise, it should be a file
        object, which will be used to read or write the compressed data.

        mode can be 'r' for reading (default), 'w' for (over)writing,
        'x' for creating exclusively, or 'a' for appending. These can
        equivalently be given as 'rb', 'wb', 'xb', and 'ab'.

        If mode is 'w', 'x' or 'a', compresslevel can be a number between 1
        and 9 specifying the level of compression: 1 produces the least
        compression, and 9 (default) produces the most compression.

        If mode is 'r', the input file may be the concatenation of
        multiple compressed streams.
        _closefpcompresslevel must be between 1 and 9mode_code_compressorxbabInvalid mode: %rfilename must be a str, bytes, file or PathLike objectFlush and close the file.

        May be called more than once without error. Once the file is
        closed, any other operation on it will raise a ValueError.
        True if this file is closed.Return the file descriptor for the underlying file.Return whether the file supports seeking.Return whether the file was opened for reading.Return whether the file was opened for writing.Return buffered data without advancing the file position.

        Always returns at least one byte of data, unless at EOF.
        The exact number of bytes returned is unspecified.
        Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b'' if the file is already at EOF.
        Read up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b'' if the file is at EOF.
        Read bytes into b.

        Returns the number of bytes read (0 for EOF).
        Read a line of uncompressed bytes from the file.

        The terminating newline (if present) is retained. If size is
        non-negative, no more than size bytes will be read (in which
        case the line may be incomplete). Returns b'' if already at EOF.
        Integer argument expectedRead a list of lines of uncompressed bytes from the file.

        size can be specified to control the number of lines read: no
        further lines will be read once the total size of the lines read
        so far equals or exceeds size.
        Write a byte string to the file.

        Returns the number of uncompressed bytes written, which is
        always the length of data in bytes. Note that due to buffering,
        the file on disk may not reflect the data written until close()
        is called.
        compressedWrite a sequence of byte strings to the file.

        Returns the number of uncompressed bytes written.
        seq can be any iterable yielding byte strings.

        Line separators are not added between the written byte strings.
        Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Values for whence are:

            0: start of stream (default); offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        Open a bzip2-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str, bytes, or
    PathLike object), or an existing file object to read from or write
    to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or
    "ab" for binary mode, or "rt", "wt", "xt" or "at" for text mode.
    The default mode is "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the BZ2File
    constructor: BZ2File(filename, mode, compresslevel). In this case,
    the encoding, errors and newline arguments must not be provided.

    For text mode, a BZ2File object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    Argument 'encoding' not supported in binary modeArgument 'errors' not supported in binary modeArgument 'newline' not supported in binary modebz_modebinary_fileCompress a block of data.

    compresslevel, if given, must be a number between 1 and 9.

    For incremental compression, use a BZ2Compressor object instead.
    compDecompress a block of data.

    For incremental decompression, use a BZ2Decompressor object instead.
    decompCompressed data ended before the end-of-stream marker was reached"Compressed data ended before the "# Value 2 no longer used# Relies on the undocumented fact that BufferedReader.peek()# always returns at least one byte (except at EOF), independent# of the value of n# accept any data that supports the buffer protocol# Leftover data is not a valid bzip2 stream; ignore it.# Error on the first iteration; bail out.b'Interface to the libbzip2 compression library.

This module provides a file interface, classes for incremental
(de)compression, and functions for one-shot (de)compression.
'u'Interface to the libbzip2 compression library.

This module provides a file interface, classes for incremental
(de)compression, and functions for one-shot (de)compression.
'b'BZ2File'u'BZ2File'b'BZ2Compressor'u'BZ2Compressor'b'BZ2Decompressor'u'BZ2Decompressor'b'compress'u'compress'b'decompress'u'decompress'b'Nadeem Vawda <nadeem.vawda@gmail.com>'u'Nadeem Vawda <nadeem.vawda@gmail.com>'b'A file object providing transparent bzip2 (de)compression.

    A BZ2File can act as a wrapper for an existing file object, or refer
    directly to a named file on disk.

    Note that BZ2File provides a *binary* file interface - data read is
    returned as bytes, and data to be written should be given as bytes.
    'u'A file object providing transparent bzip2 (de)compression.

    A BZ2File can act as a wrapper for an existing file object, or refer
    directly to a named file on disk.

    Note that BZ2File provides a *binary* file interface - data read is
    returned as bytes, and data to be written should be given as bytes.
    'b'Open a bzip2-compressed file.

        If filename is a str, bytes, or PathLike object, it gives the
        name of the file to be opened. Otherwise, it should be a file
        object, which will be used to read or write the compressed data.

        mode can be 'r' for reading (default), 'w' for (over)writing,
        'x' for creating exclusively, or 'a' for appending. These can
        equivalently be given as 'rb', 'wb', 'xb', and 'ab'.

        If mode is 'w', 'x' or 'a', compresslevel can be a number between 1
        and 9 specifying the level of compression: 1 produces the least
        compression, and 9 (default) produces the most compression.

        If mode is 'r', the input file may be the concatenation of
        multiple compressed streams.
        'u'Open a bzip2-compressed file.

        If filename is a str, bytes, or PathLike object, it gives the
        name of the file to be opened. Otherwise, it should be a file
        object, which will be used to read or write the compressed data.

        mode can be 'r' for reading (default), 'w' for (over)writing,
        'x' for creating exclusively, or 'a' for appending. These can
        equivalently be given as 'rb', 'wb', 'xb', and 'ab'.

        If mode is 'w', 'x' or 'a', compresslevel can be a number between 1
        and 9 specifying the level of compression: 1 produces the least
        compression, and 9 (default) produces the most compression.

        If mode is 'r', the input file may be the concatenation of
        multiple compressed streams.
        'b'compresslevel must be between 1 and 9'u'compresslevel must be between 1 and 9'b'xb'u'xb'b'ab'u'ab'b'Invalid mode: %r'u'Invalid mode: %r'b'filename must be a str, bytes, file or PathLike object'u'filename must be a str, bytes, file or PathLike object'b'Flush and close the file.

        May be called more than once without error. Once the file is
        closed, any other operation on it will raise a ValueError.
        'u'Flush and close the file.

        May be called more than once without error. Once the file is
        closed, any other operation on it will raise a ValueError.
        'b'True if this file is closed.'u'True if this file is closed.'b'Return the file descriptor for the underlying file.'u'Return the file descriptor for the underlying file.'b'Return whether the file supports seeking.'u'Return whether the file supports seeking.'b'Return whether the file was opened for reading.'u'Return whether the file was opened for reading.'b'Return whether the file was opened for writing.'u'Return whether the file was opened for writing.'b'Return buffered data without advancing the file position.

        Always returns at least one byte of data, unless at EOF.
        The exact number of bytes returned is unspecified.
        'u'Return buffered data without advancing the file position.

        Always returns at least one byte of data, unless at EOF.
        The exact number of bytes returned is unspecified.
        'b'Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b'' if the file is already at EOF.
        'u'Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b'' if the file is already at EOF.
        'b'Read up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b'' if the file is at EOF.
        'u'Read up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b'' if the file is at EOF.
        'b'Read bytes into b.

        Returns the number of bytes read (0 for EOF).
        'u'Read bytes into b.

        Returns the number of bytes read (0 for EOF).
        'b'Read a line of uncompressed bytes from the file.

        The terminating newline (if present) is retained. If size is
        non-negative, no more than size bytes will be read (in which
        case the line may be incomplete). Returns b'' if already at EOF.
        'u'Read a line of uncompressed bytes from the file.

        The terminating newline (if present) is retained. If size is
        non-negative, no more than size bytes will be read (in which
        case the line may be incomplete). Returns b'' if already at EOF.
        'b'__index__'u'__index__'b'Integer argument expected'u'Integer argument expected'b'Read a list of lines of uncompressed bytes from the file.

        size can be specified to control the number of lines read: no
        further lines will be read once the total size of the lines read
        so far equals or exceeds size.
        'u'Read a list of lines of uncompressed bytes from the file.

        size can be specified to control the number of lines read: no
        further lines will be read once the total size of the lines read
        so far equals or exceeds size.
        'b'Write a byte string to the file.

        Returns the number of uncompressed bytes written, which is
        always the length of data in bytes. Note that due to buffering,
        the file on disk may not reflect the data written until close()
        is called.
        'u'Write a byte string to the file.

        Returns the number of uncompressed bytes written, which is
        always the length of data in bytes. Note that due to buffering,
        the file on disk may not reflect the data written until close()
        is called.
        'b'Write a sequence of byte strings to the file.

        Returns the number of uncompressed bytes written.
        seq can be any iterable yielding byte strings.

        Line separators are not added between the written byte strings.
        'u'Write a sequence of byte strings to the file.

        Returns the number of uncompressed bytes written.
        seq can be any iterable yielding byte strings.

        Line separators are not added between the written byte strings.
        'b'Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Values for whence are:

            0: start of stream (default); offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        'u'Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Values for whence are:

            0: start of stream (default); offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        'b'Open a bzip2-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str, bytes, or
    PathLike object), or an existing file object to read from or write
    to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or
    "ab" for binary mode, or "rt", "wt", "xt" or "at" for text mode.
    The default mode is "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the BZ2File
    constructor: BZ2File(filename, mode, compresslevel). In this case,
    the encoding, errors and newline arguments must not be provided.

    For text mode, a BZ2File object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    'u'Open a bzip2-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str, bytes, or
    PathLike object), or an existing file object to read from or write
    to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or
    "ab" for binary mode, or "rt", "wt", "xt" or "at" for text mode.
    The default mode is "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the BZ2File
    constructor: BZ2File(filename, mode, compresslevel). In this case,
    the encoding, errors and newline arguments must not be provided.

    For text mode, a BZ2File object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    'b'Argument 'encoding' not supported in binary mode'u'Argument 'encoding' not supported in binary mode'b'Argument 'errors' not supported in binary mode'u'Argument 'errors' not supported in binary mode'b'Argument 'newline' not supported in binary mode'u'Argument 'newline' not supported in binary mode'b'Compress a block of data.

    compresslevel, if given, must be a number between 1 and 9.

    For incremental compression, use a BZ2Compressor object instead.
    'u'Compress a block of data.

    compresslevel, if given, must be a number between 1 and 9.

    For incremental compression, use a BZ2Compressor object instead.
    'b'Decompress a block of data.

    For incremental decompression, use a BZ2Decompressor object instead.
    'u'Decompress a block of data.

    For incremental decompression, use a BZ2Decompressor object instead.
    'b'Compressed data ended before the end-of-stream marker was reached'u'Compressed data ended before the end-of-stream marker was reached'# Deprecated alias for xml.etree.ElementTreeu'xml.etree.cElementTree'u'etree.cElementTree'u'cElementTree'Calendar printing functions

Note when comparing these calendars to the ones printed by cal(1): By
default, these calendars have Monday as the first day of the week, and
Sunday as the last (the European convention). Use setfirstweekday() to
set the first day of the week (0=Monday, 6=Sunday).IllegalMonthErrorIllegalWeekdayErrorsetfirstweekdayfirstweekdayisleapleapdaysmonthcalendarprmonthprcalmonth_namemonth_abbrday_nameday_abbrCalendarTextCalendarHTMLCalendarLocaleTextCalendarLocaleHTMLCalendarweekheaderMONDAYTUESDAYWEDNESDAYTHURSDAYFRIDAYSATURDAYSUNDAYbad month number %r; must be 1-12bad weekday number %r; must be 0 (Monday) to 6 (Sunday)mdays_localized_month2001funcs_localized_day_days%a%BReturn True for leap years, False for non-leap years.Return number of leap years in range [y1, y2).
       Assume y1 <= y2.Return weekday (0-6 ~ Mon-Sun) for year, month (1-12), day (1-31).Return weekday (0-6 ~ Mon-Sun) and number of days (28-31) for
       year, month.day1ndays_monthlen_prevmonth_nextmonth
    Base calendar class. This class doesn't do any formatting. It simply
    provides data to subclasses.
    getfirstweekday_firstweekdayiterweekdays
        Return an iterator for one week of weekday numbers starting with the
        configured first one.
        itermonthdates
        Return an iterator for one month. The iterator will yield datetime.date
        values and will always iterate through complete weeks, so it will yield
        dates outside the specified month.
        itermonthdays3itermonthdays
        Like itermonthdates(), but will yield day numbers. For days outside
        the specified month the day number is 0.
        days_beforedays_afteritermonthdays2
        Like itermonthdates(), but will yield (day number, weekday number)
        tuples. For days outside the specified month the day number is 0.
        
        Like itermonthdates(), but will yield (year, month, day) tuples.  Can be
        used for dates outside of datetime.date range.
        itermonthdays4
        Like itermonthdates(), but will yield (year, month, day, day_of_week) tuples.
        Can be used for dates outside of datetime.date range.
        monthdatescalendar
        Return a matrix (list of lists) representing a month's calendar.
        Each row represents a week; week entries are datetime.date values.
        datesmonthdays2calendar
        Return a matrix representing a month's calendar.
        Each row represents a week; week entries are
        (day number, weekday number) tuples. Day numbers outside this month
        are zero.
        monthdayscalendar
        Return a matrix representing a month's calendar.
        Each row represents a week; days outside this month are zero.
        yeardatescalendar
        Return the data for the specified year ready for formatting. The return
        value is a list of month rows. Each month row contains up to width months.
        Each month contains between 4 and 6 weeks and each week contains 1-7
        days. Days are datetime.date objects.
        monthsyeardays2calendar
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are
        (day number, weekday number) tuples. Day numbers outside this month are
        zero.
        yeardayscalendar
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are day numbers.
        Day numbers outside this month are zero.
        
    Subclass of Calendar that outputs a calendar as a simple plain text
    similar to the UNIX program cal.
    prweektheweek
        Print a single week (no newline).
        formatweekformatday
        Returns a formatted day.
        %2i
        Returns a single week in a string (no newline).
        wdformatweekday
        Returns a formatted week day name.
        formatweekheader
        Return a header for a week.
        formatmonthnametheyearthemonthwithyear
        Return a formatted month name.
        %s %r
        Print a month's calendar.
        formatmonth
        Return a month's calendar string (multi-line).
        formatyear
        Returns a year's calendar as a multi-line string.
        colwidthformatstringcalweekspryearPrint a year's calendar.
    This calendar returns complete HTML pages.
    cssclassescssclasses_weekday_headnodaycssclass_nodaycssclass_month_headcssclass_monthcssclass_year_headcssclass_year
        Return a day as a table cell.
        <td class="%s">&nbsp;</td><td class="%s">%d</td>
        Return a complete week as a table row.
        <tr>%s</tr>
        Return a weekday name as a table header.
        <th class="%s">%s</th>
        Return a header for a week as a table row.
        
        Return a month name as a table row.
        <tr><th colspan="7" class="%s">%s</th></tr>
        Return a formatted month as a table.
        <table border="0" cellpadding="0" cellspacing="0" class="%s"></table>
        Return a formatted year as a table of tables.
        <tr><th colspan="%d" class="%s">%s</th></tr><tr><td></td></tr>formatyearpagecalendar.csscss
        Return a formatted year as a complete HTML page.
        <?xml version="1.0" encoding="%s"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=%s" />
<link rel="stylesheet" type="text/css" href="%s" />
<title>Calendar for %d</title>
</head>
<body>
</body>
</html>
different_localegetlocaleoldlocale
    This class can be passed a locale name in the constructor and will return
    month and weekday names in the specified locale. If this locale includes
    an encoding all strings containing month and weekday names will be returned
    as unicode.
    _colwidth_spacingcolsspacingPrints multi-column formatting for year calendarsReturns a string formatted from n strings, centered within n columns.1970EPOCH_EPOCH_ORDUnrelated but handy function to calculate Unix timestamp from GMT.text only argumentstextgrouphtml only argumentshtmlgroup-w--widthwidth of date column (default 2)-l--linesnumber of lines for each week (default 1)-s--spacingspacing between months (default 6)--monthsmonths per row (default 3)-c--cssCSS to use for page-L--localelocale to be used from month and weekday names--encodingencoding to use for output--typeoutput type (text or html)year number (1-9999)month number (1-12, text only)if --locale is specified --encoding is requiredoptdictincorrect number of arguments# Exception raised for bad input (with string parameter for details)# Exceptions raised for bad input# Constants for months referenced later# Number of days per month (except for February in leap years)# This module used to have hard-coded lists of day and month names, as# English strings.  The classes following emulate a read-only version of# that, but supply localized names.  Note that the values are computed# fresh on each call, in case the user changes locale between calls.# January 1, 2001, was a Monday.# Full and abbreviated names of weekdays# Full and abbreviated names of months (1-based arrays!!!)# Constants for weekdays# 0 = Monday, 6 = Sunday# right-align single-digit days# months in this row# max number of weeks for this row# CSS classes for the day <td>s# CSS classes for the day <th>s# CSS class for the days before and after current month# CSS class for the month's head# CSS class for the month# CSS class for the year's table head# CSS class for the whole year table# day outside month# Support for old module level interface# Spacing of month columns for multi-column year calendar# Amount printed by prweek()# Number of spaces between columnsb'Calendar printing functions

Note when comparing these calendars to the ones printed by cal(1): By
default, these calendars have Monday as the first day of the week, and
Sunday as the last (the European convention). Use setfirstweekday() to
set the first day of the week (0=Monday, 6=Sunday).'u'Calendar printing functions

Note when comparing these calendars to the ones printed by cal(1): By
default, these calendars have Monday as the first day of the week, and
Sunday as the last (the European convention). Use setfirstweekday() to
set the first day of the week (0=Monday, 6=Sunday).'b'IllegalMonthError'u'IllegalMonthError'b'IllegalWeekdayError'u'IllegalWeekdayError'b'setfirstweekday'u'setfirstweekday'b'firstweekday'u'firstweekday'b'isleap'u'isleap'b'leapdays'u'leapdays'b'monthrange'u'monthrange'b'monthcalendar'u'monthcalendar'b'prmonth'u'prmonth'b'prcal'u'prcal'b'calendar'u'calendar'b'timegm'u'timegm'b'month_name'u'month_name'b'month_abbr'u'month_abbr'b'day_name'u'day_name'b'day_abbr'u'day_abbr'b'Calendar'u'Calendar'b'TextCalendar'u'TextCalendar'b'HTMLCalendar'u'HTMLCalendar'b'LocaleTextCalendar'u'LocaleTextCalendar'b'LocaleHTMLCalendar'u'LocaleHTMLCalendar'b'weekheader'u'weekheader'b'MONDAY'u'MONDAY'b'TUESDAY'u'TUESDAY'b'WEDNESDAY'u'WEDNESDAY'b'THURSDAY'u'THURSDAY'b'FRIDAY'u'FRIDAY'b'SATURDAY'u'SATURDAY'b'SUNDAY'u'SUNDAY'b'bad month number %r; must be 1-12'u'bad month number %r; must be 1-12'b'bad weekday number %r; must be 0 (Monday) to 6 (Sunday)'u'bad weekday number %r; must be 0 (Monday) to 6 (Sunday)'b'%a'u'%a'b'%B'u'%B'b'Return True for leap years, False for non-leap years.'u'Return True for leap years, False for non-leap years.'b'Return number of leap years in range [y1, y2).
       Assume y1 <= y2.'u'Return number of leap years in range [y1, y2).
       Assume y1 <= y2.'b'Return weekday (0-6 ~ Mon-Sun) for year, month (1-12), day (1-31).'u'Return weekday (0-6 ~ Mon-Sun) for year, month (1-12), day (1-31).'b'Return weekday (0-6 ~ Mon-Sun) and number of days (28-31) for
       year, month.'u'Return weekday (0-6 ~ Mon-Sun) and number of days (28-31) for
       year, month.'b'
    Base calendar class. This class doesn't do any formatting. It simply
    provides data to subclasses.
    'u'
    Base calendar class. This class doesn't do any formatting. It simply
    provides data to subclasses.
    'b'
        Return an iterator for one week of weekday numbers starting with the
        configured first one.
        'u'
        Return an iterator for one week of weekday numbers starting with the
        configured first one.
        'b'
        Return an iterator for one month. The iterator will yield datetime.date
        values and will always iterate through complete weeks, so it will yield
        dates outside the specified month.
        'u'
        Return an iterator for one month. The iterator will yield datetime.date
        values and will always iterate through complete weeks, so it will yield
        dates outside the specified month.
        'b'
        Like itermonthdates(), but will yield day numbers. For days outside
        the specified month the day number is 0.
        'u'
        Like itermonthdates(), but will yield day numbers. For days outside
        the specified month the day number is 0.
        'b'
        Like itermonthdates(), but will yield (day number, weekday number)
        tuples. For days outside the specified month the day number is 0.
        'u'
        Like itermonthdates(), but will yield (day number, weekday number)
        tuples. For days outside the specified month the day number is 0.
        'b'
        Like itermonthdates(), but will yield (year, month, day) tuples.  Can be
        used for dates outside of datetime.date range.
        'u'
        Like itermonthdates(), but will yield (year, month, day) tuples.  Can be
        used for dates outside of datetime.date range.
        'b'
        Like itermonthdates(), but will yield (year, month, day, day_of_week) tuples.
        Can be used for dates outside of datetime.date range.
        'u'
        Like itermonthdates(), but will yield (year, month, day, day_of_week) tuples.
        Can be used for dates outside of datetime.date range.
        'b'
        Return a matrix (list of lists) representing a month's calendar.
        Each row represents a week; week entries are datetime.date values.
        'u'
        Return a matrix (list of lists) representing a month's calendar.
        Each row represents a week; week entries are datetime.date values.
        'b'
        Return a matrix representing a month's calendar.
        Each row represents a week; week entries are
        (day number, weekday number) tuples. Day numbers outside this month
        are zero.
        'u'
        Return a matrix representing a month's calendar.
        Each row represents a week; week entries are
        (day number, weekday number) tuples. Day numbers outside this month
        are zero.
        'b'
        Return a matrix representing a month's calendar.
        Each row represents a week; days outside this month are zero.
        'u'
        Return a matrix representing a month's calendar.
        Each row represents a week; days outside this month are zero.
        'b'
        Return the data for the specified year ready for formatting. The return
        value is a list of month rows. Each month row contains up to width months.
        Each month contains between 4 and 6 weeks and each week contains 1-7
        days. Days are datetime.date objects.
        'u'
        Return the data for the specified year ready for formatting. The return
        value is a list of month rows. Each month row contains up to width months.
        Each month contains between 4 and 6 weeks and each week contains 1-7
        days. Days are datetime.date objects.
        'b'
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are
        (day number, weekday number) tuples. Day numbers outside this month are
        zero.
        'u'
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are
        (day number, weekday number) tuples. Day numbers outside this month are
        zero.
        'b'
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are day numbers.
        Day numbers outside this month are zero.
        'u'
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are day numbers.
        Day numbers outside this month are zero.
        'b'
    Subclass of Calendar that outputs a calendar as a simple plain text
    similar to the UNIX program cal.
    'u'
    Subclass of Calendar that outputs a calendar as a simple plain text
    similar to the UNIX program cal.
    'b'
        Print a single week (no newline).
        'u'
        Print a single week (no newline).
        'b'
        Returns a formatted day.
        'u'
        Returns a formatted day.
        'b'%2i'u'%2i'b'
        Returns a single week in a string (no newline).
        'u'
        Returns a single week in a string (no newline).
        'b'
        Returns a formatted week day name.
        'u'
        Returns a formatted week day name.
        'b'
        Return a header for a week.
        'u'
        Return a header for a week.
        'b'
        Return a formatted month name.
        'u'
        Return a formatted month name.
        'b'%s %r'u'%s %r'b'
        Print a month's calendar.
        'u'
        Print a month's calendar.
        'b'
        Return a month's calendar string (multi-line).
        'u'
        Return a month's calendar string (multi-line).
        'b'
        Returns a year's calendar as a multi-line string.
        'u'
        Returns a year's calendar as a multi-line string.
        'b'Print a year's calendar.'u'Print a year's calendar.'b'
    This calendar returns complete HTML pages.
    'u'
    This calendar returns complete HTML pages.
    'b'noday'u'noday'b'
        Return a day as a table cell.
        'u'
        Return a day as a table cell.
        'b'<td class="%s">&nbsp;</td>'u'<td class="%s">&nbsp;</td>'b'<td class="%s">%d</td>'u'<td class="%s">%d</td>'b'
        Return a complete week as a table row.
        'u'
        Return a complete week as a table row.
        'b'<tr>%s</tr>'u'<tr>%s</tr>'b'
        Return a weekday name as a table header.
        'u'
        Return a weekday name as a table header.
        'b'<th class="%s">%s</th>'u'<th class="%s">%s</th>'b'
        Return a header for a week as a table row.
        'u'
        Return a header for a week as a table row.
        'b'
        Return a month name as a table row.
        'u'
        Return a month name as a table row.
        'b'<tr><th colspan="7" class="%s">%s</th></tr>'u'<tr><th colspan="7" class="%s">%s</th></tr>'b'
        Return a formatted month as a table.
        'u'
        Return a formatted month as a table.
        'b'<table border="0" cellpadding="0" cellspacing="0" class="%s">'u'<table border="0" cellpadding="0" cellspacing="0" class="%s">'b'</table>'u'</table>'b'
        Return a formatted year as a table of tables.
        'u'
        Return a formatted year as a table of tables.
        'b'<tr><th colspan="%d" class="%s">%s</th></tr>'u'<tr><th colspan="%d" class="%s">%s</th></tr>'b'<tr>'u'<tr>'b'<td>'u'<td>'b'</td>'u'</td>'b'</tr>'u'</tr>'b'calendar.css'u'calendar.css'b'
        Return a formatted year as a complete HTML page.
        'u'
        Return a formatted year as a complete HTML page.
        'b'<?xml version="1.0" encoding="%s"?>
'u'<?xml version="1.0" encoding="%s"?>
'b'<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
'u'<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
'b'<html>
'u'<html>
'b'<head>
'u'<head>
'b'<meta http-equiv="Content-Type" content="text/html; charset=%s" />
'u'<meta http-equiv="Content-Type" content="text/html; charset=%s" />
'b'<link rel="stylesheet" type="text/css" href="%s" />
'u'<link rel="stylesheet" type="text/css" href="%s" />
'b'<title>Calendar for %d</title>
'u'<title>Calendar for %d</title>
'b'</head>
'u'</head>
'b'<body>
'u'<body>
'b'</body>
'u'</body>
'b'</html>
'u'</html>
'b'
    This class can be passed a locale name in the constructor and will return
    month and weekday names in the specified locale. If this locale includes
    an encoding all strings containing month and weekday names will be returned
    as unicode.
    'u'
    This class can be passed a locale name in the constructor and will return
    month and weekday names in the specified locale. If this locale includes
    an encoding all strings containing month and weekday names will be returned
    as unicode.
    'b'Prints multi-column formatting for year calendars'u'Prints multi-column formatting for year calendars'b'Returns a string formatted from n strings, centered within n columns.'u'Returns a string formatted from n strings, centered within n columns.'b'Unrelated but handy function to calculate Unix timestamp from GMT.'u'Unrelated but handy function to calculate Unix timestamp from GMT.'b'text only arguments'u'text only arguments'b'html only arguments'u'html only arguments'b'-w'u'-w'b'--width'u'--width'b'width of date column (default 2)'u'width of date column (default 2)'b'-l'u'-l'b'--lines'u'--lines'b'number of lines for each week (default 1)'u'number of lines for each week (default 1)'b'-s'u'-s'b'--spacing'u'--spacing'b'spacing between months (default 6)'u'spacing between months (default 6)'b'--months'u'--months'b'months per row (default 3)'u'months per row (default 3)'b'-c'b'--css'u'--css'b'CSS to use for page'u'CSS to use for page'b'-L'u'-L'b'--locale'u'--locale'b'locale to be used from month and weekday names'u'locale to be used from month and weekday names'b'--encoding'u'--encoding'b'encoding to use for output'u'encoding to use for output'b'--type'u'--type'b'output type (text or html)'u'output type (text or html)'b'year number (1-9999)'u'year number (1-9999)'b'month number (1-12, text only)'u'month number (1-12, text only)'b'if --locale is specified --encoding is required'u'if --locale is specified --encoding is required'b'incorrect number of arguments'u'incorrect number of arguments'Test case implementationdifflibstrclasssafe_repr_count_diff_all_purpose_count_diff_hashable_common_shorten_repr_subtest_msg_sentinel
Diff is %s characters long. Set self.maxDiff to None to see it.'\nDiff is %s characters long. ''Set self.maxDiff to None to see it.'DIFF_OMITTED
    Raise this exception in a test to skip it.

    Usually you can use TestCase.skipTest() or one of the skipping decorators
    instead of raising this directly.
    _ShouldStop
    The test should stop.
    _UnexpectedSuccess
    The test was supposed to fail, but it didn't!
    _Outcomeexpecting_failureaddSubTestresult_supports_subtestssuccesstestPartExecutorisTestold_success_module_cleanupsSame as addCleanup, except the cleanup items are called even if
    setUpModule fails (unlike tearDownModule).doModuleCleanupsExecute all module cleanup functions. Normally called for you after
    tearDownModule.
    Unconditionally skip a test.
    test_itemskip_wrapper__unittest_skip____unittest_skip_why__
    Skip a test if the condition is true.
    
    Skip a test unless the condition is true.
    __unittest_expecting_failure___is_subtypebasetype_BaseTestCaseContext_raiseFailurestandardMsg_formatMessagefailureException_AssertRaisesBaseContextexpected_regexobj_name
        If args is empty, assertRaises/Warns is being used as a
        context manager, so check for a 'msg' kwarg and return self.
        If args is not empty, call a callable passing positional and keyword
        arguments.
        _base_type%s() arg 1 must be %s_base_type_str%r is an invalid keyword argument for this function'%r is an invalid keyword argument for ''this function'callable_obj_AssertRaisesContextA context manager used to implement TestCase.assertRaises* methods.an exception type or tuple of exception typesexc_name{} not raised by {}{} not raisedclear_frames"{}" does not match "{}"_AssertWarnsContextA context manager used to implement TestCase.assertWarns* methods.a warning type or tuple of warning types__warningregistry__catch_warningswarnings_managerfirst_matching{} not triggered by {}{} not triggered_OrderedChainMapA class whose instances are single test cases.

    By default, the test code itself should be placed in a method named
    'runTest'.

    If the fixture may be used for many test cases, create as
    many test methods as are needed. When instantiating such a TestCase
    subclass, specify in the constructor arguments the name of the test method
    that the instance is to execute.

    Test authors should subclass TestCase for their own tests. Construction
    and deconstruction of the test's environment ('fixture') can be
    implemented by overriding the 'setUp' and 'tearDown' methods respectively.

    If it is necessary to override the __init__ method, the base class
    __init__ method must always be called. It is important that subclasses
    should not change the signature of their __init__ method, since instances
    of the classes are instantiated automatically by parts of the framework
    in order to be run.

    When subclassing TestCase, you can set these attributes:
    * failureException: determines which exception will be raised when
        the instance's assertion methods fail; test methods raising this
        exception will be deemed to have 'failed' rather than 'errored'.
    * longMessage: determines whether long messages (including repr of
        objects used in assert methods) will be printed on failure in *addition*
        to any explicit message passed.
    * maxDiff: sets the maximum length of a diff in failure messages
        by assert methods using difflib. It is looked up as an instance
        attribute so can be configured by individual tests if required.
    longMessagemaxDiff_diffThreshold_classSetupFailed_class_cleanupsCreate an instance of the class that will use the named test
           method when executed. Raises a ValueError if the instance does
           not have a method with the specified name.
        _testMethodName_outcomeNo test_testMethodDoctestMethodno such test method in %s: %s_cleanups_subtest_type_equality_funcsaddTypeEqualityFuncassertDictEqualassertListEqualassertTupleEqualassertSetEqualassertMultiLineEqualtypeobjAdd a type specific assertEqual style function to compare a type.

        This method is for use by TestCase subclasses that need to register
        their own type equality functions to provide nicer error messages.

        Args:
            typeobj: The data type to call this function on when both values
                    are of the same type in assertEqual().
            function: The callable taking two arguments and an optional
                    msg= argument that raises self.failureException with a
                    useful error message when the two arguments are not equal.
        Add a function, with arguments, to be called when the test is
        completed. Functions added are called on a LIFO basis and are
        called after tearDown on test failure or success.

        Cleanup items are called even if setUp fails (unlike tearDown).addClassCleanupSame as addCleanup, except the cleanup items are called even if
        setUpClass fails (unlike tearDownClass).Hook method for setting up the test fixture before exercising it.Hook method for deconstructing the test fixture after testing it.setUpClassHook method for setting up class fixture before running tests in the class.tearDownClassHook method for deconstructing the class fixture after running all tests in the class.countTestCasesdefaultTestResultshortDescriptionReturns a one-line description of the test, or None if no
        description has been provided.

        The default implementation of this method returns the first line of
        the specified test method's docstring.
        %s.%s%s (%s)<%s testMethod=%s>_addSkipaddSkipTestResult has no addSkip method, skips not reportedaddSuccesssubTestReturn a context manager that will return the enclosed block
        of code in a subtest identified by the optional message and
        keyword parameters.  A failure in the subtest marks the test
        case as failed but resumes execution at the end of the enclosed
        block, allowing further test code to be executed.
        params_map_SubTest_feedErrorsToResultaddFailureaddError_addExpectedFailureaddExpectedFailureTestResult has no addExpectedFailure method, reporting as passes_addUnexpectedSuccessaddUnexpectedSuccessTestResult has no addUnexpectedSuccess method, reporting as failurestartTestRunstopTestRunstartTestskip_whyoutcomedoCleanupsstopTestExecute all cleanup functions. Normally called for you after
        tearDown.doClassCleanupsExecute all class cleanup functions. Normally called for you after
        tearDownClass.tearDown_exceptionsRun the test without collecting errors in a TestResultskipTestSkip this test.failFail immediately, with the given message.assertFalseCheck that the expression is false.%s is not falseCheck that the expression is true.%s is not trueHonour the longMessage attribute when generating failure messages.
        If longMessage is False this means:
        * Use only an explicit message if it is provided
        * Otherwise use the standard message for the assert

        If longMessage is True:
        * Use the standard message
        * If an explicit message is provided, plus ' : ' and the explicit message
        %s : %sexpected_exceptionFail unless an exception of class expected_exception is raised
           by the callable when invoked with specified positional and
           keyword arguments. If a different type of exception is
           raised, it will not be caught, and the test case will be
           deemed to have suffered an error, exactly as for an
           unexpected exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertRaises(SomeException):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertRaises
           is used as a context object.

           The context manager keeps a reference to the exception as
           the 'exception' attribute. This allows you to inspect the
           exception after the assertion::

               with self.assertRaises(SomeException) as cm:
                   do_something()
               the_exception = cm.exception
               self.assertEqual(the_exception.error_code, 3)
        assertWarnsexpected_warningFail unless a warning of class warnClass is triggered
           by the callable when invoked with specified positional and
           keyword arguments.  If a different type of warning is
           triggered, it will not be handled: depending on the other
           warning filtering rules in effect, it might be silenced, printed
           out, or raised as an exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertWarns(SomeWarning):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertWarns
           is used as a context object.

           The context manager keeps a reference to the first matching
           warning as the 'warning' attribute; similarly, the 'filename'
           and 'lineno' attributes give you information about the line
           of Python code from which the warning was triggered.
           This allows you to inspect the warning after the assertion::

               with self.assertWarns(SomeWarning) as cm:
                   do_something()
               the_warning = cm.warning
               self.assertEqual(the_warning.some_attribute, 147)
        assertLogsFail unless a log message of level *level* or higher is emitted
        on *logger_name* or its children.  If omitted, *level* defaults to
        INFO and *logger* defaults to the root logger.

        This method must be used as a context manager, and will yield
        a recording object with two attributes: `output` and `records`.
        At the end of the context manager, the `output` attribute will
        be a list of the matching formatted log messages and the
        `records` attribute will be a list of the corresponding LogRecord
        objects.

        Example::

            with self.assertLogs('foo', level='INFO') as cm:
                logging.getLogger('foo').info('first message')
                logging.getLogger('foo.bar').error('second message')
            self.assertEqual(cm.output, ['INFO:foo:first message',
                                         'ERROR:foo.bar:second message'])
        _AssertLogsContextno_logsassertNoLogs Fail unless no log messages of level *level* or higher are emitted
        on *logger_name* or its children.

        This method must be used as a context manager.
        _getAssertEqualityFuncGet a detailed comparison function for the types of the two args.

        Returns: A callable accepting (first, second, msg=None) that will
        raise a failure exception if first != second with a useful human
        readable error message for those types.
        asserter_baseAssertEqualThe default assertEqual implementation, not type specific.%s != %sFail if the two objects are unequal as determined by the '=='
           operator.
        assertion_funcassertNotEqualFail if the two objects are equal as determined by the '!='
           operator.
        %s == %sassertAlmostEqualFail if the two objects are unequal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is more than the given
           delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           If the two objects compare equal then they will automatically
           compare almost equal.
        specify delta or places not bothdiff%s != %s within %s delta (%s difference)%s != %s within %r places (%s difference)assertNotAlmostEqualFail if the two objects are equal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is less than the given delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           Objects that are equal automatically fail.
        %s == %s within %s delta (%s difference)%s == %s within %r placesassertSequenceEqualseq1seq2seq_typeAn equality assertion for ordered sequences (like lists and tuples).

        For the purposes of this function, a valid ordered sequence type is one
        which can be indexed, has a length, and has an equality operator.

        Args:
            seq1: The first sequence to compare.
            seq2: The second sequence to compare.
            seq_type: The expected datatype of the sequences, or None if no
                    datatype should be enforced.
            msg: Optional message to use on failure instead of a list of
                    differences.
        seq_type_nameFirst sequence is not a %s: %sSecond sequence is not a %s: %sdifferinglen1First %s has no length.    Non-sequence?len2Second %s has no length.    Non-sequence?%ss differ: %s != %s
item1
Unable to index element %d of first %s
item2
Unable to index element %d of second %s

First differing element %d:
%s
%s

First %s contains %d additional elements.
'\nFirst %s contains %d additional ''elements.\n'First extra element %d:
%s
Unable to index element %d of first %s
'Unable to index element %d ''of first %s\n'
Second %s contains %d additional elements.
'\nSecond %s contains %d additional 'Unable to index element %d of second %s
'of second %s\n'ndiffpformatdiffMsg_truncateMessagemax_difflist1list2A list-specific equality assertion.

        Args:
            list1: The first list to compare.
            list2: The second list to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        tuple1tuple2A tuple-specific equality assertion.

        Args:
            tuple1: The first tuple to compare.
            tuple2: The second tuple to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.
        set1set2A set-specific equality assertion.

        Args:
            set1: The first set to compare.
            set2: The second set to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        assertSetEqual uses ducktyping to support different types of sets, and
        is optimized for sets specifically (parameters must support a
        difference method).
        difference1invalid type when attempting set difference: %sfirst argument does not support set difference: %sdifference2second argument does not support set difference: %sItems in the first set but not the second:Items in the second set but not the first:assertInJust like self.assertTrue(a in b), but with a nicer default message.%s not found in %sassertNotInJust like self.assertTrue(a not in b), but with a nicer default message.%s unexpectedly found in %sassertIsexpr1expr2Just like self.assertTrue(a is b), but with a nicer default message.%s is not %sassertIsNotJust like self.assertTrue(a is not b), but with a nicer default message.unexpectedly identical: %sd1assertIsInstanceFirst argument is not a dictionarySecond argument is not a dictionaryassertDictContainsSubsetsubsetChecks whether dictionary is a superset of subset.assertDictContainsSubset is deprecatedmismatched%s, expected: %s, actual: %sMissing: %sMismatched values: %sAsserts that two iterables have the same elements, the same number of
        times, without regard to order.

            self.assertEqual(Counter(list(first)),
                             Counter(list(second)))

         Example:
            - [0, 1, 1] and [1, 0, 1] compare equal.
            - [0, 0, 1] and [0, 1] compare unequal.

        first_seqsecond_seqdifferencesElement counts were not equal:
First has %d, Second has %d:  %rAssert that two multi-line strings are equal.First argument is not a stringSecond argument is not a stringfirstlinessecondlinesassertLessJust like self.assertTrue(a < b), but with a nicer default message.%s not less than %sassertLessEqualJust like self.assertTrue(a <= b), but with a nicer default message.%s not less than or equal to %sassertGreaterJust like self.assertTrue(a > b), but with a nicer default message.%s not greater than %sassertGreaterEqualJust like self.assertTrue(a >= b), but with a nicer default message.%s not greater than or equal to %sassertIsNoneSame as self.assertTrue(obj is None), with a nicer default message.%s is not NoneIncluded for symmetry with assertIsNone.unexpectedly NoneSame as self.assertTrue(isinstance(obj, cls)), with a nicer
        default message.%s is not an instance of %rassertNotIsInstanceIncluded for symmetry with assertIsInstance.%s is an instance of %rAsserts that the message in a raised exception matches a regex.

        Args:
            expected_exception: Exception class expected to be raised.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertRaisesRegex is used as a context manager.
        assertWarnsRegexAsserts that the message in a triggered warning matches a regexp.
        Basic functioning is similar to assertWarns() with the addition
        that only warnings whose messages also match the regular expression
        are considered successful matches.

        Args:
            expected_warning: Warning class expected to be triggered.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertWarnsRegex is used as a context manager.
        assertRegexFail the test unless the text matches the regular expression.expected_regex must not be empty.Regex didn't match: %r not found in %rassertNotRegexunexpected_regexFail the test if the text matches the regular expression.Regex matched: %r matches %r in %r_deprecateoriginal_funcPlease use {0} instead.failUnlessEqualassertEqualsfailIfEqualassertNotEqualsfailUnlessAlmostEqualassertAlmostEqualsfailIfAlmostEqualassertNotAlmostEqualsfailUnlessassert_failUnlessRaisesfailIfassertRaisesRegexpassertRegexpMatchesassertNotRegexpMatchesA test case that wraps a test function.

    This is useful for slipping pre-existing test functions into the
    unittest framework. Optionally, set-up and tidy-up functions can be
    supplied. As with TestCase, the tidy-up ('tearDown') function will
    always be called if the set-up ('setUp') function ran successfully.
    testFunc_setUpFunc_tearDownFunc_testFunc_description<%s tec=%s>_messagesubtests cannot be run directly_subDescription[{}]params_desc({})(<subtest>){} {}Returns a one-line description of the subtest, or None if no
        description has been provided.
        # explicitly break a reference cycle:# exc_info -> frame -> exc_info# Swallows all but first exception. If a multi-exception handler# gets written we should use that here instead.# bpo-23890: manually break a reference cycle# let unexpected exceptions pass through# store exception, without traceback, for later retrieval# The __warningregistry__'s need to be in a pristine state for tests# to work properly.# store warning for later retrieval# Now we simply try to choose a helpful failure message# If a string is longer than _diffThreshold, use normal comparison instead# of difflib.  See #11763.# Attribute used by TestSuite for classSetUp# we allow instantiation with no explicit method name# but not an *incorrect* or missing method name# Map types to custom assertEqual functions that will compare# instances of said type in more detail to generate a more useful# error message.# If the test is expecting a failure, we really want to# stop now and register the expected failure.# We need to pass an actual exception and traceback to addFailure,# otherwise the legacy result can choke.# If the class or method was skipped.# explicitly break reference cycles:# outcome.errors -> frame -> outcome -> outcome.errors# outcome.expectedFailure -> frame -> outcome -> outcome.expectedFailure# clear the outcome, no more needed# return this for backwards compatibility# even though we no longer use it internally# don't switch to '{}' formatting in Python 2.X# it changes the way unicode input is handled# Lazy import to avoid importing logging if it is not needed.# NOTE(gregory.p.smith): I considered isinstance(first, type(second))# and vice versa.  I opted for the conservative approach in case# subclasses are not intended to be compared in detail to their super# class instances using a type equality func.  This means testing# subtypes won't automagically use the detailed comparison.  Callers# should use their type specific assertSpamEqual method to compare# subclasses if the detailed comparison is desired and appropriate.# See the discussion in http://bugs.python.org/issue2578.# shortcut# The sequences are the same, but have differing types.# Handle case with unhashable elements# don't use difflib if the strings are too long# _formatMessage ensures the longMessage option is respected# see #9424b'Test case implementation'u'Test case implementation'b'
Diff is %s characters long. Set self.maxDiff to None to see it.'u'
Diff is %s characters long. Set self.maxDiff to None to see it.'b'
    Raise this exception in a test to skip it.

    Usually you can use TestCase.skipTest() or one of the skipping decorators
    instead of raising this directly.
    'u'
    Raise this exception in a test to skip it.

    Usually you can use TestCase.skipTest() or one of the skipping decorators
    instead of raising this directly.
    'b'
    The test should stop.
    'u'
    The test should stop.
    'b'
    The test was supposed to fail, but it didn't!
    'u'
    The test was supposed to fail, but it didn't!
    'b'addSubTest'u'addSubTest'b'Same as addCleanup, except the cleanup items are called even if
    setUpModule fails (unlike tearDownModule).'u'Same as addCleanup, except the cleanup items are called even if
    setUpModule fails (unlike tearDownModule).'b'Execute all module cleanup functions. Normally called for you after
    tearDownModule.'u'Execute all module cleanup functions. Normally called for you after
    tearDownModule.'b'
    Unconditionally skip a test.
    'u'
    Unconditionally skip a test.
    'b'
    Skip a test if the condition is true.
    'u'
    Skip a test if the condition is true.
    'b'
    Skip a test unless the condition is true.
    'u'
    Skip a test unless the condition is true.
    'b'
        If args is empty, assertRaises/Warns is being used as a
        context manager, so check for a 'msg' kwarg and return self.
        If args is not empty, call a callable passing positional and keyword
        arguments.
        'u'
        If args is empty, assertRaises/Warns is being used as a
        context manager, so check for a 'msg' kwarg and return self.
        If args is not empty, call a callable passing positional and keyword
        arguments.
        'b'%s() arg 1 must be %s'u'%s() arg 1 must be %s'b'%r is an invalid keyword argument for this function'u'%r is an invalid keyword argument for this function'b'A context manager used to implement TestCase.assertRaises* methods.'u'A context manager used to implement TestCase.assertRaises* methods.'b'an exception type or tuple of exception types'u'an exception type or tuple of exception types'b'{} not raised by {}'u'{} not raised by {}'b'{} not raised'u'{} not raised'b'"{}" does not match "{}"'u'"{}" does not match "{}"'b'A context manager used to implement TestCase.assertWarns* methods.'u'A context manager used to implement TestCase.assertWarns* methods.'b'a warning type or tuple of warning types'u'a warning type or tuple of warning types'b'__warningregistry__'u'__warningregistry__'b'{} not triggered by {}'u'{} not triggered by {}'b'{} not triggered'u'{} not triggered'b'A class whose instances are single test cases.

    By default, the test code itself should be placed in a method named
    'runTest'.

    If the fixture may be used for many test cases, create as
    many test methods as are needed. When instantiating such a TestCase
    subclass, specify in the constructor arguments the name of the test method
    that the instance is to execute.

    Test authors should subclass TestCase for their own tests. Construction
    and deconstruction of the test's environment ('fixture') can be
    implemented by overriding the 'setUp' and 'tearDown' methods respectively.

    If it is necessary to override the __init__ method, the base class
    __init__ method must always be called. It is important that subclasses
    should not change the signature of their __init__ method, since instances
    of the classes are instantiated automatically by parts of the framework
    in order to be run.

    When subclassing TestCase, you can set these attributes:
    * failureException: determines which exception will be raised when
        the instance's assertion methods fail; test methods raising this
        exception will be deemed to have 'failed' rather than 'errored'.
    * longMessage: determines whether long messages (including repr of
        objects used in assert methods) will be printed on failure in *addition*
        to any explicit message passed.
    * maxDiff: sets the maximum length of a diff in failure messages
        by assert methods using difflib. It is looked up as an instance
        attribute so can be configured by individual tests if required.
    'u'A class whose instances are single test cases.

    By default, the test code itself should be placed in a method named
    'runTest'.

    If the fixture may be used for many test cases, create as
    many test methods as are needed. When instantiating such a TestCase
    subclass, specify in the constructor arguments the name of the test method
    that the instance is to execute.

    Test authors should subclass TestCase for their own tests. Construction
    and deconstruction of the test's environment ('fixture') can be
    implemented by overriding the 'setUp' and 'tearDown' methods respectively.

    If it is necessary to override the __init__ method, the base class
    __init__ method must always be called. It is important that subclasses
    should not change the signature of their __init__ method, since instances
    of the classes are instantiated automatically by parts of the framework
    in order to be run.

    When subclassing TestCase, you can set these attributes:
    * failureException: determines which exception will be raised when
        the instance's assertion methods fail; test methods raising this
        exception will be deemed to have 'failed' rather than 'errored'.
    * longMessage: determines whether long messages (including repr of
        objects used in assert methods) will be printed on failure in *addition*
        to any explicit message passed.
    * maxDiff: sets the maximum length of a diff in failure messages
        by assert methods using difflib. It is looked up as an instance
        attribute so can be configured by individual tests if required.
    'b'Create an instance of the class that will use the named test
           method when executed. Raises a ValueError if the instance does
           not have a method with the specified name.
        'u'Create an instance of the class that will use the named test
           method when executed. Raises a ValueError if the instance does
           not have a method with the specified name.
        'b'No test'u'No test'b'no such test method in %s: %s'u'no such test method in %s: %s'b'assertDictEqual'u'assertDictEqual'b'assertListEqual'u'assertListEqual'b'assertTupleEqual'u'assertTupleEqual'b'assertSetEqual'u'assertSetEqual'b'assertMultiLineEqual'u'assertMultiLineEqual'b'Add a type specific assertEqual style function to compare a type.

        This method is for use by TestCase subclasses that need to register
        their own type equality functions to provide nicer error messages.

        Args:
            typeobj: The data type to call this function on when both values
                    are of the same type in assertEqual().
            function: The callable taking two arguments and an optional
                    msg= argument that raises self.failureException with a
                    useful error message when the two arguments are not equal.
        'u'Add a type specific assertEqual style function to compare a type.

        This method is for use by TestCase subclasses that need to register
        their own type equality functions to provide nicer error messages.

        Args:
            typeobj: The data type to call this function on when both values
                    are of the same type in assertEqual().
            function: The callable taking two arguments and an optional
                    msg= argument that raises self.failureException with a
                    useful error message when the two arguments are not equal.
        'b'Add a function, with arguments, to be called when the test is
        completed. Functions added are called on a LIFO basis and are
        called after tearDown on test failure or success.

        Cleanup items are called even if setUp fails (unlike tearDown).'u'Add a function, with arguments, to be called when the test is
        completed. Functions added are called on a LIFO basis and are
        called after tearDown on test failure or success.

        Cleanup items are called even if setUp fails (unlike tearDown).'b'Same as addCleanup, except the cleanup items are called even if
        setUpClass fails (unlike tearDownClass).'u'Same as addCleanup, except the cleanup items are called even if
        setUpClass fails (unlike tearDownClass).'b'Hook method for setting up the test fixture before exercising it.'u'Hook method for setting up the test fixture before exercising it.'b'Hook method for deconstructing the test fixture after testing it.'u'Hook method for deconstructing the test fixture after testing it.'b'Hook method for setting up class fixture before running tests in the class.'u'Hook method for setting up class fixture before running tests in the class.'b'Hook method for deconstructing the class fixture after running all tests in the class.'u'Hook method for deconstructing the class fixture after running all tests in the class.'b'Returns a one-line description of the test, or None if no
        description has been provided.

        The default implementation of this method returns the first line of
        the specified test method's docstring.
        'u'Returns a one-line description of the test, or None if no
        description has been provided.

        The default implementation of this method returns the first line of
        the specified test method's docstring.
        'b'%s.%s'u'%s.%s'b'%s (%s)'u'%s (%s)'b'<%s testMethod=%s>'u'<%s testMethod=%s>'b'addSkip'u'addSkip'b'TestResult has no addSkip method, skips not reported'u'TestResult has no addSkip method, skips not reported'b'Return a context manager that will return the enclosed block
        of code in a subtest identified by the optional message and
        keyword parameters.  A failure in the subtest marks the test
        case as failed but resumes execution at the end of the enclosed
        block, allowing further test code to be executed.
        'u'Return a context manager that will return the enclosed block
        of code in a subtest identified by the optional message and
        keyword parameters.  A failure in the subtest marks the test
        case as failed but resumes execution at the end of the enclosed
        block, allowing further test code to be executed.
        'b'TestResult has no addExpectedFailure method, reporting as passes'u'TestResult has no addExpectedFailure method, reporting as passes'b'TestResult has no addUnexpectedSuccess method, reporting as failure'u'TestResult has no addUnexpectedSuccess method, reporting as failure'b'startTestRun'u'startTestRun'b'stopTestRun'u'stopTestRun'b'__unittest_skip__'u'__unittest_skip__'b'__unittest_skip_why__'u'__unittest_skip_why__'b'__unittest_expecting_failure__'u'__unittest_expecting_failure__'b'Execute all cleanup functions. Normally called for you after
        tearDown.'u'Execute all cleanup functions. Normally called for you after
        tearDown.'b'Execute all class cleanup functions. Normally called for you after
        tearDownClass.'u'Execute all class cleanup functions. Normally called for you after
        tearDownClass.'b'Run the test without collecting errors in a TestResult'u'Run the test without collecting errors in a TestResult'b'Skip this test.'u'Skip this test.'b'Fail immediately, with the given message.'u'Fail immediately, with the given message.'b'Check that the expression is false.'u'Check that the expression is false.'b'%s is not false'u'%s is not false'b'Check that the expression is true.'u'Check that the expression is true.'b'%s is not true'u'%s is not true'b'Honour the longMessage attribute when generating failure messages.
        If longMessage is False this means:
        * Use only an explicit message if it is provided
        * Otherwise use the standard message for the assert

        If longMessage is True:
        * Use the standard message
        * If an explicit message is provided, plus ' : ' and the explicit message
        'u'Honour the longMessage attribute when generating failure messages.
        If longMessage is False this means:
        * Use only an explicit message if it is provided
        * Otherwise use the standard message for the assert

        If longMessage is True:
        * Use the standard message
        * If an explicit message is provided, plus ' : ' and the explicit message
        'b'%s : %s'u'%s : %s'b'Fail unless an exception of class expected_exception is raised
           by the callable when invoked with specified positional and
           keyword arguments. If a different type of exception is
           raised, it will not be caught, and the test case will be
           deemed to have suffered an error, exactly as for an
           unexpected exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertRaises(SomeException):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertRaises
           is used as a context object.

           The context manager keeps a reference to the exception as
           the 'exception' attribute. This allows you to inspect the
           exception after the assertion::

               with self.assertRaises(SomeException) as cm:
                   do_something()
               the_exception = cm.exception
               self.assertEqual(the_exception.error_code, 3)
        'u'Fail unless an exception of class expected_exception is raised
           by the callable when invoked with specified positional and
           keyword arguments. If a different type of exception is
           raised, it will not be caught, and the test case will be
           deemed to have suffered an error, exactly as for an
           unexpected exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertRaises(SomeException):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertRaises
           is used as a context object.

           The context manager keeps a reference to the exception as
           the 'exception' attribute. This allows you to inspect the
           exception after the assertion::

               with self.assertRaises(SomeException) as cm:
                   do_something()
               the_exception = cm.exception
               self.assertEqual(the_exception.error_code, 3)
        'b'assertRaises'u'assertRaises'b'Fail unless a warning of class warnClass is triggered
           by the callable when invoked with specified positional and
           keyword arguments.  If a different type of warning is
           triggered, it will not be handled: depending on the other
           warning filtering rules in effect, it might be silenced, printed
           out, or raised as an exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertWarns(SomeWarning):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertWarns
           is used as a context object.

           The context manager keeps a reference to the first matching
           warning as the 'warning' attribute; similarly, the 'filename'
           and 'lineno' attributes give you information about the line
           of Python code from which the warning was triggered.
           This allows you to inspect the warning after the assertion::

               with self.assertWarns(SomeWarning) as cm:
                   do_something()
               the_warning = cm.warning
               self.assertEqual(the_warning.some_attribute, 147)
        'u'Fail unless a warning of class warnClass is triggered
           by the callable when invoked with specified positional and
           keyword arguments.  If a different type of warning is
           triggered, it will not be handled: depending on the other
           warning filtering rules in effect, it might be silenced, printed
           out, or raised as an exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertWarns(SomeWarning):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertWarns
           is used as a context object.

           The context manager keeps a reference to the first matching
           warning as the 'warning' attribute; similarly, the 'filename'
           and 'lineno' attributes give you information about the line
           of Python code from which the warning was triggered.
           This allows you to inspect the warning after the assertion::

               with self.assertWarns(SomeWarning) as cm:
                   do_something()
               the_warning = cm.warning
               self.assertEqual(the_warning.some_attribute, 147)
        'b'assertWarns'u'assertWarns'b'Fail unless a log message of level *level* or higher is emitted
        on *logger_name* or its children.  If omitted, *level* defaults to
        INFO and *logger* defaults to the root logger.

        This method must be used as a context manager, and will yield
        a recording object with two attributes: `output` and `records`.
        At the end of the context manager, the `output` attribute will
        be a list of the matching formatted log messages and the
        `records` attribute will be a list of the corresponding LogRecord
        objects.

        Example::

            with self.assertLogs('foo', level='INFO') as cm:
                logging.getLogger('foo').info('first message')
                logging.getLogger('foo.bar').error('second message')
            self.assertEqual(cm.output, ['INFO:foo:first message',
                                         'ERROR:foo.bar:second message'])
        'u'Fail unless a log message of level *level* or higher is emitted
        on *logger_name* or its children.  If omitted, *level* defaults to
        INFO and *logger* defaults to the root logger.

        This method must be used as a context manager, and will yield
        a recording object with two attributes: `output` and `records`.
        At the end of the context manager, the `output` attribute will
        be a list of the matching formatted log messages and the
        `records` attribute will be a list of the corresponding LogRecord
        objects.

        Example::

            with self.assertLogs('foo', level='INFO') as cm:
                logging.getLogger('foo').info('first message')
                logging.getLogger('foo.bar').error('second message')
            self.assertEqual(cm.output, ['INFO:foo:first message',
                                         'ERROR:foo.bar:second message'])
        'b' Fail unless no log messages of level *level* or higher are emitted
        on *logger_name* or its children.

        This method must be used as a context manager.
        'u' Fail unless no log messages of level *level* or higher are emitted
        on *logger_name* or its children.

        This method must be used as a context manager.
        'b'Get a detailed comparison function for the types of the two args.

        Returns: A callable accepting (first, second, msg=None) that will
        raise a failure exception if first != second with a useful human
        readable error message for those types.
        'u'Get a detailed comparison function for the types of the two args.

        Returns: A callable accepting (first, second, msg=None) that will
        raise a failure exception if first != second with a useful human
        readable error message for those types.
        'b'The default assertEqual implementation, not type specific.'u'The default assertEqual implementation, not type specific.'b'%s != %s'u'%s != %s'b'Fail if the two objects are unequal as determined by the '=='
           operator.
        'u'Fail if the two objects are unequal as determined by the '=='
           operator.
        'b'Fail if the two objects are equal as determined by the '!='
           operator.
        'u'Fail if the two objects are equal as determined by the '!='
           operator.
        'b'%s == %s'u'%s == %s'b'Fail if the two objects are unequal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is more than the given
           delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           If the two objects compare equal then they will automatically
           compare almost equal.
        'u'Fail if the two objects are unequal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is more than the given
           delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           If the two objects compare equal then they will automatically
           compare almost equal.
        'b'specify delta or places not both'u'specify delta or places not both'b'%s != %s within %s delta (%s difference)'u'%s != %s within %s delta (%s difference)'b'%s != %s within %r places (%s difference)'u'%s != %s within %r places (%s difference)'b'Fail if the two objects are equal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is less than the given delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           Objects that are equal automatically fail.
        'u'Fail if the two objects are equal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is less than the given delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           Objects that are equal automatically fail.
        'b'%s == %s within %s delta (%s difference)'u'%s == %s within %s delta (%s difference)'b'%s == %s within %r places'u'%s == %s within %r places'b'An equality assertion for ordered sequences (like lists and tuples).

        For the purposes of this function, a valid ordered sequence type is one
        which can be indexed, has a length, and has an equality operator.

        Args:
            seq1: The first sequence to compare.
            seq2: The second sequence to compare.
            seq_type: The expected datatype of the sequences, or None if no
                    datatype should be enforced.
            msg: Optional message to use on failure instead of a list of
                    differences.
        'u'An equality assertion for ordered sequences (like lists and tuples).

        For the purposes of this function, a valid ordered sequence type is one
        which can be indexed, has a length, and has an equality operator.

        Args:
            seq1: The first sequence to compare.
            seq2: The second sequence to compare.
            seq_type: The expected datatype of the sequences, or None if no
                    datatype should be enforced.
            msg: Optional message to use on failure instead of a list of
                    differences.
        'b'First sequence is not a %s: %s'u'First sequence is not a %s: %s'b'Second sequence is not a %s: %s'u'Second sequence is not a %s: %s'b'sequence'u'sequence'b'First %s has no length.    Non-sequence?'u'First %s has no length.    Non-sequence?'b'Second %s has no length.    Non-sequence?'u'Second %s has no length.    Non-sequence?'b'%ss differ: %s != %s
'u'%ss differ: %s != %s
'b'
Unable to index element %d of first %s
'u'
Unable to index element %d of first %s
'b'
Unable to index element %d of second %s
'u'
Unable to index element %d of second %s
'b'
First differing element %d:
%s
%s
'u'
First differing element %d:
%s
%s
'b'
First %s contains %d additional elements.
'u'
First %s contains %d additional elements.
'b'First extra element %d:
%s
'u'First extra element %d:
%s
'b'Unable to index element %d of first %s
'u'Unable to index element %d of first %s
'b'
Second %s contains %d additional elements.
'u'
Second %s contains %d additional elements.
'b'Unable to index element %d of second %s
'u'Unable to index element %d of second %s
'b'A list-specific equality assertion.

        Args:
            list1: The first list to compare.
            list2: The second list to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        'u'A list-specific equality assertion.

        Args:
            list1: The first list to compare.
            list2: The second list to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        'b'A tuple-specific equality assertion.

        Args:
            tuple1: The first tuple to compare.
            tuple2: The second tuple to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.
        'u'A tuple-specific equality assertion.

        Args:
            tuple1: The first tuple to compare.
            tuple2: The second tuple to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.
        'b'A set-specific equality assertion.

        Args:
            set1: The first set to compare.
            set2: The second set to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        assertSetEqual uses ducktyping to support different types of sets, and
        is optimized for sets specifically (parameters must support a
        difference method).
        'u'A set-specific equality assertion.

        Args:
            set1: The first set to compare.
            set2: The second set to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        assertSetEqual uses ducktyping to support different types of sets, and
        is optimized for sets specifically (parameters must support a
        difference method).
        'b'invalid type when attempting set difference: %s'u'invalid type when attempting set difference: %s'b'first argument does not support set difference: %s'u'first argument does not support set difference: %s'b'second argument does not support set difference: %s'u'second argument does not support set difference: %s'b'Items in the first set but not the second:'u'Items in the first set but not the second:'b'Items in the second set but not the first:'u'Items in the second set but not the first:'b'Just like self.assertTrue(a in b), but with a nicer default message.'u'Just like self.assertTrue(a in b), but with a nicer default message.'b'%s not found in %s'u'%s not found in %s'b'Just like self.assertTrue(a not in b), but with a nicer default message.'u'Just like self.assertTrue(a not in b), but with a nicer default message.'b'%s unexpectedly found in %s'u'%s unexpectedly found in %s'b'Just like self.assertTrue(a is b), but with a nicer default message.'u'Just like self.assertTrue(a is b), but with a nicer default message.'b'%s is not %s'u'%s is not %s'b'Just like self.assertTrue(a is not b), but with a nicer default message.'u'Just like self.assertTrue(a is not b), but with a nicer default message.'b'unexpectedly identical: %s'u'unexpectedly identical: %s'b'First argument is not a dictionary'u'First argument is not a dictionary'b'Second argument is not a dictionary'u'Second argument is not a dictionary'b'Checks whether dictionary is a superset of subset.'u'Checks whether dictionary is a superset of subset.'b'assertDictContainsSubset is deprecated'u'assertDictContainsSubset is deprecated'b'%s, expected: %s, actual: %s'u'%s, expected: %s, actual: %s'b'Missing: %s'u'Missing: %s'b'Mismatched values: %s'u'Mismatched values: %s'b'Asserts that two iterables have the same elements, the same number of
        times, without regard to order.

            self.assertEqual(Counter(list(first)),
                             Counter(list(second)))

         Example:
            - [0, 1, 1] and [1, 0, 1] compare equal.
            - [0, 0, 1] and [0, 1] compare unequal.

        'u'Asserts that two iterables have the same elements, the same number of
        times, without regard to order.

            self.assertEqual(Counter(list(first)),
                             Counter(list(second)))

         Example:
            - [0, 1, 1] and [1, 0, 1] compare equal.
            - [0, 0, 1] and [0, 1] compare unequal.

        'b'Element counts were not equal:
'u'Element counts were not equal:
'b'First has %d, Second has %d:  %r'u'First has %d, Second has %d:  %r'b'Assert that two multi-line strings are equal.'u'Assert that two multi-line strings are equal.'b'First argument is not a string'u'First argument is not a string'b'Second argument is not a string'u'Second argument is not a string'b'Just like self.assertTrue(a < b), but with a nicer default message.'u'Just like self.assertTrue(a < b), but with a nicer default message.'b'%s not less than %s'u'%s not less than %s'b'Just like self.assertTrue(a <= b), but with a nicer default message.'u'Just like self.assertTrue(a <= b), but with a nicer default message.'b'%s not less than or equal to %s'u'%s not less than or equal to %s'b'Just like self.assertTrue(a > b), but with a nicer default message.'u'Just like self.assertTrue(a > b), but with a nicer default message.'b'%s not greater than %s'u'%s not greater than %s'b'Just like self.assertTrue(a >= b), but with a nicer default message.'u'Just like self.assertTrue(a >= b), but with a nicer default message.'b'%s not greater than or equal to %s'u'%s not greater than or equal to %s'b'Same as self.assertTrue(obj is None), with a nicer default message.'u'Same as self.assertTrue(obj is None), with a nicer default message.'b'%s is not None'u'%s is not None'b'Included for symmetry with assertIsNone.'u'Included for symmetry with assertIsNone.'b'unexpectedly None'u'unexpectedly None'b'Same as self.assertTrue(isinstance(obj, cls)), with a nicer
        default message.'u'Same as self.assertTrue(isinstance(obj, cls)), with a nicer
        default message.'b'%s is not an instance of %r'u'%s is not an instance of %r'b'Included for symmetry with assertIsInstance.'u'Included for symmetry with assertIsInstance.'b'%s is an instance of %r'u'%s is an instance of %r'b'Asserts that the message in a raised exception matches a regex.

        Args:
            expected_exception: Exception class expected to be raised.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertRaisesRegex is used as a context manager.
        'u'Asserts that the message in a raised exception matches a regex.

        Args:
            expected_exception: Exception class expected to be raised.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertRaisesRegex is used as a context manager.
        'b'assertRaisesRegex'u'assertRaisesRegex'b'Asserts that the message in a triggered warning matches a regexp.
        Basic functioning is similar to assertWarns() with the addition
        that only warnings whose messages also match the regular expression
        are considered successful matches.

        Args:
            expected_warning: Warning class expected to be triggered.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertWarnsRegex is used as a context manager.
        'u'Asserts that the message in a triggered warning matches a regexp.
        Basic functioning is similar to assertWarns() with the addition
        that only warnings whose messages also match the regular expression
        are considered successful matches.

        Args:
            expected_warning: Warning class expected to be triggered.
            expected_regex: Regex (re.Pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertWarnsRegex is used as a context manager.
        'b'assertWarnsRegex'u'assertWarnsRegex'b'Fail the test unless the text matches the regular expression.'u'Fail the test unless the text matches the regular expression.'b'expected_regex must not be empty.'u'expected_regex must not be empty.'b'Regex didn't match: %r not found in %r'u'Regex didn't match: %r not found in %r'b'Fail the test if the text matches the regular expression.'u'Fail the test if the text matches the regular expression.'b'Regex matched: %r matches %r in %r'u'Regex matched: %r matches %r in %r'b'Please use {0} instead.'u'Please use {0} instead.'b'A test case that wraps a test function.

    This is useful for slipping pre-existing test functions into the
    unittest framework. Optionally, set-up and tidy-up functions can be
    supplied. As with TestCase, the tidy-up ('tearDown') function will
    always be called if the set-up ('setUp') function ran successfully.
    'u'A test case that wraps a test function.

    This is useful for slipping pre-existing test functions into the
    unittest framework. Optionally, set-up and tidy-up functions can be
    supplied. As with TestCase, the tidy-up ('tearDown') function will
    always be called if the set-up ('setUp') function ran successfully.
    'b'<%s tec=%s>'u'<%s tec=%s>'b'subtests cannot be run directly'u'subtests cannot be run directly'b'[{}]'u'[{}]'b'({})'u'({})'b'(<subtest>)'u'(<subtest>)'b'{} {}'u'{} {}'b'Returns a one-line description of the subtest, or None if no
        description has been provided.
        'u'Returns a one-line description of the subtest, or None if no
        description has been provided.
        'u'unittest.case'u'case'distutils.ccompiler

Contains CCompiler, an abstract base class that defines the interface
for the Distutils compiler abstraction model.distutils.errorsdistutils.spawndistutils.file_utilmove_filedistutils.dir_utilmkpathdistutils.dep_utilnewer_groupdistutils.utilsplit_quotedexecuteCCompilerAbstract base class to define the interface that must be implemented
    by real compiler classes.  Also has some utility methods used by
    several compiler classes.

    The basic idea behind a compiler abstraction class is that each
    instance can be used for all the compile/link steps in building a
    single project.  Thus, attributes common to all of those compile and
    link steps -- include directories, macros to define, libraries to link
    against, etc. -- are attributes of the compiler instance.  To allow for
    variability in how individual files are treated, most of those
    attributes may be varied on a per-compilation or per-link basis.
    src_extensionsobj_extensionstatic_lib_extensionshared_lib_extensionstatic_lib_formatshared_lib_formatexe_extension.cc++.cc.cpp.cxxobjc.mlanguage_maplanguage_orderoutput_dirmacrosinclude_dirslibrarieslibrary_dirsruntime_library_dirsset_executableset_executablesDefine the executables (and options for them) that will be run
        to perform the various stages of compilation.  The exact set of
        executables that may be specified here depends on the compiler
        class (via the 'executables' class attribute), but most will have:
          compiler      the C/C++ compiler
          linker_so     linker used to create shared objects and libraries
          linker_exe    linker used to create binary executables
          archiver      static library creator

        On platforms with a command-line (Unix, DOS/Windows), each of these
        is a string that will be split into executable name and (optional)
        list of arguments.  (Splitting the string is done similarly to how
        Unix shells operate: words are delimited by spaces, but quotes and
        backslashes can override this.  See
        'distutils.util.split_quoted()'.)
        unknown executable '%s' for class %s_find_macrodefn_check_macro_definitionsdefinitionsEnsures that every element of 'definitions' is a valid macro
        definition, ie. either (name,value) 2-tuple or a (name,) tuple.  Do
        nothing if all definitions are OK, raise TypeError otherwise.
        invalid macro definition '%s': must be tuple (string,), (string, string), or (string, None)define_macroDefine a preprocessor macro for all compilations driven by this
        compiler object.  The optional parameter 'value' should be a
        string; if it is not supplied, then the macro will be defined
        without an explicit value and the exact outcome depends on the
        compiler used (XXX true? does ANSI say anything about this?)
        undefine_macroUndefine a preprocessor macro for all compilations driven by
        this compiler object.  If the same macro is defined by
        'define_macro()' and undefined by 'undefine_macro()' the last call
        takes precedence (including multiple redefinitions or
        undefinitions).  If the macro is redefined/undefined on a
        per-compilation basis (ie. in the call to 'compile()'), then that
        takes precedence.
        undefnadd_include_dirAdd 'dir' to the list of directories that will be searched for
        header files.  The compiler is instructed to search directories in
        the order in which they are supplied by successive calls to
        'add_include_dir()'.
        set_include_dirsdirsSet the list of directories that will be searched to 'dirs' (a
        list of strings).  Overrides any preceding calls to
        'add_include_dir()'; subsequence calls to 'add_include_dir()' add
        to the list passed to 'set_include_dirs()'.  This does not affect
        any list of standard include directories that the compiler may
        search by default.
        add_libraryAdd 'libname' to the list of libraries that will be included in
        all links driven by this compiler object.  Note that 'libname'
        should *not* be the name of a file containing a library, but the
        name of the library itself: the actual filename will be inferred by
        the linker, the compiler, or the compiler class (depending on the
        platform).

        The linker will be instructed to link against libraries in the
        order they were supplied to 'add_library()' and/or
        'set_libraries()'.  It is perfectly valid to duplicate library
        names; the linker will be instructed to link against libraries as
        many times as they are mentioned.
        set_librariesSet the list of libraries to be included in all links driven by
        this compiler object to 'libnames' (a list of strings).  This does
        not affect any standard system libraries that the linker may
        include by default.
        add_library_dirAdd 'dir' to the list of directories that will be searched for
        libraries specified to 'add_library()' and 'set_libraries()'.  The
        linker will be instructed to search for libraries in the order they
        are supplied to 'add_library_dir()' and/or 'set_library_dirs()'.
        set_library_dirsSet the list of library search directories to 'dirs' (a list of
        strings).  This does not affect any standard library search path
        that the linker may search by default.
        add_runtime_library_dirAdd 'dir' to the list of directories that will be searched for
        shared libraries at runtime.
        set_runtime_library_dirsSet the list of directories to search for shared libraries at
        runtime to 'dirs' (a list of strings).  This does not affect any
        standard search path that the runtime linker may search by
        default.
        add_link_objectAdd 'object' to the list of object files (or analogues, such as
        explicitly named library files or the output of "resource
        compilers") to be included in every link driven by this compiler
        object.
        set_link_objectsSet the list of object files (or analogues) to be included in
        every link to 'objects'.  This does not affect any standard object
        files that the linker may include by default (such as system
        libraries).
        _setup_compileoutdirincdirssourcesdependsProcess arguments and decide which source files to compile.'output_dir' must be a string or None'macros' (if supplied) must be a list of tuples'include_dirs' (if supplied) must be a list of stringsobject_filenamesstrip_dirgen_preprocess_optionspp_optsbuildsrc_get_cc_args-g_fix_compile_argsTypecheck and fix-up some of the arguments to the 'compile()'
        method, and return fixed-up values.  Specifically: if 'output_dir'
        is None, replaces it with 'self.output_dir'; ensures that 'macros'
        is a list, and augments it with 'self.macros'; ensures that
        'include_dirs' is a list, and augments it with 'self.include_dirs'.
        Guarantees that the returned values are of the correct type,
        i.e. for 'output_dir' either string or None, and for 'macros' and
        'include_dirs' either list or None.
        _prep_compileDecide which source files must be recompiled.

        Determine the list of object files corresponding to 'sources',
        and figure out which ones really need to be recompiled.
        Return a list of all object files and a dictionary telling
        which source files can be skipped.
        _fix_object_argsTypecheck and fix up some arguments supplied to various methods.
        Specifically: ensure that 'objects' is a list; if output_dir is
        None, replace with self.output_dir.  Return fixed versions of
        'objects' and 'output_dir'.
        'objects' must be a list or tuple of strings_fix_lib_argsTypecheck and fix up some of the arguments supplied to the
        'link_*' methods.  Specifically: ensure that all arguments are
        lists, and augment them with their permanent versions
        (eg. 'self.libraries' augments 'libraries').  Return a tuple with
        fixed versions of all arguments.
        'libraries' (if supplied) must be a list of strings'library_dirs' (if supplied) must be a list of strings'runtime_library_dirs' (if supplied) must be a list of strings"'runtime_library_dirs' (if supplied) ""must be a list of strings"_need_linkoutput_fileReturn true if we need to relink the files listed in 'objects'
        to recreate 'output_file'.
        newerdetect_languageDetect the language of a given file, or list of files. Uses
        language_map, and language_order to do the job.
        extlangextindexpreprocessextra_preargsextra_postargsPreprocess a single C/C++ source file, named in 'source'.
        Output will be written to file named 'output_file', or stdout if
        'output_file' not supplied.  'macros' is a list of macro
        definitions as for 'compile()', which will augment the macros set
        with 'define_macro()' and 'undefine_macro()'.  'include_dirs' is a
        list of directory names that will be added to the default list.

        Raises PreprocessError on failure.
        Compile one or more source files.

        'sources' must be a list of filenames, most likely C/C++
        files, but in reality anything that can be handled by a
        particular compiler and compiler class (eg. MSVCCompiler can
        handle resource files in 'sources').  Return a list of object
        filenames, one per source filename in 'sources'.  Depending on
        the implementation, not all source files will necessarily be
        compiled, but all corresponding object filenames will be
        returned.

        If 'output_dir' is given, object files will be put under it, while
        retaining their original path component.  That is, "foo/bar.c"
        normally compiles to "foo/bar.o" (for a Unix implementation); if
        'output_dir' is "build", then it would compile to
        "build/foo/bar.o".

        'macros', if given, must be a list of macro definitions.  A macro
        definition is either a (name, value) 2-tuple or a (name,) 1-tuple.
        The former defines a macro; if the value is None, the macro is
        defined without an explicit value.  The 1-tuple case undefines a
        macro.  Later definitions/redefinitions/ undefinitions take
        precedence.

        'include_dirs', if given, must be a list of strings, the
        directories to add to the default include file search path for this
        compilation only.

        'debug' is a boolean; if true, the compiler will be instructed to
        output debug symbols in (or alongside) the object file(s).

        'extra_preargs' and 'extra_postargs' are implementation- dependent.
        On platforms that have the notion of a command-line (e.g. Unix,
        DOS/Windows), they are most likely lists of strings: extra
        command-line arguments to prepend/append to the compiler command
        line.  On other platforms, consult the implementation class
        documentation.  In any event, they are intended as an escape hatch
        for those occasions when the abstract compiler framework doesn't
        cut the mustard.

        'depends', if given, is a list of filenames that all targets
        depend on.  If a source file is older than any file in
        depends, then the source file will be recompiled.  This
        supports dependency tracking, but only at a coarse
        granularity.

        Raises CompileError on failure.
        _compileCompile 'src' to product 'obj'.create_static_liboutput_libnametarget_langLink a bunch of stuff together to create a static library file.
        The "bunch of stuff" consists of the list of object files supplied
        as 'objects', the extra object files supplied to
        'add_link_object()' and/or 'set_link_objects()', the libraries
        supplied to 'add_library()' and/or 'set_libraries()', and the
        libraries supplied as 'libraries' (if any).

        'output_libname' should be a library name, not a filename; the
        filename will be inferred from the library name.  'output_dir' is
        the directory where the library file will be put.

        'debug' is a boolean; if true, debugging information will be
        included in the library (note that on most platforms, it is the
        compile step where this matters: the 'debug' flag is included here
        just for consistency).

        'target_lang' is the target language for which the given objects
        are being compiled. This allows specific linkage time treatment of
        certain languages.

        Raises LibError on failure.
        shared_objectSHARED_OBJECTshared_librarySHARED_LIBRARYEXECUTABLEtarget_descoutput_filenameexport_symbolsbuild_tempLink a bunch of stuff together to create an executable or
        shared library file.

        The "bunch of stuff" consists of the list of object files supplied
        as 'objects'.  'output_filename' should be a filename.  If
        'output_dir' is supplied, 'output_filename' is relative to it
        (i.e. 'output_filename' can provide directory components if
        needed).

        'libraries' is a list of libraries to link against.  These are
        library names, not filenames, since they're translated into
        filenames in a platform-specific way (eg. "foo" becomes "libfoo.a"
        on Unix and "foo.lib" on DOS/Windows).  However, they can include a
        directory component, which means the linker will look in that
        specific directory rather than searching all the normal locations.

        'library_dirs', if supplied, should be a list of directories to
        search for libraries that were specified as bare library names
        (ie. no directory component).  These are on top of the system
        default and those supplied to 'add_library_dir()' and/or
        'set_library_dirs()'.  'runtime_library_dirs' is a list of
        directories that will be embedded into the shared library and used
        to search for other shared libraries that *it* depends on at
        run-time.  (This may only be relevant on Unix.)

        'export_symbols' is a list of symbols that the shared library will
        export.  (This appears to be relevant only on Windows.)

        'debug' is as for 'compile()' and 'create_static_lib()', with the
        slight distinction that it actually matters on most platforms (as
        opposed to 'create_static_lib()', which includes a 'debug' flag
        mostly for form's sake).

        'extra_preargs' and 'extra_postargs' are as for 'compile()' (except
        of course that they supply command-line arguments for the
        particular linker being used).

        'target_lang' is the target language for which the given objects
        are being compiled. This allows specific linkage time treatment of
        certain languages.

        Raises LinkError on failure.
        link_shared_liblibrary_filenamelib_typelink_shared_objectlink_executableoutput_prognameexecutable_filenamelibrary_dir_optionReturn the compiler option to add 'dir' to the list of
        directories searched for libraries.
        runtime_library_dir_optionReturn the compiler option to add 'dir' to the list of
        directories searched for runtime libraries.
        library_optionReturn the compiler option to add 'lib' to the list of libraries
        linked into the shared library or executable.
        has_functionReturn a boolean indicating whether funcname is supported on
        the current platform.  The optional arguments can be used to
        augment the compilation environment.
        fnamefdopenincl#include "%s"
int main (int argc, char **argv) {
    %s();
    return 0;
}
CompileErrora.outLinkErrorfind_library_fileSearch the specified list of directories for a static or shared
        library file 'lib' and return the full path to that file.  If
        'debug' true, look for a debugging version (if that makes sense on
        the current platform).  Return None if 'lib' wasn't found in any of
        the specified directories.
        source_filenamesobj_namessrc_namesplitdriveUnknownFileErrorunknown file type '%s' (from '%s')shared_object_filenamestaticdylibxcode_stub'lib_type' must be "static", "shared", "dylib", or "xcode_stub"_lib_format_lib_extensionannouncedebug_printdistutils.debugwarning: %s
0o777cygwin.*unix_default_compilersget_default_compilerDetermine the default compiler to use for the given platform.

       osname should be one of the standard Python OS names (i.e. the
       ones returned by os.name) and platform the common value
       returned by sys.platform for the platform in question.

       The default values are os.name and sys.platform in case the
       parameters are not given.
    unixccompilerUnixCCompilerstandard UNIX-style compiler_msvccompilerMSVCCompilerMicrosoft Visual C++cygwinccompilerCygwinCCompilerCygwin port of GNU C Compiler for Win32Mingw32CCompilerMingw32 port of GNU C Compiler for Win32mingw32bcppcompilerBCPPCompilerBorland C++ Compilerbcppcompiler_classshow_compilersPrint list of available compilers (used by the "--help-compiler"
    options to "build", "build_ext", "build_clib").
    distutils.fancy_getoptFancyGetoptcompilerscompiler=pretty_printerList of available compilers:platGenerate an instance of some CCompiler subclass for the supplied
    platform/compiler combination.  'plat' defaults to 'os.name'
    (eg. 'posix', 'nt'), and 'compiler' defaults to the default compiler
    for that platform.  Currently only 'posix' and 'nt' are supported, and
    the default compilers are "traditional Unix interface" (UnixCCompiler
    class) and Visual C++ (MSVCCompiler class).  Note that it's perfectly
    possible to ask for a Unix compiler object under Windows, and a
    Microsoft compiler object under Unix -- if you supply a value for
    'compiler', 'plat' is ignored.
    long_descriptiondon't know how to compile C/C++ code on platform '%s' with '%s' compilerdistutils.DistutilsModuleErrorcan't compile C/C++ code: unable to load module '%s'can't compile C/C++ code: unable to find class '%s' in module '%s'"can't compile C/C++ code: unable to find class '%s' ""in module '%s'"Generate C pre-processor options (-D, -U, -I) as used by at least
    two types of compilers: the typical Unix compiler and Visual C++.
    'macros' is the usual thing, a list of 1- or 2-tuples, where (name,)
    means undefine (-U) macro 'name', and (name,value) means define (-D)
    macro 'name' to 'value'.  'include_dirs' is just a list of directory
    names to be added to the header file search path (-I).  Returns a list
    of command-line options suitable for either Unix compilers or Visual
    C++.
    macrobad macro definition '%s': each element of 'macros' list must be a 1- or 2-tuple"bad macro definition '%s': ""each element of 'macros' list must be a 1- or 2-tuple"-U%s-D%s-D%s=%s-I%sgen_lib_optionsGenerate linker options for searching library directories and
    linking with specific libraries.  'libraries' and 'library_dirs' are,
    respectively, lists of library names (not filenames!) and search
    directories.  Returns a list of command-line options suitable for use
    with some compiler (depending on the two format strings passed in).
    lib_optslib_dirlib_namelib_fileno library file corresponding to '%s' found (skipping)"no library file corresponding to ""'%s' found (skipping)"# 'compiler_type' is a class attribute that identifies this class.  It# keeps code that wants to know what kind of compiler it's dealing with# from having to import all possible compiler classes just to do an# 'isinstance'.  In concrete CCompiler subclasses, 'compiler_type'# should really, really be one of the keys of the 'compiler_class'# dictionary (see below -- used by the 'new_compiler()' factory# function) -- authors of new compiler interface classes are# responsible for updating 'compiler_class'!# XXX things not handled by this compiler abstraction model:#   * client can't provide additional options for a compiler,#     e.g. warning, optimization, debugging flags.  Perhaps this#     should be the domain of concrete compiler abstraction classes#     (UnixCCompiler, MSVCCompiler, etc.) -- or perhaps the base#     class should have methods for the common ones.#   * can't completely override the include or library searchg#     path, ie. no "cc -I -Idir1 -Idir2" or "cc -L -Ldir1 -Ldir2".#     I'm not sure how widely supported this is even by Unix#     compilers, much less on other platforms.  And I'm even less#     sure how useful it is; maybe for cross-compiling, but#     support for that is a ways off.  (And anyways, cross#     compilers probably have a dedicated binary with the#     right paths compiled in.  I hope.)#   * can't do really freaky things with the library list/library#     dirs, e.g. "-Ldir1 -lfoo -Ldir2 -lfoo" to link against#     different versions of libfoo.a in different locations.  I#     think this is useless without the ability to null out the#     library search path anyways.# Subclasses that rely on the standard filename generation methods# implemented below should override these; see the comment near# those methods ('object_filenames()' et. al.) for details:# list of strings# string# format string# prob. same as static_lib_format# Default language settings. language_map is used to detect a source# file or Extension target language, checking source filenames.# language_order is used to detect the language precedence, when deciding# what language to use when mixing source types. For example, if some# extension has two files with ".c" extension, and one with ".cpp", it# is still linked as c++.# 'output_dir': a common output directory for object, library,# shared object, and shared library files# 'macros': a list of macro definitions (or undefinitions).  A# macro definition is a 2-tuple (name, value), where the value is# either a string or None (no explicit value).  A macro# undefinition is a 1-tuple (name,).# 'include_dirs': a list of directories to search for include files# 'libraries': a list of libraries to include in any link# (library names, not filenames: eg. "foo" not "libfoo.a")# 'library_dirs': a list of directories to search for libraries# 'runtime_library_dirs': a list of directories to search for# shared libraries/objects at runtime# 'objects': a list of object files (or similar, such as explicitly# named library files) to include on any link# Note that some CCompiler implementation classes will define class# attributes 'cpp', 'cc', etc. with hard-coded executable names;# this is appropriate when a compiler class is for exactly one# compiler/OS combination (eg. MSVCCompiler).  Other compiler# classes (UnixCCompiler, in particular) are driven by information# discovered at run-time, since there are many different ways to do# basically the same things with Unix C compilers.# -- Bookkeeping methods -------------------------------------------# Delete from the list of macro definitions/undefinitions if# already there (so that this one will take precedence).# -- Private utility methods --------------------------------------# (here for the convenience of subclasses)# Helper method to prep compiler in subclass compile() methods# Get the list of expected output (object) files# works for unixccompiler, cygwinccompiler# Return an empty dict for the "which source files can be skipped"# return value to preserve API compatibility.# -- Worker methods ------------------------------------------------# (must be implemented by subclasses)# A concrete compiler class can either override this method# entirely or implement _compile().# Return *all* object filenames, not just the ones we just built.# A concrete compiler class that does not override compile()# should implement _compile().# values for target_desc parameter in link()# Old 'link_*()' methods, rewritten to use the new 'link()' method.# -- Miscellaneous methods -----------------------------------------# These are all used by the 'gen_lib_options() function; there is# no appropriate default implementation so subclasses should# implement all of these.# this can't be included at module scope because it tries to# import math which might not be available at that point - maybe# the necessary logic should just be inlined?# -- Filename generation methods -----------------------------------# The default implementation of the filename generating methods are# prejudiced towards the Unix/DOS/Windows view of the world:#   * object files are named by replacing the source file extension#     (eg. .c/.cpp -> .o/.obj)#   * library files (shared or static) are named by plugging the#     library name and extension into a format string, eg.#     "lib%s.%s" % (lib_name, ".a") for Unix static libraries#   * executables are named by appending an extension (possibly#     empty) to the program name: eg. progname + ".exe" for#     Windows# To reduce redundant code, these methods expect to find# several attributes in the current object (presumably defined# as class attributes):#   * src_extensions -#     list of C/C++ source file extensions, eg. ['.c', '.cpp']#   * obj_extension -#     object file extension, eg. '.o' or '.obj'#   * static_lib_extension -#     extension for static library files, eg. '.a' or '.lib'#   * shared_lib_extension -#     extension for shared library/object files, eg. '.so', '.dll'#   * static_lib_format -#     format string for generating static library filenames,#     eg. 'lib%s.%s' or '%s.%s'#   * shared_lib_format#     format string for generating shared library filenames#     (probably same as static_lib_format, since the extension#     is one of the intended parameters to the format string)#   * exe_extension -#     extension for executable files, eg. '' or '.exe'# Chop off the drive# If abs, chop off leading /# or 'shared'# -- Utility methods -----------------------------------------------# Map a sys.platform/os.name ('posix', 'nt') to the default compiler# type for that platform. Keys are interpreted as re match# patterns. Order is important; platform mappings are preferred over# OS names.# Platform string mappings# on a cygwin built python we can use gcc like an ordinary UNIXish# compiler# OS name mappings# Default to Unix compiler# Map compiler types to (module_name, class_name) pairs -- ie. where to# find the code that implements an interface to this compiler.  (The module# is assumed to be in the 'distutils' package.)# XXX this "knows" that the compiler option it's describing is# "--compiler", which just happens to be the case for the three# commands that use it.# XXX The None is necessary to preserve backwards compatibility# with classes that expect verbose to be the first positional# argument.# XXX it would be nice (mainly aesthetic, and so we don't generate# stupid-looking command lines) to go over 'macros' and eliminate# redundant definitions/undefinitions (ie. ensure that only the# latest mention of a particular macro winds up on the command# line).  I don't think it's essential, though, since most (all?)# Unix C compilers only pay attention to the latest -D or -U# mention of a macro on their command line.  Similar situation for# 'include_dirs'.  I'm punting on both for now.  Anyways, weeding out# redundancies like this should probably be the province of# CCompiler, since the data structures used are inherited from it# and therefore common to all CCompiler classes.# undefine this macro# define with no explicit value# XXX *don't* need to be clever about quoting the# macro value here, because we're going to avoid the# shell at all costs when we spawn the command!# XXX it's important that we *not* remove redundant library mentions!# sometimes you really do have to say "-lfoo -lbar -lfoo" in order to# resolve all symbols.  I just hope we never have to say "-lfoo obj.o# -lbar" to get things to work -- that's certainly a possibility, but a# pretty nasty way to arrange your C code.b'distutils.ccompiler

Contains CCompiler, an abstract base class that defines the interface
for the Distutils compiler abstraction model.'u'distutils.ccompiler

Contains CCompiler, an abstract base class that defines the interface
for the Distutils compiler abstraction model.'b'Abstract base class to define the interface that must be implemented
    by real compiler classes.  Also has some utility methods used by
    several compiler classes.

    The basic idea behind a compiler abstraction class is that each
    instance can be used for all the compile/link steps in building a
    single project.  Thus, attributes common to all of those compile and
    link steps -- include directories, macros to define, libraries to link
    against, etc. -- are attributes of the compiler instance.  To allow for
    variability in how individual files are treated, most of those
    attributes may be varied on a per-compilation or per-link basis.
    'u'Abstract base class to define the interface that must be implemented
    by real compiler classes.  Also has some utility methods used by
    several compiler classes.

    The basic idea behind a compiler abstraction class is that each
    instance can be used for all the compile/link steps in building a
    single project.  Thus, attributes common to all of those compile and
    link steps -- include directories, macros to define, libraries to link
    against, etc. -- are attributes of the compiler instance.  To allow for
    variability in how individual files are treated, most of those
    attributes may be varied on a per-compilation or per-link basis.
    'b'.c'u'.c'b'c++'u'c++'b'.cc'u'.cc'b'.cpp'u'.cpp'b'.cxx'u'.cxx'b'objc'u'objc'b'.m'u'.m'b'Define the executables (and options for them) that will be run
        to perform the various stages of compilation.  The exact set of
        executables that may be specified here depends on the compiler
        class (via the 'executables' class attribute), but most will have:
          compiler      the C/C++ compiler
          linker_so     linker used to create shared objects and libraries
          linker_exe    linker used to create binary executables
          archiver      static library creator

        On platforms with a command-line (Unix, DOS/Windows), each of these
        is a string that will be split into executable name and (optional)
        list of arguments.  (Splitting the string is done similarly to how
        Unix shells operate: words are delimited by spaces, but quotes and
        backslashes can override this.  See
        'distutils.util.split_quoted()'.)
        'u'Define the executables (and options for them) that will be run
        to perform the various stages of compilation.  The exact set of
        executables that may be specified here depends on the compiler
        class (via the 'executables' class attribute), but most will have:
          compiler      the C/C++ compiler
          linker_so     linker used to create shared objects and libraries
          linker_exe    linker used to create binary executables
          archiver      static library creator

        On platforms with a command-line (Unix, DOS/Windows), each of these
        is a string that will be split into executable name and (optional)
        list of arguments.  (Splitting the string is done similarly to how
        Unix shells operate: words are delimited by spaces, but quotes and
        backslashes can override this.  See
        'distutils.util.split_quoted()'.)
        'b'unknown executable '%s' for class %s'u'unknown executable '%s' for class %s'b'Ensures that every element of 'definitions' is a valid macro
        definition, ie. either (name,value) 2-tuple or a (name,) tuple.  Do
        nothing if all definitions are OK, raise TypeError otherwise.
        'u'Ensures that every element of 'definitions' is a valid macro
        definition, ie. either (name,value) 2-tuple or a (name,) tuple.  Do
        nothing if all definitions are OK, raise TypeError otherwise.
        'b'invalid macro definition '%s': 'u'invalid macro definition '%s': 'b'must be tuple (string,), (string, string), or 'u'must be tuple (string,), (string, string), or 'b'(string, None)'u'(string, None)'b'Define a preprocessor macro for all compilations driven by this
        compiler object.  The optional parameter 'value' should be a
        string; if it is not supplied, then the macro will be defined
        without an explicit value and the exact outcome depends on the
        compiler used (XXX true? does ANSI say anything about this?)
        'u'Define a preprocessor macro for all compilations driven by this
        compiler object.  The optional parameter 'value' should be a
        string; if it is not supplied, then the macro will be defined
        without an explicit value and the exact outcome depends on the
        compiler used (XXX true? does ANSI say anything about this?)
        'b'Undefine a preprocessor macro for all compilations driven by
        this compiler object.  If the same macro is defined by
        'define_macro()' and undefined by 'undefine_macro()' the last call
        takes precedence (including multiple redefinitions or
        undefinitions).  If the macro is redefined/undefined on a
        per-compilation basis (ie. in the call to 'compile()'), then that
        takes precedence.
        'u'Undefine a preprocessor macro for all compilations driven by
        this compiler object.  If the same macro is defined by
        'define_macro()' and undefined by 'undefine_macro()' the last call
        takes precedence (including multiple redefinitions or
        undefinitions).  If the macro is redefined/undefined on a
        per-compilation basis (ie. in the call to 'compile()'), then that
        takes precedence.
        'b'Add 'dir' to the list of directories that will be searched for
        header files.  The compiler is instructed to search directories in
        the order in which they are supplied by successive calls to
        'add_include_dir()'.
        'u'Add 'dir' to the list of directories that will be searched for
        header files.  The compiler is instructed to search directories in
        the order in which they are supplied by successive calls to
        'add_include_dir()'.
        'b'Set the list of directories that will be searched to 'dirs' (a
        list of strings).  Overrides any preceding calls to
        'add_include_dir()'; subsequence calls to 'add_include_dir()' add
        to the list passed to 'set_include_dirs()'.  This does not affect
        any list of standard include directories that the compiler may
        search by default.
        'u'Set the list of directories that will be searched to 'dirs' (a
        list of strings).  Overrides any preceding calls to
        'add_include_dir()'; subsequence calls to 'add_include_dir()' add
        to the list passed to 'set_include_dirs()'.  This does not affect
        any list of standard include directories that the compiler may
        search by default.
        'b'Add 'libname' to the list of libraries that will be included in
        all links driven by this compiler object.  Note that 'libname'
        should *not* be the name of a file containing a library, but the
        name of the library itself: the actual filename will be inferred by
        the linker, the compiler, or the compiler class (depending on the
        platform).

        The linker will be instructed to link against libraries in the
        order they were supplied to 'add_library()' and/or
        'set_libraries()'.  It is perfectly valid to duplicate library
        names; the linker will be instructed to link against libraries as
        many times as they are mentioned.
        'u'Add 'libname' to the list of libraries that will be included in
        all links driven by this compiler object.  Note that 'libname'
        should *not* be the name of a file containing a library, but the
        name of the library itself: the actual filename will be inferred by
        the linker, the compiler, or the compiler class (depending on the
        platform).

        The linker will be instructed to link against libraries in the
        order they were supplied to 'add_library()' and/or
        'set_libraries()'.  It is perfectly valid to duplicate library
        names; the linker will be instructed to link against libraries as
        many times as they are mentioned.
        'b'Set the list of libraries to be included in all links driven by
        this compiler object to 'libnames' (a list of strings).  This does
        not affect any standard system libraries that the linker may
        include by default.
        'u'Set the list of libraries to be included in all links driven by
        this compiler object to 'libnames' (a list of strings).  This does
        not affect any standard system libraries that the linker may
        include by default.
        'b'Add 'dir' to the list of directories that will be searched for
        libraries specified to 'add_library()' and 'set_libraries()'.  The
        linker will be instructed to search for libraries in the order they
        are supplied to 'add_library_dir()' and/or 'set_library_dirs()'.
        'u'Add 'dir' to the list of directories that will be searched for
        libraries specified to 'add_library()' and 'set_libraries()'.  The
        linker will be instructed to search for libraries in the order they
        are supplied to 'add_library_dir()' and/or 'set_library_dirs()'.
        'b'Set the list of library search directories to 'dirs' (a list of
        strings).  This does not affect any standard library search path
        that the linker may search by default.
        'u'Set the list of library search directories to 'dirs' (a list of
        strings).  This does not affect any standard library search path
        that the linker may search by default.
        'b'Add 'dir' to the list of directories that will be searched for
        shared libraries at runtime.
        'u'Add 'dir' to the list of directories that will be searched for
        shared libraries at runtime.
        'b'Set the list of directories to search for shared libraries at
        runtime to 'dirs' (a list of strings).  This does not affect any
        standard search path that the runtime linker may search by
        default.
        'u'Set the list of directories to search for shared libraries at
        runtime to 'dirs' (a list of strings).  This does not affect any
        standard search path that the runtime linker may search by
        default.
        'b'Add 'object' to the list of object files (or analogues, such as
        explicitly named library files or the output of "resource
        compilers") to be included in every link driven by this compiler
        object.
        'u'Add 'object' to the list of object files (or analogues, such as
        explicitly named library files or the output of "resource
        compilers") to be included in every link driven by this compiler
        object.
        'b'Set the list of object files (or analogues) to be included in
        every link to 'objects'.  This does not affect any standard object
        files that the linker may include by default (such as system
        libraries).
        'u'Set the list of object files (or analogues) to be included in
        every link to 'objects'.  This does not affect any standard object
        files that the linker may include by default (such as system
        libraries).
        'b'Process arguments and decide which source files to compile.'u'Process arguments and decide which source files to compile.'b''output_dir' must be a string or None'u''output_dir' must be a string or None'b''macros' (if supplied) must be a list of tuples'u''macros' (if supplied) must be a list of tuples'b''include_dirs' (if supplied) must be a list of strings'u''include_dirs' (if supplied) must be a list of strings'b'-g'u'-g'b'Typecheck and fix-up some of the arguments to the 'compile()'
        method, and return fixed-up values.  Specifically: if 'output_dir'
        is None, replaces it with 'self.output_dir'; ensures that 'macros'
        is a list, and augments it with 'self.macros'; ensures that
        'include_dirs' is a list, and augments it with 'self.include_dirs'.
        Guarantees that the returned values are of the correct type,
        i.e. for 'output_dir' either string or None, and for 'macros' and
        'include_dirs' either list or None.
        'u'Typecheck and fix-up some of the arguments to the 'compile()'
        method, and return fixed-up values.  Specifically: if 'output_dir'
        is None, replaces it with 'self.output_dir'; ensures that 'macros'
        is a list, and augments it with 'self.macros'; ensures that
        'include_dirs' is a list, and augments it with 'self.include_dirs'.
        Guarantees that the returned values are of the correct type,
        i.e. for 'output_dir' either string or None, and for 'macros' and
        'include_dirs' either list or None.
        'b'Decide which source files must be recompiled.

        Determine the list of object files corresponding to 'sources',
        and figure out which ones really need to be recompiled.
        Return a list of all object files and a dictionary telling
        which source files can be skipped.
        'u'Decide which source files must be recompiled.

        Determine the list of object files corresponding to 'sources',
        and figure out which ones really need to be recompiled.
        Return a list of all object files and a dictionary telling
        which source files can be skipped.
        'b'Typecheck and fix up some arguments supplied to various methods.
        Specifically: ensure that 'objects' is a list; if output_dir is
        None, replace with self.output_dir.  Return fixed versions of
        'objects' and 'output_dir'.
        'u'Typecheck and fix up some arguments supplied to various methods.
        Specifically: ensure that 'objects' is a list; if output_dir is
        None, replace with self.output_dir.  Return fixed versions of
        'objects' and 'output_dir'.
        'b''objects' must be a list or tuple of strings'u''objects' must be a list or tuple of strings'b'Typecheck and fix up some of the arguments supplied to the
        'link_*' methods.  Specifically: ensure that all arguments are
        lists, and augment them with their permanent versions
        (eg. 'self.libraries' augments 'libraries').  Return a tuple with
        fixed versions of all arguments.
        'u'Typecheck and fix up some of the arguments supplied to the
        'link_*' methods.  Specifically: ensure that all arguments are
        lists, and augment them with their permanent versions
        (eg. 'self.libraries' augments 'libraries').  Return a tuple with
        fixed versions of all arguments.
        'b''libraries' (if supplied) must be a list of strings'u''libraries' (if supplied) must be a list of strings'b''library_dirs' (if supplied) must be a list of strings'u''library_dirs' (if supplied) must be a list of strings'b''runtime_library_dirs' (if supplied) must be a list of strings'u''runtime_library_dirs' (if supplied) must be a list of strings'b'Return true if we need to relink the files listed in 'objects'
        to recreate 'output_file'.
        'u'Return true if we need to relink the files listed in 'objects'
        to recreate 'output_file'.
        'b'newer'u'newer'b'Detect the language of a given file, or list of files. Uses
        language_map, and language_order to do the job.
        'u'Detect the language of a given file, or list of files. Uses
        language_map, and language_order to do the job.
        'b'Preprocess a single C/C++ source file, named in 'source'.
        Output will be written to file named 'output_file', or stdout if
        'output_file' not supplied.  'macros' is a list of macro
        definitions as for 'compile()', which will augment the macros set
        with 'define_macro()' and 'undefine_macro()'.  'include_dirs' is a
        list of directory names that will be added to the default list.

        Raises PreprocessError on failure.
        'u'Preprocess a single C/C++ source file, named in 'source'.
        Output will be written to file named 'output_file', or stdout if
        'output_file' not supplied.  'macros' is a list of macro
        definitions as for 'compile()', which will augment the macros set
        with 'define_macro()' and 'undefine_macro()'.  'include_dirs' is a
        list of directory names that will be added to the default list.

        Raises PreprocessError on failure.
        'b'Compile one or more source files.

        'sources' must be a list of filenames, most likely C/C++
        files, but in reality anything that can be handled by a
        particular compiler and compiler class (eg. MSVCCompiler can
        handle resource files in 'sources').  Return a list of object
        filenames, one per source filename in 'sources'.  Depending on
        the implementation, not all source files will necessarily be
        compiled, but all corresponding object filenames will be
        returned.

        If 'output_dir' is given, object files will be put under it, while
        retaining their original path component.  That is, "foo/bar.c"
        normally compiles to "foo/bar.o" (for a Unix implementation); if
        'output_dir' is "build", then it would compile to
        "build/foo/bar.o".

        'macros', if given, must be a list of macro definitions.  A macro
        definition is either a (name, value) 2-tuple or a (name,) 1-tuple.
        The former defines a macro; if the value is None, the macro is
        defined without an explicit value.  The 1-tuple case undefines a
        macro.  Later definitions/redefinitions/ undefinitions take
        precedence.

        'include_dirs', if given, must be a list of strings, the
        directories to add to the default include file search path for this
        compilation only.

        'debug' is a boolean; if true, the compiler will be instructed to
        output debug symbols in (or alongside) the object file(s).

        'extra_preargs' and 'extra_postargs' are implementation- dependent.
        On platforms that have the notion of a command-line (e.g. Unix,
        DOS/Windows), they are most likely lists of strings: extra
        command-line arguments to prepend/append to the compiler command
        line.  On other platforms, consult the implementation class
        documentation.  In any event, they are intended as an escape hatch
        for those occasions when the abstract compiler framework doesn't
        cut the mustard.

        'depends', if given, is a list of filenames that all targets
        depend on.  If a source file is older than any file in
        depends, then the source file will be recompiled.  This
        supports dependency tracking, but only at a coarse
        granularity.

        Raises CompileError on failure.
        'u'Compile one or more source files.

        'sources' must be a list of filenames, most likely C/C++
        files, but in reality anything that can be handled by a
        particular compiler and compiler class (eg. MSVCCompiler can
        handle resource files in 'sources').  Return a list of object
        filenames, one per source filename in 'sources'.  Depending on
        the implementation, not all source files will necessarily be
        compiled, but all corresponding object filenames will be
        returned.

        If 'output_dir' is given, object files will be put under it, while
        retaining their original path component.  That is, "foo/bar.c"
        normally compiles to "foo/bar.o" (for a Unix implementation); if
        'output_dir' is "build", then it would compile to
        "build/foo/bar.o".

        'macros', if given, must be a list of macro definitions.  A macro
        definition is either a (name, value) 2-tuple or a (name,) 1-tuple.
        The former defines a macro; if the value is None, the macro is
        defined without an explicit value.  The 1-tuple case undefines a
        macro.  Later definitions/redefinitions/ undefinitions take
        precedence.

        'include_dirs', if given, must be a list of strings, the
        directories to add to the default include file search path for this
        compilation only.

        'debug' is a boolean; if true, the compiler will be instructed to
        output debug symbols in (or alongside) the object file(s).

        'extra_preargs' and 'extra_postargs' are implementation- dependent.
        On platforms that have the notion of a command-line (e.g. Unix,
        DOS/Windows), they are most likely lists of strings: extra
        command-line arguments to prepend/append to the compiler command
        line.  On other platforms, consult the implementation class
        documentation.  In any event, they are intended as an escape hatch
        for those occasions when the abstract compiler framework doesn't
        cut the mustard.

        'depends', if given, is a list of filenames that all targets
        depend on.  If a source file is older than any file in
        depends, then the source file will be recompiled.  This
        supports dependency tracking, but only at a coarse
        granularity.

        Raises CompileError on failure.
        'b'Compile 'src' to product 'obj'.'u'Compile 'src' to product 'obj'.'b'Link a bunch of stuff together to create a static library file.
        The "bunch of stuff" consists of the list of object files supplied
        as 'objects', the extra object files supplied to
        'add_link_object()' and/or 'set_link_objects()', the libraries
        supplied to 'add_library()' and/or 'set_libraries()', and the
        libraries supplied as 'libraries' (if any).

        'output_libname' should be a library name, not a filename; the
        filename will be inferred from the library name.  'output_dir' is
        the directory where the library file will be put.

        'debug' is a boolean; if true, debugging information will be
        included in the library (note that on most platforms, it is the
        compile step where this matters: the 'debug' flag is included here
        just for consistency).

        'target_lang' is the target language for which the given objects
        are being compiled. This allows specific linkage time treatment of
        certain languages.

        Raises LibError on failure.
        'u'Link a bunch of stuff together to create a static library file.
        The "bunch of stuff" consists of the list of object files supplied
        as 'objects', the extra object files supplied to
        'add_link_object()' and/or 'set_link_objects()', the libraries
        supplied to 'add_library()' and/or 'set_libraries()', and the
        libraries supplied as 'libraries' (if any).

        'output_libname' should be a library name, not a filename; the
        filename will be inferred from the library name.  'output_dir' is
        the directory where the library file will be put.

        'debug' is a boolean; if true, debugging information will be
        included in the library (note that on most platforms, it is the
        compile step where this matters: the 'debug' flag is included here
        just for consistency).

        'target_lang' is the target language for which the given objects
        are being compiled. This allows specific linkage time treatment of
        certain languages.

        Raises LibError on failure.
        'b'shared_object'u'shared_object'b'shared_library'u'shared_library'b'executable'u'executable'b'Link a bunch of stuff together to create an executable or
        shared library file.

        The "bunch of stuff" consists of the list of object files supplied
        as 'objects'.  'output_filename' should be a filename.  If
        'output_dir' is supplied, 'output_filename' is relative to it
        (i.e. 'output_filename' can provide directory components if
        needed).

        'libraries' is a list of libraries to link against.  These are
        library names, not filenames, since they're translated into
        filenames in a platform-specific way (eg. "foo" becomes "libfoo.a"
        on Unix and "foo.lib" on DOS/Windows).  However, they can include a
        directory component, which means the linker will look in that
        specific directory rather than searching all the normal locations.

        'library_dirs', if supplied, should be a list of directories to
        search for libraries that were specified as bare library names
        (ie. no directory component).  These are on top of the system
        default and those supplied to 'add_library_dir()' and/or
        'set_library_dirs()'.  'runtime_library_dirs' is a list of
        directories that will be embedded into the shared library and used
        to search for other shared libraries that *it* depends on at
        run-time.  (This may only be relevant on Unix.)

        'export_symbols' is a list of symbols that the shared library will
        export.  (This appears to be relevant only on Windows.)

        'debug' is as for 'compile()' and 'create_static_lib()', with the
        slight distinction that it actually matters on most platforms (as
        opposed to 'create_static_lib()', which includes a 'debug' flag
        mostly for form's sake).

        'extra_preargs' and 'extra_postargs' are as for 'compile()' (except
        of course that they supply command-line arguments for the
        particular linker being used).

        'target_lang' is the target language for which the given objects
        are being compiled. This allows specific linkage time treatment of
        certain languages.

        Raises LinkError on failure.
        'u'Link a bunch of stuff together to create an executable or
        shared library file.

        The "bunch of stuff" consists of the list of object files supplied
        as 'objects'.  'output_filename' should be a filename.  If
        'output_dir' is supplied, 'output_filename' is relative to it
        (i.e. 'output_filename' can provide directory components if
        needed).

        'libraries' is a list of libraries to link against.  These are
        library names, not filenames, since they're translated into
        filenames in a platform-specific way (eg. "foo" becomes "libfoo.a"
        on Unix and "foo.lib" on DOS/Windows).  However, they can include a
        directory component, which means the linker will look in that
        specific directory rather than searching all the normal locations.

        'library_dirs', if supplied, should be a list of directories to
        search for libraries that were specified as bare library names
        (ie. no directory component).  These are on top of the system
        default and those supplied to 'add_library_dir()' and/or
        'set_library_dirs()'.  'runtime_library_dirs' is a list of
        directories that will be embedded into the shared library and used
        to search for other shared libraries that *it* depends on at
        run-time.  (This may only be relevant on Unix.)

        'export_symbols' is a list of symbols that the shared library will
        export.  (This appears to be relevant only on Windows.)

        'debug' is as for 'compile()' and 'create_static_lib()', with the
        slight distinction that it actually matters on most platforms (as
        opposed to 'create_static_lib()', which includes a 'debug' flag
        mostly for form's sake).

        'extra_preargs' and 'extra_postargs' are as for 'compile()' (except
        of course that they supply command-line arguments for the
        particular linker being used).

        'target_lang' is the target language for which the given objects
        are being compiled. This allows specific linkage time treatment of
        certain languages.

        Raises LinkError on failure.
        'b'shared'u'shared'b'Return the compiler option to add 'dir' to the list of
        directories searched for libraries.
        'u'Return the compiler option to add 'dir' to the list of
        directories searched for libraries.
        'b'Return the compiler option to add 'dir' to the list of
        directories searched for runtime libraries.
        'u'Return the compiler option to add 'dir' to the list of
        directories searched for runtime libraries.
        'b'Return the compiler option to add 'lib' to the list of libraries
        linked into the shared library or executable.
        'u'Return the compiler option to add 'lib' to the list of libraries
        linked into the shared library or executable.
        'b'Return a boolean indicating whether funcname is supported on
        the current platform.  The optional arguments can be used to
        augment the compilation environment.
        'u'Return a boolean indicating whether funcname is supported on
        the current platform.  The optional arguments can be used to
        augment the compilation environment.
        'b'#include "%s"
'u'#include "%s"
'b'int main (int argc, char **argv) {
    %s();
    return 0;
}
'u'int main (int argc, char **argv) {
    %s();
    return 0;
}
'b'a.out'u'a.out'b'Search the specified list of directories for a static or shared
        library file 'lib' and return the full path to that file.  If
        'debug' true, look for a debugging version (if that makes sense on
        the current platform).  Return None if 'lib' wasn't found in any of
        the specified directories.
        'u'Search the specified list of directories for a static or shared
        library file 'lib' and return the full path to that file.  If
        'debug' true, look for a debugging version (if that makes sense on
        the current platform).  Return None if 'lib' wasn't found in any of
        the specified directories.
        'b'unknown file type '%s' (from '%s')'u'unknown file type '%s' (from '%s')'b'static'u'static'b'dylib'u'dylib'b'xcode_stub'u'xcode_stub'b''lib_type' must be "static", "shared", "dylib", or "xcode_stub"'u''lib_type' must be "static", "shared", "dylib", or "xcode_stub"'b'_lib_format'u'_lib_format'b'_lib_extension'u'_lib_extension'b'warning: %s
'u'warning: %s
'b'cygwin.*'u'cygwin.*'b'unix'u'unix'b'Determine the default compiler to use for the given platform.

       osname should be one of the standard Python OS names (i.e. the
       ones returned by os.name) and platform the common value
       returned by sys.platform for the platform in question.

       The default values are os.name and sys.platform in case the
       parameters are not given.
    'u'Determine the default compiler to use for the given platform.

       osname should be one of the standard Python OS names (i.e. the
       ones returned by os.name) and platform the common value
       returned by sys.platform for the platform in question.

       The default values are os.name and sys.platform in case the
       parameters are not given.
    'b'unixccompiler'u'unixccompiler'b'UnixCCompiler'u'UnixCCompiler'b'standard UNIX-style compiler'u'standard UNIX-style compiler'b'_msvccompiler'u'_msvccompiler'b'MSVCCompiler'u'MSVCCompiler'b'Microsoft Visual C++'u'Microsoft Visual C++'b'cygwinccompiler'u'cygwinccompiler'b'CygwinCCompiler'u'CygwinCCompiler'b'Cygwin port of GNU C Compiler for Win32'u'Cygwin port of GNU C Compiler for Win32'b'Mingw32CCompiler'u'Mingw32CCompiler'b'Mingw32 port of GNU C Compiler for Win32'u'Mingw32 port of GNU C Compiler for Win32'b'mingw32'u'mingw32'b'bcppcompiler'u'bcppcompiler'b'BCPPCompiler'u'BCPPCompiler'b'Borland C++ Compiler'u'Borland C++ Compiler'b'bcpp'u'bcpp'b'Print list of available compilers (used by the "--help-compiler"
    options to "build", "build_ext", "build_clib").
    'u'Print list of available compilers (used by the "--help-compiler"
    options to "build", "build_ext", "build_clib").
    'b'compiler='u'compiler='b'List of available compilers:'u'List of available compilers:'b'Generate an instance of some CCompiler subclass for the supplied
    platform/compiler combination.  'plat' defaults to 'os.name'
    (eg. 'posix', 'nt'), and 'compiler' defaults to the default compiler
    for that platform.  Currently only 'posix' and 'nt' are supported, and
    the default compilers are "traditional Unix interface" (UnixCCompiler
    class) and Visual C++ (MSVCCompiler class).  Note that it's perfectly
    possible to ask for a Unix compiler object under Windows, and a
    Microsoft compiler object under Unix -- if you supply a value for
    'compiler', 'plat' is ignored.
    'u'Generate an instance of some CCompiler subclass for the supplied
    platform/compiler combination.  'plat' defaults to 'os.name'
    (eg. 'posix', 'nt'), and 'compiler' defaults to the default compiler
    for that platform.  Currently only 'posix' and 'nt' are supported, and
    the default compilers are "traditional Unix interface" (UnixCCompiler
    class) and Visual C++ (MSVCCompiler class).  Note that it's perfectly
    possible to ask for a Unix compiler object under Windows, and a
    Microsoft compiler object under Unix -- if you supply a value for
    'compiler', 'plat' is ignored.
    'b'don't know how to compile C/C++ code on platform '%s''u'don't know how to compile C/C++ code on platform '%s''b' with '%s' compiler'u' with '%s' compiler'b'distutils.'u'distutils.'b'can't compile C/C++ code: unable to load module '%s''u'can't compile C/C++ code: unable to load module '%s''b'can't compile C/C++ code: unable to find class '%s' in module '%s''u'can't compile C/C++ code: unable to find class '%s' in module '%s''b'Generate C pre-processor options (-D, -U, -I) as used by at least
    two types of compilers: the typical Unix compiler and Visual C++.
    'macros' is the usual thing, a list of 1- or 2-tuples, where (name,)
    means undefine (-U) macro 'name', and (name,value) means define (-D)
    macro 'name' to 'value'.  'include_dirs' is just a list of directory
    names to be added to the header file search path (-I).  Returns a list
    of command-line options suitable for either Unix compilers or Visual
    C++.
    'u'Generate C pre-processor options (-D, -U, -I) as used by at least
    two types of compilers: the typical Unix compiler and Visual C++.
    'macros' is the usual thing, a list of 1- or 2-tuples, where (name,)
    means undefine (-U) macro 'name', and (name,value) means define (-D)
    macro 'name' to 'value'.  'include_dirs' is just a list of directory
    names to be added to the header file search path (-I).  Returns a list
    of command-line options suitable for either Unix compilers or Visual
    C++.
    'b'bad macro definition '%s': each element of 'macros' list must be a 1- or 2-tuple'u'bad macro definition '%s': each element of 'macros' list must be a 1- or 2-tuple'b'-U%s'u'-U%s'b'-D%s'u'-D%s'b'-D%s=%s'u'-D%s=%s'b'-I%s'u'-I%s'b'Generate linker options for searching library directories and
    linking with specific libraries.  'libraries' and 'library_dirs' are,
    respectively, lists of library names (not filenames!) and search
    directories.  Returns a list of command-line options suitable for use
    with some compiler (depending on the two format strings passed in).
    'u'Generate linker options for searching library directories and
    linking with specific libraries.  'libraries' and 'library_dirs' are,
    respectively, lists of library names (not filenames!) and search
    directories.  Returns a list of command-line options suitable for use
    with some compiler (depending on the two format strings passed in).
    'b'no library file corresponding to '%s' found (skipping)'u'no library file corresponding to '%s' found (skipping)'u'distutils.ccompiler'u'ccompiler'IncrementalDecoderlru_cacheTypeCounterassetsKO_NAMESLANGUAGE_SUPPORTED_COUNTZH_NAMESis_suspiciously_successive_rangeCoherenceMatchesis_accentuatedis_latinis_unicode_range_secondaryunicode_rangeencoding_unicode_range
    Return associated unicode ranges in a single byte code page.
    Function not supported on multi-byte code pageencodings.{}seen_rangescharacter_count0x400xFFcharacter_range0.15unicode_range_languagesprimary_range
    Return inferred languages used with a unicode range.
    languageslanguagecharacters
    Single-byte encoding language association. Some code page are heavily linked to particular language(s).
    This function does the correspondence.
    unicode_rangesspecified_rangeLatinLatin Based
    Multi-byte encoding language association. Some code page are heavily linked to particular language(s).
    This function does the correspondence.
    shift_euc_jgbget_target_features
    Determine main aspects from a supported language if it contains accents and if is pure Latin.
    target_have_accentstarget_pure_latinalphabet_languagesignore_non_latin
    Return associated languages associated to given characters.
    source_have_accentslanguage_characterscharacter_match_countratiocompatible_languagecharacters_popularity_compareordered_characters
    Determine if a ordered characters list (by occurrence from most appearance to rarest) match a particular language.
    The result is a ratio between 0. (absolutely no correspondence) and 1. (near perfect fit).
    Beware that is function is not strict on the match in order to ease the detection. (Meaning close match is 1.)
    {} not availablecharacter_approved_countFREQUENCIES_language_setordered_characters_counttarget_language_characters_countlarge_alphabetcharacter_rankcharacter_rank_in_languageexpected_projection_ratiocharacter_rank_projectioncharacters_before_sourcecharacters_after_sourcecharacters_beforecharacters_afterbefore_match_countafter_match_countalpha_unicode_splitdecoded_sequence
    Given a decoded text sequence, return a list of str. Unicode range / alphabet separation.
    Ex. a text containing English/Latin with a bit a Hebrew will return two items in the resulting list;
    One containing the latin letters and the other hebrew.
    layerslayer_target_rangediscovered_range
    This function merge results previously given by the function coherence_ratio.
    The return type is the same as coherence_ratio.
    per_language_ratiossub_resultmergefilter_alt_coherence_matches
    We shall NOT return "English" in CoherenceMatches because it is an alternative
    of "English". This function only keeps the best match and remove the em-dash in it.
    index_resultsno_em_namefiltered_resultslg_inclusion
    Detect ANY language that can be identified in given sequence. The sequence will be analysed by layers.
    A layer = Character extraction by alphabets/ranges.
    sufficient_match_countlg_inclusion_listlayersequence_frequenciespopular_character_orderedb'
    Return associated unicode ranges in a single byte code page.
    'u'
    Return associated unicode ranges in a single byte code page.
    'b'Function not supported on multi-byte code page'u'Function not supported on multi-byte code page'b'encodings.{}'u'encodings.{}'b'
    Return inferred languages used with a unicode range.
    'u'
    Return inferred languages used with a unicode range.
    'b'
    Single-byte encoding language association. Some code page are heavily linked to particular language(s).
    This function does the correspondence.
    'u'
    Single-byte encoding language association. Some code page are heavily linked to particular language(s).
    This function does the correspondence.
    'b'Latin'u'Latin'b'Latin Based'u'Latin Based'b'
    Multi-byte encoding language association. Some code page are heavily linked to particular language(s).
    This function does the correspondence.
    'u'
    Multi-byte encoding language association. Some code page are heavily linked to particular language(s).
    This function does the correspondence.
    'b'shift_'u'shift_'b'euc_j'u'euc_j'b'gb'u'gb'b'
    Determine main aspects from a supported language if it contains accents and if is pure Latin.
    'u'
    Determine main aspects from a supported language if it contains accents and if is pure Latin.
    'b'
    Return associated languages associated to given characters.
    'u'
    Return associated languages associated to given characters.
    'b'
    Determine if a ordered characters list (by occurrence from most appearance to rarest) match a particular language.
    The result is a ratio between 0. (absolutely no correspondence) and 1. (near perfect fit).
    Beware that is function is not strict on the match in order to ease the detection. (Meaning close match is 1.)
    'u'
    Determine if a ordered characters list (by occurrence from most appearance to rarest) match a particular language.
    The result is a ratio between 0. (absolutely no correspondence) and 1. (near perfect fit).
    Beware that is function is not strict on the match in order to ease the detection. (Meaning close match is 1.)
    'b'{} not available'u'{} not available'b'
    Given a decoded text sequence, return a list of str. Unicode range / alphabet separation.
    Ex. a text containing English/Latin with a bit a Hebrew will return two items in the resulting list;
    One containing the latin letters and the other hebrew.
    'u'
    Given a decoded text sequence, return a list of str. Unicode range / alphabet separation.
    Ex. a text containing English/Latin with a bit a Hebrew will return two items in the resulting list;
    One containing the latin letters and the other hebrew.
    'b'
    This function merge results previously given by the function coherence_ratio.
    The return type is the same as coherence_ratio.
    'u'
    This function merge results previously given by the function coherence_ratio.
    The return type is the same as coherence_ratio.
    'u'
    We shall NOT return "English" in CoherenceMatches because it is an alternative
    of "English". This function only keeps the best match and remove the em-dash in it.
    'b'
    Detect ANY language that can be identified in given sequence. The sequence will be analysed by layers.
    A layer = Character extraction by alphabets/ranges.
    'u'
    Detect ANY language that can be identified in given sequence. The sequence will be analysed by layers.
    A layer = Character extraction by alphabets/ranges.
    'u'charset_normalizer.cd'u'cd'
requests.certs
~~~~~~~~~~~~~~

This module returns the preferred default CA certificate bundle. There is
only one  the one from the certifi package.

If you are packaging Requests, e.g., for a Linux distribution or a managed
environment, you can change the definition of where() to return a separately
packaged CA bundle.
certifi#!/usr/bin/env pythonu'
requests.certs
~~~~~~~~~~~~~~

This module returns the preferred default CA certificate bundle. There is
only one  the one from the certifi package.

If you are packaging Requests, e.g., for a Linux distribution or a managed
environment, you can change the definition of where() to return a separately
packaged CA bundle.
'u'requests.certs'u'certs'Charsetadd_aliasadd_charsetadd_codecemail.base64mimeemail.quoprimimeemail.encodersencode_7or8bitQPBASE64SHORTESTRFC2047_CHROME_LENDEFAULT_CHARSETiso-8859-2iso-8859-3iso-8859-4iso-8859-9iso-8859-10iso-8859-13iso-8859-14iso-8859-15iso-8859-16windows-1252visciiiso-2022-jpeuc-jpkoi8-rCHARSETSlatin_2latin-2latin_3latin-3latin_4latin-4latin_5latin-5latin_6latin-6latin_7latin-7latin_8latin-8latin_9latin-9latin_10latin-10ks_c_5601-1987euc-krALIASESCODEC_MAPheader_encbody_encoutput_charsetAdd character set properties to the global registry.

    charset is the input character set, and must be the canonical name of a
    character set.

    Optional header_enc and body_enc is either charset.QP for
    quoted-printable, charset.BASE64 for base64 encoding, charset.SHORTEST for
    the shortest of qp or base64 encoding, or None for no encoding.  SHORTEST
    is only valid for header_enc.  It describes how message headers and
    message bodies in the input charset are to be encoded.  Default is no
    encoding.

    Optional output_charset is the character set that the output should be
    in.  Conversions will proceed from input charset, to Unicode, to the
    output charset when the method Charset.convert() is called.  The default
    is to output in the same character set as the input.

    Both input_charset and output_charset must have Unicode codec entries in
    the module's charset-to-codec mapping; use add_codec(charset, codecname)
    to add codecs the module does not know about.  See the codecs module's
    documentation for more information.
    SHORTEST not allowed for body_encAdd a character set alias.

    alias is the alias name, e.g. latin-1
    canonical is the character set's canonical name, e.g. iso-8859-1
    codecnameAdd a codec that map characters in the given charset to/from Unicode.

    charset is the canonical name of a character set.  codecname is the name
    of a Python codec, as appropriate for the second argument to the unicode()
    built-in, or to the encode() method of a Unicode string.
    _encodecodecMap character sets to their email properties.

    This class provides information about the requirements imposed on email
    for a specific character set.  It also provides convenience routines for
    converting between character sets, given the availability of the
    applicable codecs.  Given a character set, it will do its best to provide
    information on how to use that character set in an email in an
    RFC-compliant way.

    Certain character sets must be encoded with quoted-printable or base64
    when used in email headers or bodies.  Certain character sets must be
    converted outright, and are not allowed in email.  Instances of this
    module expose the following information about a character set:

    input_charset: The initial character set specified.  Common aliases
                   are converted to their `official' email names (e.g. latin_1
                   is converted to iso-8859-1).  Defaults to 7-bit us-ascii.

    header_encoding: If the character set must be encoded before it can be
                     used in an email header, this attribute will be set to
                     charset.QP (for quoted-printable), charset.BASE64 (for
                     base64 encoding), or charset.SHORTEST for the shortest of
                     QP or BASE64 encoding.  Otherwise, it will be None.

    body_encoding: Same as header_encoding, but describes the encoding for the
                   mail message's body, which indeed may be different than the
                   header encoding.  charset.SHORTEST is not allowed for
                   body_encoding.

    output_charset: Some character sets must be converted before they can be
                    used in email headers or bodies.  If the input_charset is
                    one of them, this attribute will contain the name of the
                    charset output will be converted to.  Otherwise, it will
                    be None.

    input_codec: The name of the Python codec used to convert the
                 input_charset to Unicode.  If no conversion codec is
                 necessary, this attribute will be None.

    output_codec: The name of the Python codec used to convert Unicode
                  to the output_charset.  If no conversion codec is necessary,
                  this attribute will have the same value as the input_codec.
    input_charsethencbencheader_encodingbody_encodinginput_codecoutput_codecget_body_encodingReturn the content-transfer-encoding used for body encoding.

        This is either the string `quoted-printable' or `base64' depending on
        the encoding used, or it is a function in which case you should call
        the function with a single argument, the Message object being
        encoded.  The function should then set the Content-Transfer-Encoding
        header itself to whatever is appropriate.

        Returns "quoted-printable" if self.body_encoding is QP.
        Returns "base64" if self.body_encoding is BASE64.
        Returns conversion function otherwise.
        quoted-printableget_output_charsetReturn the output character set.

        This is self.output_charset if that is not None, otherwise it is
        self.input_charset.
        Header-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        this charset's `header_encoding`.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :return: The encoded string, with RFC 2047 chrome.
        _get_encoderencoder_moduleheader_encode_linesmaxlengthsHeader-encode a string by converting it first to bytes.

        This is similar to `header_encode()` except that the string is fit
        into maximum line lengths as given by the argument.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :param maxlengths: Maximum line length iterator.  Each element
            returned from this iterator will provide the next maximum line
            length.  This parameter is used as an argument to built-in next()
            and should never be exhausted.  The maximum line lengths should
            not count the RFC 2047 chrome.  These line lengths are only a
            hint; the splitter does the best it can.
        :return: Lines of encoded strings, each with RFC 2047 chrome.
        current_linethis_linejoined_linelen64lenqpBody-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        self.body_encoding.  If body_encoding is None, we assume the
        output charset is a 7bit encoding, so re-encoding the decoded
        string using the ascii codec produces the correct string version
        of the content.
        # Author: Ben Gertzfield, Barry Warsaw# Flags for types of header encodings# Quoted-Printable# the shorter of QP and base64, but only for headers# In "=?charset?q?hello_world?=", the =?, ?q?, and ?= add up to 7# Defaults# input        header enc  body enc output conv# iso-8859-5 is Cyrillic, and not especially used# iso-8859-6 is Arabic, also not particularly used# iso-8859-7 is Greek, QP will not make it readable# iso-8859-8 is Hebrew, QP will not make it readable# iso-8859-11 is Thai, QP will not make it readable# Aliases for other commonly-used names for character sets.  Map# them to the real ones used in email.# Map charsets to their Unicode codec strings.# Hack: We don't want *any* conversion for stuff marked us-ascii, as all# sorts of garbage might be sent to us in the guise of 7-bit us-ascii.# Let that stuff pass through without conversion to/from Unicode.# Convenience functions for extending the above mappings# Convenience function for encoding strings, taking into account# that they might be unknown-8bit (ie: have surrogate-escaped bytes)# RFC 2046, $4.1.2 says charsets are not case sensitive.  We coerce to# unicode because its .lower() is locale insensitive.  If the argument# is already a unicode, we leave it at that, but ensure that the# charset is ASCII, as the standard (RFC XXX) requires.# Set the input charset after filtering through the aliases# We can try to guess which encoding and conversion to use by the# charset_map dictionary.  Try that first, but let the user override# it.# Set the attributes, allowing the arguments to override the default.# Now set the codecs.  If one isn't defined for input_charset,# guess and try a Unicode codec with the same name as input_codec.# 7bit/8bit encodings return the string unchanged (modulo conversions)# See which encoding we should use.# Calculate the number of characters that the RFC 2047 chrome will# contribute to each line.# Now comes the hard part.  We must encode bytes but we can't split on# bytes because some character sets are variable length and each# encoded word must stand on its own.  So the problem is you have to# encode to bytes to figure out this word's length, but you must split# on characters.  This causes two problems: first, we don't know how# many octets a specific substring of unicode characters will get# encoded to, and second, we don't know how many ASCII characters# those octets will get encoded to.  Unless we try it.  Which seems# inefficient.  In the interest of being correct rather than fast (and# in the hope that there will be few encoded headers in any such# message), brute force it. :(# This last character doesn't fit so pop it off.# Does nothing fit on the first line?# quopromime.body_encode takes a string, but operates on it as if# it were a list of byte codes.  For a (minimal) history on why# this is so, see changeset 0cf700464177.  To correctly encode a# character set, then, we must turn it into pseudo bytes via the# latin1 charset, which will encode any byte as a single code point# between 0 and 255, which is what body_encode is expecting.b'Charset'u'Charset'b'add_alias'u'add_alias'b'add_charset'u'add_charset'b'add_codec'u'add_codec'b'iso-8859-2'u'iso-8859-2'b'iso-8859-3'u'iso-8859-3'b'iso-8859-4'u'iso-8859-4'b'iso-8859-9'u'iso-8859-9'b'iso-8859-10'u'iso-8859-10'b'iso-8859-13'u'iso-8859-13'b'iso-8859-14'u'iso-8859-14'b'iso-8859-15'u'iso-8859-15'b'iso-8859-16'u'iso-8859-16'b'windows-1252'u'windows-1252'b'viscii'u'viscii'b'iso-2022-jp'u'iso-2022-jp'b'euc-jp'u'euc-jp'b'koi8-r'u'koi8-r'b'latin_2'u'latin_2'b'latin-2'u'latin-2'b'latin_3'u'latin_3'b'latin-3'u'latin-3'b'latin_4'u'latin_4'b'latin-4'u'latin-4'b'latin_5'u'latin_5'b'latin-5'u'latin-5'b'latin_6'u'latin_6'b'latin-6'u'latin-6'b'latin_7'u'latin_7'b'latin-7'u'latin-7'b'latin_8'u'latin_8'b'latin-8'u'latin-8'b'latin_9'u'latin_9'b'latin-9'u'latin-9'b'latin_10'u'latin_10'b'latin-10'u'latin-10'b'ks_c_5601-1987'u'ks_c_5601-1987'b'euc-kr'u'euc-kr'b'Add character set properties to the global registry.

    charset is the input character set, and must be the canonical name of a
    character set.

    Optional header_enc and body_enc is either charset.QP for
    quoted-printable, charset.BASE64 for base64 encoding, charset.SHORTEST for
    the shortest of qp or base64 encoding, or None for no encoding.  SHORTEST
    is only valid for header_enc.  It describes how message headers and
    message bodies in the input charset are to be encoded.  Default is no
    encoding.

    Optional output_charset is the character set that the output should be
    in.  Conversions will proceed from input charset, to Unicode, to the
    output charset when the method Charset.convert() is called.  The default
    is to output in the same character set as the input.

    Both input_charset and output_charset must have Unicode codec entries in
    the module's charset-to-codec mapping; use add_codec(charset, codecname)
    to add codecs the module does not know about.  See the codecs module's
    documentation for more information.
    'u'Add character set properties to the global registry.

    charset is the input character set, and must be the canonical name of a
    character set.

    Optional header_enc and body_enc is either charset.QP for
    quoted-printable, charset.BASE64 for base64 encoding, charset.SHORTEST for
    the shortest of qp or base64 encoding, or None for no encoding.  SHORTEST
    is only valid for header_enc.  It describes how message headers and
    message bodies in the input charset are to be encoded.  Default is no
    encoding.

    Optional output_charset is the character set that the output should be
    in.  Conversions will proceed from input charset, to Unicode, to the
    output charset when the method Charset.convert() is called.  The default
    is to output in the same character set as the input.

    Both input_charset and output_charset must have Unicode codec entries in
    the module's charset-to-codec mapping; use add_codec(charset, codecname)
    to add codecs the module does not know about.  See the codecs module's
    documentation for more information.
    'b'SHORTEST not allowed for body_enc'u'SHORTEST not allowed for body_enc'b'Add a character set alias.

    alias is the alias name, e.g. latin-1
    canonical is the character set's canonical name, e.g. iso-8859-1
    'u'Add a character set alias.

    alias is the alias name, e.g. latin-1
    canonical is the character set's canonical name, e.g. iso-8859-1
    'b'Add a codec that map characters in the given charset to/from Unicode.

    charset is the canonical name of a character set.  codecname is the name
    of a Python codec, as appropriate for the second argument to the unicode()
    built-in, or to the encode() method of a Unicode string.
    'u'Add a codec that map characters in the given charset to/from Unicode.

    charset is the canonical name of a character set.  codecname is the name
    of a Python codec, as appropriate for the second argument to the unicode()
    built-in, or to the encode() method of a Unicode string.
    'b'Map character sets to their email properties.

    This class provides information about the requirements imposed on email
    for a specific character set.  It also provides convenience routines for
    converting between character sets, given the availability of the
    applicable codecs.  Given a character set, it will do its best to provide
    information on how to use that character set in an email in an
    RFC-compliant way.

    Certain character sets must be encoded with quoted-printable or base64
    when used in email headers or bodies.  Certain character sets must be
    converted outright, and are not allowed in email.  Instances of this
    module expose the following information about a character set:

    input_charset: The initial character set specified.  Common aliases
                   are converted to their `official' email names (e.g. latin_1
                   is converted to iso-8859-1).  Defaults to 7-bit us-ascii.

    header_encoding: If the character set must be encoded before it can be
                     used in an email header, this attribute will be set to
                     charset.QP (for quoted-printable), charset.BASE64 (for
                     base64 encoding), or charset.SHORTEST for the shortest of
                     QP or BASE64 encoding.  Otherwise, it will be None.

    body_encoding: Same as header_encoding, but describes the encoding for the
                   mail message's body, which indeed may be different than the
                   header encoding.  charset.SHORTEST is not allowed for
                   body_encoding.

    output_charset: Some character sets must be converted before they can be
                    used in email headers or bodies.  If the input_charset is
                    one of them, this attribute will contain the name of the
                    charset output will be converted to.  Otherwise, it will
                    be None.

    input_codec: The name of the Python codec used to convert the
                 input_charset to Unicode.  If no conversion codec is
                 necessary, this attribute will be None.

    output_codec: The name of the Python codec used to convert Unicode
                  to the output_charset.  If no conversion codec is necessary,
                  this attribute will have the same value as the input_codec.
    'u'Map character sets to their email properties.

    This class provides information about the requirements imposed on email
    for a specific character set.  It also provides convenience routines for
    converting between character sets, given the availability of the
    applicable codecs.  Given a character set, it will do its best to provide
    information on how to use that character set in an email in an
    RFC-compliant way.

    Certain character sets must be encoded with quoted-printable or base64
    when used in email headers or bodies.  Certain character sets must be
    converted outright, and are not allowed in email.  Instances of this
    module expose the following information about a character set:

    input_charset: The initial character set specified.  Common aliases
                   are converted to their `official' email names (e.g. latin_1
                   is converted to iso-8859-1).  Defaults to 7-bit us-ascii.

    header_encoding: If the character set must be encoded before it can be
                     used in an email header, this attribute will be set to
                     charset.QP (for quoted-printable), charset.BASE64 (for
                     base64 encoding), or charset.SHORTEST for the shortest of
                     QP or BASE64 encoding.  Otherwise, it will be None.

    body_encoding: Same as header_encoding, but describes the encoding for the
                   mail message's body, which indeed may be different than the
                   header encoding.  charset.SHORTEST is not allowed for
                   body_encoding.

    output_charset: Some character sets must be converted before they can be
                    used in email headers or bodies.  If the input_charset is
                    one of them, this attribute will contain the name of the
                    charset output will be converted to.  Otherwise, it will
                    be None.

    input_codec: The name of the Python codec used to convert the
                 input_charset to Unicode.  If no conversion codec is
                 necessary, this attribute will be None.

    output_codec: The name of the Python codec used to convert Unicode
                  to the output_charset.  If no conversion codec is necessary,
                  this attribute will have the same value as the input_codec.
    'b'Return the content-transfer-encoding used for body encoding.

        This is either the string `quoted-printable' or `base64' depending on
        the encoding used, or it is a function in which case you should call
        the function with a single argument, the Message object being
        encoded.  The function should then set the Content-Transfer-Encoding
        header itself to whatever is appropriate.

        Returns "quoted-printable" if self.body_encoding is QP.
        Returns "base64" if self.body_encoding is BASE64.
        Returns conversion function otherwise.
        'u'Return the content-transfer-encoding used for body encoding.

        This is either the string `quoted-printable' or `base64' depending on
        the encoding used, or it is a function in which case you should call
        the function with a single argument, the Message object being
        encoded.  The function should then set the Content-Transfer-Encoding
        header itself to whatever is appropriate.

        Returns "quoted-printable" if self.body_encoding is QP.
        Returns "base64" if self.body_encoding is BASE64.
        Returns conversion function otherwise.
        'b'quoted-printable'u'quoted-printable'b'Return the output character set.

        This is self.output_charset if that is not None, otherwise it is
        self.input_charset.
        'u'Return the output character set.

        This is self.output_charset if that is not None, otherwise it is
        self.input_charset.
        'b'Header-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        this charset's `header_encoding`.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :return: The encoded string, with RFC 2047 chrome.
        'u'Header-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        this charset's `header_encoding`.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :return: The encoded string, with RFC 2047 chrome.
        'b'Header-encode a string by converting it first to bytes.

        This is similar to `header_encode()` except that the string is fit
        into maximum line lengths as given by the argument.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :param maxlengths: Maximum line length iterator.  Each element
            returned from this iterator will provide the next maximum line
            length.  This parameter is used as an argument to built-in next()
            and should never be exhausted.  The maximum line lengths should
            not count the RFC 2047 chrome.  These line lengths are only a
            hint; the splitter does the best it can.
        :return: Lines of encoded strings, each with RFC 2047 chrome.
        'u'Header-encode a string by converting it first to bytes.

        This is similar to `header_encode()` except that the string is fit
        into maximum line lengths as given by the argument.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :param maxlengths: Maximum line length iterator.  Each element
            returned from this iterator will provide the next maximum line
            length.  This parameter is used as an argument to built-in next()
            and should never be exhausted.  The maximum line lengths should
            not count the RFC 2047 chrome.  These line lengths are only a
            hint; the splitter does the best it can.
        :return: Lines of encoded strings, each with RFC 2047 chrome.
        'b'Body-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        self.body_encoding.  If body_encoding is None, we assume the
        output charset is a 7bit encoding, so re-encoding the decoded
        string using the ascii codec produces the correct string version
        of the content.
        'u'Body-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        self.body_encoding.  If body_encoding is None, we assume the
        output charset is a 7bit encoding, so re-encoding the decoded
        string using the ascii codec produces the correct string version
        of the content.
        'u'email.charset'HTTP/1.1 client library

<intro stuff goes here>
<other stuff, too>

HTTPConnection goes through a number of "states", which define when a client
may legally make another request or fetch the response for a particular
request. This diagram details these state transitions:

    (null)
      |
      | HTTPConnection()
      v
    Idle
      |
      | putrequest()
      v
    Request-started
      |
      | ( putheader() )*  endheaders()
      v
    Request-sent
      |\_____________________________
      |                              | getresponse() raises
      | response = getresponse()     | ConnectionError
      v                              v
    Unread-response                Idle
    [Response-headers-read]
      |\____________________
      |                     |
      | response.read()     | putrequest()
      v                     v
    Idle                  Req-started-unread-response
                     ______/|
                   /        |
   response.read() |        | ( putheader() )*  endheaders()
                   v        v
       Request-started    Req-sent-unread-response
                            |
                            | response.read()
                            v
                          Request-sent

This diagram presents the following rules:
  -- a second request may not be started until {response-headers-read}
  -- a response [object] cannot be retrieved until {request-sent}
  -- there is no differentiation between an unread response body and a
     partially read response body

Note: this enforcement is applied by the HTTPConnection class. The
      HTTPResponse class does not enforce this state machine, which
      implies sophisticated clients may accelerate the request/response
      pipeline. Caution should be taken, though: accelerating the states
      beyond the above pattern may imply knowledge of the server's
      connection-close behavior for certain requests. For example, it
      is impossible to tell whether the server will close the connection
      UNTIL the response headers have been read; this means that further
      requests cannot be placed into the pipeline until it is known that
      the server will NOT be closing the connection.

Logical State                  __state            __response
-------------                  -------            ----------
Idle                           _CS_IDLE           None
Request-started                _CS_REQ_STARTED    None
Request-sent                   _CS_REQ_SENT       None
Unread-response                _CS_IDLE           <response_class>
Req-started-unread-response    _CS_REQ_STARTED    <response_class>
Req-sent-unread-response       _CS_REQ_SENT       <response_class>
email.messageHTTPExceptionNotConnectedUnknownProtocolUnknownTransferEncodingUnimplementedFileModeIncompleteReadImproperConnectionStateCannotSendRequestCannotSendHeaderResponseNotReadyBadStatusLineLineTooLongRemoteDisconnectedHTTP_PORTHTTPS_PORT_UNKNOWNIdle_CS_IDLERequest-started_CS_REQ_STARTEDRequest-sent_CS_REQ_SENT__members___MAXLINE_MAXHEADERS[^:\s][^:\r\n]*rb'_is_legal_header_name\n(?![ \t])|\r(?![ \t\n])_is_illegal_header_value[ - ]_contains_disallowed_url_pchar_re[ -]_contains_disallowed_method_pchar_rePATCHPOSTPUT_METHODS_EXPECTING_BODYCall data.encode("latin-1") but show a better error message.%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') if you want to send it encoded in UTF-8."%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') ""if you want to send it encoded in UTF-8."HTTPMessageFind all header lines matching a given header name.

        Look through the list of headers and find all lines matching a given
        header name (and their continuation lines).  A list of the lines is
        returned, without interpretation.  If the header does not occur, an
        empty list is returned.  If the header occurs multiple times, all
        occurrences are returned.  Case is not important in the header name.

        hit_read_headersReads potential header lines into a list from a file pointer.

    Length of line is limited by _MAXLINE, and number of
    headers is limited by _MAXHEADERS.
    header linegot more than %d headersparse_headers_classParses only RFC2822 headers from a file pointer.

    email Parser wants to see strings rather than bytes.
    But a TextIOWrapper around self.rfile would buffer too many bytes
    from the stream, bytes which we later need to read as bytes.
    So we read the correct bytes here, as bytes, for email Parser
    to parse.

    hstringdebuglevel_methodchunk_leftwill_closestatus linereply:Remote end closed connection without response"Remote end closed connection without"" response"_close_conn999beginskipped_headersheaders:HTTP/1.0HTTP/0.9HTTP/1.hdrheader:transfer-encodingtr_enc_check_closecontent-lengthkeep-aliveproxy-connectionpconnAlways returns TrueisclosedTrue if the connection is closed.amt_read_chunked_safe_readRead up to len(b) bytes into bytearray b and return the number
        of bytes read.
        _readinto_chunked_read_next_chunk_sizechunk size_read_and_discard_trailertrailer line_get_chunk_lefttotal_bytesmvb_safe_readintotemp_mvbRead the number of bytes requested.

        This function should be used when <amt> bytes "should" be present for
        reading. If the bytes are truly not available (due to EOF), then the
        IncompleteRead exception can be used to detect the problem.
        Same as _safe_read, but for reading into a buffer.Read with at most one underlying system call.  If at least one
        byte is buffered, return that instead.
        _read1_chunked_peek_chunkedgetheaderReturns the value of the header matching *name*.

        If there are multiple matching headers, the values are
        combined into a single string separated by commas and spaces.

        If no matching header is found, returns *default* or None if
        the *default* is not specified.

        If the headers are unknown, raises http.client.ResponseNotReady.

        Return list of (header, value) tuples.Returns an instance of the class mimetools.Message containing
        meta-information associated with the URL.

        When the method is HTTP, these headers are those returned by
        the server at the head of the retrieved HTML page (including
        Content-Length and Content-Type).

        When the method is FTP, a Content-Length header will be
        present if (as is now usual) the server passed back a file
        length in response to the FTP retrieval request. A
        Content-Type header will be present if the MIME type can be
        guessed.

        When the method is local-file, returned headers will include
        a Date representing the file's last-modified time, a
        Content-Length giving file size, and a Content-Type
        containing a guess at the file's type. See also the
        description of the mimetools module.

        Return the real URL of the page.

        In some cases, the HTTP server redirects a client to another
        URL. The urlopen() function handles this transparently, but in
        some cases the caller needs to know which URL the client was
        redirected to. The geturl() method can be used to get at this
        redirected URL.

        getcodeReturn the HTTP status code that was sent with the response,
        or None if the URL is not an HTTP URL.

        _http_vsnHTTP/1.1_http_vsn_strdefault_portauto_open_is_textIOTest whether a file-like object is a text or a binary stream.
        TextIOBase_get_content_lengthGet the content-length based on the body.

        If the body is None, we set Content-Length: 0 for methods that expect
        a body (RFC 7230, Section 3.3.2). We also set the Content-Length for
        any method if the body is a str or bytes-like object and not a file.
        mvsource_address__response__state_tunnel_host_tunnel_port_tunnel_headers_get_hostport_validate_host_create_connectionset_tunnelSet up host and port for HTTP CONNECT tunnelling.

        In a connection that uses HTTP CONNECT tunneling, the host passed to the
        constructor is used as a proxy server that relays all communication to
        the endpoint passed to `set_tunnel`. This done by sending an HTTP
        CONNECT request to the proxy server when the connection is established.

        This method must be called before the HTTP connection has been
        established.

        The headers argument should be a mapping of extra HTTP headers to send
        with the CONNECT request.
        Can't set up tunnel for established connectionnonnumeric port: '%s'set_debuglevel_tunnelCONNECT %s:%d HTTP/1.0
Tunnel connection failed: Connect to the host and port specified in __init__.http.client.connectENOPROTOOPTClose the connection to the HTTP server.Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        send:sendIng a read()ableencoding file using iso-8859-1datablockhttp.client.senddata should be a bytes-like object or an iterable, got %r"data should be a bytes-like object ""or an iterable, got %r"_outputAdd a line of output to the current request buffer.

        Assumes that the line does *not* end with \r\n.
        _read_readableencode_chunkedSend the currently buffered request and clear the buffer.

        Appends an extra \r\n to the buffer.
        A message_body may be specified, to be appended to the request.
        message_body should be a bytes-like object or an iterable, got %r"message_body should be a bytes-like ""object or an iterable, got %r"Zero length chunk ignoredSend a request to the server.

        `method' specifies an HTTP request method, e.g. 'GET'.
        `url' specifies the object being requested, e.g. '/index.html'.
        `skip_host' if True does not add automatically a 'Host:' header
        `skip_accept_encoding' if True does not add automatically an
           'Accept-Encoding:' header
        _validate_method_validate_path%s %s %s_encode_requestnilnetloc_enchost_encValidate a method name for putrequest.method can't contain control characters.  (found at least "(found at least "Validate a url for putrequest.URL can't contain control characters. Validate a host so it doesn't contain control characters.Send a request header line to the server.

        For example: h.putheader('Accept', 'text/html')
        Invalid header name %rone_valueInvalid header value %r
	Indicate that the last header line has been sent to the server.

        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        Send a complete request to the server.header_namesskipsaccept-encodingcontent_lengthUnable to determine size of %rGet the response from the server.

        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.

        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        HTTPSConnectionThis class allows communication via SSL.key_file, cert_file and check_hostname are deprecated, use a custom context instead."key_file, cert_file and check_hostname are ""deprecated, use a custom context instead."_create_default_https_contextset_alpn_protocolshttp/1.1will_verifycheck_hostname needs a SSL context with either CERT_OPTIONAL or CERT_REQUIRED"check_hostname needs a SSL context with ""either CERT_OPTIONAL or CERT_REQUIRED"_contextConnect to a host on a given (SSL) port.wrap_socket, %i more expected%s(%i bytes read%s)line_typegot more than %d bytes when reading %s# HTTPMessage, parse_headers(), and the HTTP status code constants are# intentionally omitted for simplicity# connection states# hack to maintain backwards compatibility# another hack to maintain backwards compatibility# Mapping status codes to official W3C names# maximal line length when calling readline().# Header name/value ABNF (http://tools.ietf.org/html/rfc7230#section-3.2)# VCHAR          = %x21-7E# obs-text       = %x80-FF# header-field   = field-name ":" OWS field-value OWS# field-name     = token# field-value    = *( field-content / obs-fold )# field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]# field-vchar    = VCHAR / obs-text# obs-fold       = CRLF 1*( SP / HTAB )#                ; obsolete line folding#                ; see Section 3.2.4# token          = 1*tchar# tchar          = "!" / "#" / "$" / "%" / "&" / "'" / "*"#                / "+" / "-" / "." / "^" / "_" / "`" / "|" / "~"#                / DIGIT / ALPHA#                ; any VCHAR, except delimiters# VCHAR defined in http://tools.ietf.org/html/rfc5234#appendix-B.1# the patterns for both name and value are more lenient than RFC# definitions to allow for backwards compatibility# These characters are not allowed within HTTP URL paths.#  See https://tools.ietf.org/html/rfc3986#section-3.3 and the#  https://tools.ietf.org/html/rfc3986#appendix-A pchar definition.# Prevents CVE-2019-9740.  Includes control characters such as \r\n.# We don't restrict chars above \x7f as putrequest() limits us to ASCII.# Arguably only these _should_ allowed:#  _is_allowed_url_pchars_re = re.compile(r"^[/!$&'()*+,;=:@%a-zA-Z0-9._~-]+$")# We are more lenient for assumed real world compatibility purposes.# These characters are not allowed within HTTP method names# to prevent http header injection.# We always set the Content-Length header for these methods because some# servers will otherwise respond with a 411# XXX The only usage of this method is in# http.server.CGIHTTPRequestHandler.  Maybe move the code there so# that it doesn't need to be part of the public API.  The API has# never been defined so this could cause backwards compatibility# issues.# See RFC 2616 sec 19.6 and RFC 1945 sec 6 for details.# The bytes from the socket object are iso-8859-1 strings.# See RFC 2616 sec 2.2 which notes an exception for MIME-encoded# text following RFC 2047.  The basic status line parsing only# accepts iso-8859-1.# If the response includes a content-length header, we need to# make sure that the client doesn't read more than the# specified number of bytes.  If it does, it will block until# the server times out and closes the connection.  This will# happen if a self.fp.read() is done (without a size) whether# self.fp is buffered or not.  So, no self.fp.read() by# clients unless they know what they are doing.# The HTTPResponse object is returned via urllib.  The clients# of http and urllib expect different attributes for the# headers.  headers is used here and supports urllib.  msg is# provided as a backwards compatibility layer for http# clients.# from the Status-Line of the response# HTTP-Version# Status-Code# Reason-Phrase# is "chunked" being used?# bytes left to read in current chunk# number of bytes left in response# conn will close at end of response# Presumably, the server closed the connection before# sending a valid response.# empty version will cause next test to fail.# The status code is a three-digit number# we've already started reading the response# read until we get a non-100 response# skip the header from the 100 response# Some servers might still return "0.9", treat it as 1.0 anyway# use HTTP/1.1 code for HTTP/1.x where x>=1# are we using the chunked-style of transfer encoding?# will the connection close at the end of the response?# do we have a Content-Length?# NOTE: RFC 2616, S4.4, #3 says we ignore this if tr_enc is "chunked"# ignore nonsensical negative lengths# does the body have a fixed length? (of zero)# 1xx codes# if the connection remains open, and we aren't using chunked, and# a content-length was not provided, then assume that the connection# WILL close.# An HTTP/1.1 proxy is assumed to stay open unless# explicitly closed.# Some HTTP/1.0 implementations have support for persistent# connections, using rules different than HTTP/1.1.# For older HTTP, Keep-Alive indicates persistent connection.# At least Akamai returns a "Connection: Keep-Alive" header,# which was supposed to be sent by the client.# Proxy-Connection is a netscape hack.# otherwise, assume it will close# set "closed" flag# These implementations are for the benefit of io.BufferedReader.# XXX This class should probably be revised to act more like# the "raw stream" that BufferedReader expects.# End of "raw stream" methods# NOTE: it is possible that we will not ever call self.close(). This#       case occurs when will_close is TRUE, length is None, and we#       read up to the last byte, but NOT past it.# IMPLIES: if will_close is FALSE, then self.close() will ALWAYS be#          called, meaning self.isclosed() is meaningful.# clip the read to the "end of response"# Ideally, we would raise IncompleteRead if the content-length# wasn't satisfied, but it might break compatibility.# Amount is not given (unbounded read) so we must check self.length# we read everything# we do not use _safe_read() here because this may be a .will_close# connection, and the user is reading more bytes than will be provided# (for example, reading in 1k chunks)# Read the next chunk size from the file# strip chunk-extensions# close the connection as protocol synchronisation is# probably lost# read and discard trailer up to the CRLF terminator### note: we shouldn't have any trailers!# a vanishingly small number of sites EOF without# sending the trailer# return self.chunk_left, reading a new chunk if necessary.# chunk_left == 0: at the end of the current chunk, need to close it# chunk_left == None: No current chunk, should read next.# This function returns non-zero or None if the last chunk has# been read.# Can be 0 or None# We are at the end of chunk, discard chunk end# toss the CRLF at the end of the chunk# last chunk: 1*("0") [ chunk-extension ] CRLF# we read everything; close the "file"# Having this enables IOBase.readline() to read more than one# byte at a time# Fallback to IOBase readline which uses peek() and read()# Strictly speaking, _get_chunk_left() may cause more than one read,# but that is ok, since that is to satisfy the chunked protocol.# if n is negative or larger than chunk_left# peek doesn't worry about protocol# eof# peek is allowed to return more than requested.  Just request the# entire chunk, and truncate what we get.# We override IOBase.__iter__ so that it doesn't check for closed-ness# For compatibility with old-style urllib responses.# do an explicit check for not None here to distinguish# between unset and set but empty# file-like object.# does it implement the buffer protocol (bytes, bytearray, array)?# This is stored as an instance variable to allow unit# tests to replace it with a suitable mockup# ipv6 addresses have [...]# http://foo.com:/ == http://foo.com/# Making a single send() call instead of one per line encourages# the host OS to use a more optimal packet size instead of# potentially emitting a series of small packets.# for sites which EOF without sending a trailer# Might fail in OSs that don't implement TCP_NODELAY# close it manually... there may be other refs# create a consistent interface to message_body# Let file-like take precedence over byte-like.  This# is needed to allow the current position of mmap'ed# files to be taken into account.# this is solely to check to see if message_body# implements the buffer API.  it /would/ be easier# to capture if PyObject_CheckBuffer was exposed# to Python.# the object implements the buffer interface and# can be passed directly into socket methods# chunked encoding# end chunked transfer# if a prior response has been completed, then forget about it.# in certain cases, we cannot issue another request on this connection.# this occurs when:#   1) we are in the process of sending a request.   (_CS_REQ_STARTED)#   2) a response to a previous request has signalled that it is going#      to close the connection upon completion.#   3) the headers for the previous response have not been read, thus#      we cannot determine whether point (2) is true.   (_CS_REQ_SENT)# if there is no prior response, then we can request at will.# if point (2) is true, then we will have passed the socket to the# response (effectively meaning, "there is no prior response"), and# will open a new one when a new request is made.# Note: if a prior response exists, then we *can* start a new request.#       We are not allowed to begin fetching the response to this new#       request, however, until that prior response is complete.# Save the method for use later in the response phase# Issue some standard headers for better HTTP/1.1 compliance# this header is issued *only* for HTTP/1.1# connections. more specifically, this means it is# only issued when the client uses the new# HTTPConnection() class. backwards-compat clients# will be using HTTP/1.0 and those clients may be# issuing this header themselves. we should NOT issue# it twice; some web servers (such as Apache) barf# when they see two Host: headers# If we need a non-standard port,include it in the# header.  If the request is going through a proxy,# but the host of the actual URL, not the host of the# proxy.# As per RFC 273, IPv6 address should be wrapped with []# when used as Host header# note: we are assuming that clients will not attempt to set these#       headers since *this* library must deal with the#       consequences. this also means that when the supporting#       libraries are updated to recognize other forms, then this#       code should be changed (removed or updated).# we only want a Content-Encoding of "identity" since we don't# support encodings such as x-gzip or x-deflate.# we can accept "chunked" Transfer-Encodings, but no others# NOTE: no TE header implies *only* "chunked"#self.putheader('TE', 'chunked')# if TE is supplied in the header, then it must appear in a# Connection header.#self.putheader('Connection', 'TE')# For HTTP/1.0, the server will assume "not chunked"# ASCII also helps prevent CVE-2019-9740.# prevent http header injection# Prevent CVE-2019-9740.# Prevent CVE-2019-18348.# Honor explicitly requested Host: and Accept-Encoding: headers.# chunked encoding will happen if HTTP/1.1 is used and either# the caller passes encode_chunked=True or the following# conditions hold:# 1. content-length has not been explicitly set# 2. the body is a file or iterable, but not a str or bytes-like# 3. Transfer-Encoding has NOT been explicitly set by the caller# only chunk body if not explicitly set for backwards# compatibility, assuming the client code is already handling the# chunking# if content-length cannot be automatically determined, fall# back to chunked encoding# RFC 2616 Section 3.7.1 says that text default has a# default charset of iso-8859-1.# if a prior response exists, then it must be completed (otherwise, we# cannot read this response's header to determine the connection-close# behavior)# note: if a prior response existed, but was connection-close, then the# socket and response were made independent of this HTTPConnection# object since a new request requires that we open a whole new# connection# this means the prior response had one of two states:#   1) will_close: this connection was reset and the prior socket and#                  response operate independently#   2) persistent: the response was retained and we await its#                  isclosed() status to become true.# this effectively passes the connection to the response# remember this, so we can tell when it is complete# XXX Should key_file and cert_file be deprecated in favour of context?# send ALPN extension to indicate HTTP/1.1 protocol# enable PHA for TLS 1.3 connections if available# cert and key file means the user wants to authenticate.# enable TLS 1.3 PHA implicitly even for custom contexts.# Subclasses that define an __init__ must call Exception.__init__# or define self.args.  Otherwise, str() will fail.# for backwards compatibilityb'HTTP/1.1 client library

<intro stuff goes here>
<other stuff, too>

HTTPConnection goes through a number of "states", which define when a client
may legally make another request or fetch the response for a particular
request. This diagram details these state transitions:

    (null)
      |
      | HTTPConnection()
      v
    Idle
      |
      | putrequest()
      v
    Request-started
      |
      | ( putheader() )*  endheaders()
      v
    Request-sent
      |\_____________________________
      |                              | getresponse() raises
      | response = getresponse()     | ConnectionError
      v                              v
    Unread-response                Idle
    [Response-headers-read]
      |\____________________
      |                     |
      | response.read()     | putrequest()
      v                     v
    Idle                  Req-started-unread-response
                     ______/|
                   /        |
   response.read() |        | ( putheader() )*  endheaders()
                   v        v
       Request-started    Req-sent-unread-response
                            |
                            | response.read()
                            v
                          Request-sent

This diagram presents the following rules:
  -- a second request may not be started until {response-headers-read}
  -- a response [object] cannot be retrieved until {request-sent}
  -- there is no differentiation between an unread response body and a
     partially read response body

Note: this enforcement is applied by the HTTPConnection class. The
      HTTPResponse class does not enforce this state machine, which
      implies sophisticated clients may accelerate the request/response
      pipeline. Caution should be taken, though: accelerating the states
      beyond the above pattern may imply knowledge of the server's
      connection-close behavior for certain requests. For example, it
      is impossible to tell whether the server will close the connection
      UNTIL the response headers have been read; this means that further
      requests cannot be placed into the pipeline until it is known that
      the server will NOT be closing the connection.

Logical State                  __state            __response
-------------                  -------            ----------
Idle                           _CS_IDLE           None
Request-started                _CS_REQ_STARTED    None
Request-sent                   _CS_REQ_SENT       None
Unread-response                _CS_IDLE           <response_class>
Req-started-unread-response    _CS_REQ_STARTED    <response_class>
Req-sent-unread-response       _CS_REQ_SENT       <response_class>
'u'HTTP/1.1 client library

<intro stuff goes here>
<other stuff, too>

HTTPConnection goes through a number of "states", which define when a client
may legally make another request or fetch the response for a particular
request. This diagram details these state transitions:

    (null)
      |
      | HTTPConnection()
      v
    Idle
      |
      | putrequest()
      v
    Request-started
      |
      | ( putheader() )*  endheaders()
      v
    Request-sent
      |\_____________________________
      |                              | getresponse() raises
      | response = getresponse()     | ConnectionError
      v                              v
    Unread-response                Idle
    [Response-headers-read]
      |\____________________
      |                     |
      | response.read()     | putrequest()
      v                     v
    Idle                  Req-started-unread-response
                     ______/|
                   /        |
   response.read() |        | ( putheader() )*  endheaders()
                   v        v
       Request-started    Req-sent-unread-response
                            |
                            | response.read()
                            v
                          Request-sent

This diagram presents the following rules:
  -- a second request may not be started until {response-headers-read}
  -- a response [object] cannot be retrieved until {request-sent}
  -- there is no differentiation between an unread response body and a
     partially read response body

Note: this enforcement is applied by the HTTPConnection class. The
      HTTPResponse class does not enforce this state machine, which
      implies sophisticated clients may accelerate the request/response
      pipeline. Caution should be taken, though: accelerating the states
      beyond the above pattern may imply knowledge of the server's
      connection-close behavior for certain requests. For example, it
      is impossible to tell whether the server will close the connection
      UNTIL the response headers have been read; this means that further
      requests cannot be placed into the pipeline until it is known that
      the server will NOT be closing the connection.

Logical State                  __state            __response
-------------                  -------            ----------
Idle                           _CS_IDLE           None
Request-started                _CS_REQ_STARTED    None
Request-sent                   _CS_REQ_SENT       None
Unread-response                _CS_IDLE           <response_class>
Req-started-unread-response    _CS_REQ_STARTED    <response_class>
Req-sent-unread-response       _CS_REQ_SENT       <response_class>
'b'HTTPConnection'u'HTTPConnection'b'HTTPException'u'HTTPException'b'NotConnected'u'NotConnected'b'UnknownProtocol'u'UnknownProtocol'b'UnknownTransferEncoding'u'UnknownTransferEncoding'b'UnimplementedFileMode'u'UnimplementedFileMode'b'IncompleteRead'u'IncompleteRead'b'InvalidURL'u'InvalidURL'b'ImproperConnectionState'u'ImproperConnectionState'b'CannotSendRequest'u'CannotSendRequest'b'CannotSendHeader'u'CannotSendHeader'b'ResponseNotReady'u'ResponseNotReady'b'BadStatusLine'u'BadStatusLine'b'LineTooLong'u'LineTooLong'b'RemoteDisconnected'u'RemoteDisconnected'b'responses'u'responses'b'Idle'u'Idle'b'Request-started'u'Request-started'b'Request-sent'u'Request-sent'b'[^:\s][^:\r\n]*'b'\n(?![ \t])|\r(?![ \t\n])'b'[ - ]'u'[ - ]'b'[ -]'u'[ -]'b'PATCH'u'PATCH'b'POST'u'POST'b'PUT'u'PUT'b'Call data.encode("latin-1") but show a better error message.'u'Call data.encode("latin-1") but show a better error message.'b'%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') if you want to send it encoded in UTF-8.'u'%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') if you want to send it encoded in UTF-8.'b'Find all header lines matching a given header name.

        Look through the list of headers and find all lines matching a given
        header name (and their continuation lines).  A list of the lines is
        returned, without interpretation.  If the header does not occur, an
        empty list is returned.  If the header occurs multiple times, all
        occurrences are returned.  Case is not important in the header name.

        'u'Find all header lines matching a given header name.

        Look through the list of headers and find all lines matching a given
        header name (and their continuation lines).  A list of the lines is
        returned, without interpretation.  If the header does not occur, an
        empty list is returned.  If the header occurs multiple times, all
        occurrences are returned.  Case is not important in the header name.

        'b'Reads potential header lines into a list from a file pointer.

    Length of line is limited by _MAXLINE, and number of
    headers is limited by _MAXHEADERS.
    'u'Reads potential header lines into a list from a file pointer.

    Length of line is limited by _MAXLINE, and number of
    headers is limited by _MAXHEADERS.
    'b'header line'u'header line'b'got more than %d headers'u'got more than %d headers'b'Parses only RFC2822 headers from a file pointer.

    email Parser wants to see strings rather than bytes.
    But a TextIOWrapper around self.rfile would buffer too many bytes
    from the stream, bytes which we later need to read as bytes.
    So we read the correct bytes here, as bytes, for email Parser
    to parse.

    'u'Parses only RFC2822 headers from a file pointer.

    email Parser wants to see strings rather than bytes.
    But a TextIOWrapper around self.rfile would buffer too many bytes
    from the stream, bytes which we later need to read as bytes.
    So we read the correct bytes here, as bytes, for email Parser
    to parse.

    'b'status line'u'status line'b'reply:'u'reply:'b'Remote end closed connection without response'u'Remote end closed connection without response'u'HTTP/'b'headers:'u'headers:'b'HTTP/1.0'u'HTTP/1.0'b'HTTP/0.9'u'HTTP/0.9'b'HTTP/1.'u'HTTP/1.'b'header:'u'header:'b'transfer-encoding'u'transfer-encoding'b'content-length'u'content-length'b'connection'u'connection'b'keep-alive'u'keep-alive'b'proxy-connection'u'proxy-connection'b'Always returns True'u'Always returns True'b'True if the connection is closed.'u'True if the connection is closed.'b'Read up to len(b) bytes into bytearray b and return the number
        of bytes read.
        'u'Read up to len(b) bytes into bytearray b and return the number
        of bytes read.
        'b'chunk size'u'chunk size'b'trailer line'u'trailer line'b'Read the number of bytes requested.

        This function should be used when <amt> bytes "should" be present for
        reading. If the bytes are truly not available (due to EOF), then the
        IncompleteRead exception can be used to detect the problem.
        'u'Read the number of bytes requested.

        This function should be used when <amt> bytes "should" be present for
        reading. If the bytes are truly not available (due to EOF), then the
        IncompleteRead exception can be used to detect the problem.
        'b'Same as _safe_read, but for reading into a buffer.'u'Same as _safe_read, but for reading into a buffer.'b'Read with at most one underlying system call.  If at least one
        byte is buffered, return that instead.
        'u'Read with at most one underlying system call.  If at least one
        byte is buffered, return that instead.
        'b'Returns the value of the header matching *name*.

        If there are multiple matching headers, the values are
        combined into a single string separated by commas and spaces.

        If no matching header is found, returns *default* or None if
        the *default* is not specified.

        If the headers are unknown, raises http.client.ResponseNotReady.

        'u'Returns the value of the header matching *name*.

        If there are multiple matching headers, the values are
        combined into a single string separated by commas and spaces.

        If no matching header is found, returns *default* or None if
        the *default* is not specified.

        If the headers are unknown, raises http.client.ResponseNotReady.

        'b'Return list of (header, value) tuples.'u'Return list of (header, value) tuples.'b'Returns an instance of the class mimetools.Message containing
        meta-information associated with the URL.

        When the method is HTTP, these headers are those returned by
        the server at the head of the retrieved HTML page (including
        Content-Length and Content-Type).

        When the method is FTP, a Content-Length header will be
        present if (as is now usual) the server passed back a file
        length in response to the FTP retrieval request. A
        Content-Type header will be present if the MIME type can be
        guessed.

        When the method is local-file, returned headers will include
        a Date representing the file's last-modified time, a
        Content-Length giving file size, and a Content-Type
        containing a guess at the file's type. See also the
        description of the mimetools module.

        'u'Returns an instance of the class mimetools.Message containing
        meta-information associated with the URL.

        When the method is HTTP, these headers are those returned by
        the server at the head of the retrieved HTML page (including
        Content-Length and Content-Type).

        When the method is FTP, a Content-Length header will be
        present if (as is now usual) the server passed back a file
        length in response to the FTP retrieval request. A
        Content-Type header will be present if the MIME type can be
        guessed.

        When the method is local-file, returned headers will include
        a Date representing the file's last-modified time, a
        Content-Length giving file size, and a Content-Type
        containing a guess at the file's type. See also the
        description of the mimetools module.

        'b'Return the real URL of the page.

        In some cases, the HTTP server redirects a client to another
        URL. The urlopen() function handles this transparently, but in
        some cases the caller needs to know which URL the client was
        redirected to. The geturl() method can be used to get at this
        redirected URL.

        'u'Return the real URL of the page.

        In some cases, the HTTP server redirects a client to another
        URL. The urlopen() function handles this transparently, but in
        some cases the caller needs to know which URL the client was
        redirected to. The geturl() method can be used to get at this
        redirected URL.

        'b'Return the HTTP status code that was sent with the response,
        or None if the URL is not an HTTP URL.

        'u'Return the HTTP status code that was sent with the response,
        or None if the URL is not an HTTP URL.

        'b'HTTP/1.1'u'HTTP/1.1'b'Test whether a file-like object is a text or a binary stream.
        'u'Test whether a file-like object is a text or a binary stream.
        'b'Get the content-length based on the body.

        If the body is None, we set Content-Length: 0 for methods that expect
        a body (RFC 7230, Section 3.3.2). We also set the Content-Length for
        any method if the body is a str or bytes-like object and not a file.
        'u'Get the content-length based on the body.

        If the body is None, we set Content-Length: 0 for methods that expect
        a body (RFC 7230, Section 3.3.2). We also set the Content-Length for
        any method if the body is a str or bytes-like object and not a file.
        'b'Set up host and port for HTTP CONNECT tunnelling.

        In a connection that uses HTTP CONNECT tunneling, the host passed to the
        constructor is used as a proxy server that relays all communication to
        the endpoint passed to `set_tunnel`. This done by sending an HTTP
        CONNECT request to the proxy server when the connection is established.

        This method must be called before the HTTP connection has been
        established.

        The headers argument should be a mapping of extra HTTP headers to send
        with the CONNECT request.
        'u'Set up host and port for HTTP CONNECT tunnelling.

        In a connection that uses HTTP CONNECT tunneling, the host passed to the
        constructor is used as a proxy server that relays all communication to
        the endpoint passed to `set_tunnel`. This done by sending an HTTP
        CONNECT request to the proxy server when the connection is established.

        This method must be called before the HTTP connection has been
        established.

        The headers argument should be a mapping of extra HTTP headers to send
        with the CONNECT request.
        'b'Can't set up tunnel for established connection'u'Can't set up tunnel for established connection'b'nonnumeric port: '%s''u'nonnumeric port: '%s''b'CONNECT %s:%d HTTP/1.0
'b'Tunnel connection failed: 'u'Tunnel connection failed: 'b'Connect to the host and port specified in __init__.'u'Connect to the host and port specified in __init__.'b'http.client.connect'u'http.client.connect'b'Close the connection to the HTTP server.'u'Close the connection to the HTTP server.'b'Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        'u'Send `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        'b'send:'u'send:'b'sendIng a read()able'u'sendIng a read()able'b'encoding file using iso-8859-1'u'encoding file using iso-8859-1'b'http.client.send'u'http.client.send'b'data should be a bytes-like object or an iterable, got %r'u'data should be a bytes-like object or an iterable, got %r'b'Add a line of output to the current request buffer.

        Assumes that the line does *not* end with \r\n.
        'u'Add a line of output to the current request buffer.

        Assumes that the line does *not* end with \r\n.
        'b'Send the currently buffered request and clear the buffer.

        Appends an extra \r\n to the buffer.
        A message_body may be specified, to be appended to the request.
        'u'Send the currently buffered request and clear the buffer.

        Appends an extra \r\n to the buffer.
        A message_body may be specified, to be appended to the request.
        'b'message_body should be a bytes-like object or an iterable, got %r'u'message_body should be a bytes-like object or an iterable, got %r'b'Zero length chunk ignored'u'Zero length chunk ignored'b'Send a request to the server.

        `method' specifies an HTTP request method, e.g. 'GET'.
        `url' specifies the object being requested, e.g. '/index.html'.
        `skip_host' if True does not add automatically a 'Host:' header
        `skip_accept_encoding' if True does not add automatically an
           'Accept-Encoding:' header
        'u'Send a request to the server.

        `method' specifies an HTTP request method, e.g. 'GET'.
        `url' specifies the object being requested, e.g. '/index.html'.
        `skip_host' if True does not add automatically a 'Host:' header
        `skip_accept_encoding' if True does not add automatically an
           'Accept-Encoding:' header
        'b'%s %s %s'u'%s %s %s'b'Validate a method name for putrequest.'u'Validate a method name for putrequest.'b'method can't contain control characters. 'u'method can't contain control characters. 'b' (found at least 'u' (found at least 'b'Validate a url for putrequest.'u'Validate a url for putrequest.'b'URL can't contain control characters. 'u'URL can't contain control characters. 'b'Validate a host so it doesn't contain control characters.'u'Validate a host so it doesn't contain control characters.'b'Send a request header line to the server.

        For example: h.putheader('Accept', 'text/html')
        'u'Send a request header line to the server.

        For example: h.putheader('Accept', 'text/html')
        'b'Invalid header name %r'u'Invalid header name %r'b'Invalid header value %r'u'Invalid header value %r'b'
	'b'Indicate that the last header line has been sent to the server.

        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        'u'Indicate that the last header line has been sent to the server.

        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        'b'Send a complete request to the server.'u'Send a complete request to the server.'b'skip_host'u'skip_host'b'accept-encoding'u'accept-encoding'b'skip_accept_encoding'u'skip_accept_encoding'b'Unable to determine size of %r'u'Unable to determine size of %r'b'Get the response from the server.

        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.

        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        'u'Get the response from the server.

        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.

        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        'b'This class allows communication via SSL.'u'This class allows communication via SSL.'b'key_file, cert_file and check_hostname are deprecated, use a custom context instead.'u'key_file, cert_file and check_hostname are deprecated, use a custom context instead.'b'http/1.1'u'http/1.1'b'check_hostname needs a SSL context with either CERT_OPTIONAL or CERT_REQUIRED'u'check_hostname needs a SSL context with either CERT_OPTIONAL or CERT_REQUIRED'b'Connect to a host on a given (SSL) port.'u'Connect to a host on a given (SSL) port.'b'HTTPSConnection'u'HTTPSConnection'b', %i more expected'u', %i more expected'b'%s(%i bytes read%s)'u'%s(%i bytes read%s)'b'got more than %d bytes when reading %s'u'got more than %d bytes when reading %s'botocore.docs.clientClientDocumenterBoto3ClientDocumenter_add_client_creation_examplestart_codeblocknew_lineimport boto3client = boto3.client('{service}')end_codeblockb'import boto3'u'import boto3'b'client = boto3.client('{service}')'u'client = boto3.client('{service}')'u'boto3.docs.client'u'docs.client'botocore.argsbotocore.awsrequestbotocore.discoveryEndpointDiscoveryHandlerEndpointDiscoveryManagerblock_endpoint_discovery_required_operationsbotocore.docs.docstringClientMethodDocstringPaginatorDocstringDataNotFoundErrorInvalidEndpointDiscoveryConfigurationErrorOperationNotPageableErrorUnknownServiceErrorUnknownSignatureVersionErrorbotocore.historyget_global_history_recorderbotocore.hooksfirst_non_none_responsebotocore.httpchecksumapply_request_checksumresolve_checksum_contextServiceModelbotocore.paginatePaginatoradaptiveCachedPropertyEventbridgeSignerSetterS3ControlArnParamHandlerv2S3RegionRedirectorv2ClientErrorS3ArnParamHandlerS3ControlArnParamHandlerS3ControlEndpointSetterS3EndpointSetterS3RegionRedirector_LEGACY_SIGNATURE_VERSIONShistory_recorderClientCreatorCreates client objects for a service.endpoint_resolverretry_handler_factoryretry_config_translator_endpoint_resolver_retry_handler_factory_retry_config_translatorcreate_clientchoose-service-name_load_service_model_load_service_endpoints_rulesetload_datapartitionsNo endpoints ruleset found for service %s, falling back to legacy endpoint routing.'No endpoints ruleset found for service %s, falling back to ''legacy endpoint routing.'_create_client_class_normalize_fips_regionClientEndpointBridgesigningNameservice_signing_namesignatureVersionservice_signature_version_get_client_argsclient_argsservice_client_register_retries_register_s3_events_register_s3_control_events_register_endpoint_discoverycreate_client_class_create_methods_create_name_mappingpy_name_to_operation_name_PY_TO_OP_NAMEBaseClienthyphenizecreating-client-class.%sbase_classesfips--fipsnormalized_region_nameconfig_use_fips_endpointtransforming region from %s to %s and setting use_fips_endpoint to true. client should not be configured with a fips psuedo region.'transforming region from %s to %s and setting ''use_fips_endpoint to true. client should not ''be configured with a fips psuedo region.'load_service_modelservice-2json_modelendpoint-rule-set-1_register_v2_standard_retries_register_v2_adaptive_retries_register_legacy_retriesservice_event_name_retryoriginal_config_transform_legacy_retriesbuild_retry_configretry_configRegistering retry handlers for service: %screate_retry_handlerretry-config-%sunique_idneeds-retry.copied_args_get_retry_modeclient_retriesendpoint_discovery_operationendpoint_discovery_enabled_normalize_endpoint_discovery_config_requires_endpoint_discoveryalways_discoverbefore-parameter-buildConfig must either be a boolean-string or string-literal 'auto'config_valueendpoint_discovery_required_register_eventbridge_events_set_s3_presign_signature_versions3controlclient_meta_get_configured_signature_versionprovided_signature_versionget_available_endpointsregionsconstruct_endpointsignatureVersionssignature_versionschoose-signer.s3_default_s3_presign_to_sigv2
        Returns the 's3' (sigv2) signer if presigning an s3 request. This is
        intended to be used to set the default signature version for the signer
        to sigv2. Situations where an asymmetric signature is required are the
        exception, for example MRAP needs v4a.

        :type signature_version: str
        :param signature_version: The current client signature version.

        :type signing_name: str
        :param signing_name: The signing name of the service.

        :return: 's3' if the request is an s3 presign request, None otherwise
        -query-presign-postargs_creatorop_dictoperation_namespy_operation_name_create_api_method_api_call() only accepts keyword arguments._make_api_callresponse = client.%sBridges endpoint data and client creation

    This class handles taking out the relevant arguments from the endpoint
    resolver and determining which values to use, taking into account any
    client configuration options and scope configuration options.

    This class also handles determining what, if any, region to use if no
    explicit region setting is provided. For example, Amazon S3 client will
    utilize "us-east-1" by default if no region can be resolved.{service}.{region}.amazonaws.comDEFAULT_ENDPOINT_DUALSTACK_CUSTOMIZED_SERVICESdefault_endpoint_check_default_regionawspartition_name_create_endpoint_assume_endpointuses_builtin_data_pick_region_values_make_url_resolve_signature_version_resolve_signing_name_create_resultconfig_var_is_s3_dualstack_modes3_dualstack_modeAssuming an endpoint for supported_protocols://credentialScopeendpointNameconfigured_versionpotential_versionsknown_serializer_endpoint_ruleset_resolver_response_parser_request_signer_client_configClientMeta_exceptions_register_handlersgetattr.emit_until_responseevent_response' object has no attribute 'Closes underlying endpoint connections.request-created.api_paramsAPI_CALLdeprecatedWarning: %s.%s() is deprecatedclient_regionauth_type_resolve_endpoint_rulesetadditional_headers_convert_to_request_dictbefore-call.{service_id}.{operation_name}parsed_response_make_requestafter-call.{service_id}.{operation_name}http_responseCodeerror_codefrom_codeerror_classmake_requestafter-call-error.{service_id}.{operation_name}set_user_agent_header_emit_api_paramsserialize_to_requestprovide-client-params.before-parameter-build.ignore_signing_regionReturns endpoint URL and list of additional headers returned from
        EndpointRulesetResolver for the given operation and params. If the
        ruleset resolver is not available, for example because the service has
        no endpoints ruleset file, the legacy endpoint resolver's value is
        returned.

        Use ignore_signing_region for generating presigned URLs or any other
        situtation where the signing region information from the ruleset
        resolver should be ignored.

        Returns tuple of URL and headers dictionary. Additionally, the
        request_context dict is modified in place with any signing information
        returned from the ruleset resolver.
        call_argsendpoint_infopropertiesauthSchemesauth_schemesauth_schemes_to_signing_ctxauth_infosigning_contextsigningget_paginatorCreate a paginator for an operation.

        :type operation_name: string
        :param operation_name: The operation name.  This is the same name
            as the method name on the client.  For example, if the
            method name is ``create_foo``, and you'd normally invoke the
            operation as ``client.create_foo(**kwargs)``, if the
            ``create_foo`` operation can be paginated, you can use the
            call ``client.get_paginator("create_foo")``.

        :raise OperationNotPageableError: Raised if the operation is not
            pageable.  You can use the ``client.can_paginate`` method to
            check if an operation is pageable.

        :rtype: L{botocore.paginate.Paginator}
        :return: A paginator object.

        can_paginateactual_operation_namepaginatepage_configpaginator_configpaginator_nameservice_module_name.Paginator.paginator_class_namedocumented_paginator_clspaginatorCheck if an operation can be paginated.

        :type operation_name: string
        :param operation_name: The operation name.  This is the same name
            as the method name on the client.  For example, if the
            method name is ``create_foo``, and you'd normally invoke the
            operation as ``client.create_foo(**kwargs)``, if the
            ``create_foo`` operation can be paginated, you can use the
            call ``client.get_paginator("create_foo")``.

        :return: ``True`` if the operation can be paginated,
            ``False`` otherwise.

        paginators-1pagination_get_waiter_configwaiter_configwaiters-2Returns an object that can wait for some condition.

        :type waiter_name: str
        :param waiter_name: The name of the waiter to get. See the waiters
            section of the service docs for a list of available waiters.

        :returns: The specified waiter object.
        :rtype: botocore.waiter.Waiter
        Waiter does not exist: %sWaiterModelwaiter_namescreate_waiter_with_clientReturns a list of all available waiters._load_exceptionscreate_client_exceptionsHolds additional client methods.

    This class holds additional information for clients.  It exists for
    two reasons:

        * To give advanced functionality to clients
        * To namespace additional client attributes from the operation
          names which are mapped to methods at runtime.  This avoids
          ever running into collisions with operation names.

    method_to_api_mapping_endpoint_url_method_to_api_mapping_partition
    Gets the manually configured signature version.

    :returns: the customer configured signature version, or None if no
        signature version was configured.
    service_configSwitching signature version for service %s to version %s based on config file override."Switching signature version for service %s ""to version %s based on config file override."# Keep these imported.  There's pre-existing code that uses:# "from botocore.client import UNSIGNED"# "from botocore.client import ClientError"# TODO: Migrate things away from scoped_config in favor of the# config_store.  The config store can pull things from both the scoped# config and environment variables (and potentially more in the# future).# If region has been transformed then set flag# Keeping endpoint setting client specific# First, we load the entire retry config for all services,# then pull out just the information we need.# Don't register any handlers in the case of a custom endpoint url# Only attach handlers if the service supports discovery# This will return the manually configured signature version, or None# if none was manually set. If a customer manually sets the signature# version, we always want to use what they set.# Check to see if the region is a region that we know about. If we# don't know about a region, then we can safely assume it's a new# region that is sigv4 only, since all new S3 regions only allow sigv4.# The only exception is aws-global. This is a pseudo-region for the# global endpoint, we should respect the signature versions it# supports, which includes v2.# If it is a region we know about, we want to default to sigv2, so here# we check to see if it is available.# We now know that we're in a known region that supports sigv2 and# the customer hasn't set a signature version so we default the# signature version to sigv2.# py_name -> OperationName, for every operation available# for a service.# We're accepting *args so that we can give a more helpful# error message than TypeError: _api_call takes exactly# 1 argument.# The "self" in this scope is referring to the BaseClient.# Add the docstring to the client method# If we can't resolve the region, we'll attempt to get a global# endpoint for non-regionalized services (iam, route53, etc)# TODO: fallback partition_name should be configurable in the# future for users to define as needed.# Use the client_config region if no explicit region was provided.# Client configuration arg has precedence# Check config store# TODO: This normalization logic is duplicated from the# ClientArgsCreator class.  Consolidate everything to# ClientArgsCreator.  _resolve_signature_version also has similarly# duplicated logic.# Client config trumps scoped config.# Expand the default hostname URI template.# We still want to allow the user to provide an explicit version.# CredentialScope overrides everything else.# Use the signingName from the model if present.# Just assume is the same as the service name.# Do not use the region name or signing name from the resolved# endpoint if the user explicitly provides an endpoint_url. This# would happen if we resolve to an endpoint where the service has# a "defaults" section that overrides all endpoint with a single# hostname and credentialScope. This has been the case historically# for how STS has worked. The only way to resolve an STS endpoint# was to provide a region_name and an endpoint_url. In that case,# we would still resolve an endpoint, but we would not use the# resolved endpointName or signingRegion because we want to allow# custom endpoints.# Prefer the service model as most specific# source of truth for new signature versions.# Pick a signature version from the endpoint metadata if present.# Now just iterate over the signature versions in order until we# find the first one that is known to Botocore.# This is actually reassigned with the py->op_name mapping# when the client creator creates the subclass.  This value is used# because calls such as client.get_paginator('list_objects') use the# snake_case name, but we need to know the ListObjects form.# xform_name() does the ListObjects->list_objects conversion, but# we need the reverse mapping here.# Register the handler required to sign requests.# Given the API params provided by the user and the operation_model# we can serialize the request to a request_dict.# Emit an event that allows users to modify the parameters at the# beginning of the method. It allows handlers to modify existing# parameters or return a new set of parameters to use.# If authSchemes is present, overwrite default auth type and# signing context derived from service model.# Create a new paginate method that will serve as a proxy to# the underlying Paginator.paginate method. This is needed to# attach a docstring to the method.# Add the docstring for the paginate method.# Rename the paginator class based on the type of paginator.# Create the new paginator class# Waiter configs is a dict, we just want the waiter names# which are the keys in the dict.# Client config overrides everything.# Scoped config overrides picking from the endpoint metadata.# A given service may have service specific configuration in the# config file, so we need to check there as well.b'Creates client objects for a service.'u'Creates client objects for a service.'b'choose-service-name'u'choose-service-name'b'partitions'u'partitions'b'No endpoints ruleset found for service %s, falling back to legacy endpoint routing.'u'No endpoints ruleset found for service %s, falling back to legacy endpoint routing.'b'signingName'u'signingName'b'signatureVersion'u'signatureVersion'b'_PY_TO_OP_NAME'u'_PY_TO_OP_NAME'b'creating-client-class.%s'u'creating-client-class.%s'b'fips-'u'fips-'b'-fips'u'-fips'b'transforming region from %s to %s and setting use_fips_endpoint to true. client should not be configured with a fips psuedo region.'u'transforming region from %s to %s and setting use_fips_endpoint to true. client should not be configured with a fips psuedo region.'b'service-2'u'service-2'b'endpoint-rule-set-1'u'endpoint-rule-set-1'b'standard'u'standard'b'adaptive'b'_retry'u'_retry'b'retry'u'retry'b'definitions'u'definitions'b'Registering retry handlers for service: %s'u'Registering retry handlers for service: %s'b'retry-config-%s'u'retry-config-%s'b'needs-retry.'u'needs-retry.'b'endpoint_discovery_enabled'u'endpoint_discovery_enabled'b'before-parameter-build'u'before-parameter-build'b'Config must either be a boolean-string or string-literal 'auto''u'Config must either be a boolean-string or string-literal 'auto''b'auto'u'auto'b'events'u'events'b's3control'u's3control'b'signatureVersions'u'signatureVersions'b'choose-signer.s3'u'choose-signer.s3'b'
        Returns the 's3' (sigv2) signer if presigning an s3 request. This is
        intended to be used to set the default signature version for the signer
        to sigv2. Situations where an asymmetric signature is required are the
        exception, for example MRAP needs v4a.

        :type signature_version: str
        :param signature_version: The current client signature version.

        :type signing_name: str
        :param signing_name: The signing name of the service.

        :return: 's3' if the request is an s3 presign request, None otherwise
        'u'
        Returns the 's3' (sigv2) signer if presigning an s3 request. This is
        intended to be used to set the default signature version for the signer
        to sigv2. Situations where an asymmetric signature is required are the
        exception, for example MRAP needs v4a.

        :type signature_version: str
        :param signature_version: The current client signature version.

        :type signing_name: str
        :param signing_name: The signing name of the service.

        :return: 's3' if the request is an s3 presign request, None otherwise
        'b'-query'u'-query'b'-presign-post'u'-presign-post'b'() only accepts keyword arguments.'u'() only accepts keyword arguments.'b'response = client.%s'u'response = client.%s'b'Bridges endpoint data and client creation

    This class handles taking out the relevant arguments from the endpoint
    resolver and determining which values to use, taking into account any
    client configuration options and scope configuration options.

    This class also handles determining what, if any, region to use if no
    explicit region setting is provided. For example, Amazon S3 client will
    utilize "us-east-1" by default if no region can be resolved.'u'Bridges endpoint data and client creation

    This class handles taking out the relevant arguments from the endpoint
    resolver and determining which values to use, taking into account any
    client configuration options and scope configuration options.

    This class also handles determining what, if any, region to use if no
    explicit region setting is provided. For example, Amazon S3 client will
    utilize "us-east-1" by default if no region can be resolved.'b'{service}.{region}.amazonaws.com'u'{service}.{region}.amazonaws.com'b'aws'u'aws'b'hostname'u'hostname'b'protocols'u'protocols'b'True'u'True'b'Assuming an endpoint for 'u'Assuming an endpoint for 'b'://'u'://'b'credentialScope'u'credentialScope'b'service'u'service'b'endpointName'u'endpointName'b'region'u'region'b'getattr.'u'getattr.'b'' object has no attribute ''u'' object has no attribute ''b'Closes underlying endpoint connections.'u'Closes underlying endpoint connections.'b'request-created.'u'request-created.'b'API_CALL'u'API_CALL'b'operation'u'operation'b'params'u'params'b'Warning: %s.%s() is deprecated'u'Warning: %s.%s() is deprecated'b'client_region'u'client_region'b'auth_type'u'auth_type'b'before-call.{service_id}.{operation_name}'u'before-call.{service_id}.{operation_name}'b'after-call.{service_id}.{operation_name}'u'after-call.{service_id}.{operation_name}'b'Code'u'Code'b'after-call-error.{service_id}.{operation_name}'u'after-call-error.{service_id}.{operation_name}'b'provide-client-params.'u'provide-client-params.'b'before-parameter-build.'u'before-parameter-build.'b'Returns endpoint URL and list of additional headers returned from
        EndpointRulesetResolver for the given operation and params. If the
        ruleset resolver is not available, for example because the service has
        no endpoints ruleset file, the legacy endpoint resolver's value is
        returned.

        Use ignore_signing_region for generating presigned URLs or any other
        situtation where the signing region information from the ruleset
        resolver should be ignored.

        Returns tuple of URL and headers dictionary. Additionally, the
        request_context dict is modified in place with any signing information
        returned from the ruleset resolver.
        'u'Returns endpoint URL and list of additional headers returned from
        EndpointRulesetResolver for the given operation and params. If the
        ruleset resolver is not available, for example because the service has
        no endpoints ruleset file, the legacy endpoint resolver's value is
        returned.

        Use ignore_signing_region for generating presigned URLs or any other
        situtation where the signing region information from the ruleset
        resolver should be ignored.

        Returns tuple of URL and headers dictionary. Additionally, the
        request_context dict is modified in place with any signing information
        returned from the ruleset resolver.
        'b'authSchemes'u'authSchemes'b'signing'u'signing'b'Create a paginator for an operation.

        :type operation_name: string
        :param operation_name: The operation name.  This is the same name
            as the method name on the client.  For example, if the
            method name is ``create_foo``, and you'd normally invoke the
            operation as ``client.create_foo(**kwargs)``, if the
            ``create_foo`` operation can be paginated, you can use the
            call ``client.get_paginator("create_foo")``.

        :raise OperationNotPageableError: Raised if the operation is not
            pageable.  You can use the ``client.can_paginate`` method to
            check if an operation is pageable.

        :rtype: L{botocore.paginate.Paginator}
        :return: A paginator object.

        'u'Create a paginator for an operation.

        :type operation_name: string
        :param operation_name: The operation name.  This is the same name
            as the method name on the client.  For example, if the
            method name is ``create_foo``, and you'd normally invoke the
            operation as ``client.create_foo(**kwargs)``, if the
            ``create_foo`` operation can be paginated, you can use the
            call ``client.get_paginator("create_foo")``.

        :raise OperationNotPageableError: Raised if the operation is not
            pageable.  You can use the ``client.can_paginate`` method to
            check if an operation is pageable.

        :rtype: L{botocore.paginate.Paginator}
        :return: A paginator object.

        'b'page_config'u'page_config'b'.Paginator.'u'.Paginator.'b'paginate'u'paginate'b'Check if an operation can be paginated.

        :type operation_name: string
        :param operation_name: The operation name.  This is the same name
            as the method name on the client.  For example, if the
            method name is ``create_foo``, and you'd normally invoke the
            operation as ``client.create_foo(**kwargs)``, if the
            ``create_foo`` operation can be paginated, you can use the
            call ``client.get_paginator("create_foo")``.

        :return: ``True`` if the operation can be paginated,
            ``False`` otherwise.

        'u'Check if an operation can be paginated.

        :type operation_name: string
        :param operation_name: The operation name.  This is the same name
            as the method name on the client.  For example, if the
            method name is ``create_foo``, and you'd normally invoke the
            operation as ``client.create_foo(**kwargs)``, if the
            ``create_foo`` operation can be paginated, you can use the
            call ``client.get_paginator("create_foo")``.

        :return: ``True`` if the operation can be paginated,
            ``False`` otherwise.

        'b'paginators-1'u'paginators-1'b'pagination'u'pagination'b'waiter_config'u'waiter_config'b'waiters-2'u'waiters-2'b'Returns an object that can wait for some condition.

        :type waiter_name: str
        :param waiter_name: The name of the waiter to get. See the waiters
            section of the service docs for a list of available waiters.

        :returns: The specified waiter object.
        :rtype: botocore.waiter.Waiter
        'u'Returns an object that can wait for some condition.

        :type waiter_name: str
        :param waiter_name: The name of the waiter to get. See the waiters
            section of the service docs for a list of available waiters.

        :returns: The specified waiter object.
        :rtype: botocore.waiter.Waiter
        'b'Waiter does not exist: %s'u'Waiter does not exist: %s'b'Returns a list of all available waiters.'u'Returns a list of all available waiters.'b'Holds additional client methods.

    This class holds additional information for clients.  It exists for
    two reasons:

        * To give advanced functionality to clients
        * To namespace additional client attributes from the operation
          names which are mapped to methods at runtime.  This avoids
          ever running into collisions with operation names.

    'u'Holds additional client methods.

    This class holds additional information for clients.  It exists for
    two reasons:

        * To give advanced functionality to clients
        * To namespace additional client attributes from the operation
          names which are mapped to methods at runtime.  This avoids
          ever running into collisions with operation names.

    'b'
    Gets the manually configured signature version.

    :returns: the customer configured signature version, or None if no
        signature version was configured.
    'u'
    Gets the manually configured signature version.

    :returns: the customer configured signature version, or None if no
        signature version was configured.
    'b'Switching signature version for service %s to version %s based on config file override.'u'Switching signature version for service %s to version %s based on config file override.'u'botocore.client'botocore.docs.exampleResponseExampleDocumenterget_instance_public_methodsbotocore.docs.sharedexampledocument_shared_examplesbotocore.docs.utilsDocumentedShapeget_official_service_name_allowlist_generate_presigned_urlgenerate_presigned_url_CLIENT_METHODS_FILTERSshared_examples_shared_examplesdocument_clientDocuments a client and its methods

        :param section: The section to write to.
        _add_title_add_class_signature_get_client_methodsclient_methods_add_client_intro_add_client_methods_filter_client_methodsfiltered_methods_filter_client_methodfilter_includeh2Clientintroofficial_service_nameA low-level client representing These are the available methods:li:py:meth:`~.Client.`start_sphinx_py_class.Clientclient = session.create_client('{service}')_add_client_method_is_custom_method_add_custom_method_add_model_driven_method_add_method_exceptions_listerror_sectionboldExceptionsclient_nameerror_shapes.Client.exceptions.:py:class:`%s`ClientExceptionsDocumenterhttps://boto3.amazonaws.com/v1/documentation/api/latest/guide/error-handling.html'https://boto3.amazonaws.com/''v1/documentation/api/latest/guide/error-handling.html'_USER_GUIDE_LINKstructureNormalized access to common exception attributes.An identifier specifying the exception type.A descriptive message explaining why the exception occured.'A descriptive message explaining why the exception ''occured.'_GENERIC_ERROR_SHAPEdocument_exceptions_add_overview_add_exceptions_list_add_exception_classesClient ExceptionsClient exceptions are available on a client instance via the ``exceptions`` property. For more detailed instructions and examples on the exact usage of client exceptions, see the error handling 'Client exceptions are available on a client instance ''via the ``exceptions`` property. For more detailed instructions ''and examples on the exact usage of client exceptions, see the ''error handling 'external_linkuser guide_exception_class_namecls_nameThis client has no modeled exception classes.The available client exceptions are:_add_exception_classclass_section_add_top_level_documentation_add_exception_catch_example_add_response_attrend_sphinx_py_classExampletry:dedentexcept client.exceptions.%s as e:print(e.response)response_section_add_response_attr_description_add_response_example_add_response_paramsend_sphinx_py_attrThe parsed error response. All exceptions have a top level ``Error`` key that provides normalized access to common exception atrributes. All other keys are specific to this service or exception class.'The parsed error response. All exceptions have a top level ''``Error`` key that provides normalized access to common ''exception atrributes. All other keys are specific to this ''service or exception class.'syntaxexample_sectionSyntaxnew_paragraphdocumenterdocument_exampleparams_section# Apply each filter to the method# Use the first non-None value returned by any of the filters# Otherwise default to including it# Write out the top level description for the client.# Write out the client example instantiation.# List out all of the possible client methods.# Add any modeled exceptions# Add the shared examplesb'generate_presigned_url'u'generate_presigned_url'b'Documents a client and its methods

        :param section: The section to write to.
        'u'Documents a client and its methods

        :param section: The section to write to.
        'b'Client'u'Client'b'intro'u'intro'b'A low-level client representing 'u'A low-level client representing 'b'These are the available methods:'u'These are the available methods:'b':py:meth:`~'u':py:meth:`~'b'.Client.'u'.Client.'b'`'u'`'b'.Client'u'.Client'b'client = session.create_client('{service}')'u'client = session.create_client('{service}')'b'methods'u'methods'b'Exceptions'u'Exceptions'b'.Client.exceptions.'u'.Client.exceptions.'b':py:class:`%s`'u':py:class:`%s`'b'https://boto3.amazonaws.com/v1/documentation/api/latest/guide/error-handling.html'u'https://boto3.amazonaws.com/v1/documentation/api/latest/guide/error-handling.html'b'structure'u'structure'b'Normalized access to common exception attributes.'u'Normalized access to common exception attributes.'b'An identifier specifying the exception type.'u'An identifier specifying the exception type.'b'Message'u'Message'b'A descriptive message explaining why the exception occured.'u'A descriptive message explaining why the exception occured.'b'Client Exceptions'u'Client Exceptions'b'Client exceptions are available on a client instance via the ``exceptions`` property. For more detailed instructions and examples on the exact usage of client exceptions, see the error handling 'u'Client exceptions are available on a client instance via the ``exceptions`` property. For more detailed instructions and examples on the exact usage of client exceptions, see the error handling 'b'user guide'u'user guide'b'This client has no modeled exception classes.'u'This client has no modeled exception classes.'b'The available client exceptions are:'u'The available client exceptions are:'b'Example'u'Example'b'try:'u'try:'b'except client.exceptions.%s as e:'u'except client.exceptions.%s as e:'b'print(e.response)'u'print(e.response)'b'The parsed error response. All exceptions have a top level ``Error`` key that provides normalized access to common exception atrributes. All other keys are specific to this service or exception class.'u'The parsed error response. All exceptions have a top level ``Error`` key that provides normalized access to common exception atrributes. All other keys are specific to this service or exception class.'b'syntax'u'syntax'b'Syntax'u'Syntax'b'Structure'u'Structure'u'botocore.docs.client'
An XML-RPC client interface for Python.

The marshalling and response parser code can also be used to
implement XML-RPC servers.

Exported exceptions:

  Error          Base class for client errors
  ProtocolError  Indicates an HTTP protocol error
  ResponseError  Indicates a broken response package
  Fault          Indicates an XML-RPC fault package

Exported classes:

  ServerProxy    Represents a logical connection to an XML-RPC server

  MultiCall      Executor of boxcared xmlrpc requests
  DateTime       dateTime wrapper for an ISO 8601 string or time tuple or
                 localtime integer value to generate a "dateTime.iso8601"
                 XML-RPC value
  Binary         binary data wrapper

  Marshaller     Generate an XML-RPC params chunk from a Python data structure
  Unmarshaller   Unmarshal an XML-RPC response from incoming XML event message
  Transport      Handles an HTTP transaction to an XML-RPC server
  SafeTransport  Handles an HTTPS transaction to an XML-RPC server

Exported constants:

  (none)

Exported functions:

  getparser      Create instance of the fastest available parser & attach
                 to an unmarshalling object
  dumps          Convert an argument tuple or a Fault instance to an XML-RPC
                 request (or response, if the methodresponse option is used).
  loads          Convert an XML-RPC packet to unmarshalled data plus a method
                 name (None if not present).
MAXINTMININT32700PARSE_ERROR32600SERVER_ERROR32500APPLICATION_ERROR32400SYSTEM_ERROR32300TRANSPORT_ERRORNOT_WELLFORMED_ERROR32701UNSUPPORTED_ENCODING32702INVALID_ENCODING_CHARINVALID_XMLRPC32601METHOD_NOT_FOUND32602INVALID_METHOD_PARAMS32603INTERNAL_ERRORBase class for client errors.Indicates an HTTP protocol error.errcodeerrmsg<%s for %s: %s %s>Indicates a broken response package.FaultIndicates an XML-RPC fault package.faultCodefaultString<%s %s: %r>Boolean_day0_try0001_iso8601_format%Y%m%dT%H:%M:%S%4Y%4Y%m%dT%H:%M:%S_strftimestruct_time%04d%02d%02dT%02d:%02d:%02dDateTimeDateTime wrapper for an ISO 8601 string or time tuple or
    localtime integer value to generate 'dateTime.iso8601' XML-RPC
    value.
    make_comparable<value><dateTime.iso8601></dateTime.iso8601></value>
_datetime_typeBinaryWrapper for binary data.expected bytes or bytearray, not %s<value><base64>
</base64></value>
_binaryWRAPPERSExpatParserMarshallerGenerate an XML-RPC params chunk from a Python data structure.

    Create a Marshaller instance for each set of parameters, and use
    the "dumps" method to convert your data (represented as a tuple)
    to an XML-RPC params chunk.  To write a fault response, pass a
    Fault instance instead.  You may prefer to use the "dumps" module
    function for this purpose.
    allow_nonedispatch__dump<fault>
</fault>
<params>
<param>
</param>
</params>
cannot marshal %s objects_arbitrary_instancedump_nilcannot marshal None unless allow_none is enabled<value><nil/></value>dump_bool<value><boolean></boolean></value>
dump_longint exceeds XML-RPC limits<value><int></int></value>
dump_intdump_double<value><double></double></value>
dump_unicode<value><string></string></value>
dump_bytesdump_arraycannot marshal recursive sequences<value><array><data>
</data></array></value>
dump_structcannot marshal recursive dictionaries<value><struct>
<member>
dictionary key must be string<name>%s</name>
</member>
</struct></value>
dump_datetimedump_instanceUnmarshallerUnmarshal an XML-RPC response, based on incoming XML event
    messages (start, data, end).  Call close() to get the resulting
    data structure.

    Note that this reader is fairly tolerant, and gladly accepts bogus
    XML-RPC data without complaining (but not bogus XML).
    use_datetimeuse_builtin_types_type_stack_marks_value_methodname_use_datetime_use_bytesfaultgetmethodnamestandaloneunknown tag %rend_dispatchend_nilend_booleanbad boolean valueend_inti1i2i4i8bigintegerend_doubleend_bigdecimalbigdecimalend_stringend_arrayend_structend_base64end_dateTimedateTime.iso8601end_valueend_paramsend_faultend_methodName_MultiCallMethodcall_list__call_list__nameMultiCallIteratorIterates over the results of a multicall. Exceptions are
    raised in response to xmlrpc faults.unexpected type in multicall resultMultiCallserver -> an object used to boxcar method calls

    server should be a ServerProxy object.

    Methods can be added to the MultiCall using normal
    method call syntax e.g.:

    multicall = MultiCall(server_proxy)
    multicall.add(2,3)
    multicall.get_address("Guido")

    To execute the multicall, call the MultiCall object e.g.:

    add_result, address = multicall()
    __server<%s at %#x>marshalled_listmulticallFastMarshallerFastParserFastUnmarshallergetparsergetparser() -> parser, unmarshaller

    Create an instance of the fastest available parser, and attach it
    to an unmarshalling object.  Return both objects.
    mkdatetimemkbytesmethodnamemethodresponsedata [,options] -> marshalled data

    Convert an argument tuple or a Fault instance to an XML-RPC
    request (or response, if the methodresponse option is used).

    In addition to the data object, the following options can be given
    as keyword arguments:

        methodname: the method name for a methodCall packet

        methodresponse: true to create a methodResponse packet.
        If this option is used with a tuple, the tuple must be
        a singleton (i.e. it can contain only one element).

        encoding: the packet encoding (default is UTF-8)

    All byte strings in the data structure are assumed to use the
    packet encoding.  Unicode strings are automatically converted,
    where necessary.
    argument must be tuple or Fault instanceresponse tuple must be a singletonxmlheader<?xml version='1.0'?>
<methodCall>
<methodName>"<methodCall>\n""<methodName>"</methodName>
</methodCall>
<methodResponse>
</methodResponse>
data -> unmarshalled data, method name

    Convert an XML-RPC packet to unmarshalled data plus a method
    name (None if not present).

    If the XML-RPC packet represents a fault condition, this function
    raises a Fault exception.
    gzip_encodedata -> gzip encoded data

    Encode data using the gzip content encoding as described in RFC 1952
    gzfgzip_decode20971520max_decodegzip encoded data -> unencoded data

    Decode data using the gzip content encoding as described in RFC 1952
    invalid datamax gzipped payload length exceededGzipDecodedResponsea file-like object to decode a response encoded with the gzip
    method, as described in RFC 1952.
    _Method__sendTransportHandles an HTTP transaction to an XML-RPC server.Python-xmlrpc/%saccept_gzip_encodingencode_threshold_use_builtin_types_connection_headers_extra_headerssingle_requestECONNRESETECONNABORTEDEPIPEsend_requesthttp_connparse_responseget_host_infox509_splituserextra_headersmake_connectionchosttext/xmlsend_headerssend_contentbody:SafeTransportHandles an HTTPS transaction to an XML-RPC server.your version of http.client doesn't support HTTPSServerProxyuri [,options] -> a logical connection to an XML-RPC server

    uri is the connection point on the server, given as
    scheme://host/target.

    The standard implementation always supports the "http" scheme.  If
    SSL socket support is available (Python 2.0), it also supports
    "https".

    If the target part and the slash preceding it are both omitted,
    "/RPC2" is assumed.

    The following options can be given as keyword arguments:

        transport: a transport factory
        encoding: the request encoding (default is UTF-8)

    All 8-bit strings passed to the server proxy are assumed to use
    the given encoding.
    unsupported XML-RPC protocol__host__handler/RPC2extra_kwargs__transport__encoding__verbose__allow_none__close__request<%s for %s%s>A workaround to get special attributes on the ServerProxy
           without interfering with the magic __getattr__
        Attribute %r not foundhttp://localhost:8000currentTimegetCurrentTimemultigetData# XML-RPC CLIENT LIBRARY# $Id$# an XML-RPC client interface for Python.# the marshalling and response parser code can also be used to# implement XML-RPC servers.# Notes:# this version is designed to work with Python 2.1 or newer.# History:# 1999-01-14 fl  Created# 1999-01-15 fl  Changed dateTime to use localtime# 1999-01-16 fl  Added Binary/base64 element, default to RPC2 service# 1999-01-19 fl  Fixed array data element (from Skip Montanaro)# 1999-01-21 fl  Fixed dateTime constructor, etc.# 1999-02-02 fl  Added fault handling, handle empty sequences, etc.# 1999-02-10 fl  Fixed problem with empty responses (from Skip Montanaro)# 1999-06-20 fl  Speed improvements, pluggable parsers/transports (0.9.8)# 2000-11-28 fl  Changed boolean to check the truth value of its argument# 2001-02-24 fl  Added encoding/Unicode/SafeTransport patches# 2001-02-26 fl  Added compare support to wrappers (0.9.9/1.0b1)# 2001-03-28 fl  Make sure response tuple is a singleton# 2001-03-29 fl  Don't require empty params element (from Nicholas Riley)# 2001-06-10 fl  Folded in _xmlrpclib accelerator support (1.0b2)# 2001-08-20 fl  Base xmlrpclib.Error on built-in Exception (from Paul Prescod)# 2001-09-03 fl  Allow Transport subclass to override getparser# 2001-09-10 fl  Lazy import of urllib, cgi, xmllib (20x import speedup)# 2001-10-01 fl  Remove containers from memo cache when done with them# 2001-10-01 fl  Use faster escape method (80% dumps speedup)# 2001-10-02 fl  More dumps microtuning# 2001-10-04 fl  Make sure import expat gets a parser (from Guido van Rossum)# 2001-10-10 sm  Allow long ints to be passed as ints if they don't overflow# 2001-10-17 sm  Test for int and long overflow (allows use on 64-bit systems)# 2001-11-12 fl  Use repr() to marshal doubles (from Paul Felix)# 2002-03-17 fl  Avoid buffered read when possible (from James Rucker)# 2002-04-07 fl  Added pythondoc comments# 2002-04-16 fl  Added __str__ methods to datetime/binary wrappers# 2002-05-15 fl  Added error constants (from Andrew Kuchling)# 2002-06-27 fl  Merged with Python CVS version# 2002-10-22 fl  Added basic authentication (based on code from Phillip Eby)# 2003-01-22 sm  Add support for the bool type# 2003-02-27 gvr Remove apply calls# 2003-04-24 sm  Use cStringIO if available# 2003-04-25 ak  Add support for nil# 2003-06-15 gn  Add support for time.struct_time# 2003-07-12 gp  Correct marshalling of Faults# 2003-10-31 mvl Add multicall support# 2004-08-20 mvl Bump minimum supported Python version to 2.1# 2014-12-02 ch/doko  Add workaround for gzip bomb vulnerability# Copyright (c) 1999-2002 by Secret Labs AB.# Copyright (c) 1999-2002 by Fredrik Lundh.# info@pythonware.com# The XML-RPC client interface is# Copyright (c) 1999-2002 by Secret Labs AB# Copyright (c) 1999-2002 by Fredrik Lundh#python can be built without zlib/gzip support# Internal stuff# used in User-Agent header sent# xmlrpc integer limits# Error constants (from Dan Libby's specification at# http://xmlrpc-epi.sourceforge.net/specs/rfc.fault_codes.php)# Ranges of errors# Specific errors# Base class for all kinds of client-side errors.# Indicates an HTTP-level protocol error.  This is raised by the HTTP# transport layer, if the server returns an error code other than 200# (OK).# @param url The target URL.# @param errcode The HTTP error code.# @param errmsg The HTTP error message.# @param headers The HTTP header dictionary.# Indicates a broken XML-RPC response package.  This exception is# raised by the unmarshalling layer, if the XML-RPC response is# malformed.# Indicates an XML-RPC fault response package.  This exception is# raised by the unmarshalling layer, if the XML-RPC response contains# a fault string.  This exception can also be used as a class, to# generate a fault XML-RPC message.# @param faultCode The XML-RPC fault code.# @param faultString The XML-RPC fault string.# Special values# Backwards compatibility# Wrapper for XML-RPC DateTime values.  This converts a time value to# the format used by XML-RPC.# <p># The value can be given as a datetime object, as a string in the# format "yyyymmddThh:mm:ss", as a 9-item time tuple (as returned by# time.localtime()), or an integer value (as returned by time.time()).# The wrapper uses time.localtime() to convert an integer to a time# @param value The time, given as a datetime object, an ISO 8601 string,#              a time tuple, or an integer time value.# Issue #13305: different format codes across platforms# Mac OS X# Linux# Get date/time value.# @return Date/time value, as an ISO 8601 string.# decode xml element contents into a DateTime structure.# Wrapper for binary data.  This can be used to transport any kind# of binary data over XML-RPC, using BASE64 encoding.# @param data An 8-bit string containing arbitrary data.# Make a copy of the bytes!# Get buffer contents.# @return Buffer contents, as an 8-bit string.# XXX encoding?!# decode xml element contents into a Binary structure# XML parsers# fast expat parser for Python 2.0 and later.# XML-RPC marshalling and unmarshalling code# XML-RPC marshaller.# @param encoding Default encoding for 8-bit strings.  The default#     value is None (interpreted as UTF-8).# @see dumps# by the way, if you don't understand what's going on in here,# that's perfectly ok.# fault instance# parameter block# FIXME: the xml-rpc specification allows us to leave out# the entire <params> block if there are no parameters.# however, changing this may break older code (including# old versions of xmlrpclib.py), so this is better left as# is for now.  See @XMLRPC3 for more information. /F# check if this object can be marshalled as a structure# check if this class is a sub-class of a basic type,# because we don't know how to marshal these types# (e.g. a string sub-class)# XXX(twouters): using "_arbitrary_instance" as key as a quick-fix# for the p3yk merge, this should probably be fixed more neatly.# backward compatible# check for special wrappers# store instance attributes as a struct (really?)# XML-RPC unmarshaller.# @see loads# and again, if you don't understand what's going on in here,# return response tuple and target method# event handlers# FIXME: assert standalone == 1 ???# prepare to handle this element# call the appropriate end tag handler# unknown tag ?# accelerator support# dispatch data# element decoders# struct keys are always strings# map arrays to Python lists# map structs to Python dictionaries# if we stumble upon a value element with no internal# elements, treat it as a string element# no params## Multicall support# some lesser magic to store calls made to a MultiCall object# for batch execution# convenience functions# Create a parser object, and connect it to an unmarshalling instance.# This function picks the fastest available XML parser.# return A (parser, unmarshaller) tuple.# Convert a Python tuple or a Fault instance to an XML-RPC packet.# @def dumps(params, **options)# @param params A tuple or Fault instance.# @keyparam methodname If given, create a methodCall request for#     this method name.# @keyparam methodresponse If given, create a methodResponse packet.#     If used with a tuple, the tuple must be a singleton (that is,#     it must contain exactly one element).# @keyparam encoding The packet encoding.# @return A string containing marshalled data.# utf-8 is default# standard XML-RPC wrappings# a method call# a method response, or a fault structure# return as is# Convert an XML-RPC packet to a Python object.  If the XML-RPC packet# represents a fault condition, this function raises a Fault exception.# @param data An XML-RPC packet, given as an 8-bit string.# @return A tuple containing the unpacked data, and the method name#     (None if not present).# @see Fault# Encode a string using the gzip content encoding such as specified by the# Content-Encoding: gzip# in the HTTP header, as described in RFC 1952# @param data the unencoded data# @return the encoded data# Decode a string using the gzip content encoding such as specified by the# @param data The encoded data# @keyparam max_decode Maximum bytes to decode (20 MiB default), use negative#    values for unlimited decoding# @return the unencoded data# @raises ValueError if data is not correctly coded.# @raises ValueError if max gzipped payload length exceeded# no limit# Return a decoded file-like object for the gzip encoding# as described in RFC 1952.# @param response A stream supporting a read() method# @return a file-like object that the decoded data can be read() from#response doesn't support tell() and read(), required by#GzipFile# request dispatcher# some magic to bind an XML-RPC method to an RPC server.# supports "nested" methods (e.g. examples.getStateName)# Standard transport class for XML-RPC over HTTP.# You can create custom transports by subclassing this method, and# overriding selected methods.# client identifier (may be overridden)#if true, we'll request gzip encoding# if positive, encode request using gzip if it exceeds this threshold# note that many servers will get confused, so only use it if you know# that they can decode such a request#None = don't encode# Send a complete request, and parse the response.# Retry request if a cached connection has disconnected.# @param host Target host.# @param handler Target PRC handler.# @param request_body XML-RPC request body.# @param verbose Debugging flag.# @return Parsed response.#retry request once if cached connection has gone cold# issue XML-RPC request#All unexpected errors leave connection in# a strange state, so we clear it.#We got an error response.#Discard any response data and raise exception# Create parser.# @return A 2-tuple containing a parser and an unmarshaller.# get parser and unmarshaller# Get authorization info from host parameter# Host may be a string, or a (host, x509-dict) tuple; if a string,# it is checked for a "user:pw@host" format, and a "Basic# Authentication" header is added if appropriate.# @param host Host descriptor (URL or (URL, x509 info) tuple).# @return A 3-tuple containing (actual host, extra headers,#     x509 info).  The header and x509 fields may be None.# get rid of whitespace# Connect to server.# @return An HTTPConnection object#return an existing connection if possible.  This allows#HTTP/1.1 keep-alive.# create a HTTP connection object from a host descriptor# Clear any cached connection object.# Used in the event of socket errors.# Send HTTP request.# @param handler Target RPC handler (a path relative to host)# @param request_body The XML-RPC request body# @param debug Enable debugging if debug is true.# @return An HTTPConnection.# Send request headers.# This function provides a useful hook for subclassing# @param connection httpConnection.# @param headers list of key,value pairs for HTTP headers# Send request body.#optionally encode the request# Parse response.# @param file Stream.# @return Response tuple and target method.# read response data from httpresponse, and parse it# Check for new http response object, otherwise it is a file object.# Standard transport class for XML-RPC over HTTPS.# FIXME: mostly untested# create a HTTPS connection object from a host descriptor# host may be a string, or a (host, x509-dict) tuple# Standard server proxy.  This class establishes a virtual connection# to an XML-RPC server.# This class is available as ServerProxy and Server.  New code should# use ServerProxy, to avoid confusion.# @def ServerProxy(uri, **options)# @param uri The connection point on the server.# @keyparam transport A transport factory, compatible with the#    standard transport class.# @keyparam encoding The default encoding used for 8-bit strings#    (default is UTF-8).# @keyparam verbose Use a true value to enable debugging output.#    (printed to standard output).# @see Transport# establish a "logical" server connection# get the url# call a method on the remote server# magic method dispatcher# note: to call a remote object with a non-standard name, use# result getattr(server, "strange-python-name")(args)# compatibility# test code# simple test program (from the XML-RPC specification)# local server, available from Lib/xmlrpc/server.pyb'
An XML-RPC client interface for Python.

The marshalling and response parser code can also be used to
implement XML-RPC servers.

Exported exceptions:

  Error          Base class for client errors
  ProtocolError  Indicates an HTTP protocol error
  ResponseError  Indicates a broken response package
  Fault          Indicates an XML-RPC fault package

Exported classes:

  ServerProxy    Represents a logical connection to an XML-RPC server

  MultiCall      Executor of boxcared xmlrpc requests
  DateTime       dateTime wrapper for an ISO 8601 string or time tuple or
                 localtime integer value to generate a "dateTime.iso8601"
                 XML-RPC value
  Binary         binary data wrapper

  Marshaller     Generate an XML-RPC params chunk from a Python data structure
  Unmarshaller   Unmarshal an XML-RPC response from incoming XML event message
  Transport      Handles an HTTP transaction to an XML-RPC server
  SafeTransport  Handles an HTTPS transaction to an XML-RPC server

Exported constants:

  (none)

Exported functions:

  getparser      Create instance of the fastest available parser & attach
                 to an unmarshalling object
  dumps          Convert an argument tuple or a Fault instance to an XML-RPC
                 request (or response, if the methodresponse option is used).
  loads          Convert an XML-RPC packet to unmarshalled data plus a method
                 name (None if not present).
'u'
An XML-RPC client interface for Python.

The marshalling and response parser code can also be used to
implement XML-RPC servers.

Exported exceptions:

  Error          Base class for client errors
  ProtocolError  Indicates an HTTP protocol error
  ResponseError  Indicates a broken response package
  Fault          Indicates an XML-RPC fault package

Exported classes:

  ServerProxy    Represents a logical connection to an XML-RPC server

  MultiCall      Executor of boxcared xmlrpc requests
  DateTime       dateTime wrapper for an ISO 8601 string or time tuple or
                 localtime integer value to generate a "dateTime.iso8601"
                 XML-RPC value
  Binary         binary data wrapper

  Marshaller     Generate an XML-RPC params chunk from a Python data structure
  Unmarshaller   Unmarshal an XML-RPC response from incoming XML event message
  Transport      Handles an HTTP transaction to an XML-RPC server
  SafeTransport  Handles an HTTPS transaction to an XML-RPC server

Exported constants:

  (none)

Exported functions:

  getparser      Create instance of the fastest available parser & attach
                 to an unmarshalling object
  dumps          Convert an argument tuple or a Fault instance to an XML-RPC
                 request (or response, if the methodresponse option is used).
  loads          Convert an XML-RPC packet to unmarshalled data plus a method
                 name (None if not present).
'b'Base class for client errors.'u'Base class for client errors.'b'Indicates an HTTP protocol error.'u'Indicates an HTTP protocol error.'b'<%s for %s: %s %s>'u'<%s for %s: %s %s>'b'Indicates a broken response package.'u'Indicates a broken response package.'b'Indicates an XML-RPC fault package.'u'Indicates an XML-RPC fault package.'b'<%s %s: %r>'u'<%s %s: %r>'b'0001'u'0001'b'%Y%m%dT%H:%M:%S'u'%Y%m%dT%H:%M:%S'b'%4Y'u'%4Y'b'%4Y%m%dT%H:%M:%S'u'%4Y%m%dT%H:%M:%S'b'%04d%02d%02dT%02d:%02d:%02d'u'%04d%02d%02dT%02d:%02d:%02d'b'DateTime wrapper for an ISO 8601 string or time tuple or
    localtime integer value to generate 'dateTime.iso8601' XML-RPC
    value.
    'u'DateTime wrapper for an ISO 8601 string or time tuple or
    localtime integer value to generate 'dateTime.iso8601' XML-RPC
    value.
    'b'timetuple'u'timetuple'b'<value><dateTime.iso8601>'u'<value><dateTime.iso8601>'b'</dateTime.iso8601></value>
'u'</dateTime.iso8601></value>
'b'Wrapper for binary data.'u'Wrapper for binary data.'b'expected bytes or bytearray, not %s'u'expected bytes or bytearray, not %s'b'<value><base64>
'u'<value><base64>
'b'</base64></value>
'u'</base64></value>
'b'Generate an XML-RPC params chunk from a Python data structure.

    Create a Marshaller instance for each set of parameters, and use
    the "dumps" method to convert your data (represented as a tuple)
    to an XML-RPC params chunk.  To write a fault response, pass a
    Fault instance instead.  You may prefer to use the "dumps" module
    function for this purpose.
    'u'Generate an XML-RPC params chunk from a Python data structure.

    Create a Marshaller instance for each set of parameters, and use
    the "dumps" method to convert your data (represented as a tuple)
    to an XML-RPC params chunk.  To write a fault response, pass a
    Fault instance instead.  You may prefer to use the "dumps" module
    function for this purpose.
    'b'<fault>
'u'<fault>
'b'faultCode'u'faultCode'b'faultString'u'faultString'b'</fault>
'u'</fault>
'b'<params>
'u'<params>
'b'<param>
'u'<param>
'b'</param>
'u'</param>
'b'</params>
'u'</params>
'b'cannot marshal %s objects'u'cannot marshal %s objects'b'_arbitrary_instance'u'_arbitrary_instance'b'cannot marshal None unless allow_none is enabled'u'cannot marshal None unless allow_none is enabled'b'<value><nil/></value>'u'<value><nil/></value>'b'<value><boolean>'u'<value><boolean>'b'</boolean></value>
'u'</boolean></value>
'b'int exceeds XML-RPC limits'u'int exceeds XML-RPC limits'b'<value><int>'u'<value><int>'b'</int></value>
'u'</int></value>
'b'<value><double>'u'<value><double>'b'</double></value>
'u'</double></value>
'b'<value><string>'u'<value><string>'b'</string></value>
'u'</string></value>
'b'cannot marshal recursive sequences'u'cannot marshal recursive sequences'b'<value><array><data>
'u'<value><array><data>
'b'</data></array></value>
'u'</data></array></value>
'b'cannot marshal recursive dictionaries'u'cannot marshal recursive dictionaries'b'<value><struct>
'u'<value><struct>
'b'<member>
'u'<member>
'b'dictionary key must be string'u'dictionary key must be string'b'<name>%s</name>
'u'<name>%s</name>
'b'</member>
'u'</member>
'b'</struct></value>
'u'</struct></value>
'b'Unmarshal an XML-RPC response, based on incoming XML event
    messages (start, data, end).  Call close() to get the resulting
    data structure.

    Note that this reader is fairly tolerant, and gladly accepts bogus
    XML-RPC data without complaining (but not bogus XML).
    'u'Unmarshal an XML-RPC response, based on incoming XML event
    messages (start, data, end).  Call close() to get the resulting
    data structure.

    Note that this reader is fairly tolerant, and gladly accepts bogus
    XML-RPC data without complaining (but not bogus XML).
    'b'fault'u'fault'b'array'b'struct'b'unknown tag %r'u'unknown tag %r'b'nil'u'nil'b'bad boolean value'u'bad boolean value'b'i1'u'i1'b'i2'u'i2'b'i4'u'i4'b'i8'u'i8'b'biginteger'u'biginteger'b'bigdecimal'u'bigdecimal'b'dateTime.iso8601'u'dateTime.iso8601'b'methodName'u'methodName'b'Iterates over the results of a multicall. Exceptions are
    raised in response to xmlrpc faults.'u'Iterates over the results of a multicall. Exceptions are
    raised in response to xmlrpc faults.'b'unexpected type in multicall result'u'unexpected type in multicall result'b'server -> an object used to boxcar method calls

    server should be a ServerProxy object.

    Methods can be added to the MultiCall using normal
    method call syntax e.g.:

    multicall = MultiCall(server_proxy)
    multicall.add(2,3)
    multicall.get_address("Guido")

    To execute the multicall, call the MultiCall object e.g.:

    add_result, address = multicall()
    'u'server -> an object used to boxcar method calls

    server should be a ServerProxy object.

    Methods can be added to the MultiCall using normal
    method call syntax e.g.:

    multicall = MultiCall(server_proxy)
    multicall.add(2,3)
    multicall.get_address("Guido")

    To execute the multicall, call the MultiCall object e.g.:

    add_result, address = multicall()
    'b'<%s at %#x>'u'<%s at %#x>'b'getparser() -> parser, unmarshaller

    Create an instance of the fastest available parser, and attach it
    to an unmarshalling object.  Return both objects.
    'u'getparser() -> parser, unmarshaller

    Create an instance of the fastest available parser, and attach it
    to an unmarshalling object.  Return both objects.
    'b'data [,options] -> marshalled data

    Convert an argument tuple or a Fault instance to an XML-RPC
    request (or response, if the methodresponse option is used).

    In addition to the data object, the following options can be given
    as keyword arguments:

        methodname: the method name for a methodCall packet

        methodresponse: true to create a methodResponse packet.
        If this option is used with a tuple, the tuple must be
        a singleton (i.e. it can contain only one element).

        encoding: the packet encoding (default is UTF-8)

    All byte strings in the data structure are assumed to use the
    packet encoding.  Unicode strings are automatically converted,
    where necessary.
    'u'data [,options] -> marshalled data

    Convert an argument tuple or a Fault instance to an XML-RPC
    request (or response, if the methodresponse option is used).

    In addition to the data object, the following options can be given
    as keyword arguments:

        methodname: the method name for a methodCall packet

        methodresponse: true to create a methodResponse packet.
        If this option is used with a tuple, the tuple must be
        a singleton (i.e. it can contain only one element).

        encoding: the packet encoding (default is UTF-8)

    All byte strings in the data structure are assumed to use the
    packet encoding.  Unicode strings are automatically converted,
    where necessary.
    'b'argument must be tuple or Fault instance'u'argument must be tuple or Fault instance'b'response tuple must be a singleton'u'response tuple must be a singleton'b'<?xml version='1.0'?>
'u'<?xml version='1.0'?>
'b'<methodCall>
<methodName>'u'<methodCall>
<methodName>'b'</methodName>
'u'</methodName>
'b'</methodCall>
'u'</methodCall>
'b'<methodResponse>
'u'<methodResponse>
'b'</methodResponse>
'u'</methodResponse>
'b'data -> unmarshalled data, method name

    Convert an XML-RPC packet to unmarshalled data plus a method
    name (None if not present).

    If the XML-RPC packet represents a fault condition, this function
    raises a Fault exception.
    'u'data -> unmarshalled data, method name

    Convert an XML-RPC packet to unmarshalled data plus a method
    name (None if not present).

    If the XML-RPC packet represents a fault condition, this function
    raises a Fault exception.
    'b'data -> gzip encoded data

    Encode data using the gzip content encoding as described in RFC 1952
    'u'data -> gzip encoded data

    Encode data using the gzip content encoding as described in RFC 1952
    'b'gzip encoded data -> unencoded data

    Decode data using the gzip content encoding as described in RFC 1952
    'u'gzip encoded data -> unencoded data

    Decode data using the gzip content encoding as described in RFC 1952
    'b'invalid data'u'invalid data'b'max gzipped payload length exceeded'u'max gzipped payload length exceeded'b'a file-like object to decode a response encoded with the gzip
    method, as described in RFC 1952.
    'u'a file-like object to decode a response encoded with the gzip
    method, as described in RFC 1952.
    'b'Handles an HTTP transaction to an XML-RPC server.'u'Handles an HTTP transaction to an XML-RPC server.'b'Python-xmlrpc/%s'u'Python-xmlrpc/%s'b'text/xml'u'text/xml'b'getheader'u'getheader'b'body:'u'body:'b'Handles an HTTPS transaction to an XML-RPC server.'u'Handles an HTTPS transaction to an XML-RPC server.'b'your version of http.client doesn't support HTTPS'u'your version of http.client doesn't support HTTPS'b'uri [,options] -> a logical connection to an XML-RPC server

    uri is the connection point on the server, given as
    scheme://host/target.

    The standard implementation always supports the "http" scheme.  If
    SSL socket support is available (Python 2.0), it also supports
    "https".

    If the target part and the slash preceding it are both omitted,
    "/RPC2" is assumed.

    The following options can be given as keyword arguments:

        transport: a transport factory
        encoding: the request encoding (default is UTF-8)

    All 8-bit strings passed to the server proxy are assumed to use
    the given encoding.
    'u'uri [,options] -> a logical connection to an XML-RPC server

    uri is the connection point on the server, given as
    scheme://host/target.

    The standard implementation always supports the "http" scheme.  If
    SSL socket support is available (Python 2.0), it also supports
    "https".

    If the target part and the slash preceding it are both omitted,
    "/RPC2" is assumed.

    The following options can be given as keyword arguments:

        transport: a transport factory
        encoding: the request encoding (default is UTF-8)

    All 8-bit strings passed to the server proxy are assumed to use
    the given encoding.
    'b'unsupported XML-RPC protocol'u'unsupported XML-RPC protocol'b'/RPC2'u'/RPC2'b'<%s for %s%s>'u'<%s for %s%s>'b'A workaround to get special attributes on the ServerProxy
           without interfering with the magic __getattr__
        'u'A workaround to get special attributes on the ServerProxy
           without interfering with the magic __getattr__
        'b'transport'u'transport'b'Attribute %r not found'u'Attribute %r not found'b'http://localhost:8000'u'http://localhost:8000'A generic class to build line-oriented command interpreters.

Interpreters constructed with this class obey the following conventions:

1. End of file on input is processed as the command 'EOF'.
2. A command is parsed out of each line by collecting the prefix composed
   of characters in the identchars member.
3. A command `foo' is dispatched to a method 'do_foo()'; the do_ method
   is passed a single argument consisting of the remainder of the line.
4. Typing an empty line repeats the last command.  (Actually, it calls the
   method `emptyline', which may be overridden in a subclass.)
5. There is a predefined `help' method.  Given an argument `topic', it
   calls the command `help_topic'.  With no arguments, it lists all topics
   with defined help_ functions, broken into up to three topics; documented
   commands, miscellaneous help topics, and undocumented commands.
6. The command '?' is a synonym for `help'.  The command '!' is a synonym
   for `shell', if a do_shell method exists.
7. If completion is enabled, completing commands will be done automatically,
   and completing of commands args is done by calling complete_foo() with
   arguments text, line, begidx, endidx.  text is string we are matching
   against, all returned matches must begin with it.  line is the current
   input line (lstripped), begidx and endidx are the beginning and end
   indexes of the text being matched, which could be used to provide
   different completion depending upon which position the argument is in.

The `default' method may be overridden to intercept commands for which there
is no do_ method.

The `completedefault' method may be overridden to intercept completions for
commands that have no complete_ method.

The data member `self.ruler' sets the character used to draw separator lines
in the help messages.  If empty, no ruler line is drawn.  It defaults to "=".

If the value of `self.intro' is nonempty when the cmdloop method is called,
it is printed out on interpreter startup.  This value may be overridden
via an optional argument to the cmdloop() method.

The data members `self.doc_header', `self.misc_header', and
`self.undoc_header' set the headers used for the help function's
listings of documented functions, miscellaneous topics, and undocumented
functions respectively.
Cmd(Cmd) PROMPTIDENTCHARSA simple framework for writing line-oriented command interpreters.

    These are often useful for test harnesses, administrative tools, and
    prototypes that will later be wrapped in a more sophisticated interface.

    A Cmd instance or subclass instance is a line-oriented interpreter
    framework.  There is no good reason to instantiate Cmd itself; rather,
    it's useful as a superclass of an interpreter class you define yourself
    in order to inherit Cmd's methods and encapsulate action methods.

    promptidentcharsrulerlastcmddoc_leaderDocumented commands (type help <topic>):doc_headerMiscellaneous help topics:misc_headerUndocumented commands:undoc_header*** No help on %snohelpuse_rawinputtabcompletekeyInstantiate a line-oriented interpreter framework.

        The optional argument 'completekey' is the readline name of a
        completion key; it defaults to the Tab key. If completekey is
        not None and the readline module is available, command completion
        is done automatically. The optional arguments stdin and stdout
        specify alternate input and output file objects; if not specified,
        sys.stdin and sys.stdout are used.

        cmdqueuecmdloopRepeatedly issue a prompt, accept input, parse an initial prefix
        off the received input, and dispatch to action methods, passing them
        the remainder of the line as argument.

        preloopget_completerold_completerset_completercompleteparse_and_bind: completeEOFprecmdonecmdpostcmdpostloopHook method executed just before the command line is
        interpreted, but after the input prompt is generated and issued.

        Hook method executed just after a command dispatch is finished.Hook method executed once when the cmdloop() method is called.Hook method executed once when the cmdloop() method is about to
        return.

        parselineParse the line into a command name and a string containing
        the arguments.  Returns a tuple containing (command, args, line).
        'command' and 'args' may be None if the line couldn't be parsed.
        help do_shellshell Interpret the argument as though it had been typed in response
        to the prompt.

        This may be overridden, but should not normally need to be;
        see the precmd() and postcmd() methods for useful execution hooks.
        The return value is a flag indicating whether interpretation of
        commands by the interpreter should stop.

        emptylinedo_Called when an empty line is entered in response to the prompt.

        If this method is not overridden, it repeats the last nonempty
        command entered.

        Called on an input line when the command prefix is not recognized.

        If this method is not overridden, it prints an error message and
        returns.

        *** Unknown syntax: %s
completedefaultignoredMethod called to complete an input line when no command-specific
        complete_*() method is available.

        By default, it returns an empty list.

        completenamesdotextget_namesReturn the next possible completion for 'text'.

        If a command has not been entered, then complete against command list.
        Otherwise try to call complete_<command> to get list of completions.
        get_line_bufferoriglinestrippedget_begidxbegidxget_endidxendidxcompfunccomplete_completion_matchescomplete_helphelp_topicsdo_helpList available commands with "help" or detailed help with "help cmd".%s
cmds_doccmds_undocprevnameprint_topicscmdscmdlenmaxcolcolumnizedisplaywidthDisplay a list of strings as a compact set of columns.

        Each column is only as wide as necessary.
        Columns are separated by two spaces (one was not legible enough).
        <empty>
nonstringslist[i] not a string for i in %snrowsncolscolwidthstotwidthtexts# This method used to pull in base class attributes# at a time dir() didn't do it yet.# XXX check arg syntax# There can be duplicates if routines overridden# Try every row count from 1 upwardsb'A generic class to build line-oriented command interpreters.

Interpreters constructed with this class obey the following conventions:

1. End of file on input is processed as the command 'EOF'.
2. A command is parsed out of each line by collecting the prefix composed
   of characters in the identchars member.
3. A command `foo' is dispatched to a method 'do_foo()'; the do_ method
   is passed a single argument consisting of the remainder of the line.
4. Typing an empty line repeats the last command.  (Actually, it calls the
   method `emptyline', which may be overridden in a subclass.)
5. There is a predefined `help' method.  Given an argument `topic', it
   calls the command `help_topic'.  With no arguments, it lists all topics
   with defined help_ functions, broken into up to three topics; documented
   commands, miscellaneous help topics, and undocumented commands.
6. The command '?' is a synonym for `help'.  The command '!' is a synonym
   for `shell', if a do_shell method exists.
7. If completion is enabled, completing commands will be done automatically,
   and completing of commands args is done by calling complete_foo() with
   arguments text, line, begidx, endidx.  text is string we are matching
   against, all returned matches must begin with it.  line is the current
   input line (lstripped), begidx and endidx are the beginning and end
   indexes of the text being matched, which could be used to provide
   different completion depending upon which position the argument is in.

The `default' method may be overridden to intercept commands for which there
is no do_ method.

The `completedefault' method may be overridden to intercept completions for
commands that have no complete_ method.

The data member `self.ruler' sets the character used to draw separator lines
in the help messages.  If empty, no ruler line is drawn.  It defaults to "=".

If the value of `self.intro' is nonempty when the cmdloop method is called,
it is printed out on interpreter startup.  This value may be overridden
via an optional argument to the cmdloop() method.

The data members `self.doc_header', `self.misc_header', and
`self.undoc_header' set the headers used for the help function's
listings of documented functions, miscellaneous topics, and undocumented
functions respectively.
'u'A generic class to build line-oriented command interpreters.

Interpreters constructed with this class obey the following conventions:

1. End of file on input is processed as the command 'EOF'.
2. A command is parsed out of each line by collecting the prefix composed
   of characters in the identchars member.
3. A command `foo' is dispatched to a method 'do_foo()'; the do_ method
   is passed a single argument consisting of the remainder of the line.
4. Typing an empty line repeats the last command.  (Actually, it calls the
   method `emptyline', which may be overridden in a subclass.)
5. There is a predefined `help' method.  Given an argument `topic', it
   calls the command `help_topic'.  With no arguments, it lists all topics
   with defined help_ functions, broken into up to three topics; documented
   commands, miscellaneous help topics, and undocumented commands.
6. The command '?' is a synonym for `help'.  The command '!' is a synonym
   for `shell', if a do_shell method exists.
7. If completion is enabled, completing commands will be done automatically,
   and completing of commands args is done by calling complete_foo() with
   arguments text, line, begidx, endidx.  text is string we are matching
   against, all returned matches must begin with it.  line is the current
   input line (lstripped), begidx and endidx are the beginning and end
   indexes of the text being matched, which could be used to provide
   different completion depending upon which position the argument is in.

The `default' method may be overridden to intercept commands for which there
is no do_ method.

The `completedefault' method may be overridden to intercept completions for
commands that have no complete_ method.

The data member `self.ruler' sets the character used to draw separator lines
in the help messages.  If empty, no ruler line is drawn.  It defaults to "=".

If the value of `self.intro' is nonempty when the cmdloop method is called,
it is printed out on interpreter startup.  This value may be overridden
via an optional argument to the cmdloop() method.

The data members `self.doc_header', `self.misc_header', and
`self.undoc_header' set the headers used for the help function's
listings of documented functions, miscellaneous topics, and undocumented
functions respectively.
'b'Cmd'u'Cmd'b'(Cmd) 'u'(Cmd) 'b'A simple framework for writing line-oriented command interpreters.

    These are often useful for test harnesses, administrative tools, and
    prototypes that will later be wrapped in a more sophisticated interface.

    A Cmd instance or subclass instance is a line-oriented interpreter
    framework.  There is no good reason to instantiate Cmd itself; rather,
    it's useful as a superclass of an interpreter class you define yourself
    in order to inherit Cmd's methods and encapsulate action methods.

    'u'A simple framework for writing line-oriented command interpreters.

    These are often useful for test harnesses, administrative tools, and
    prototypes that will later be wrapped in a more sophisticated interface.

    A Cmd instance or subclass instance is a line-oriented interpreter
    framework.  There is no good reason to instantiate Cmd itself; rather,
    it's useful as a superclass of an interpreter class you define yourself
    in order to inherit Cmd's methods and encapsulate action methods.

    'b'Documented commands (type help <topic>):'u'Documented commands (type help <topic>):'b'Miscellaneous help topics:'u'Miscellaneous help topics:'b'Undocumented commands:'u'Undocumented commands:'b'*** No help on %s'u'*** No help on %s'b'tab'u'tab'b'Instantiate a line-oriented interpreter framework.

        The optional argument 'completekey' is the readline name of a
        completion key; it defaults to the Tab key. If completekey is
        not None and the readline module is available, command completion
        is done automatically. The optional arguments stdin and stdout
        specify alternate input and output file objects; if not specified,
        sys.stdin and sys.stdout are used.

        'u'Instantiate a line-oriented interpreter framework.

        The optional argument 'completekey' is the readline name of a
        completion key; it defaults to the Tab key. If completekey is
        not None and the readline module is available, command completion
        is done automatically. The optional arguments stdin and stdout
        specify alternate input and output file objects; if not specified,
        sys.stdin and sys.stdout are used.

        'b'Repeatedly issue a prompt, accept input, parse an initial prefix
        off the received input, and dispatch to action methods, passing them
        the remainder of the line as argument.

        'u'Repeatedly issue a prompt, accept input, parse an initial prefix
        off the received input, and dispatch to action methods, passing them
        the remainder of the line as argument.

        'b': complete'u': complete'b'EOF'u'EOF'b'Hook method executed just before the command line is
        interpreted, but after the input prompt is generated and issued.

        'u'Hook method executed just before the command line is
        interpreted, but after the input prompt is generated and issued.

        'b'Hook method executed just after a command dispatch is finished.'u'Hook method executed just after a command dispatch is finished.'b'Hook method executed once when the cmdloop() method is called.'u'Hook method executed once when the cmdloop() method is called.'b'Hook method executed once when the cmdloop() method is about to
        return.

        'u'Hook method executed once when the cmdloop() method is about to
        return.

        'b'Parse the line into a command name and a string containing
        the arguments.  Returns a tuple containing (command, args, line).
        'command' and 'args' may be None if the line couldn't be parsed.
        'u'Parse the line into a command name and a string containing
        the arguments.  Returns a tuple containing (command, args, line).
        'command' and 'args' may be None if the line couldn't be parsed.
        'b'help 'u'help 'b'do_shell'u'do_shell'b'shell 'u'shell 'b'Interpret the argument as though it had been typed in response
        to the prompt.

        This may be overridden, but should not normally need to be;
        see the precmd() and postcmd() methods for useful execution hooks.
        The return value is a flag indicating whether interpretation of
        commands by the interpreter should stop.

        'u'Interpret the argument as though it had been typed in response
        to the prompt.

        This may be overridden, but should not normally need to be;
        see the precmd() and postcmd() methods for useful execution hooks.
        The return value is a flag indicating whether interpretation of
        commands by the interpreter should stop.

        'b'do_'u'do_'b'Called when an empty line is entered in response to the prompt.

        If this method is not overridden, it repeats the last nonempty
        command entered.

        'u'Called when an empty line is entered in response to the prompt.

        If this method is not overridden, it repeats the last nonempty
        command entered.

        'b'Called on an input line when the command prefix is not recognized.

        If this method is not overridden, it prints an error message and
        returns.

        'u'Called on an input line when the command prefix is not recognized.

        If this method is not overridden, it prints an error message and
        returns.

        'b'*** Unknown syntax: %s
'u'*** Unknown syntax: %s
'b'Method called to complete an input line when no command-specific
        complete_*() method is available.

        By default, it returns an empty list.

        'u'Method called to complete an input line when no command-specific
        complete_*() method is available.

        By default, it returns an empty list.

        'b'Return the next possible completion for 'text'.

        If a command has not been entered, then complete against command list.
        Otherwise try to call complete_<command> to get list of completions.
        'u'Return the next possible completion for 'text'.

        If a command has not been entered, then complete against command list.
        Otherwise try to call complete_<command> to get list of completions.
        'b'complete_'u'complete_'b'help_'u'help_'b'List available commands with "help" or detailed help with "help cmd".'u'List available commands with "help" or detailed help with "help cmd".'b'%s
'u'%s
'b'Display a list of strings as a compact set of columns.

        Each column is only as wide as necessary.
        Columns are separated by two spaces (one was not legible enough).
        'u'Display a list of strings as a compact set of columns.

        Each column is only as wide as necessary.
        Columns are separated by two spaces (one was not legible enough).
        'b'<empty>
'u'<empty>
'b'list[i] not a string for i in %s'u'list[i] not a string for i in %s'u'cmd'Utilities needed to emulate Python's interactive interpreter.

codeopCommandCompilercompile_commandInteractiveInterpreterInteractiveConsoleinteractBase class for InteractiveConsole.

    This class deals with parsing and interpreter state (the user's
    namespace); it doesn't deal with input buffering or prompting or
    input file naming (the filename is always passed in explicitly).

    Constructor.

        The optional 'locals' argument specifies the dictionary in
        which code will be executed; it defaults to a newly created
        dictionary with key "__name__" set to "__console__" and key
        "__doc__" set to None.

        __console__runsource<input>symbolCompile and run some source in the interpreter.

        Arguments are as for compile_command().

        One of several things can happen:

        1) The input is incorrect; compile_command() raised an
        exception (SyntaxError or OverflowError).  A syntax traceback
        will be printed by calling the showsyntaxerror() method.

        2) The input is incomplete, and more input is required;
        compile_command() returned None.  Nothing happens.

        3) The input is complete; compile_command() returned a code
        object.  The code is executed by calling self.runcode() (which
        also handles run-time exceptions, except for SystemExit).

        The return value is True in case 2, False in the other cases (unless
        an exception is raised).  The return value can be used to
        decide whether to use sys.ps1 or sys.ps2 to prompt the next
        line.

        showsyntaxerrorruncodeExecute a code object.

        When an exception occurs, self.showtraceback() is called to
        display a traceback.  All exceptions are caught except
        SystemExit, which is reraised.

        A note about KeyboardInterrupt: this exception may occur
        elsewhere in this code, and may not always be caught.  The
        caller should be prepared to deal with it.

        showtracebackDisplay the syntax error that just occurred.

        This doesn't display a stack trace because there isn't one.

        If a filename is given, it is stuffed in the exception instead
        of what was there before (because Python's parser always uses
        "<string>" when reading from a string).

        The output is written by self.write(), below.

        dummy_filenameDisplay the exception that just occurred.

        We remove the first stack item because it is our own code.

        The output is written by self.write(), below.

        last_tbformat_exceptionWrite a string.

        The base implementation writes to sys.stderr; a subclass may
        replace this with a different implementation.

        Closely emulate the behavior of the interactive Python interpreter.

    This class builds on InteractiveInterpreter and adds prompting
    using the familiar sys.ps1 and sys.ps2, and input buffering.

    <console>Constructor.

        The optional locals argument will be passed to the
        InteractiveInterpreter base class.

        The optional filename argument should specify the (file)name
        of the input stream; it will show up in tracebacks.

        resetbufferReset the input buffer.bannerexitmsgClosely emulate the interactive Python console.

        The optional banner argument specifies the banner to print
        before the first interaction; by default it prints a banner
        similar to the one printed by the real Python interpreter,
        followed by the current class name in parentheses (so as not
        to confuse this with the real interpreter -- since it's so
        close!).

        The optional exitmsg argument specifies the exit message
        printed when exiting. Pass the empty string to suppress
        printing an exit message. If exitmsg is not given or None,
        a default message is printed.

        ps1>>> ps2... Type "help", "copyright", "credits" or "license" for more information.cprtPython %s on %s
%s
(%s)
morepush
KeyboardInterrupt
now exiting %s...
Push a line to the interpreter.

        The line should not have a trailing newline; it may have
        internal newlines.  The line is appended to a buffer and the
        interpreter's runsource() method is called with the
        concatenated contents of the buffer as source.  If this
        indicates that the command was executed or invalid, the buffer
        is reset; otherwise, the command is incomplete, and the buffer
        is left as it was after the line was appended.  The return
        value is 1 if more input is required, 0 if the line was dealt
        with in some way (this is the same as runsource()).

        Write a prompt and read a line.

        The returned line does not include the trailing newline.
        When the user enters the EOF key sequence, EOFError is raised.

        The base implementation uses the built-in function
        input(); a subclass may replace this with a different
        implementation.

        readfuncClosely emulate the interactive Python interpreter.

    This is a backwards compatible interface to the InteractiveConsole
    class.  When readfunc is not specified, it attempts to import the
    readline module to enable GNU readline if it is available.

    Arguments (all optional, all default to None):

    banner -- passed to InteractiveConsole.interact()
    readfunc -- if not None, replaces InteractiveConsole.raw_input()
    local -- passed to InteractiveInterpreter.__init__()
    exitmsg -- passed to InteractiveConsole.interact()

    console-qdon't print version and copyright messages# Inspired by similar code by Jeff Epler and Fredrik Lundh.# Case 1# Case 2# Case 3# Work hard to stuff the correct filename in the exception# Not the format we expect; leave it alone# Stuff in the right filename# If someone has set sys.excepthook, we let that take precedence# over self.writeb'Utilities needed to emulate Python's interactive interpreter.

'u'Utilities needed to emulate Python's interactive interpreter.

'b'InteractiveInterpreter'u'InteractiveInterpreter'b'InteractiveConsole'u'InteractiveConsole'b'interact'u'interact'b'compile_command'u'compile_command'b'Base class for InteractiveConsole.

    This class deals with parsing and interpreter state (the user's
    namespace); it doesn't deal with input buffering or prompting or
    input file naming (the filename is always passed in explicitly).

    'u'Base class for InteractiveConsole.

    This class deals with parsing and interpreter state (the user's
    namespace); it doesn't deal with input buffering or prompting or
    input file naming (the filename is always passed in explicitly).

    'b'Constructor.

        The optional 'locals' argument specifies the dictionary in
        which code will be executed; it defaults to a newly created
        dictionary with key "__name__" set to "__console__" and key
        "__doc__" set to None.

        'u'Constructor.

        The optional 'locals' argument specifies the dictionary in
        which code will be executed; it defaults to a newly created
        dictionary with key "__name__" set to "__console__" and key
        "__doc__" set to None.

        'b'__console__'u'__console__'b'<input>'u'<input>'b'Compile and run some source in the interpreter.

        Arguments are as for compile_command().

        One of several things can happen:

        1) The input is incorrect; compile_command() raised an
        exception (SyntaxError or OverflowError).  A syntax traceback
        will be printed by calling the showsyntaxerror() method.

        2) The input is incomplete, and more input is required;
        compile_command() returned None.  Nothing happens.

        3) The input is complete; compile_command() returned a code
        object.  The code is executed by calling self.runcode() (which
        also handles run-time exceptions, except for SystemExit).

        The return value is True in case 2, False in the other cases (unless
        an exception is raised).  The return value can be used to
        decide whether to use sys.ps1 or sys.ps2 to prompt the next
        line.

        'u'Compile and run some source in the interpreter.

        Arguments are as for compile_command().

        One of several things can happen:

        1) The input is incorrect; compile_command() raised an
        exception (SyntaxError or OverflowError).  A syntax traceback
        will be printed by calling the showsyntaxerror() method.

        2) The input is incomplete, and more input is required;
        compile_command() returned None.  Nothing happens.

        3) The input is complete; compile_command() returned a code
        object.  The code is executed by calling self.runcode() (which
        also handles run-time exceptions, except for SystemExit).

        The return value is True in case 2, False in the other cases (unless
        an exception is raised).  The return value can be used to
        decide whether to use sys.ps1 or sys.ps2 to prompt the next
        line.

        'b'Execute a code object.

        When an exception occurs, self.showtraceback() is called to
        display a traceback.  All exceptions are caught except
        SystemExit, which is reraised.

        A note about KeyboardInterrupt: this exception may occur
        elsewhere in this code, and may not always be caught.  The
        caller should be prepared to deal with it.

        'u'Execute a code object.

        When an exception occurs, self.showtraceback() is called to
        display a traceback.  All exceptions are caught except
        SystemExit, which is reraised.

        A note about KeyboardInterrupt: this exception may occur
        elsewhere in this code, and may not always be caught.  The
        caller should be prepared to deal with it.

        'b'Display the syntax error that just occurred.

        This doesn't display a stack trace because there isn't one.

        If a filename is given, it is stuffed in the exception instead
        of what was there before (because Python's parser always uses
        "<string>" when reading from a string).

        The output is written by self.write(), below.

        'u'Display the syntax error that just occurred.

        This doesn't display a stack trace because there isn't one.

        If a filename is given, it is stuffed in the exception instead
        of what was there before (because Python's parser always uses
        "<string>" when reading from a string).

        The output is written by self.write(), below.

        'b'Display the exception that just occurred.

        We remove the first stack item because it is our own code.

        The output is written by self.write(), below.

        'u'Display the exception that just occurred.

        We remove the first stack item because it is our own code.

        The output is written by self.write(), below.

        'b'Write a string.

        The base implementation writes to sys.stderr; a subclass may
        replace this with a different implementation.

        'u'Write a string.

        The base implementation writes to sys.stderr; a subclass may
        replace this with a different implementation.

        'b'Closely emulate the behavior of the interactive Python interpreter.

    This class builds on InteractiveInterpreter and adds prompting
    using the familiar sys.ps1 and sys.ps2, and input buffering.

    'u'Closely emulate the behavior of the interactive Python interpreter.

    This class builds on InteractiveInterpreter and adds prompting
    using the familiar sys.ps1 and sys.ps2, and input buffering.

    'b'<console>'u'<console>'b'Constructor.

        The optional locals argument will be passed to the
        InteractiveInterpreter base class.

        The optional filename argument should specify the (file)name
        of the input stream; it will show up in tracebacks.

        'u'Constructor.

        The optional locals argument will be passed to the
        InteractiveInterpreter base class.

        The optional filename argument should specify the (file)name
        of the input stream; it will show up in tracebacks.

        'b'Reset the input buffer.'u'Reset the input buffer.'b'Closely emulate the interactive Python console.

        The optional banner argument specifies the banner to print
        before the first interaction; by default it prints a banner
        similar to the one printed by the real Python interpreter,
        followed by the current class name in parentheses (so as not
        to confuse this with the real interpreter -- since it's so
        close!).

        The optional exitmsg argument specifies the exit message
        printed when exiting. Pass the empty string to suppress
        printing an exit message. If exitmsg is not given or None,
        a default message is printed.

        'u'Closely emulate the interactive Python console.

        The optional banner argument specifies the banner to print
        before the first interaction; by default it prints a banner
        similar to the one printed by the real Python interpreter,
        followed by the current class name in parentheses (so as not
        to confuse this with the real interpreter -- since it's so
        close!).

        The optional exitmsg argument specifies the exit message
        printed when exiting. Pass the empty string to suppress
        printing an exit message. If exitmsg is not given or None,
        a default message is printed.

        'b'>>> 'u'>>> 'b'... 'u'... 'b'Type "help", "copyright", "credits" or "license" for more information.'u'Type "help", "copyright", "credits" or "license" for more information.'b'Python %s on %s
%s
(%s)
'u'Python %s on %s
%s
(%s)
'b'
KeyboardInterrupt
'u'
KeyboardInterrupt
'b'now exiting %s...
'u'now exiting %s...
'b'Push a line to the interpreter.

        The line should not have a trailing newline; it may have
        internal newlines.  The line is appended to a buffer and the
        interpreter's runsource() method is called with the
        concatenated contents of the buffer as source.  If this
        indicates that the command was executed or invalid, the buffer
        is reset; otherwise, the command is incomplete, and the buffer
        is left as it was after the line was appended.  The return
        value is 1 if more input is required, 0 if the line was dealt
        with in some way (this is the same as runsource()).

        'u'Push a line to the interpreter.

        The line should not have a trailing newline; it may have
        internal newlines.  The line is appended to a buffer and the
        interpreter's runsource() method is called with the
        concatenated contents of the buffer as source.  If this
        indicates that the command was executed or invalid, the buffer
        is reset; otherwise, the command is incomplete, and the buffer
        is left as it was after the line was appended.  The return
        value is 1 if more input is required, 0 if the line was dealt
        with in some way (this is the same as runsource()).

        'b'Write a prompt and read a line.

        The returned line does not include the trailing newline.
        When the user enters the EOF key sequence, EOFError is raised.

        The base implementation uses the built-in function
        input(); a subclass may replace this with a different
        implementation.

        'u'Write a prompt and read a line.

        The returned line does not include the trailing newline.
        When the user enters the EOF key sequence, EOFError is raised.

        The base implementation uses the built-in function
        input(); a subclass may replace this with a different
        implementation.

        'b'Closely emulate the interactive Python interpreter.

    This is a backwards compatible interface to the InteractiveConsole
    class.  When readfunc is not specified, it attempts to import the
    readline module to enable GNU readline if it is available.

    Arguments (all optional, all default to None):

    banner -- passed to InteractiveConsole.interact()
    readfunc -- if not None, replaces InteractiveConsole.raw_input()
    local -- passed to InteractiveInterpreter.__init__()
    exitmsg -- passed to InteractiveConsole.interact()

    'u'Closely emulate the interactive Python interpreter.

    This is a backwards compatible interface to the InteractiveConsole
    class.  When readfunc is not specified, it attempts to import the
    readline module to enable GNU readline if it is available.

    Arguments (all optional, all default to None):

    banner -- passed to InteractiveConsole.interact()
    readfunc -- if not None, replaces InteractiveConsole.raw_input()
    local -- passed to InteractiveInterpreter.__init__()
    exitmsg -- passed to InteractiveConsole.interact()

    'b'-q'u'-q'b'don't print version and copyright messages'u'don't print version and copyright messages'u'code' codecs -- Python Codec Registry, API and helpers.


Written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

whyFailed to load the builtin codecs: %sEncodedFileBOMBOM_BEBOM_LEBOM32_BEBOM32_LEBOM64_BEBOM64_LEBOM_UTF16BOM_UTF32CodecIncrementalEncoderStreamReaderStreamWriterStreamReaderWriterStreamRecodergetencodergetdecodergetincrementalencodergetincrementaldecodergetreadergetwriteriterdecodestrict_errorsignore_errorsreplace_errorsxmlcharrefreplace_errorsbackslashreplace_errorsnamereplace_errors    Codec details when looking up the codec registry_is_text_encodingstreamreaderstreamwriterincrementalencoderincrementaldecoder<%s.%s object for encoding %s at %#x> Defines the interface for stateless encoders/decoders.

        The .encode()/.decode() methods may use different error
        handling schemes by providing the errors argument. These
        string values are predefined:

         'strict' - raise a ValueError error (or a subclass)
         'ignore' - ignore the character and continue with the next
         'replace' - replace with a suitable replacement character;
                    Python will use the official U+FFFD REPLACEMENT
                    CHARACTER for the builtin Unicode codecs on
                    decoding and '?' on encoding.
         'surrogateescape' - replace with private code points U+DCnn.
         'xmlcharrefreplace' - Replace with the appropriate XML
                               character reference (only for encoding).
         'backslashreplace'  - Replace with backslashed escape sequences.
         'namereplace'       - Replace with \N{...} escape sequences
                               (only for encoding).

        The set of allowed values can be extended via register_error.

     Encodes the object input and returns a tuple (output
            object, length consumed).

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamWriter for codecs which have to keep state in order to
            make encoding efficient.

            The encoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

         Decodes the object input and returns a tuple (output
            object, length consumed).

            input must be an object which provides the bf_getreadbuf
            buffer slot. Python strings, buffer objects and memory
            mapped files are examples of objects providing this slot.

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamReader for codecs which have to keep state in order to
            make decoding efficient.

            The decoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        
    An IncrementalEncoder encodes an input in multiple steps. The input can
    be passed piece by piece to the encode() method. The IncrementalEncoder
    remembers the state of the encoding process between calls to encode().
    
        Creates an IncrementalEncoder instance.

        The IncrementalEncoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        
        Encodes input and returns the resulting object.
        
        Resets the encoder to the initial state.
        
        Return the current state of the encoder.
        
        Set the current state of the encoder. state must have been
        returned by getstate().
        BufferedIncrementalEncoder
    This subclass of IncrementalEncoder can be used as the baseclass for an
    incremental encoder if the encoder must keep some of the output in a
    buffer between calls to encode().
    _buffer_encodeconsumed
    An IncrementalDecoder decodes an input in multiple steps. The input can
    be passed piece by piece to the decode() method. The IncrementalDecoder
    remembers the state of the decoding process between calls to decode().
    
        Create an IncrementalDecoder instance.

        The IncrementalDecoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        
        Decode input and returns the resulting object.
        
        Reset the decoder to the initial state.
        
        Return the current state of the decoder.

        This must be a (buffered_input, additional_state_info) tuple.
        buffered_input must be a bytes object containing bytes that
        were passed to decode() that have not yet been converted.
        additional_state_info must be a non-negative integer
        representing the state of the decoder WITHOUT yet having
        processed the contents of buffered_input.  In the initial state
        and after reset(), getstate() must return (b"", 0).
        
        Set the current state of the decoder.

        state must have been returned by getstate().  The effect of
        setstate((b"", 0)) must be equivalent to reset().
        BufferedIncrementalDecoder
    This subclass of IncrementalDecoder can be used as the baseclass for an
    incremental decoder if the decoder must be able to handle incomplete
    byte sequences.
    _buffer_decode Creates a StreamWriter instance.

            stream must be a file-like object open for writing.

            The StreamWriter may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'xmlcharrefreplace' - Replace with the appropriate XML
                                   character reference.
             'backslashreplace'  - Replace with backslashed escape
                                   sequences.
             'namereplace'       - Replace with \N{...} escape sequences.

            The set of allowed parameter values can be extended via
            register_error.
         Writes the object's contents encoded to self.stream.
         Writes the concatenated list of strings to the stream
            using .write().
         Resets the codec buffers used for keeping internal state.

            Calling this method should ensure that the data on the
            output is put into a clean state, that allows appending
            of new fresh data without having to rescan the whole
            stream to recover state.

         Inherit all other methods from the underlying stream.
        charbuffertype Creates a StreamReader instance.

            stream must be a file-like object open for reading.

            The StreamReader may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'backslashreplace' - Replace with backslashed escape sequences;

            The set of allowed parameter values can be extended via
            register_error.
        bytebuffer_empty_charbuffercharbufferlinebufferfirstline Decodes data from the stream self.stream and returns the
            resulting object.

            chars indicates the number of decoded code points or bytes to
            return. read() will never return more data than requested,
            but it might return less, if there is not enough available.

            size indicates the approximate maximum number of decoded
            bytes or code points to read for decoding. The decoder
            can modify this setting as appropriate. The default value
            -1 indicates to read and decode as much as possible.  size
            is intended to prevent having to decode huge files in one
            step.

            If firstline is true, and a UnicodeDecodeError happens
            after the first line terminator in the input only the first line
            will be returned, the rest of the input will be kept until the
            next call to read().

            The method should use a greedy read strategy, meaning that
            it should read as much data as is allowed within the
            definition of the encoding and the given size, e.g.  if
            optional encoding endings or state markers are available
            on the stream, these should be read too.
        newdatanewcharsdecodedbytes Read one line from the input stream and return the
            decoded data.

            size, if given, is passed as size argument to the
            read() method.

        72readsizeline0withendline0withoutend8000sizehint Read all lines available on the input stream
            and return them as a list.

            Line breaks are implemented using the codec's decoder
            method and are included in the list entries.

            sizehint, if given, is ignored since there is no efficient
            way to finding the true end-of-line.

         Resets the codec buffers used for keeping internal state.

            Note that no stream repositioning should take place.
            This method is primarily intended to be able to recover
            from decoding errors.

         Set the input stream's current position.

            Resets the codec buffers used for keeping state.
         Return the next decoded line from the input stream. StreamReaderWriter instances allow wrapping streams which
        work in both read and write modes.

        The design is such that one can use the factory functions
        returned by the codec.lookup() function to construct the
        instance.

    ReaderWriter Creates a StreamReaderWriter instance.

            stream must be a Stream-like object.

            Reader, Writer must be factory functions or classes
            providing the StreamReader, StreamWriter interface resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        writer StreamRecoder instances translate data from one encoding to another.

        They use the complete set of APIs returned by the
        codecs.lookup() function to implement their task.

        Data written to the StreamRecoder is first decoded into an
        intermediate format (depending on the "decode" codec) and then
        written to the underlying stream using an instance of the provided
        Writer class.

        In the other direction, data is read from the underlying stream using
        a Reader instance and then encoded and returned to the caller.

    data_encodingfile_encoding Creates a StreamRecoder instance which implements a two-way
            conversion: encode and decode work on the frontend (the
            data visible to .read() and .write()) while Reader and Writer
            work on the backend (the data in stream).

            You can use these objects to do transparent
            transcodings from e.g. latin-1 to utf-8 and back.

            stream must be a file-like object.

            encode and decode must adhere to the Codec interface; Reader and
            Writer must be factory functions or classes providing the
            StreamReader and StreamWriter interfaces resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        bytesencodedbytesdecodedbuffering Open an encoded file using the given mode and return
        a wrapped version providing transparent encoding/decoding.

        Note: The wrapped version will only accept the object format
        defined by the codecs, i.e. Unicode objects for most builtin
        codecs. Output is also codec dependent and will usually be
        Unicode as well.

        If encoding is not None, then the
        underlying encoded files are always opened in binary mode.
        The default file mode is 'r', meaning to open the file in read mode.

        encoding specifies the encoding which is to be used for the
        file.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        buffering has the same meaning as for the builtin open() API.
        It defaults to -1 which means that the default buffer size will
        be used.

        The returned wrapped file object provides an extra attribute
        .encoding which allows querying the used encoding. This
        attribute is only available if an encoding was specified as
        parameter.

    srw Return a wrapped version of file which provides transparent
        encoding translation.

        Data written to the wrapped file is decoded according
        to the given data_encoding and then encoded to the underlying
        file using file_encoding. The intermediate data type
        will usually be Unicode but depends on the specified codecs.

        Bytes read from the file are decoded using file_encoding and then
        passed back to the caller encoded using data_encoding.

        If file_encoding is not given, it defaults to data_encoding.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        The returned wrapped file object provides two extra attributes
        .data_encoding and .file_encoding which reflect the given
        parameters of the same name. The attributes can be used for
        introspection by Python programs.

    data_infofile_infosr Lookup up the codec for the given encoding and return
        its encoder function.

        Raises a LookupError in case the encoding cannot be found.

     Lookup up the codec for the given encoding and return
        its decoder function.

        Raises a LookupError in case the encoding cannot be found.

     Lookup up the codec for the given encoding and return
        its IncrementalEncoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental encoder.

     Lookup up the codec for the given encoding and return
        its IncrementalDecoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental decoder.

     Lookup up the codec for the given encoding and return
        its StreamReader class or factory function.

        Raises a LookupError in case the encoding cannot be found.

     Lookup up the codec for the given encoding and return
        its StreamWriter class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    
    Encoding iterator.

    Encodes the input strings from the iterator using an IncrementalEncoder.

    errors and kwargs are passed through to the IncrementalEncoder
    constructor.
    
    Decoding iterator.

    Decodes the input strings from the iterator using an IncrementalDecoder.

    errors and kwargs are passed through to the IncrementalDecoder
    constructor.
    make_identity_dictrng make_identity_dict(rng) -> dict

        Return a dictionary where elements of the rng sequence are
        mapped to themselves.

    make_encoding_mapdecoding_map Creates an encoding map from a decoding map.

        If a target mapping in the decoding map occurs multiple
        times, then that target is mapped to None (undefined mapping),
        causing an exception when encountered by the charmap codec
        during translation.

        One example where this happens is cp875.py which decodes
        multiple character to \u001a.

    namereplace_false### Registry and builtin stateless codec functions### Constants# Byte Order Mark (BOM = ZERO WIDTH NO-BREAK SPACE = U+FEFF)# and its possible byte string values# for UTF8/UTF16/UTF32 output and little/big endian machines# UTF-8# UTF-16, little endian# UTF-16, big endian# UTF-32, little endian# UTF-32, big endian# UTF-16, native endianness# UTF-32, native endianness# Old broken names (don't use in new code)### Codec base classes (defining the API)# Private API to allow Python 3.4 to denylist the known non-Unicode# codecs in the standard library. A more general mechanism to# reliably distinguish test encodings from other codecs will hopefully# be defined for Python 3.5# See http://bugs.python.org/issue19619# Assume codecs are text encodings by default# unencoded input that is kept between calls to encode()# Overwrite this method in subclasses: It must encode input# and return an (output, length consumed) tuple# encode input (taking the buffer into account)# keep unencoded input until the next call# undecoded input that is kept between calls to decode()# Overwrite this method in subclasses: It must decode input# decode input (taking the buffer into account)# keep undecoded input until the next call# additional state info is always 0# ignore additional state info# The StreamWriter and StreamReader class provide generic working# interfaces which can be used to implement new encoding submodules# very easily. See encodings/utf_8.py for an example on how this is# done.# If we have lines cached, first merge them back into characters# For compatibility with other read() methods that take a# single argument# read until we get the required number of characters (if available)# can the request be satisfied from the character buffer?# we need more data# decode bytes (those remaining from the last call included)# keep undecoded bytes until the next call# put new characters in the character buffer# there was no data available# Return everything we've got# Return the first chars characters# If we have lines cached from an earlier read, return# them unconditionally# revert to charbuffer mode; we might need more data# next time# If size is given, we call read() only once# If we're at a "\r" read one extra character (which might# be a "\n") to get a proper line ending. If the stream is# temporarily exhausted we return the wrong line ending.# More than one line result; the first line is a full line# to return# cache the remaining lines# only one remaining line, put it back into charbuffer# We really have a line end# Put the rest back together and keep it until the next call# we didn't get anything or this was our only try# Optional attributes set by the file wrappers below# these are needed to make "with StreamReaderWriter(...)" work properly# Seeks must be propagated to both the readers and writers# as they might need to reset their internal buffers.### Shortcuts# Force opening of the file in binary mode# Add attributes to simplify introspection### Helpers for codec lookup### Helpers for charmap-based codecs### error handlers# In --disable-unicode builds, these error handler are missing# Tell modulefinder that using codecs probably needs the encodings# package### Tests# Make stdout translate Latin-1 output into UTF-8 output# Have stdin translate Latin-1 input into UTF-8 inputb' codecs -- Python Codec Registry, API and helpers.


Written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

'u' codecs -- Python Codec Registry, API and helpers.


Written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

'b'Failed to load the builtin codecs: %s'u'Failed to load the builtin codecs: %s'b'register'u'register'b'lookup'u'lookup'b'EncodedFile'u'EncodedFile'b'BOM'u'BOM'b'BOM_BE'u'BOM_BE'b'BOM_LE'u'BOM_LE'b'BOM32_BE'u'BOM32_BE'b'BOM32_LE'u'BOM32_LE'b'BOM64_BE'u'BOM64_BE'b'BOM64_LE'u'BOM64_LE'b'BOM_UTF8'u'BOM_UTF8'b'BOM_UTF16'u'BOM_UTF16'b'BOM_UTF16_LE'u'BOM_UTF16_LE'b'BOM_UTF16_BE'u'BOM_UTF16_BE'b'BOM_UTF32'u'BOM_UTF32'b'BOM_UTF32_LE'u'BOM_UTF32_LE'b'BOM_UTF32_BE'u'BOM_UTF32_BE'b'CodecInfo'u'CodecInfo'b'Codec'u'Codec'b'IncrementalEncoder'u'IncrementalEncoder'b'IncrementalDecoder'u'IncrementalDecoder'b'StreamReader'u'StreamReader'b'StreamWriter'u'StreamWriter'b'StreamReaderWriter'u'StreamReaderWriter'b'StreamRecoder'u'StreamRecoder'b'getencoder'u'getencoder'b'getdecoder'u'getdecoder'b'getincrementalencoder'u'getincrementalencoder'b'getincrementaldecoder'u'getincrementaldecoder'b'getreader'u'getreader'b'getwriter'u'getwriter'b'iterencode'u'iterencode'b'iterdecode'u'iterdecode'b'strict_errors'u'strict_errors'b'ignore_errors'u'ignore_errors'b'replace_errors'u'replace_errors'b'xmlcharrefreplace_errors'u'xmlcharrefreplace_errors'b'backslashreplace_errors'u'backslashreplace_errors'b'namereplace_errors'u'namereplace_errors'b'register_error'u'register_error'b'lookup_error'u'lookup_error'b''b''b'  'b'  'b'Codec details when looking up the codec registry'u'Codec details when looking up the codec registry'b'<%s.%s object for encoding %s at %#x>'u'<%s.%s object for encoding %s at %#x>'b' Defines the interface for stateless encoders/decoders.

        The .encode()/.decode() methods may use different error
        handling schemes by providing the errors argument. These
        string values are predefined:

         'strict' - raise a ValueError error (or a subclass)
         'ignore' - ignore the character and continue with the next
         'replace' - replace with a suitable replacement character;
                    Python will use the official U+FFFD REPLACEMENT
                    CHARACTER for the builtin Unicode codecs on
                    decoding and '?' on encoding.
         'surrogateescape' - replace with private code points U+DCnn.
         'xmlcharrefreplace' - Replace with the appropriate XML
                               character reference (only for encoding).
         'backslashreplace'  - Replace with backslashed escape sequences.
         'namereplace'       - Replace with \N{...} escape sequences
                               (only for encoding).

        The set of allowed values can be extended via register_error.

    'u' Defines the interface for stateless encoders/decoders.

        The .encode()/.decode() methods may use different error
        handling schemes by providing the errors argument. These
        string values are predefined:

         'strict' - raise a ValueError error (or a subclass)
         'ignore' - ignore the character and continue with the next
         'replace' - replace with a suitable replacement character;
                    Python will use the official U+FFFD REPLACEMENT
                    CHARACTER for the builtin Unicode codecs on
                    decoding and '?' on encoding.
         'surrogateescape' - replace with private code points U+DCnn.
         'xmlcharrefreplace' - Replace with the appropriate XML
                               character reference (only for encoding).
         'backslashreplace'  - Replace with backslashed escape sequences.
         'namereplace'       - Replace with \N{...} escape sequences
                               (only for encoding).

        The set of allowed values can be extended via register_error.

    'b' Encodes the object input and returns a tuple (output
            object, length consumed).

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamWriter for codecs which have to keep state in order to
            make encoding efficient.

            The encoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        'u' Encodes the object input and returns a tuple (output
            object, length consumed).

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamWriter for codecs which have to keep state in order to
            make encoding efficient.

            The encoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        'b' Decodes the object input and returns a tuple (output
            object, length consumed).

            input must be an object which provides the bf_getreadbuf
            buffer slot. Python strings, buffer objects and memory
            mapped files are examples of objects providing this slot.

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamReader for codecs which have to keep state in order to
            make decoding efficient.

            The decoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        'u' Decodes the object input and returns a tuple (output
            object, length consumed).

            input must be an object which provides the bf_getreadbuf
            buffer slot. Python strings, buffer objects and memory
            mapped files are examples of objects providing this slot.

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamReader for codecs which have to keep state in order to
            make decoding efficient.

            The decoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        'b'
    An IncrementalEncoder encodes an input in multiple steps. The input can
    be passed piece by piece to the encode() method. The IncrementalEncoder
    remembers the state of the encoding process between calls to encode().
    'u'
    An IncrementalEncoder encodes an input in multiple steps. The input can
    be passed piece by piece to the encode() method. The IncrementalEncoder
    remembers the state of the encoding process between calls to encode().
    'b'
        Creates an IncrementalEncoder instance.

        The IncrementalEncoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        'u'
        Creates an IncrementalEncoder instance.

        The IncrementalEncoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        'b'
        Encodes input and returns the resulting object.
        'u'
        Encodes input and returns the resulting object.
        'b'
        Resets the encoder to the initial state.
        'u'
        Resets the encoder to the initial state.
        'b'
        Return the current state of the encoder.
        'u'
        Return the current state of the encoder.
        'b'
        Set the current state of the encoder. state must have been
        returned by getstate().
        'u'
        Set the current state of the encoder. state must have been
        returned by getstate().
        'b'
    This subclass of IncrementalEncoder can be used as the baseclass for an
    incremental encoder if the encoder must keep some of the output in a
    buffer between calls to encode().
    'u'
    This subclass of IncrementalEncoder can be used as the baseclass for an
    incremental encoder if the encoder must keep some of the output in a
    buffer between calls to encode().
    'b'
    An IncrementalDecoder decodes an input in multiple steps. The input can
    be passed piece by piece to the decode() method. The IncrementalDecoder
    remembers the state of the decoding process between calls to decode().
    'u'
    An IncrementalDecoder decodes an input in multiple steps. The input can
    be passed piece by piece to the decode() method. The IncrementalDecoder
    remembers the state of the decoding process between calls to decode().
    'b'
        Create an IncrementalDecoder instance.

        The IncrementalDecoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        'u'
        Create an IncrementalDecoder instance.

        The IncrementalDecoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        'b'
        Decode input and returns the resulting object.
        'u'
        Decode input and returns the resulting object.
        'b'
        Reset the decoder to the initial state.
        'u'
        Reset the decoder to the initial state.
        'b'
        Return the current state of the decoder.

        This must be a (buffered_input, additional_state_info) tuple.
        buffered_input must be a bytes object containing bytes that
        were passed to decode() that have not yet been converted.
        additional_state_info must be a non-negative integer
        representing the state of the decoder WITHOUT yet having
        processed the contents of buffered_input.  In the initial state
        and after reset(), getstate() must return (b"", 0).
        'u'
        Return the current state of the decoder.

        This must be a (buffered_input, additional_state_info) tuple.
        buffered_input must be a bytes object containing bytes that
        were passed to decode() that have not yet been converted.
        additional_state_info must be a non-negative integer
        representing the state of the decoder WITHOUT yet having
        processed the contents of buffered_input.  In the initial state
        and after reset(), getstate() must return (b"", 0).
        'b'
        Set the current state of the decoder.

        state must have been returned by getstate().  The effect of
        setstate((b"", 0)) must be equivalent to reset().
        'u'
        Set the current state of the decoder.

        state must have been returned by getstate().  The effect of
        setstate((b"", 0)) must be equivalent to reset().
        'b'
    This subclass of IncrementalDecoder can be used as the baseclass for an
    incremental decoder if the decoder must be able to handle incomplete
    byte sequences.
    'u'
    This subclass of IncrementalDecoder can be used as the baseclass for an
    incremental decoder if the decoder must be able to handle incomplete
    byte sequences.
    'b' Creates a StreamWriter instance.

            stream must be a file-like object open for writing.

            The StreamWriter may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'xmlcharrefreplace' - Replace with the appropriate XML
                                   character reference.
             'backslashreplace'  - Replace with backslashed escape
                                   sequences.
             'namereplace'       - Replace with \N{...} escape sequences.

            The set of allowed parameter values can be extended via
            register_error.
        'u' Creates a StreamWriter instance.

            stream must be a file-like object open for writing.

            The StreamWriter may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'xmlcharrefreplace' - Replace with the appropriate XML
                                   character reference.
             'backslashreplace'  - Replace with backslashed escape
                                   sequences.
             'namereplace'       - Replace with \N{...} escape sequences.

            The set of allowed parameter values can be extended via
            register_error.
        'b' Writes the object's contents encoded to self.stream.
        'u' Writes the object's contents encoded to self.stream.
        'b' Writes the concatenated list of strings to the stream
            using .write().
        'u' Writes the concatenated list of strings to the stream
            using .write().
        'b' Resets the codec buffers used for keeping internal state.

            Calling this method should ensure that the data on the
            output is put into a clean state, that allows appending
            of new fresh data without having to rescan the whole
            stream to recover state.

        'u' Resets the codec buffers used for keeping internal state.

            Calling this method should ensure that the data on the
            output is put into a clean state, that allows appending
            of new fresh data without having to rescan the whole
            stream to recover state.

        'b' Inherit all other methods from the underlying stream.
        'u' Inherit all other methods from the underlying stream.
        'b' Creates a StreamReader instance.

            stream must be a file-like object open for reading.

            The StreamReader may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'backslashreplace' - Replace with backslashed escape sequences;

            The set of allowed parameter values can be extended via
            register_error.
        'u' Creates a StreamReader instance.

            stream must be a file-like object open for reading.

            The StreamReader may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'backslashreplace' - Replace with backslashed escape sequences;

            The set of allowed parameter values can be extended via
            register_error.
        'b' Decodes data from the stream self.stream and returns the
            resulting object.

            chars indicates the number of decoded code points or bytes to
            return. read() will never return more data than requested,
            but it might return less, if there is not enough available.

            size indicates the approximate maximum number of decoded
            bytes or code points to read for decoding. The decoder
            can modify this setting as appropriate. The default value
            -1 indicates to read and decode as much as possible.  size
            is intended to prevent having to decode huge files in one
            step.

            If firstline is true, and a UnicodeDecodeError happens
            after the first line terminator in the input only the first line
            will be returned, the rest of the input will be kept until the
            next call to read().

            The method should use a greedy read strategy, meaning that
            it should read as much data as is allowed within the
            definition of the encoding and the given size, e.g.  if
            optional encoding endings or state markers are available
            on the stream, these should be read too.
        'u' Decodes data from the stream self.stream and returns the
            resulting object.

            chars indicates the number of decoded code points or bytes to
            return. read() will never return more data than requested,
            but it might return less, if there is not enough available.

            size indicates the approximate maximum number of decoded
            bytes or code points to read for decoding. The decoder
            can modify this setting as appropriate. The default value
            -1 indicates to read and decode as much as possible.  size
            is intended to prevent having to decode huge files in one
            step.

            If firstline is true, and a UnicodeDecodeError happens
            after the first line terminator in the input only the first line
            will be returned, the rest of the input will be kept until the
            next call to read().

            The method should use a greedy read strategy, meaning that
            it should read as much data as is allowed within the
            definition of the encoding and the given size, e.g.  if
            optional encoding endings or state markers are available
            on the stream, these should be read too.
        'b' Read one line from the input stream and return the
            decoded data.

            size, if given, is passed as size argument to the
            read() method.

        'u' Read one line from the input stream and return the
            decoded data.

            size, if given, is passed as size argument to the
            read() method.

        'b' Read all lines available on the input stream
            and return them as a list.

            Line breaks are implemented using the codec's decoder
            method and are included in the list entries.

            sizehint, if given, is ignored since there is no efficient
            way to finding the true end-of-line.

        'u' Read all lines available on the input stream
            and return them as a list.

            Line breaks are implemented using the codec's decoder
            method and are included in the list entries.

            sizehint, if given, is ignored since there is no efficient
            way to finding the true end-of-line.

        'b' Resets the codec buffers used for keeping internal state.

            Note that no stream repositioning should take place.
            This method is primarily intended to be able to recover
            from decoding errors.

        'u' Resets the codec buffers used for keeping internal state.

            Note that no stream repositioning should take place.
            This method is primarily intended to be able to recover
            from decoding errors.

        'b' Set the input stream's current position.

            Resets the codec buffers used for keeping state.
        'u' Set the input stream's current position.

            Resets the codec buffers used for keeping state.
        'b' Return the next decoded line from the input stream.'u' Return the next decoded line from the input stream.'b' StreamReaderWriter instances allow wrapping streams which
        work in both read and write modes.

        The design is such that one can use the factory functions
        returned by the codec.lookup() function to construct the
        instance.

    'u' StreamReaderWriter instances allow wrapping streams which
        work in both read and write modes.

        The design is such that one can use the factory functions
        returned by the codec.lookup() function to construct the
        instance.

    'b' Creates a StreamReaderWriter instance.

            stream must be a Stream-like object.

            Reader, Writer must be factory functions or classes
            providing the StreamReader, StreamWriter interface resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        'u' Creates a StreamReaderWriter instance.

            stream must be a Stream-like object.

            Reader, Writer must be factory functions or classes
            providing the StreamReader, StreamWriter interface resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        'b' StreamRecoder instances translate data from one encoding to another.

        They use the complete set of APIs returned by the
        codecs.lookup() function to implement their task.

        Data written to the StreamRecoder is first decoded into an
        intermediate format (depending on the "decode" codec) and then
        written to the underlying stream using an instance of the provided
        Writer class.

        In the other direction, data is read from the underlying stream using
        a Reader instance and then encoded and returned to the caller.

    'u' StreamRecoder instances translate data from one encoding to another.

        They use the complete set of APIs returned by the
        codecs.lookup() function to implement their task.

        Data written to the StreamRecoder is first decoded into an
        intermediate format (depending on the "decode" codec) and then
        written to the underlying stream using an instance of the provided
        Writer class.

        In the other direction, data is read from the underlying stream using
        a Reader instance and then encoded and returned to the caller.

    'b' Creates a StreamRecoder instance which implements a two-way
            conversion: encode and decode work on the frontend (the
            data visible to .read() and .write()) while Reader and Writer
            work on the backend (the data in stream).

            You can use these objects to do transparent
            transcodings from e.g. latin-1 to utf-8 and back.

            stream must be a file-like object.

            encode and decode must adhere to the Codec interface; Reader and
            Writer must be factory functions or classes providing the
            StreamReader and StreamWriter interfaces resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        'u' Creates a StreamRecoder instance which implements a two-way
            conversion: encode and decode work on the frontend (the
            data visible to .read() and .write()) while Reader and Writer
            work on the backend (the data in stream).

            You can use these objects to do transparent
            transcodings from e.g. latin-1 to utf-8 and back.

            stream must be a file-like object.

            encode and decode must adhere to the Codec interface; Reader and
            Writer must be factory functions or classes providing the
            StreamReader and StreamWriter interfaces resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        'b' Open an encoded file using the given mode and return
        a wrapped version providing transparent encoding/decoding.

        Note: The wrapped version will only accept the object format
        defined by the codecs, i.e. Unicode objects for most builtin
        codecs. Output is also codec dependent and will usually be
        Unicode as well.

        If encoding is not None, then the
        underlying encoded files are always opened in binary mode.
        The default file mode is 'r', meaning to open the file in read mode.

        encoding specifies the encoding which is to be used for the
        file.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        buffering has the same meaning as for the builtin open() API.
        It defaults to -1 which means that the default buffer size will
        be used.

        The returned wrapped file object provides an extra attribute
        .encoding which allows querying the used encoding. This
        attribute is only available if an encoding was specified as
        parameter.

    'u' Open an encoded file using the given mode and return
        a wrapped version providing transparent encoding/decoding.

        Note: The wrapped version will only accept the object format
        defined by the codecs, i.e. Unicode objects for most builtin
        codecs. Output is also codec dependent and will usually be
        Unicode as well.

        If encoding is not None, then the
        underlying encoded files are always opened in binary mode.
        The default file mode is 'r', meaning to open the file in read mode.

        encoding specifies the encoding which is to be used for the
        file.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        buffering has the same meaning as for the builtin open() API.
        It defaults to -1 which means that the default buffer size will
        be used.

        The returned wrapped file object provides an extra attribute
        .encoding which allows querying the used encoding. This
        attribute is only available if an encoding was specified as
        parameter.

    'b' Return a wrapped version of file which provides transparent
        encoding translation.

        Data written to the wrapped file is decoded according
        to the given data_encoding and then encoded to the underlying
        file using file_encoding. The intermediate data type
        will usually be Unicode but depends on the specified codecs.

        Bytes read from the file are decoded using file_encoding and then
        passed back to the caller encoded using data_encoding.

        If file_encoding is not given, it defaults to data_encoding.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        The returned wrapped file object provides two extra attributes
        .data_encoding and .file_encoding which reflect the given
        parameters of the same name. The attributes can be used for
        introspection by Python programs.

    'u' Return a wrapped version of file which provides transparent
        encoding translation.

        Data written to the wrapped file is decoded according
        to the given data_encoding and then encoded to the underlying
        file using file_encoding. The intermediate data type
        will usually be Unicode but depends on the specified codecs.

        Bytes read from the file are decoded using file_encoding and then
        passed back to the caller encoded using data_encoding.

        If file_encoding is not given, it defaults to data_encoding.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        The returned wrapped file object provides two extra attributes
        .data_encoding and .file_encoding which reflect the given
        parameters of the same name. The attributes can be used for
        introspection by Python programs.

    'b' Lookup up the codec for the given encoding and return
        its encoder function.

        Raises a LookupError in case the encoding cannot be found.

    'u' Lookup up the codec for the given encoding and return
        its encoder function.

        Raises a LookupError in case the encoding cannot be found.

    'b' Lookup up the codec for the given encoding and return
        its decoder function.

        Raises a LookupError in case the encoding cannot be found.

    'u' Lookup up the codec for the given encoding and return
        its decoder function.

        Raises a LookupError in case the encoding cannot be found.

    'b' Lookup up the codec for the given encoding and return
        its IncrementalEncoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental encoder.

    'u' Lookup up the codec for the given encoding and return
        its IncrementalEncoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental encoder.

    'b' Lookup up the codec for the given encoding and return
        its IncrementalDecoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental decoder.

    'u' Lookup up the codec for the given encoding and return
        its IncrementalDecoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental decoder.

    'b' Lookup up the codec for the given encoding and return
        its StreamReader class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    'u' Lookup up the codec for the given encoding and return
        its StreamReader class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    'b' Lookup up the codec for the given encoding and return
        its StreamWriter class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    'u' Lookup up the codec for the given encoding and return
        its StreamWriter class or factory function.

        Raises a LookupError in case the encoding cannot be found.

    'b'
    Encoding iterator.

    Encodes the input strings from the iterator using an IncrementalEncoder.

    errors and kwargs are passed through to the IncrementalEncoder
    constructor.
    'u'
    Encoding iterator.

    Encodes the input strings from the iterator using an IncrementalEncoder.

    errors and kwargs are passed through to the IncrementalEncoder
    constructor.
    'b'
    Decoding iterator.

    Decodes the input strings from the iterator using an IncrementalDecoder.

    errors and kwargs are passed through to the IncrementalDecoder
    constructor.
    'u'
    Decoding iterator.

    Decodes the input strings from the iterator using an IncrementalDecoder.

    errors and kwargs are passed through to the IncrementalDecoder
    constructor.
    'b' make_identity_dict(rng) -> dict

        Return a dictionary where elements of the rng sequence are
        mapped to themselves.

    'u' make_identity_dict(rng) -> dict

        Return a dictionary where elements of the rng sequence are
        mapped to themselves.

    'b' Creates an encoding map from a decoding map.

        If a target mapping in the decoding map occurs multiple
        times, then that target is mapped to None (undefined mapping),
        causing an exception when encountered by the charmap codec
        during translation.

        One example where this happens is cp875.py which decodes
        multiple character to \u001a.

    'u' Creates an encoding map from a decoding map.

        If a target mapping in the decoding map occurs multiple
        times, then that target is mapped to None (undefined mapping),
        causing an exception when encountered by the charmap codec
        during translation.

        One example where this happens is cp875.py which decodes
        multiple character to \u001a.

    'b'namereplace'u'namereplace'u'codecs'Utilities to compile possibly incomplete Python source code.

This module provides two interfaces, broadly similar to the builtin
function compile(), which take program text, a filename and a 'mode'
and:

- Return code object if the command is complete and valid
- Return None if the command is incomplete
- Raise SyntaxError, ValueError or OverflowError if the command is a
  syntax error (OverflowError and ValueError can be produced by
  malformed literals).

The two interfaces are:

compile_command(source, filename, symbol):

    Compiles a single command in the manner described above.

CommandCompiler():

    Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.

The module also provides another class:

Compile():

    Instances of this class act like the built-in function compile,
    but with 'memory' in the sense described above.
_featuresCompile0x200PyCF_DONT_IMPLY_DEDENT0x4000PyCF_ALLOW_INCOMPLETE_INPUT_maybe_compileincomplete input_is_syntax_errorerr1err2rep1rep2was never closedCompile a command and determine whether it is incomplete.

    Arguments:

    source -- the source string; may contain \n characters
    filename -- optional filename from which source was read; default
                "<input>"
    symbol -- optional grammar start symbol; "single" (default), "exec"
              or "eval"

    Return value / exceptions raised:

    - Return a code object if the command is complete and valid
    - Return None if the command is incomplete
    - Raise SyntaxError, ValueError or OverflowError if the command is a
      syntax error (OverflowError and ValueError can be produced by
      malformed literals).
    Instances of this class behave much like the built-in compile
    function, but if one is used to compile text containing a future
    statement, it "remembers" and compiles all subsequent program texts
    with the statement in force.codeobfeatureInstances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.Compile a command and determine whether it is incomplete.

        Arguments:

        source -- the source string; may contain \n characters
        filename -- optional filename from which source was read;
                    default "<input>"
        symbol -- optional grammar start symbol; "single" (default) or
                  "eval"

        Return value / exceptions raised:

        - Return a code object if the command is complete and valid
        - Return None if the command is incomplete
        - Raise SyntaxError, ValueError or OverflowError if the command is a
          syntax error (OverflowError and ValueError can be produced by
          malformed literals).
        # The following flags match the values from Include/cpython/compile.h# Caveat emptor: These flags are undocumented on purpose and depending# on their effect outside the standard library is **unsupported**.# Check for source consisting of only blank lines and comments.# Leave it alone.# Replace it with a 'pass' statement# Disable compiler warnings when checking for incomplete input.# Let other compile() errors propagate.# fallthroughb'Utilities to compile possibly incomplete Python source code.

This module provides two interfaces, broadly similar to the builtin
function compile(), which take program text, a filename and a 'mode'
and:

- Return code object if the command is complete and valid
- Return None if the command is incomplete
- Raise SyntaxError, ValueError or OverflowError if the command is a
  syntax error (OverflowError and ValueError can be produced by
  malformed literals).

The two interfaces are:

compile_command(source, filename, symbol):

    Compiles a single command in the manner described above.

CommandCompiler():

    Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.

The module also provides another class:

Compile():

    Instances of this class act like the built-in function compile,
    but with 'memory' in the sense described above.
'u'Utilities to compile possibly incomplete Python source code.

This module provides two interfaces, broadly similar to the builtin
function compile(), which take program text, a filename and a 'mode'
and:

- Return code object if the command is complete and valid
- Return None if the command is incomplete
- Raise SyntaxError, ValueError or OverflowError if the command is a
  syntax error (OverflowError and ValueError can be produced by
  malformed literals).

The two interfaces are:

compile_command(source, filename, symbol):

    Compiles a single command in the manner described above.

CommandCompiler():

    Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.

The module also provides another class:

Compile():

    Instances of this class act like the built-in function compile,
    but with 'memory' in the sense described above.
'b'Compile'u'Compile'b'CommandCompiler'u'CommandCompiler'b'incomplete input'u'incomplete input'b'was never closed'u'was never closed'b'Compile a command and determine whether it is incomplete.

    Arguments:

    source -- the source string; may contain \n characters
    filename -- optional filename from which source was read; default
                "<input>"
    symbol -- optional grammar start symbol; "single" (default), "exec"
              or "eval"

    Return value / exceptions raised:

    - Return a code object if the command is complete and valid
    - Return None if the command is incomplete
    - Raise SyntaxError, ValueError or OverflowError if the command is a
      syntax error (OverflowError and ValueError can be produced by
      malformed literals).
    'u'Compile a command and determine whether it is incomplete.

    Arguments:

    source -- the source string; may contain \n characters
    filename -- optional filename from which source was read; default
                "<input>"
    symbol -- optional grammar start symbol; "single" (default), "exec"
              or "eval"

    Return value / exceptions raised:

    - Return a code object if the command is complete and valid
    - Return None if the command is incomplete
    - Raise SyntaxError, ValueError or OverflowError if the command is a
      syntax error (OverflowError and ValueError can be produced by
      malformed literals).
    'b'Instances of this class behave much like the built-in compile
    function, but if one is used to compile text containing a future
    statement, it "remembers" and compiles all subsequent program texts
    with the statement in force.'u'Instances of this class behave much like the built-in compile
    function, but if one is used to compile text containing a future
    statement, it "remembers" and compiles all subsequent program texts
    with the statement in force.'b'Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.'u'Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.'b'Compile a command and determine whether it is incomplete.

        Arguments:

        source -- the source string; may contain \n characters
        filename -- optional filename from which source was read;
                    default "<input>"
        symbol -- optional grammar start symbol; "single" (default) or
                  "eval"

        Return value / exceptions raised:

        - Return a code object if the command is complete and valid
        - Return None if the command is incomplete
        - Raise SyntaxError, ValueError or OverflowError if the command is a
          syntax error (OverflowError and ValueError can be produced by
          malformed literals).
        'u'Compile a command and determine whether it is incomplete.

        Arguments:

        source -- the source string; may contain \n characters
        filename -- optional filename from which source was read;
                    default "<input>"
        symbol -- optional grammar start symbol; "single" (default) or
                  "eval"

        Return value / exceptions raised:

        - Return a code object if the command is complete and valid
        - Return None if the command is incomplete
        - Raise SyntaxError, ValueError or OverflowError if the command is a
          syntax error (OverflowError and ValueError can be produced by
          malformed literals).
        'u'codeop'merge_dictsResourceCollection
    Represents a collection of resources, which can be iterated through,
    optionally with filtering. Collections automatically handle pagination
    for you.

    See :ref:`guide_collections` for a high-level overview of collections,
    including when remote service requests are performed.

    :type model: :py:class:`~boto3.resources.model.Collection`
    :param model: Collection model
    :type parent: :py:class:`~boto3.resources.base.ServiceResource`
    :param parent: The collection's parent resource
    :type handler: :py:class:`~boto3.resources.response.ResourceHandler`
    :param handler: The resource response handler used to create resource
                    instances
    _model_parent_py_operation_name_handlerdeepcopy{}({}, {})
        A generator which yields resource instances after doing the
        appropriate service operation calls and handling any pagination
        on your behalf.

        Page size, item limit, and filter parameters are applied
        if they have previously been set.

            >>> bucket = s3.Bucket('boto3')
            >>> for obj in bucket.objects.all():
            ...     print(obj.key)
            'key1'
            'key2'

        _clone
        Create a clone of this collection. This is used by the methods
        below to provide a chainable interface that returns copies
        rather than the original. This allows things like:

            >>> base = collection.filter(Param1=1)
            >>> query1 = base.filter(Param2=2)
            >>> query2 = base.filter(Param3=3)
            >>> query1.params
            {'Param1': 1, 'Param2': 2}
            >>> query2.params
            {'Param1': 1, 'Param3': 3}

        :rtype: :py:class:`ResourceCollection`
        :return: A clone of this resource collection
        append_lists
        A generator which yields pages of resource instances after
        doing the appropriate service operation calls and handling
        any pagination on your behalf. Non-paginated calls will
        return a single page of items.

        Page size, item limit, and filter parameters are applied
        if they have previously been set.

            >>> bucket = s3.Bucket('boto3')
            >>> for page in bucket.objects.pages():
            ...     for obj in page:
            ...         print(obj.key)
            'key1'
            'key2'

        :rtype: list(:py:class:`~boto3.resources.base.ServiceResource`)
        :return: List of resource instances
        cleaned_paramspage_sizeCalling paginated %s:%s with %rMaxItemsPageSizePaginationConfigpage_items
        Get all items from the collection, optionally with a custom
        page size and item count limit.

        This method returns an iterable generator which yields
        individual resource instances. Example use::

            # Iterate through items
            >>> for queue in sqs.queues.all():
            ...     print(queue.url)
            'https://url1'
            'https://url2'

            # Convert to list
            >>> queues = list(sqs.queues.all())
            >>> len(queues)
            2
        
        Get items from the collection, passing keyword arguments along
        as parameters to the underlying service operation, which are
        typically used to filter the results.

        This method returns an iterable generator which yields
        individual resource instances. Example use::

            # Iterate through items
            >>> for queue in sqs.queues.filter(Param='foo'):
            ...     print(queue.url)
            'https://url1'
            'https://url2'

            # Convert to list
            >>> queues = list(sqs.queues.filter(Param='foo'))
            >>> len(queues)
            2

        :rtype: :py:class:`ResourceCollection`
        
        Return at most this many resources.

            >>> for bucket in s3.buckets.limit(5):
            ...     print(bucket.name)
            'bucket1'
            'bucket2'
            'bucket3'
            'bucket4'
            'bucket5'

        :type count: int
        :param count: Return no more than this many items
        :rtype: :py:class:`ResourceCollection`
        
        Fetch at most this many resources per service request.

            >>> for obj in s3.Bucket('boto3').objects.page_size(100):
            ...     print(obj.key)

        :type count: int
        :param count: Fetch this many items per request
        :rtype: :py:class:`ResourceCollection`
        CollectionManager
    A collection manager provides access to resource collection instances,
    which can be iterated and filtered. The manager exposes some
    convenience functions that are also found on resource collections,
    such as :py:meth:`~ResourceCollection.all` and
    :py:meth:`~ResourceCollection.filter`.

    Get all items::

        >>> for bucket in s3.buckets.all():
        ...     print(bucket.name)

    Get only some items via filtering::

        >>> for queue in sqs.queues.filter(QueueNamePrefix='AWS'):
        ...     print(queue.url)

    Get whole pages of items:

        >>> for page in s3.Bucket('boto3').objects.pages():
        ...     for obj in page:
        ...         print(obj.key)

    A collection manager is not iterable. You **must** call one of the
    methods that return a :py:class:`ResourceCollection` before trying
    to iterate, slice, or convert to a list.

    See the :ref:`guide_collections` guide for a high-level overview
    of collections, including when remote service requests are performed.

    :type collection_model: :py:class:`~boto3.resources.model.Collection`
    :param model: Collection model

    :type parent: :py:class:`~boto3.resources.base.ServiceResource`
    :param parent: The collection's parent resource

    :type factory: :py:class:`~boto3.resources.factory.ResourceFactory`
    :param factory: The resource factory to create new resources

    :type service_context: :py:class:`~boto3.utils.ServiceContext`
    :param service_context: Context about the AWS service
    _collection_clscollection_model
        Get a resource collection iterator from this manager.

        :rtype: :py:class:`ResourceCollection`
        :return: An iterable representing the collection of resources
        CollectionFactory
    A factory to create new
    :py:class:`CollectionManager` and :py:class:`ResourceCollection`
    subclasses from a :py:class:`~boto3.resources.model.Collection`
    model. These subclasses include methods to perform batch operations.
    load_from_definition
        Loads a collection from a model, creating a new
        :py:class:`CollectionManager` subclass
        with the correct properties and methods, named based on the service
        and resource name, e.g. ec2.InstanceCollectionManager. It also
        creates a new :py:class:`ResourceCollection` subclass which is used
        by the new manager class.

        :type resource_name: string
        :param resource_name: Name of the resource to look up. For services,
                              this should match the ``service_name``.

        :type service_context: :py:class:`~boto3.utils.ServiceContext`
        :param service_context: Context about the AWS service

        :type event_emitter: :py:class:`~botocore.hooks.HierarchialEmitter`
        :param event_emitter: An event emitter

        :rtype: Subclass of :py:class:`CollectionManager`
        :return: The collection class.
        collection_name_load_batch_actions_load_documented_collection_methodsbase_class{}.{}Collection{}.{}.{}Collectioncollection_cls
        Batch actions on the collection become methods on both
        the collection manager and iterators.
        batch_actionssnake_cased_create_batch_actionfactory_selfCollectionMethodDocstring
        Creates a new method which makes a batch operation request
        to the underlying service API.
        batch_actionBatchActionDocstringbatch_action_model# If the limit is set and has been reached, then# we stop processing items here.# Is this a paginated operation? If so, we need to get an# iterator for the various pages. If not, then we simply# call the operation and return the result as a single# page in a list. For non-paginated results, we just ignore# the page size parameter.# Now that we have a page iterator or single page of results# we start processing and yielding individual items.# Stop reading pages if we've reached out limit# The class to use when creating an iterator# Set up some methods to proxy ResourceCollection methods# Create the batch actions for a collection# Add the documentation to the collection class's methods# Add the documentation to the collection manager's methods# The base class already has these methods defined. However# the docstrings are generic and not based for a particular service# or resource. So we override these methods by proxying to the# base class's builtin method and adding a docstring# that pertains to the resource.# A collection's all() method.# The collection's filter() method.# The collection's limit method.# The collection's page_size method.b'
    Represents a collection of resources, which can be iterated through,
    optionally with filtering. Collections automatically handle pagination
    for you.

    See :ref:`guide_collections` for a high-level overview of collections,
    including when remote service requests are performed.

    :type model: :py:class:`~boto3.resources.model.Collection`
    :param model: Collection model
    :type parent: :py:class:`~boto3.resources.base.ServiceResource`
    :param parent: The collection's parent resource
    :type handler: :py:class:`~boto3.resources.response.ResourceHandler`
    :param handler: The resource response handler used to create resource
                    instances
    'u'
    Represents a collection of resources, which can be iterated through,
    optionally with filtering. Collections automatically handle pagination
    for you.

    See :ref:`guide_collections` for a high-level overview of collections,
    including when remote service requests are performed.

    :type model: :py:class:`~boto3.resources.model.Collection`
    :param model: Collection model
    :type parent: :py:class:`~boto3.resources.base.ServiceResource`
    :param parent: The collection's parent resource
    :type handler: :py:class:`~boto3.resources.response.ResourceHandler`
    :param handler: The resource response handler used to create resource
                    instances
    'b'{}({}, {})'u'{}({}, {})'b'
        A generator which yields resource instances after doing the
        appropriate service operation calls and handling any pagination
        on your behalf.

        Page size, item limit, and filter parameters are applied
        if they have previously been set.

            >>> bucket = s3.Bucket('boto3')
            >>> for obj in bucket.objects.all():
            ...     print(obj.key)
            'key1'
            'key2'

        'u'
        A generator which yields resource instances after doing the
        appropriate service operation calls and handling any pagination
        on your behalf.

        Page size, item limit, and filter parameters are applied
        if they have previously been set.

            >>> bucket = s3.Bucket('boto3')
            >>> for obj in bucket.objects.all():
            ...     print(obj.key)
            'key1'
            'key2'

        'b'limit'u'limit'b'
        Create a clone of this collection. This is used by the methods
        below to provide a chainable interface that returns copies
        rather than the original. This allows things like:

            >>> base = collection.filter(Param1=1)
            >>> query1 = base.filter(Param2=2)
            >>> query2 = base.filter(Param3=3)
            >>> query1.params
            {'Param1': 1, 'Param2': 2}
            >>> query2.params
            {'Param1': 1, 'Param3': 3}

        :rtype: :py:class:`ResourceCollection`
        :return: A clone of this resource collection
        'u'
        Create a clone of this collection. This is used by the methods
        below to provide a chainable interface that returns copies
        rather than the original. This allows things like:

            >>> base = collection.filter(Param1=1)
            >>> query1 = base.filter(Param2=2)
            >>> query2 = base.filter(Param3=3)
            >>> query1.params
            {'Param1': 1, 'Param2': 2}
            >>> query2.params
            {'Param1': 1, 'Param3': 3}

        :rtype: :py:class:`ResourceCollection`
        :return: A clone of this resource collection
        'b'
        A generator which yields pages of resource instances after
        doing the appropriate service operation calls and handling
        any pagination on your behalf. Non-paginated calls will
        return a single page of items.

        Page size, item limit, and filter parameters are applied
        if they have previously been set.

            >>> bucket = s3.Bucket('boto3')
            >>> for page in bucket.objects.pages():
            ...     for obj in page:
            ...         print(obj.key)
            'key1'
            'key2'

        :rtype: list(:py:class:`~boto3.resources.base.ServiceResource`)
        :return: List of resource instances
        'u'
        A generator which yields pages of resource instances after
        doing the appropriate service operation calls and handling
        any pagination on your behalf. Non-paginated calls will
        return a single page of items.

        Page size, item limit, and filter parameters are applied
        if they have previously been set.

            >>> bucket = s3.Bucket('boto3')
            >>> for page in bucket.objects.pages():
            ...     for obj in page:
            ...         print(obj.key)
            'key1'
            'key2'

        :rtype: list(:py:class:`~boto3.resources.base.ServiceResource`)
        :return: List of resource instances
        'b'page_size'u'page_size'b'Calling paginated %s:%s with %r'u'Calling paginated %s:%s with %r'b'MaxItems'u'MaxItems'b'PageSize'u'PageSize'b'
        Get all items from the collection, optionally with a custom
        page size and item count limit.

        This method returns an iterable generator which yields
        individual resource instances. Example use::

            # Iterate through items
            >>> for queue in sqs.queues.all():
            ...     print(queue.url)
            'https://url1'
            'https://url2'

            # Convert to list
            >>> queues = list(sqs.queues.all())
            >>> len(queues)
            2
        'u'
        Get all items from the collection, optionally with a custom
        page size and item count limit.

        This method returns an iterable generator which yields
        individual resource instances. Example use::

            # Iterate through items
            >>> for queue in sqs.queues.all():
            ...     print(queue.url)
            'https://url1'
            'https://url2'

            # Convert to list
            >>> queues = list(sqs.queues.all())
            >>> len(queues)
            2
        'b'
        Get items from the collection, passing keyword arguments along
        as parameters to the underlying service operation, which are
        typically used to filter the results.

        This method returns an iterable generator which yields
        individual resource instances. Example use::

            # Iterate through items
            >>> for queue in sqs.queues.filter(Param='foo'):
            ...     print(queue.url)
            'https://url1'
            'https://url2'

            # Convert to list
            >>> queues = list(sqs.queues.filter(Param='foo'))
            >>> len(queues)
            2

        :rtype: :py:class:`ResourceCollection`
        'u'
        Get items from the collection, passing keyword arguments along
        as parameters to the underlying service operation, which are
        typically used to filter the results.

        This method returns an iterable generator which yields
        individual resource instances. Example use::

            # Iterate through items
            >>> for queue in sqs.queues.filter(Param='foo'):
            ...     print(queue.url)
            'https://url1'
            'https://url2'

            # Convert to list
            >>> queues = list(sqs.queues.filter(Param='foo'))
            >>> len(queues)
            2

        :rtype: :py:class:`ResourceCollection`
        'b'
        Return at most this many resources.

            >>> for bucket in s3.buckets.limit(5):
            ...     print(bucket.name)
            'bucket1'
            'bucket2'
            'bucket3'
            'bucket4'
            'bucket5'

        :type count: int
        :param count: Return no more than this many items
        :rtype: :py:class:`ResourceCollection`
        'u'
        Return at most this many resources.

            >>> for bucket in s3.buckets.limit(5):
            ...     print(bucket.name)
            'bucket1'
            'bucket2'
            'bucket3'
            'bucket4'
            'bucket5'

        :type count: int
        :param count: Return no more than this many items
        :rtype: :py:class:`ResourceCollection`
        'b'
        Fetch at most this many resources per service request.

            >>> for obj in s3.Bucket('boto3').objects.page_size(100):
            ...     print(obj.key)

        :type count: int
        :param count: Fetch this many items per request
        :rtype: :py:class:`ResourceCollection`
        'u'
        Fetch at most this many resources per service request.

            >>> for obj in s3.Bucket('boto3').objects.page_size(100):
            ...     print(obj.key)

        :type count: int
        :param count: Fetch this many items per request
        :rtype: :py:class:`ResourceCollection`
        'b'
    A collection manager provides access to resource collection instances,
    which can be iterated and filtered. The manager exposes some
    convenience functions that are also found on resource collections,
    such as :py:meth:`~ResourceCollection.all` and
    :py:meth:`~ResourceCollection.filter`.

    Get all items::

        >>> for bucket in s3.buckets.all():
        ...     print(bucket.name)

    Get only some items via filtering::

        >>> for queue in sqs.queues.filter(QueueNamePrefix='AWS'):
        ...     print(queue.url)

    Get whole pages of items:

        >>> for page in s3.Bucket('boto3').objects.pages():
        ...     for obj in page:
        ...         print(obj.key)

    A collection manager is not iterable. You **must** call one of the
    methods that return a :py:class:`ResourceCollection` before trying
    to iterate, slice, or convert to a list.

    See the :ref:`guide_collections` guide for a high-level overview
    of collections, including when remote service requests are performed.

    :type collection_model: :py:class:`~boto3.resources.model.Collection`
    :param model: Collection model

    :type parent: :py:class:`~boto3.resources.base.ServiceResource`
    :param parent: The collection's parent resource

    :type factory: :py:class:`~boto3.resources.factory.ResourceFactory`
    :param factory: The resource factory to create new resources

    :type service_context: :py:class:`~boto3.utils.ServiceContext`
    :param service_context: Context about the AWS service
    'u'
    A collection manager provides access to resource collection instances,
    which can be iterated and filtered. The manager exposes some
    convenience functions that are also found on resource collections,
    such as :py:meth:`~ResourceCollection.all` and
    :py:meth:`~ResourceCollection.filter`.

    Get all items::

        >>> for bucket in s3.buckets.all():
        ...     print(bucket.name)

    Get only some items via filtering::

        >>> for queue in sqs.queues.filter(QueueNamePrefix='AWS'):
        ...     print(queue.url)

    Get whole pages of items:

        >>> for page in s3.Bucket('boto3').objects.pages():
        ...     for obj in page:
        ...         print(obj.key)

    A collection manager is not iterable. You **must** call one of the
    methods that return a :py:class:`ResourceCollection` before trying
    to iterate, slice, or convert to a list.

    See the :ref:`guide_collections` guide for a high-level overview
    of collections, including when remote service requests are performed.

    :type collection_model: :py:class:`~boto3.resources.model.Collection`
    :param model: Collection model

    :type parent: :py:class:`~boto3.resources.base.ServiceResource`
    :param parent: The collection's parent resource

    :type factory: :py:class:`~boto3.resources.factory.ResourceFactory`
    :param factory: The resource factory to create new resources

    :type service_context: :py:class:`~boto3.utils.ServiceContext`
    :param service_context: Context about the AWS service
    'b'
        Get a resource collection iterator from this manager.

        :rtype: :py:class:`ResourceCollection`
        :return: An iterable representing the collection of resources
        'u'
        Get a resource collection iterator from this manager.

        :rtype: :py:class:`ResourceCollection`
        :return: An iterable representing the collection of resources
        'b'
    A factory to create new
    :py:class:`CollectionManager` and :py:class:`ResourceCollection`
    subclasses from a :py:class:`~boto3.resources.model.Collection`
    model. These subclasses include methods to perform batch operations.
    'u'
    A factory to create new
    :py:class:`CollectionManager` and :py:class:`ResourceCollection`
    subclasses from a :py:class:`~boto3.resources.model.Collection`
    model. These subclasses include methods to perform batch operations.
    'b'
        Loads a collection from a model, creating a new
        :py:class:`CollectionManager` subclass
        with the correct properties and methods, named based on the service
        and resource name, e.g. ec2.InstanceCollectionManager. It also
        creates a new :py:class:`ResourceCollection` subclass which is used
        by the new manager class.

        :type resource_name: string
        :param resource_name: Name of the resource to look up. For services,
                              this should match the ``service_name``.

        :type service_context: :py:class:`~boto3.utils.ServiceContext`
        :param service_context: Context about the AWS service

        :type event_emitter: :py:class:`~botocore.hooks.HierarchialEmitter`
        :param event_emitter: An event emitter

        :rtype: Subclass of :py:class:`CollectionManager`
        :return: The collection class.
        'u'
        Loads a collection from a model, creating a new
        :py:class:`CollectionManager` subclass
        with the correct properties and methods, named based on the service
        and resource name, e.g. ec2.InstanceCollectionManager. It also
        creates a new :py:class:`ResourceCollection` subclass which is used
        by the new manager class.

        :type resource_name: string
        :param resource_name: Name of the resource to look up. For services,
                              this should match the ``service_name``.

        :type service_context: :py:class:`~boto3.utils.ServiceContext`
        :param service_context: Context about the AWS service

        :type event_emitter: :py:class:`~botocore.hooks.HierarchialEmitter`
        :param event_emitter: An event emitter

        :rtype: Subclass of :py:class:`CollectionManager`
        :return: The collection class.
        'b'{}.{}Collection'u'{}.{}Collection'b'{}.{}.{}Collection'u'{}.{}.{}Collection'b'_collection_cls'u'_collection_cls'b'Manager'u'Manager'b'
        Batch actions on the collection become methods on both
        the collection manager and iterators.
        'u'
        Batch actions on the collection become methods on both
        the collection manager and iterators.
        'b'
        Creates a new method which makes a batch operation request
        to the underlying service API.
        'u'
        Creates a new method which makes a batch operation request
        to the underlying service API.
        'u'boto3.resources.collection'u'resources.collection'u'collection'CollectionDocumenterdocument_collectionscollections_listCollectionsCollections provide an interface to iterate over and manipulate groups of resources. 'Collections provide an interface to iterate over and ''manipulate groups of resources. 'guide_collectionscollectioncollection_section_document_collectiondocument_collection_objectmethod_sectiondocument_batch_actiondocument_collection_methodDocuments a collection resource object

    :param section: The section to write to

    :param collection_model: The model of the collection

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    A collection of  resources.A  Collection will include all resources by default, and extreme caution should be taken when performing actions on all resources.' Collection will include all ''resources by default, and extreme caution should be taken when ''performing actions on all resources.'Documents a collection's batch action

    :param section: The section to write to

    :param resource_name: The name of the resource

    :param action_name: The name of collection action. Currently only
        can be all, filter, limit, or page_size

    :param event_emitter: The event emitter to use to emit events

    :param batch_action_model: The model of the batch action

    :param collection_model: The model of the collection

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    {} = {}.{}.{}Documents a collection method

    :param section: The section to write to

    :param resource_name: The name of the resource

    :param action_name: The name of collection action. Currently only
        can be all, filter, limit, or page_size

    :param event_emitter: The event emitter to use to emit events

    :param collection_model: The model of the collection

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    underlying_operation_membersinput_shapeCreates an iterable of all  resources in the collection.'resources in the collection.'{}_iterator = {}.{}.all resources in the collection filtered by kwargs passed to method. A 'resources in the collection filtered by kwargs passed to ''method. A ' collection will include all resources by default if no filters are provided, and extreme caution should be taken when performing actions on all resources.' collection will ''include all resources by default if no filters are provided, ''and extreme caution should be taken when performing actions ''on all resources.'{}_iterator = {}.{}.filterCreates an iterable up to a specified amount of 'Creates an iterable up to a specified amount of '{}_iterator = {}.{}.limitThe limit to the number of resources in the iterable.'The limit to the number of resources ''in the iterable.'include_input resources in the collection, but limits the number of items returned by each service call by the specified amount.'resources in the collection, but limits the number of ''items returned by each service call by the specified amount.'{}_iterator = {}.{}.page_sizeThe number of items returned by each service call'The number of items returned by each ''service call'custom_action_info_dictaction_infob'Collections'u'Collections'b'Collections provide an interface to iterate over and manipulate groups of resources. 'u'Collections provide an interface to iterate over and manipulate groups of resources. 'b'guide_collections'u'guide_collections'b'Documents a collection resource object

    :param section: The section to write to

    :param collection_model: The model of the collection

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'u'Documents a collection resource object

    :param section: The section to write to

    :param collection_model: The model of the collection

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'b'A collection of 'u'A collection of 'b' resources.'u' resources.'b'A 'u'A 'b' Collection will include all resources by default, and extreme caution should be taken when performing actions on all resources.'u' Collection will include all resources by default, and extreme caution should be taken when performing actions on all resources.'b'Documents a collection's batch action

    :param section: The section to write to

    :param resource_name: The name of the resource

    :param action_name: The name of collection action. Currently only
        can be all, filter, limit, or page_size

    :param event_emitter: The event emitter to use to emit events

    :param batch_action_model: The model of the batch action

    :param collection_model: The model of the collection

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'u'Documents a collection's batch action

    :param section: The section to write to

    :param resource_name: The name of the resource

    :param action_name: The name of collection action. Currently only
        can be all, filter, limit, or page_size

    :param event_emitter: The event emitter to use to emit events

    :param batch_action_model: The model of the batch action

    :param collection_model: The model of the collection

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'b'{} = {}.{}.{}'u'{} = {}.{}.{}'b'Documents a collection method

    :param section: The section to write to

    :param resource_name: The name of the resource

    :param action_name: The name of collection action. Currently only
        can be all, filter, limit, or page_size

    :param event_emitter: The event emitter to use to emit events

    :param collection_model: The model of the collection

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'u'Documents a collection method

    :param section: The section to write to

    :param resource_name: The name of the resource

    :param action_name: The name of collection action. Currently only
        can be all, filter, limit, or page_size

    :param event_emitter: The event emitter to use to emit events

    :param collection_model: The model of the collection

    :param service_model: The model of the service

    :param include_signature: Whether or not to include the signature.
        It is useful for generating docstrings.
    'b'Creates an iterable of all 'u'Creates an iterable of all 'b' resources in the collection.'u' resources in the collection.'b'method_description'u'method_description'b'{}_iterator = {}.{}.all'u'{}_iterator = {}.{}.all'b'example_prefix'u'example_prefix'b'exclude_input'u'exclude_input'b' resources in the collection filtered by kwargs passed to method. A 'u' resources in the collection filtered by kwargs passed to method. A 'b' collection will include all resources by default if no filters are provided, and extreme caution should be taken when performing actions on all resources.'u' collection will include all resources by default if no filters are provided, and extreme caution should be taken when performing actions on all resources.'b'{}_iterator = {}.{}.filter'u'{}_iterator = {}.{}.filter'b'Creates an iterable up to a specified amount of 'u'Creates an iterable up to a specified amount of 'b'{}_iterator = {}.{}.limit'u'{}_iterator = {}.{}.limit'b'The limit to the number of resources in the iterable.'u'The limit to the number of resources in the iterable.'b'include_input'u'include_input'b' resources in the collection, but limits the number of items returned by each service call by the specified amount.'u' resources in the collection, but limits the number of items returned by each service call by the specified amount.'b'{}_iterator = {}.{}.page_size'u'{}_iterator = {}.{}.page_size'b'The number of items returned by each service call'u'The number of items returned by each service call'u'boto3.docs.collection'u'docs.collection'ChooseraskcolorCreate a dialog for the tk_chooseColor command.

    Args:
        master: The master widget for this dialog.  If not provided,
            defaults to options['parent'] (if defined).
        options: Dictionary of options for the tk_chooseColor call.
            initialcolor: Specifies the selected color when the
                dialog is first displayed.  This can be a tk color
                string or a 3-tuple of ints in the range (0, 255)
                for an RGB triplet.
            parent: The parent window of the color dialog.  The
                color dialog is displayed on top of this.
            title: A string for the title of the dialog box.
    tk_chooseColor_fixoptionsEnsure initialcolor is a tk color string.

        Convert initialcolor from a RGB triplet to a color string.
        initialcolor#%02x%02x%02x_fixresultAdjust result returned from call to tk_chooseColor.

        Return both an RGB tuple of ints in the range (0, 255) and the
        tk color string in the form #rrggbb.
        Display dialog window for selection of a color.

    Convenience wrapper for the Chooser class.  Displays the color
    chooser dialog with color as the initial value.
    show# tk common color chooser dialogue# this module provides an interface to the native color dialogue# available in Tk 4.2 and newer.# written by Fredrik Lundh, May 1997# fixed initialcolor handling in August 1998# Assume an RGB triplet.# Result can be many things: an empty tuple, an empty string, or# a _tkinter.Tcl_Obj, so this somewhat weird check handles that.# canceled# To simplify application code, the color chooser returns# an RGB tuple together with the Tk color string.# convenience stuff# test stuffb'Chooser'u'Chooser'b'askcolor'u'askcolor'b'Create a dialog for the tk_chooseColor command.

    Args:
        master: The master widget for this dialog.  If not provided,
            defaults to options['parent'] (if defined).
        options: Dictionary of options for the tk_chooseColor call.
            initialcolor: Specifies the selected color when the
                dialog is first displayed.  This can be a tk color
                string or a 3-tuple of ints in the range (0, 255)
                for an RGB triplet.
            parent: The parent window of the color dialog.  The
                color dialog is displayed on top of this.
            title: A string for the title of the dialog box.
    'u'Create a dialog for the tk_chooseColor command.

    Args:
        master: The master widget for this dialog.  If not provided,
            defaults to options['parent'] (if defined).
        options: Dictionary of options for the tk_chooseColor call.
            initialcolor: Specifies the selected color when the
                dialog is first displayed.  This can be a tk color
                string or a 3-tuple of ints in the range (0, 255)
                for an RGB triplet.
            parent: The parent window of the color dialog.  The
                color dialog is displayed on top of this.
            title: A string for the title of the dialog box.
    'b'tk_chooseColor'u'tk_chooseColor'b'Ensure initialcolor is a tk color string.

        Convert initialcolor from a RGB triplet to a color string.
        'u'Ensure initialcolor is a tk color string.

        Convert initialcolor from a RGB triplet to a color string.
        'b'initialcolor'u'initialcolor'b'#%02x%02x%02x'u'#%02x%02x%02x'b'Adjust result returned from call to tk_chooseColor.

        Return both an RGB tuple of ints in the range (0, 255) and the
        tk color string in the form #rrggbb.
        'u'Adjust result returned from call to tk_chooseColor.

        Return both an RGB tuple of ints in the range (0, 255) and the
        tk color string in the form #rrggbb.
        'b'Display dialog window for selection of a color.

    Convenience wrapper for the Chooser class.  Displays the color
    chooser dialog with color as the initial value.
    'u'Display dialog window for selection of a color.

    Convenience wrapper for the Chooser class.  Displays the color
    chooser dialog with color as the initial value.
    'b'color'u'color'u'colorchooser'_test_callback# base class for tk common dialogues# this module provides a base class for accessing the common# dialogues available in Tk 4.2 and newer.  use filedialog,# colorchooser, and messagebox to access the individual# dialogs.# hook# update instance options# The function below is replaced for some tests.u'commondialog'boto3.exceptionsPythonDeprecationWarningSOCKET_ERRORrename_filecurrent_filenamenew_filenameENOENTfilter_python_deprecation_warnings
    Invoking this filter acknowledges your runtime will soon be deprecated
    at which time you will stop receiving all updates to your client.
    .*Boto3 will no longer support Python.*.*boto3\.compatUse this template for future deprecation campaigns as needed.May 30, 2022https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/'https://aws.amazon.com/blogs/developer/''python-support-policy-updates-for-aws-sdks-and-tools/'blog_linkpy_36_paramsdeprecated_versionspy_versionBoto3 will no longer support Python {}.{} starting {}. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: {}"Boto3 will no longer support Python {}.{} ""starting {}. To continue receiving service updates, ""bug fixes, and security updates please upgrade to Python 3.7 or ""later. More information can be found here: {}"# In python3, socket.error is OSError, which is too general# for what we want (i.e FileNotFoundError is a subclass of OSError).# In py3 all the socket related errors are in a newly created# ConnectionError# We only want to a ignore trying to remove# a file that does not exist.  If it fails# for any other reason we should be propagating# that exception.# Example template for future deprecations# (3, 6): py_36_params,b'
    Invoking this filter acknowledges your runtime will soon be deprecated
    at which time you will stop receiving all updates to your client.
    'u'
    Invoking this filter acknowledges your runtime will soon be deprecated
    at which time you will stop receiving all updates to your client.
    'b'.*Boto3 will no longer support Python.*'u'.*Boto3 will no longer support Python.*'b'.*boto3\.compat'u'.*boto3\.compat'b'Use this template for future deprecation campaigns as needed.'u'Use this template for future deprecation campaigns as needed.'b'May 30, 2022'u'May 30, 2022'b'https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/'u'https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/'b'blog_link'u'blog_link'b'Boto3 will no longer support Python {}.{} starting {}. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: {}'u'Boto3 will no longer support Python {}.{} starting {}. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: {}'u'boto3.compat'u'compat'string_typewith_str_methodwith_repr_methodget_methodsgetmembersisfunction# In python3, we don't need to do anything, we return a str type.u'jmespath.compat'
requests.compat
~~~~~~~~~~~~~~~

This module previously handled import compatibility issues
between Python 2 and Python 3. It remains for backwards
compatibility until the next major version.
_veris_py2is_py3has_simplejsonsimplejsoncookiejarMorselurldefragurlunparsegetproxies_environmentparse_http_listproxy_bypassproxy_bypass_environmentnumeric_types# -------# Pythons# Syntax sugar.#: Python 2.x?#: Python 3.x?# json/simplejson module import resolution# Keep OrderedDict for backwards compatibility.# --------------# Legacy Importsb'
requests.compat
~~~~~~~~~~~~~~~

This module previously handled import compatibility issues
between Python 2 and Python 3. It remains for backwards
compatibility until the next major version.
'u'
requests.compat
~~~~~~~~~~~~~~~

This module previously handled import compatibility issues
between Python 2 and Python 3. It remains for backwards
compatibility until the next major version.
'u'requests.compat'botocore.vendoredMD5UnavailableErrordateutil.tzparse_qslIOBasefile_typeunquote_strset_socket_timeoutSet the timeout of the socket from an HTTPResponse.

    :param http_response: An instance of ``httplib.HTTPResponse``

    accepts_kwargsgetfullargspecensure_bytesExpected str or bytes, received xml.etree.cElementTreeETreeXMLParseErrorfilter_ssl_warningsA true SSLContext object is not available.*.*urllib3\.util\.ssl_from_dictnew_instancecopy_kwargs
    This used to be a compat shim for 2.6 but is now just an alias.
    
    Returns the total seconds in a ``datetime.timedelta``.

    This used to be a compat shim for 2.6 but is now just an alias.

    :param delta: The timedelta object
    :type delta: ``datetime.timedelta``
    get_md5
    Attempts to get an md5 hashing object.

    :param raise_error_if_unavailable: raise an error if md5 is unavailable on
        this system. If False, None will be returned if it is unavailable.
    :type raise_error_if_unavailable: bool
    :param args: Args to pass to the MD5 constructor
    :param kwargs: Key word arguments to pass to the MD5 constructor
    :return: An MD5 hashing object if available. If it is unavailable, None
        is returned if raise_error_if_unavailable is set to False.
    compat_shell_split_windows_shell_splitSplits up a windows command as the built-in command parser would.

    Windows has potentially bizarre rules depending on where you look. When
    spawning a process via the Windows C runtime (which is what python does
    when you call popen) the rules are as follows:

    https://docs.microsoft.com/en-us/cpp/cpp/parsing-cpp-command-line-arguments

    To summarize:

    * Only space and tab are valid delimiters
    * Double quotes are the only valid quotes
    * Backslash is interpreted literally unless it is part of a chain that
      leads up to a double quote. Then the backslashes escape the backslashes,
      and if there is an odd number the final backslash escapes the quote.

    :param s: The command string to split up into parts.
    :return: A list of command components.
    componentsbuffis_quotednum_backslashesNo closing quotation in string: get_tzinfo_optionsawscrt.authBOTO_DISABLE_CRT(?:[0-9]{1,3}\.){3}[0-9]{1,3}IPV4_PATIPV4_RE[0-9A-Fa-f]{1,4}HEX_PAT(?:{hex}:{hex}|{ipv4})ipv4LS32_PATls32_subs(?:%(hex)s:){6}%(ls32)s::(?:%(hex)s:){5}%(ls32)s(?:%(hex)s)?::(?:%(hex)s:){4}%(ls32)s(?:(?:%(hex)s:)?%(hex)s)?::(?:%(hex)s:){3}%(ls32)s(?:(?:%(hex)s:){0,2}%(hex)s)?::(?:%(hex)s:){2}%(ls32)s(?:(?:%(hex)s:){0,3}%(hex)s)?::%(hex)s:%(ls32)s(?:(?:%(hex)s:){0,4}%(hex)s)?::%(ls32)s(?:(?:%(hex)s:){0,5}%(hex)s)?::%(hex)s(?:(?:%(hex)s:){0,6}%(hex)s)?::_variationsABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._!\-~UNRESERVED_PAT(?:IPV6_PAT(?:%25|%)(?:[]|%[a-fA-F0-9]{2})+ZONE_ID_PAT\[)?\]IPV6_ADDRZ_PATIPV6_ADDRZ_RE	
UNSAFE_URL_CHARSHAS_GZIP# In python3, unquote takes a str() object, url decodes it,# then takes the bytestring and decodes it to utf-8.# In python3.4.1, there's backwards incompatible# changes when using getargspec with functools.partials.# NOOP in Python 3, because every string is already unicode# cElementTree does not exist from Python3.9+# Ignore warnings related to SNI as it is not being used in validations.# Checks to see if md5 is available on this system. A given system might not# have access to it for various reasons, such as FIPS mode being enabled.# We can't simply append backslashes because we don't know if# they are being used as escape characters or not. Instead we# keep track of how many we've encountered and handle them when# we encounter a different character.# The backslashes are in a chain leading up to a double# quote, so they are escaping each other.# The number of backslashes is uneven, so they are also# escaping the double quote, so it needs to be added to# the current component buffer.# We've encountered a double quote that is not escaped,# so we toggle is_quoted.# If there are quotes, then we may want an empty string. To be# safe, we add an empty string to the buffer so that we make# sure it sticks around if there's nothing else between quotes.# If there is other stuff between quotes, the empty string will# disappear during the joining process.# Since the backslashes aren't leading up to a quote, we put in# the exact number of backslashes.# Excess whitespace is ignored, so only add the components list# if there is anything in the buffer.# Quotes must be terminated.# There may be some leftover backslashes, so we need to add them in.# There's no quote so we add the exact number.# Add the final component in if there is anything in the buffer.# Due to dateutil/dateutil#197, Windows may fail to parse times in the past# with the system clock. We can alternatively fallback to tzwininfo when# this happens, which will get time info from the Windows registry.# Detect if CRT is available for use# Allow user opt-out if needed#########################################################              urllib3 compat backports                ## Vendoring IPv6 validation regex patterns from urllib3# https://github.com/urllib3/urllib3/blob/7e856c0/src/urllib3/util/url.py#                            6( h16 ":" ) ls32#                       "::" 5( h16 ":" ) ls32# [               h16 ] "::" 4( h16 ":" ) ls32# [ *1( h16 ":" ) h16 ] "::" 3( h16 ":" ) ls32# [ *2( h16 ":" ) h16 ] "::" 2( h16 ":" ) ls32# [ *3( h16 ":" ) h16 ] "::"    h16 ":"   ls32# [ *4( h16 ":" ) h16 ] "::"              ls32# [ *5( h16 ":" ) h16 ] "::"              h16# [ *6( h16 ":" ) h16 ] "::"# These are the characters that are stripped by post-bpo-43882 urlparse().# Detect if gzip is available for useb'Set the timeout of the socket from an HTTPResponse.

    :param http_response: An instance of ``httplib.HTTPResponse``

    'u'Set the timeout of the socket from an HTTPResponse.

    :param http_response: An instance of ``httplib.HTTPResponse``

    'b'Expected str or bytes, received 'u'Expected str or bytes, received 'b'A true SSLContext object is not available.*'u'A true SSLContext object is not available.*'b'.*urllib3\.util\.ssl_'u'.*urllib3\.util\.ssl_'b'
    This used to be a compat shim for 2.6 but is now just an alias.
    'u'
    This used to be a compat shim for 2.6 but is now just an alias.
    'b'
    Returns the total seconds in a ``datetime.timedelta``.

    This used to be a compat shim for 2.6 but is now just an alias.

    :param delta: The timedelta object
    :type delta: ``datetime.timedelta``
    'u'
    Returns the total seconds in a ``datetime.timedelta``.

    This used to be a compat shim for 2.6 but is now just an alias.

    :param delta: The timedelta object
    :type delta: ``datetime.timedelta``
    'b'
    Attempts to get an md5 hashing object.

    :param raise_error_if_unavailable: raise an error if md5 is unavailable on
        this system. If False, None will be returned if it is unavailable.
    :type raise_error_if_unavailable: bool
    :param args: Args to pass to the MD5 constructor
    :param kwargs: Key word arguments to pass to the MD5 constructor
    :return: An MD5 hashing object if available. If it is unavailable, None
        is returned if raise_error_if_unavailable is set to False.
    'u'
    Attempts to get an md5 hashing object.

    :param raise_error_if_unavailable: raise an error if md5 is unavailable on
        this system. If False, None will be returned if it is unavailable.
    :type raise_error_if_unavailable: bool
    :param args: Args to pass to the MD5 constructor
    :param kwargs: Key word arguments to pass to the MD5 constructor
    :return: An MD5 hashing object if available. If it is unavailable, None
        is returned if raise_error_if_unavailable is set to False.
    'b'Splits up a windows command as the built-in command parser would.

    Windows has potentially bizarre rules depending on where you look. When
    spawning a process via the Windows C runtime (which is what python does
    when you call popen) the rules are as follows:

    https://docs.microsoft.com/en-us/cpp/cpp/parsing-cpp-command-line-arguments

    To summarize:

    * Only space and tab are valid delimiters
    * Double quotes are the only valid quotes
    * Backslash is interpreted literally unless it is part of a chain that
      leads up to a double quote. Then the backslashes escape the backslashes,
      and if there is an odd number the final backslash escapes the quote.

    :param s: The command string to split up into parts.
    :return: A list of command components.
    'u'Splits up a windows command as the built-in command parser would.

    Windows has potentially bizarre rules depending on where you look. When
    spawning a process via the Windows C runtime (which is what python does
    when you call popen) the rules are as follows:

    https://docs.microsoft.com/en-us/cpp/cpp/parsing-cpp-command-line-arguments

    To summarize:

    * Only space and tab are valid delimiters
    * Double quotes are the only valid quotes
    * Backslash is interpreted literally unless it is part of a chain that
      leads up to a double quote. Then the backslashes escape the backslashes,
      and if there is an odd number the final backslash escapes the quote.

    :param s: The command string to split up into parts.
    :return: A list of command components.
    'b'No closing quotation in string: 'u'No closing quotation in string: 'b'BOTO_DISABLE_CRT'u'BOTO_DISABLE_CRT'b'(?:[0-9]{1,3}\.){3}[0-9]{1,3}'u'(?:[0-9]{1,3}\.){3}[0-9]{1,3}'b'[0-9A-Fa-f]{1,4}'u'[0-9A-Fa-f]{1,4}'b'(?:{hex}:{hex}|{ipv4})'u'(?:{hex}:{hex}|{ipv4})'b'ls32'u'ls32'b'(?:%(hex)s:){6}%(ls32)s'u'(?:%(hex)s:){6}%(ls32)s'b'::(?:%(hex)s:){5}%(ls32)s'u'::(?:%(hex)s:){5}%(ls32)s'b'(?:%(hex)s)?::(?:%(hex)s:){4}%(ls32)s'u'(?:%(hex)s)?::(?:%(hex)s:){4}%(ls32)s'b'(?:(?:%(hex)s:)?%(hex)s)?::(?:%(hex)s:){3}%(ls32)s'u'(?:(?:%(hex)s:)?%(hex)s)?::(?:%(hex)s:){3}%(ls32)s'b'(?:(?:%(hex)s:){0,2}%(hex)s)?::(?:%(hex)s:){2}%(ls32)s'u'(?:(?:%(hex)s:){0,2}%(hex)s)?::(?:%(hex)s:){2}%(ls32)s'b'(?:(?:%(hex)s:){0,3}%(hex)s)?::%(hex)s:%(ls32)s'u'(?:(?:%(hex)s:){0,3}%(hex)s)?::%(hex)s:%(ls32)s'b'(?:(?:%(hex)s:){0,4}%(hex)s)?::%(ls32)s'u'(?:(?:%(hex)s:){0,4}%(hex)s)?::%(ls32)s'b'(?:(?:%(hex)s:){0,5}%(hex)s)?::%(hex)s'u'(?:(?:%(hex)s:){0,5}%(hex)s)?::%(hex)s'b'(?:(?:%(hex)s:){0,6}%(hex)s)?::'u'(?:(?:%(hex)s:){0,6}%(hex)s)?::'b'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._!\-~'u'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._!\-~'b'(?:'u'(?:'b'(?:%25|%)(?:['u'(?:%25|%)(?:['b']|%[a-fA-F0-9]{2})+'u']|%[a-fA-F0-9]{2})+'b'\['u'\['b')?\]'u')?\]'b'	
'u'	
'u'botocore.compat'MAX_POOL_CONNECTIONSInvalidMaxRetryAttemptsErrorInvalidRetryConfigurationErrorInvalidRetryModeErrorInvalidS3AddressingStyleErrorAdvanced configuration for Botocore clients.

    :type region_name: str
    :param region_name: The region to use in instantiating the client

    :type signature_version: str
    :param signature_version: The signature version when signing requests.

    :type user_agent: str
    :param user_agent: The value to use in the User-Agent header.

    :type user_agent_extra: str
    :param user_agent_extra: The value to append to the current User-Agent
        header value.

    :type connect_timeout: float or int
    :param connect_timeout: The time in seconds till a timeout exception is
        thrown when attempting to make a connection. The default is 60
        seconds.

    :type read_timeout: float or int
    :param read_timeout: The time in seconds till a timeout exception is
        thrown when attempting to read from a connection. The default is
        60 seconds.

    :type parameter_validation: bool
    :param parameter_validation: Whether parameter validation should occur
        when serializing requests. The default is True.  You can disable
        parameter validation for performance reasons.  Otherwise, it's
        recommended to leave parameter validation enabled.

    :type max_pool_connections: int
    :param max_pool_connections: The maximum number of connections to
        keep in a connection pool.  If this value is not set, the default
        value of 10 is used.

    :type proxies: dict
    :param proxies: A dictionary of proxy servers to use by protocol or
        endpoint, e.g.:
        {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.
        The proxies are used on each request.

    :type proxies_config: dict
    :param proxies_config: A dictionary of additional proxy configurations.
        Valid keys are:

        * 'proxy_ca_bundle' -- The path to a custom certificate bundle to use
          when establishing SSL/TLS connections with proxy.

        * 'proxy_client_cert' -- The path to a certificate for proxy
          TLS client authentication.

          When a str is provided it is treated as a path to a proxy client
          certificate. When a two element tuple is provided, it will be
          interpreted as the path to the client certificate, and the path
          to the certificate key.

        * 'proxy_use_forwarding_for_https' -- For HTTPS proxies,
          forward your requests to HTTPS destinations with an absolute
          URI. We strongly recommend you only use this option with
          trusted or corporate proxies. Value must be boolean.

    :type s3: dict
    :param s3: A dictionary of s3 specific configurations.
        Valid keys are:

        * 'use_accelerate_endpoint' -- Refers to whether to use the S3
          Accelerate endpoint. The value must be a boolean. If True, the
          client will use the S3 Accelerate endpoint. If the S3 Accelerate
          endpoint is being used then the addressing style will always
          be virtual.

        * 'payload_signing_enabled' -- Refers to whether or not to SHA256
          sign sigv4 payloads. By default, this is disabled for streaming
          uploads (UploadPart and PutObject).

        * 'addressing_style' -- Refers to the style in which to address
          s3 endpoints. Values must be a string that equals:

          * auto -- Addressing style is chosen for user. Depending
            on the configuration of client, the endpoint may be addressed in
            the virtual or the path style. Note that this is the default
            behavior if no style is specified.

          * virtual -- Addressing style is always virtual. The name of the
            bucket must be DNS compatible or an exception will be thrown.
            Endpoints will be addressed as such: mybucket.s3.amazonaws.com

          * path -- Addressing style is always by path. Endpoints will be
            addressed as such: s3.amazonaws.com/mybucket

        * 'us_east_1_regional_endpoint' - Refers to what S3 endpoint to use
          when the region is configured to be us-east-1. Values must be a
          string that equals:

           * regional -- Use the us-east-1.amazonaws.com endpoint if the
             client is configured to use the us-east-1 region.

           * legacy -- Use the s3.amazonaws.com endpoint if the client is
             configured to use the us-east-1 region. This is the default if
             the configuration option is not specified.


    :type retries: dict
    :param retries: A dictionary for retry specific configurations.
        Valid keys are:

        * 'total_max_attempts' -- An integer representing the maximum number of
          total attempts that will be made on a single request.  This includes
          the initial request, so a value of 1 indicates that no requests
          will be retried.  If ``total_max_attempts`` and ``max_attempts``
          are both provided, ``total_max_attempts`` takes precedence.
          ``total_max_attempts`` is preferred over ``max_attempts`` because
          it maps to the ``AWS_MAX_ATTEMPTS`` environment variable and
          the ``max_attempts`` config file value.
        * 'max_attempts' -- An integer representing the maximum number of
          retry attempts that will be made on a single request. For
          example, setting this value to 2 will result in the request
          being retried at most two times after the initial request. Setting
          this value to 0 will result in no retries ever being attempted on
          the initial request. If not provided, the number of retries will
          default to whatever is modeled, which is typically four retries.
        * 'mode' -- A string representing the type of retry mode botocore
          should use.  Valid values are:
              * ``legacy`` - The pre-existing retry behavior.
              * ``standard`` - The standardized set of retry rules.  This
                will also default to 3 max attempts unless overridden.
              * ``adaptive`` - Retries with additional client side throttling.

    :type client_cert: str, (str, str)
    :param client_cert: The path to a certificate for TLS client authentication.

        When a str is provided it is treated as a path to a client certificate
        to be used when creating a TLS connection.

        If a client key is to be provided alongside the client certificate the
        client_cert should be set to a tuple of length two where the first
        element is the path to the client certificate and the second element is
        the path to the certificate key.

    :type inject_host_prefix: bool
    :param inject_host_prefix: Whether host prefix injection should occur.

        Defaults to True.

        Setting this to False disables the injection of operation parameters
        into the prefix of the hostname. This is useful for clients providing
        custom endpoints that should not have their host prefix modified.

    :type use_dualstack_endpoint: bool
    :param use_dualstack_endpoint: Setting to True enables dualstack
        endpoint resolution.

        Defaults to None.

    :type use_fips_endpoint: bool
    :param use_fips_endpoint: Setting to True enables fips
        endpoint resolution.

        Defaults to None.

    :type tcp_keepalive: bool
    :param tcp_keepalive: Enables the TCP Keep-Alive socket option used when
        creating new connections if set to True.

        Defaults to False.
    defaults_modeOPTION_DEFAULTSNON_LEGACY_OPTION_DEFAULTS_record_user_provided_options_user_provided_optionsconfig_vars_validate_s3_configuration_validate_retry_configurationoption_orderuser_provided_optionsGot unexpected keyword argument 'Takes at most  arguments ( given)Got multiple values for keyword argument 's3_addressing_stylevalid_optionsvalid_modesretry_config_optionprovided_max_attemptsmin_valueprovided_retry_modeother_configMerges the config object with another config object

        This will merge in all non-default values from the provided config
        and return a new config object

        :type other_config: botocore.config.Config
        :param other config: Another config object to merge with. The values
            in the provided config object will take precedence in the merging

        :returns: A config object built from the merged values of both
            config objects.
        config_options# Merge the user_provided options onto the default options# Set the attributes based on the config_vars# Validate the s3 options# Iterate through the kwargs passed through to the constructor and# map valid keys to the dictionary# The key must exist in the available options# The number of args should not be longer than the allowed# options# Iterate through the args passed through to the constructor and map# them to appropriate keys.# If it a kwarg was specified for the arg, then error out# Make a copy of the current attributes in the config object.# Merge in the user provided options from the other config# Return a new config object with the merged properties.b'Advanced configuration for Botocore clients.

    :type region_name: str
    :param region_name: The region to use in instantiating the client

    :type signature_version: str
    :param signature_version: The signature version when signing requests.

    :type user_agent: str
    :param user_agent: The value to use in the User-Agent header.

    :type user_agent_extra: str
    :param user_agent_extra: The value to append to the current User-Agent
        header value.

    :type connect_timeout: float or int
    :param connect_timeout: The time in seconds till a timeout exception is
        thrown when attempting to make a connection. The default is 60
        seconds.

    :type read_timeout: float or int
    :param read_timeout: The time in seconds till a timeout exception is
        thrown when attempting to read from a connection. The default is
        60 seconds.

    :type parameter_validation: bool
    :param parameter_validation: Whether parameter validation should occur
        when serializing requests. The default is True.  You can disable
        parameter validation for performance reasons.  Otherwise, it's
        recommended to leave parameter validation enabled.

    :type max_pool_connections: int
    :param max_pool_connections: The maximum number of connections to
        keep in a connection pool.  If this value is not set, the default
        value of 10 is used.

    :type proxies: dict
    :param proxies: A dictionary of proxy servers to use by protocol or
        endpoint, e.g.:
        {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.
        The proxies are used on each request.

    :type proxies_config: dict
    :param proxies_config: A dictionary of additional proxy configurations.
        Valid keys are:

        * 'proxy_ca_bundle' -- The path to a custom certificate bundle to use
          when establishing SSL/TLS connections with proxy.

        * 'proxy_client_cert' -- The path to a certificate for proxy
          TLS client authentication.

          When a str is provided it is treated as a path to a proxy client
          certificate. When a two element tuple is provided, it will be
          interpreted as the path to the client certificate, and the path
          to the certificate key.

        * 'proxy_use_forwarding_for_https' -- For HTTPS proxies,
          forward your requests to HTTPS destinations with an absolute
          URI. We strongly recommend you only use this option with
          trusted or corporate proxies. Value must be boolean.

    :type s3: dict
    :param s3: A dictionary of s3 specific configurations.
        Valid keys are:

        * 'use_accelerate_endpoint' -- Refers to whether to use the S3
          Accelerate endpoint. The value must be a boolean. If True, the
          client will use the S3 Accelerate endpoint. If the S3 Accelerate
          endpoint is being used then the addressing style will always
          be virtual.

        * 'payload_signing_enabled' -- Refers to whether or not to SHA256
          sign sigv4 payloads. By default, this is disabled for streaming
          uploads (UploadPart and PutObject).

        * 'addressing_style' -- Refers to the style in which to address
          s3 endpoints. Values must be a string that equals:

          * auto -- Addressing style is chosen for user. Depending
            on the configuration of client, the endpoint may be addressed in
            the virtual or the path style. Note that this is the default
            behavior if no style is specified.

          * virtual -- Addressing style is always virtual. The name of the
            bucket must be DNS compatible or an exception will be thrown.
            Endpoints will be addressed as such: mybucket.s3.amazonaws.com

          * path -- Addressing style is always by path. Endpoints will be
            addressed as such: s3.amazonaws.com/mybucket

        * 'us_east_1_regional_endpoint' - Refers to what S3 endpoint to use
          when the region is configured to be us-east-1. Values must be a
          string that equals:

           * regional -- Use the us-east-1.amazonaws.com endpoint if the
             client is configured to use the us-east-1 region.

           * legacy -- Use the s3.amazonaws.com endpoint if the client is
             configured to use the us-east-1 region. This is the default if
             the configuration option is not specified.


    :type retries: dict
    :param retries: A dictionary for retry specific configurations.
        Valid keys are:

        * 'total_max_attempts' -- An integer representing the maximum number of
          total attempts that will be made on a single request.  This includes
          the initial request, so a value of 1 indicates that no requests
          will be retried.  If ``total_max_attempts`` and ``max_attempts``
          are both provided, ``total_max_attempts`` takes precedence.
          ``total_max_attempts`` is preferred over ``max_attempts`` because
          it maps to the ``AWS_MAX_ATTEMPTS`` environment variable and
          the ``max_attempts`` config file value.
        * 'max_attempts' -- An integer representing the maximum number of
          retry attempts that will be made on a single request. For
          example, setting this value to 2 will result in the request
          being retried at most two times after the initial request. Setting
          this value to 0 will result in no retries ever being attempted on
          the initial request. If not provided, the number of retries will
          default to whatever is modeled, which is typically four retries.
        * 'mode' -- A string representing the type of retry mode botocore
          should use.  Valid values are:
              * ``legacy`` - The pre-existing retry behavior.
              * ``standard`` - The standardized set of retry rules.  This
                will also default to 3 max attempts unless overridden.
              * ``adaptive`` - Retries with additional client side throttling.

    :type client_cert: str, (str, str)
    :param client_cert: The path to a certificate for TLS client authentication.

        When a str is provided it is treated as a path to a client certificate
        to be used when creating a TLS connection.

        If a client key is to be provided alongside the client certificate the
        client_cert should be set to a tuple of length two where the first
        element is the path to the client certificate and the second element is
        the path to the certificate key.

    :type inject_host_prefix: bool
    :param inject_host_prefix: Whether host prefix injection should occur.

        Defaults to True.

        Setting this to False disables the injection of operation parameters
        into the prefix of the hostname. This is useful for clients providing
        custom endpoints that should not have their host prefix modified.

    :type use_dualstack_endpoint: bool
    :param use_dualstack_endpoint: Setting to True enables dualstack
        endpoint resolution.

        Defaults to None.

    :type use_fips_endpoint: bool
    :param use_fips_endpoint: Setting to True enables fips
        endpoint resolution.

        Defaults to None.

    :type tcp_keepalive: bool
    :param tcp_keepalive: Enables the TCP Keep-Alive socket option used when
        creating new connections if set to True.

        Defaults to False.
    'u'Advanced configuration for Botocore clients.

    :type region_name: str
    :param region_name: The region to use in instantiating the client

    :type signature_version: str
    :param signature_version: The signature version when signing requests.

    :type user_agent: str
    :param user_agent: The value to use in the User-Agent header.

    :type user_agent_extra: str
    :param user_agent_extra: The value to append to the current User-Agent
        header value.

    :type connect_timeout: float or int
    :param connect_timeout: The time in seconds till a timeout exception is
        thrown when attempting to make a connection. The default is 60
        seconds.

    :type read_timeout: float or int
    :param read_timeout: The time in seconds till a timeout exception is
        thrown when attempting to read from a connection. The default is
        60 seconds.

    :type parameter_validation: bool
    :param parameter_validation: Whether parameter validation should occur
        when serializing requests. The default is True.  You can disable
        parameter validation for performance reasons.  Otherwise, it's
        recommended to leave parameter validation enabled.

    :type max_pool_connections: int
    :param max_pool_connections: The maximum number of connections to
        keep in a connection pool.  If this value is not set, the default
        value of 10 is used.

    :type proxies: dict
    :param proxies: A dictionary of proxy servers to use by protocol or
        endpoint, e.g.:
        {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.
        The proxies are used on each request.

    :type proxies_config: dict
    :param proxies_config: A dictionary of additional proxy configurations.
        Valid keys are:

        * 'proxy_ca_bundle' -- The path to a custom certificate bundle to use
          when establishing SSL/TLS connections with proxy.

        * 'proxy_client_cert' -- The path to a certificate for proxy
          TLS client authentication.

          When a str is provided it is treated as a path to a proxy client
          certificate. When a two element tuple is provided, it will be
          interpreted as the path to the client certificate, and the path
          to the certificate key.

        * 'proxy_use_forwarding_for_https' -- For HTTPS proxies,
          forward your requests to HTTPS destinations with an absolute
          URI. We strongly recommend you only use this option with
          trusted or corporate proxies. Value must be boolean.

    :type s3: dict
    :param s3: A dictionary of s3 specific configurations.
        Valid keys are:

        * 'use_accelerate_endpoint' -- Refers to whether to use the S3
          Accelerate endpoint. The value must be a boolean. If True, the
          client will use the S3 Accelerate endpoint. If the S3 Accelerate
          endpoint is being used then the addressing style will always
          be virtual.

        * 'payload_signing_enabled' -- Refers to whether or not to SHA256
          sign sigv4 payloads. By default, this is disabled for streaming
          uploads (UploadPart and PutObject).

        * 'addressing_style' -- Refers to the style in which to address
          s3 endpoints. Values must be a string that equals:

          * auto -- Addressing style is chosen for user. Depending
            on the configuration of client, the endpoint may be addressed in
            the virtual or the path style. Note that this is the default
            behavior if no style is specified.

          * virtual -- Addressing style is always virtual. The name of the
            bucket must be DNS compatible or an exception will be thrown.
            Endpoints will be addressed as such: mybucket.s3.amazonaws.com

          * path -- Addressing style is always by path. Endpoints will be
            addressed as such: s3.amazonaws.com/mybucket

        * 'us_east_1_regional_endpoint' - Refers to what S3 endpoint to use
          when the region is configured to be us-east-1. Values must be a
          string that equals:

           * regional -- Use the us-east-1.amazonaws.com endpoint if the
             client is configured to use the us-east-1 region.

           * legacy -- Use the s3.amazonaws.com endpoint if the client is
             configured to use the us-east-1 region. This is the default if
             the configuration option is not specified.


    :type retries: dict
    :param retries: A dictionary for retry specific configurations.
        Valid keys are:

        * 'total_max_attempts' -- An integer representing the maximum number of
          total attempts that will be made on a single request.  This includes
          the initial request, so a value of 1 indicates that no requests
          will be retried.  If ``total_max_attempts`` and ``max_attempts``
          are both provided, ``total_max_attempts`` takes precedence.
          ``total_max_attempts`` is preferred over ``max_attempts`` because
          it maps to the ``AWS_MAX_ATTEMPTS`` environment variable and
          the ``max_attempts`` config file value.
        * 'max_attempts' -- An integer representing the maximum number of
          retry attempts that will be made on a single request. For
          example, setting this value to 2 will result in the request
          being retried at most two times after the initial request. Setting
          this value to 0 will result in no retries ever being attempted on
          the initial request. If not provided, the number of retries will
          default to whatever is modeled, which is typically four retries.
        * 'mode' -- A string representing the type of retry mode botocore
          should use.  Valid values are:
              * ``legacy`` - The pre-existing retry behavior.
              * ``standard`` - The standardized set of retry rules.  This
                will also default to 3 max attempts unless overridden.
              * ``adaptive`` - Retries with additional client side throttling.

    :type client_cert: str, (str, str)
    :param client_cert: The path to a certificate for TLS client authentication.

        When a str is provided it is treated as a path to a client certificate
        to be used when creating a TLS connection.

        If a client key is to be provided alongside the client certificate the
        client_cert should be set to a tuple of length two where the first
        element is the path to the client certificate and the second element is
        the path to the certificate key.

    :type inject_host_prefix: bool
    :param inject_host_prefix: Whether host prefix injection should occur.

        Defaults to True.

        Setting this to False disables the injection of operation parameters
        into the prefix of the hostname. This is useful for clients providing
        custom endpoints that should not have their host prefix modified.

    :type use_dualstack_endpoint: bool
    :param use_dualstack_endpoint: Setting to True enables dualstack
        endpoint resolution.

        Defaults to None.

    :type use_fips_endpoint: bool
    :param use_fips_endpoint: Setting to True enables fips
        endpoint resolution.

        Defaults to None.

    :type tcp_keepalive: bool
    :param tcp_keepalive: Enables the TCP Keep-Alive socket option used when
        creating new connections if set to True.

        Defaults to False.
    'b'user_agent_extra'u'user_agent_extra'b'read_timeout'u'read_timeout'b'max_pool_connections'u'max_pool_connections'b'proxies'u'proxies'b'proxies_config'u'proxies_config'b'client_cert'u'client_cert'b'inject_host_prefix'u'inject_host_prefix'b'defaults_mode'u'defaults_mode'b'Got unexpected keyword argument ''u'Got unexpected keyword argument ''b'Takes at most 'u'Takes at most 'b' arguments ('u' arguments ('b' given)'u' given)'b'Got multiple values for keyword argument ''u'Got multiple values for keyword argument ''b'Merges the config object with another config object

        This will merge in all non-default values from the provided config
        and return a new config object

        :type other_config: botocore.config.Config
        :param other config: Another config object to merge with. The values
            in the provided config object will take precedence in the merging

        :returns: A config object built from the merged values of both
            config objects.
        'u'Merges the config object with another config object

        This will merge in all non-default values from the provided config
        and return a new config object

        :type other_config: botocore.config.Config
        :param other config: Another config object to merge with. The values
            in the provided config object will take precedence in the merging

        :returns: A config object built from the merged values of both
            config objects.
        'u'botocore.config'multi_file_load_configLoad and combine multiple INI configs with profiles.

    This function will take a list of filesnames and return
    a single dictionary that represents the merging of the loaded
    config files.

    If any of the provided filenames does not exist, then that file
    is ignored.  It is therefore ok to provide a list of filenames,
    some of which may not exist.

    Configuration files are **not** deep merged, only the top level
    keys are merged.  The filenames should be passed in order of
    precedence.  The first config file has precedence over the
    second config file, which has precedence over the third config file,
    etc.  The only exception to this is that the "profiles" key is
    merged to combine profiles from multiple config files into a
    single profiles mapping.  However, if a profile is defined in
    multiple config files, then the config file with the highest
    precedence is used.  Profile values themselves are not merged.
    For example::

        FileA              FileB                FileC
        [foo]             [foo]                 [bar]
        a=1               a=2                   a=3
                          b=2

        [bar]             [baz]                [profile a]
        a=2               a=3                  region=e

        [profile a]       [profile b]          [profile c]
        region=c          region=d             region=f

    The final result of ``multi_file_load_config(FileA, FileB, FileC)``
    would be::

        {"foo": {"a": 1}, "bar": {"a": 2}, "baz": {"a": 3},
        "profiles": {"a": {"region": "c"}}, {"b": {"region": d"}},
                    {"c": {"region": "f"}}}

    Note that the "foo" key comes from A, even though it's defined in both
    FileA and FileB.  Because "foo" was defined in FileA first, then the values
    for "foo" from FileA are used and the values for "foo" from FileB are
    ignored.  Also note where the profiles originate from.  Profile "a"
    comes FileA, profile "b" comes from FileB, and profile "c" comes
    from FileC.

    configsprofilesload_configloadedConfigNotFound_merge_list_of_dictsmerged_configmerged_profileslist_of_dictsmerged_dictssingle_dictconfig_filenameParse a INI config with profiles.

    This will parse an INI config file and map top level profiles
    into a top level "profile" key.

    If you want to parse an INI file and map all section names to
    top level keys, use ``raw_config_parse`` instead.

    raw_config_parsebuild_profile_mapparse_subsectionsReturns the parsed INI config contents.

    Each section name is a top level key.

    :param config_filename: The name of the INI file to parse

    :param parse_subsections: If True, parse indented blocks as
       subsections that represent their own configuration dictionary.
       For example, if the config file had the contents::

           s3 =
              signature_version = s3v4
              addressing_style = path

        The resulting ``raw_config_parse`` would be::

            {'s3': {'signature_version': 's3v4', 'addressing_style': 'path'}}

       If False, do not try to parse subsections and return the indented
       block as its literal value::

            {'s3': '
signature_version = s3v4
addressing_style = path'}

    :returns: A dict with keys for each profile found in the config
        file and the value of each key being a dict containing name
        value pairs found in that profile.

    :raises: ConfigNotFound, ConfigParseError
    expandvarsexpanduser_unicode_path_parse_nestedConfigParseErrorfilesystem_encodingparsed_ini_configConvert the parsed INI config into a profile map.

    The config file format requires that every profile except the
    default to be prepended with "profile", e.g.::

        [profile test]
        aws_... = foo
        aws_... = bar

        [profile bar]
        aws_... = foo
        aws_... = bar

        # This is *not* a profile
        [preview]
        otherstuff = 1

        # Neither is this
        [foobar]
        morestuff = 2

    The build_profile_map will take a parsed INI config file where each top
    level key represents a section name, and convert into a format where all
    the profiles are under a single top level "profiles" key, and each key in
    the sub dictionary is a profile name.  For example, the above config file
    would be converted from::

        {"profile test": {"aws_...": "foo", "aws...": "bar"},
         "profile bar": {"aws...": "foo", "aws...": "bar"},
         "preview": {"otherstuff": ...},
         "foobar": {"morestuff": ...},
         }

    into::

        {"profiles": {"test": {"aws_...": "foo", "aws...": "bar"},
                      "bar": {"aws...": "foo", "aws...": "bar"},
         "preview": {"otherstuff": ...},
         "foobar": {"morestuff": ...},
        }

    If there are no profiles in the provided parsed INI contents, then
    an empty dict will be the value associated with the ``profiles`` key.

    .. note::

        This will not mutate the passed in parsed_ini_config.  Instead it will
        make a deepcopy and return that value.

    parsed_configsso_sessionsfinal_configprofilesso-session# Copyright 2012-2016 Amazon.com, Inc. or its affiliates. All Rights Reserved.# Then we need to parse the inner contents as# hierarchical.  We support a single level# of nesting for now.# According to the documentation getfilesystemencoding can return None# on unix in which case the default encoding is used instead.# Given a value like this:# \n# foo = bar# bar = baz# We need to parse this into# {'foo': 'bar', 'bar': 'baz}# The caller will catch ValueError# and raise an appropriate error# if this fails.# default section is special and is considered a profile# name but we don't require you use 'profile "default"'# as a section.b'Load and combine multiple INI configs with profiles.

    This function will take a list of filesnames and return
    a single dictionary that represents the merging of the loaded
    config files.

    If any of the provided filenames does not exist, then that file
    is ignored.  It is therefore ok to provide a list of filenames,
    some of which may not exist.

    Configuration files are **not** deep merged, only the top level
    keys are merged.  The filenames should be passed in order of
    precedence.  The first config file has precedence over the
    second config file, which has precedence over the third config file,
    etc.  The only exception to this is that the "profiles" key is
    merged to combine profiles from multiple config files into a
    single profiles mapping.  However, if a profile is defined in
    multiple config files, then the config file with the highest
    precedence is used.  Profile values themselves are not merged.
    For example::

        FileA              FileB                FileC
        [foo]             [foo]                 [bar]
        a=1               a=2                   a=3
                          b=2

        [bar]             [baz]                [profile a]
        a=2               a=3                  region=e

        [profile a]       [profile b]          [profile c]
        region=c          region=d             region=f

    The final result of ``multi_file_load_config(FileA, FileB, FileC)``
    would be::

        {"foo": {"a": 1}, "bar": {"a": 2}, "baz": {"a": 3},
        "profiles": {"a": {"region": "c"}}, {"b": {"region": d"}},
                    {"c": {"region": "f"}}}

    Note that the "foo" key comes from A, even though it's defined in both
    FileA and FileB.  Because "foo" was defined in FileA first, then the values
    for "foo" from FileA are used and the values for "foo" from FileB are
    ignored.  Also note where the profiles originate from.  Profile "a"
    comes FileA, profile "b" comes from FileB, and profile "c" comes
    from FileC.

    'u'Load and combine multiple INI configs with profiles.

    This function will take a list of filesnames and return
    a single dictionary that represents the merging of the loaded
    config files.

    If any of the provided filenames does not exist, then that file
    is ignored.  It is therefore ok to provide a list of filenames,
    some of which may not exist.

    Configuration files are **not** deep merged, only the top level
    keys are merged.  The filenames should be passed in order of
    precedence.  The first config file has precedence over the
    second config file, which has precedence over the third config file,
    etc.  The only exception to this is that the "profiles" key is
    merged to combine profiles from multiple config files into a
    single profiles mapping.  However, if a profile is defined in
    multiple config files, then the config file with the highest
    precedence is used.  Profile values themselves are not merged.
    For example::

        FileA              FileB                FileC
        [foo]             [foo]                 [bar]
        a=1               a=2                   a=3
                          b=2

        [bar]             [baz]                [profile a]
        a=2               a=3                  region=e

        [profile a]       [profile b]          [profile c]
        region=c          region=d             region=f

    The final result of ``multi_file_load_config(FileA, FileB, FileC)``
    would be::

        {"foo": {"a": 1}, "bar": {"a": 2}, "baz": {"a": 3},
        "profiles": {"a": {"region": "c"}}, {"b": {"region": d"}},
                    {"c": {"region": "f"}}}

    Note that the "foo" key comes from A, even though it's defined in both
    FileA and FileB.  Because "foo" was defined in FileA first, then the values
    for "foo" from FileA are used and the values for "foo" from FileB are
    ignored.  Also note where the profiles originate from.  Profile "a"
    comes FileA, profile "b" comes from FileB, and profile "c" comes
    from FileC.

    'b'profiles'u'profiles'b'Parse a INI config with profiles.

    This will parse an INI config file and map top level profiles
    into a top level "profile" key.

    If you want to parse an INI file and map all section names to
    top level keys, use ``raw_config_parse`` instead.

    'u'Parse a INI config with profiles.

    This will parse an INI config file and map top level profiles
    into a top level "profile" key.

    If you want to parse an INI file and map all section names to
    top level keys, use ``raw_config_parse`` instead.

    'b'Returns the parsed INI config contents.

    Each section name is a top level key.

    :param config_filename: The name of the INI file to parse

    :param parse_subsections: If True, parse indented blocks as
       subsections that represent their own configuration dictionary.
       For example, if the config file had the contents::

           s3 =
              signature_version = s3v4
              addressing_style = path

        The resulting ``raw_config_parse`` would be::

            {'s3': {'signature_version': 's3v4', 'addressing_style': 'path'}}

       If False, do not try to parse subsections and return the indented
       block as its literal value::

            {'s3': '
signature_version = s3v4
addressing_style = path'}

    :returns: A dict with keys for each profile found in the config
        file and the value of each key being a dict containing name
        value pairs found in that profile.

    :raises: ConfigNotFound, ConfigParseError
    'u'Returns the parsed INI config contents.

    Each section name is a top level key.

    :param config_filename: The name of the INI file to parse

    :param parse_subsections: If True, parse indented blocks as
       subsections that represent their own configuration dictionary.
       For example, if the config file had the contents::

           s3 =
              signature_version = s3v4
              addressing_style = path

        The resulting ``raw_config_parse`` would be::

            {'s3': {'signature_version': 's3v4', 'addressing_style': 'path'}}

       If False, do not try to parse subsections and return the indented
       block as its literal value::

            {'s3': '
signature_version = s3v4
addressing_style = path'}

    :returns: A dict with keys for each profile found in the config
        file and the value of each key being a dict containing name
        value pairs found in that profile.

    :raises: ConfigNotFound, ConfigParseError
    'b'Convert the parsed INI config into a profile map.

    The config file format requires that every profile except the
    default to be prepended with "profile", e.g.::

        [profile test]
        aws_... = foo
        aws_... = bar

        [profile bar]
        aws_... = foo
        aws_... = bar

        # This is *not* a profile
        [preview]
        otherstuff = 1

        # Neither is this
        [foobar]
        morestuff = 2

    The build_profile_map will take a parsed INI config file where each top
    level key represents a section name, and convert into a format where all
    the profiles are under a single top level "profiles" key, and each key in
    the sub dictionary is a profile name.  For example, the above config file
    would be converted from::

        {"profile test": {"aws_...": "foo", "aws...": "bar"},
         "profile bar": {"aws...": "foo", "aws...": "bar"},
         "preview": {"otherstuff": ...},
         "foobar": {"morestuff": ...},
         }

    into::

        {"profiles": {"test": {"aws_...": "foo", "aws...": "bar"},
                      "bar": {"aws...": "foo", "aws...": "bar"},
         "preview": {"otherstuff": ...},
         "foobar": {"morestuff": ...},
        }

    If there are no profiles in the provided parsed INI contents, then
    an empty dict will be the value associated with the ``profiles`` key.

    .. note::

        This will not mutate the passed in parsed_ini_config.  Instead it will
        make a deepcopy and return that value.

    'u'Convert the parsed INI config into a profile map.

    The config file format requires that every profile except the
    default to be prepended with "profile", e.g.::

        [profile test]
        aws_... = foo
        aws_... = bar

        [profile bar]
        aws_... = foo
        aws_... = bar

        # This is *not* a profile
        [preview]
        otherstuff = 1

        # Neither is this
        [foobar]
        morestuff = 2

    The build_profile_map will take a parsed INI config file where each top
    level key represents a section name, and convert into a format where all
    the profiles are under a single top level "profiles" key, and each key in
    the sub dictionary is a profile name.  For example, the above config file
    would be converted from::

        {"profile test": {"aws_...": "foo", "aws...": "bar"},
         "profile bar": {"aws...": "foo", "aws...": "bar"},
         "preview": {"otherstuff": ...},
         "foobar": {"morestuff": ...},
         }

    into::

        {"profiles": {"test": {"aws_...": "foo", "aws...": "bar"},
                      "bar": {"aws...": "foo", "aws...": "bar"},
         "preview": {"otherstuff": ...},
         "foobar": {"morestuff": ...},
        }

    If there are no profiles in the provided parsed INI contents, then
    an empty dict will be the value associated with the ``profiles`` key.

    .. note::

        This will not mutate the passed in parsed_ini_config.  Instead it will
        make a deepcopy and return that value.

    'b'profile'u'profile'b'sso-session'u'sso-session'b'sso_sessions'u'sso_sessions'u'botocore.configloader'u'configloader'This module contains the inteface for controlling how configuration
is loaded.
AWS_DEFAULT_PROFILEAWS_PROFILEAWS_DEFAULT_REGIONdata_pathAWS_DATA_PATHAWS_CONFIG_FILE~/.aws/configconfig_fileca_bundleAWS_CA_BUNDLEapi_versionsAWS_SHARED_CREDENTIALS_FILE~/.aws/credentialscredentials_filemetadata_service_timeoutAWS_METADATA_SERVICE_TIMEOUTmetadata_service_num_attemptsAWS_METADATA_SERVICE_NUM_ATTEMPTSec2_metadata_service_endpointAWS_EC2_METADATA_SERVICE_ENDPOINTec2_metadata_service_endpoint_modeAWS_EC2_METADATA_SERVICE_ENDPOINT_MODEimds_use_ipv6AWS_IMDS_USE_IPV6AWS_USE_DUALSTACK_ENDPOINTAWS_USE_FIPS_ENDPOINTcsm_enabledAWS_CSM_ENABLEDcsm_hostAWS_CSM_HOST127.0.0.1csm_portAWS_CSM_PORT31000csm_client_idAWS_CSM_CLIENT_IDAWS_ENDPOINT_DISCOVERY_ENABLEDAWS_STS_REGIONAL_ENDPOINTSAWS_RETRY_MODEAWS_DEFAULTS_MODEAWS_MAX_ATTEMPTSBOTOCORE_DEFAUT_SESSION_VARIABLESs3_use_arn_regions3_us_east_1_regional_endpointAWS_S3_US_EAST_1_REGIONAL_ENDPOINTAWS_S3_DISABLE_MULTIREGION_ACCESS_POINTSDEFAULT_S3_CONFIG_VARSproxy_ca_bundleproxy_client_certproxy_use_forwarding_for_httpsnormalize_booleanDEFAULT_PROXIES_CONFIG_VARScreate_botocore_default_config_mappingConfigChainFactorychain_builder_create_config_chain_mappingconfig_mappingSectionConfigProviderconfig_variableslogical_namecreate_config_chaininstance_nameenv_var_namesconfig_property_namesconversion_funcDefaultConfigResolverdefault_config_data_base_default_configmodes_modes_resolved_default_configurations_resolve_default_values_by_modedefault_configmodificationsdefault_valuemodification_dictmodificationmodification_valueget_default_modesdefault_modesget_default_config_valuesFactory class to create our most common configuration chain case.

    This is a convenience class to construct configuration chains that follow
    our most common pattern. This is to prevent ordering them incorrectly,
    and to make the config chain construction more readable.
    Initialize a ConfigChainFactory.

        :type session: :class:`botocore.session.Session`
        :param session: This is the session that should be used to look up
            values from the config file.

        :type environ: dict
        :param environ: A mapping to use for environment variables. If this
            is not provided it will default to use os.environ.
        _session_environBuild a config chain following the standard botocore pattern.

        In botocore most of our config chains follow the the precendence:
        session_instance_variables, environment, config_file, default_value.

        This is a convenience function for creating a chain that follow
        that precendence.

        :type instance_name: str
        :param instance_name: This indicates what session instance variable
            corresponds to this config value. If it is None it will not be
            added to the chain.

        :type env_var_names: str or list of str or None
        :param env_var_names: One or more environment variable names to
            search for this value. They are searched in order. If it is None
            it will not be added to the chain.

        :type config_property_names: str/tuple or list of str/tuple or None
        :param config_property_names: One of more strings or tuples
            representing the name of the key in the config file for this
            config option. They are searched in order. If it is None it will
            not be added to the chain.

        :type default: Any
        :param default: Any constant value to be returned.

        :type conversion_func: None or callable
        :param conversion_func: If this value is None then it has no effect on
            the return type. Otherwise, it is treated as a function that will
            conversion_func our provided type.

        :rvalue: ConfigChain
        :returns: A ConfigChain that resolves in the order env_var_names ->
            config_property_name -> default. Any values that were none are
            omitted form the chain.
        providersInstanceVarProviderinstance_var_get_env_providers_get_scoped_config_providersConstantProviderChainProviderenv_var_providersenv_var_nameEnvironmentProviderscoped_config_providersconfig_property_nameScopedConfigProviderconfig_var_nameConfigValueStoreThe ConfigValueStore object stores configuration values.Initialize a ConfigValueStore.

        :type mapping: dict
        :param mapping: The mapping parameter is a map of string to a subclass
            of BaseProvider. When a config variable is asked for via the
            get_config_variable method, the corresponding provider will be
            invoked to load the value.
        _overridesproviderset_config_provider
        Retrieve the value associeated with the specified logical_name
        from the corresponding provider. If no value is found None will
        be returned.

        :type logical_name: str
        :param logical_name: The logical name of the session variable
            you want to retrieve.  This name will be mapped to the
            appropriate environment variable name for this session as
            well as the appropriate config file entry.

        :returns: value of variable or None if not defined.
        provideget_config_provider
        Retrieve the provider associated with the specified logical_name.
        If no provider is found None will be returned.

        :type logical_name: str
        :param logical_name: The logical name of the session variable
            you want to retrieve.  This name will be mapped to the
            appropriate environment variable name for this session as
            well as the appropriate config file entry.

        :returns: configuration provider or None if not defined.
        set_config_variableSet a configuration variable to a specific value.

        By using this method, you can override the normal lookup
        process used in ``get_config_variable`` by explicitly setting
        a value.  Subsequent calls to ``get_config_variable`` will
        use the ``value``.  This gives you per-session specific
        configuration values.

        ::
            >>> # Assume logical name 'foo' maps to env var 'FOO'
            >>> os.environ['FOO'] = 'myvalue'
            >>> s.get_config_variable('foo')
            'myvalue'
            >>> s.set_config_variable('foo', 'othervalue')
            >>> s.get_config_variable('foo')
            'othervalue'

        :type logical_name: str
        :param logical_name: The logical name of the session variable
            you want to set.  These are the keys in ``SESSION_VARIABLES``.

        :param value: The value to associate with the config variable.
        clear_config_variableRemove an override config variable from the session.

        :type logical_name: str
        :param logical_name: The name of the parameter to clear the override
            value from.
        Set the provider for a config value.

        This provides control over how a particular configuration value is
        loaded. This replaces the provider for ``logical_name`` with the new
        ``provider``.

        :type logical_name: str
        :param logical_name: The name of the config value to change the config
            provider for.

        :type provider: :class:`botocore.configprovider.BaseProvider`
        :param provider: The new provider that should be responsible for
            providing a value for the config named ``logical_name``.
        SmartDefaultsConfigStoreFactorydefault_config_resolverimds_region_provider_default_config_resolver_imds_region_provider_instance_metadata_regionmerge_smart_defaultsresolve_auto_modedefault_configs_set_current_regionAWS_EXECUTION_ENVdefault_regionin-regioncross-region_update_providerdefault_providerset_default_providerBaseProvider_update_section_providersection_provider_set_retryMode_set_stsRegionalEndpoints_set_s3UsEast1RegionalEndpoints_set_connectTimeoutInMillisBase class for configuration value providers.

    A configuration provider has some method of providing a configuration
    value.
    Provide a config value.This provider wraps one or more other providers.

    Each provider in the chain is called, the first one returning a non-None
    value is then returned.
    Initalize a ChainProvider.

        :type providers: list
        :param providers: The initial list of providers to check for values
            when invoked.

        :type conversion_func: None or callable
        :param conversion_func: If this value is None then it has no affect on
            the return type. Otherwise, it is treated as a function that will
            transform provided value.
        _providers_conversion_funcProvide the value from the first provider to return non-None.

        Each provider in the chain has its provide method called. The first
        one in the chain to return a non-None value is the returned from the
        ChainProvider. When no non-None value is found, None is returned.
        _convert_typenum_of_constantsChainProvider object contains multiple instances of ConstantProvider objects'ChainProvider object contains multiple ''instances of ConstantProvider objects'This class loads config values from the session instance vars.Initialize InstanceVarProvider.

        :type instance_var: str
        :param instance_var: The instance variable to load from the session.

        :type session: :class:`botocore.session.Session`
        :param session: The botocore session to get the loaded configuration
            file variables from.
        _instance_varProvide a config value from the session instance vars.instance_variablesinstance_varsInstanceVarProvider(instance_var={}, session={})Initialize ScopedConfigProvider.

        :type config_var_name: str or tuple
        :param config_var_name: The name of the config variable to load from
            the configuration file. If the value is a tuple, it must only
            consist of two items, where the first item represents the section
            and the second item represents the config var name in the section.

        :type session: :class:`botocore.session.Session`
        :param session: The botocore session to get the loaded configuration
            file variables from.
        _config_var_nameProvide a value from a config file property.get_scoped_configsection_configScopedConfigProvider(config_var_name={}, session={})This class loads config values from environment variables.Initialize with the keys in the dictionary to check.

        :type name: str
        :param name: The key with that name will be loaded and returned.

        :type env: dict
        :param env: Environment variables dictionary to get variables from.
        Provide a config value from a source dictionary.EnvironmentProvider(name=, env=Provides a dictionary from a section in the scoped config

    This is useful for retrieving scoped config variables (i.e. s3) that have
    their own set of config variables and resolving logic.
    override_providers_section_name_scoped_config_provider_override_providersThe %s config key is not a dictionary type, ignoring its value of: %s"The %s config key is not a dictionary type, ""ignoring its value of: %s"section_config_varprovider_valSectionConfigProvider(section_name=, session=', ''session=', override_providers='override_providers='This provider provides a constant value.Provide the constant value given during initialization.ConstantProvider(value=%s)# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.#: A default dictionary that maps the logical names for session variables#: to the specific environment variables and configuration file names#: that contain the values for these variables.#: When creating a new Session object, you can pass in your own dictionary#: to remap the logical names or to add new logical names.  You can then#: get the current value for these variables by using the#: ``get_config_variable`` method of the :class:`botocore.session.Session`#: class.#: These form the keys of the dictionary.  The values in the dictionary#: are tuples of (<config_name>, <environment variable>, <default value>,#: <conversion func>).#: The conversion func is a function that takes the configuration value#: as an argument and returns the converted value.  If this value is#: None, then the configuration value is returned unmodified.  This#: conversion function can be used to type convert config values to#: values other than the default values of strings.#: The ``profile`` and ``config_file`` variables should always have a#: None value for the first entry in the tuple because it doesn't make#: sense to look inside the config file for the location of the config#: file or for the default profile to use.#: The ``config_name`` is the name to look for in the configuration file,#: the ``env var`` is the OS environment variable (``os.environ``) to#: use, and ``default_value`` is the value to use if no value is otherwise#: found.# logical:  config_file, env_var,        default_value, conversion_func# This is the shared credentials file amongst sdks.# These variables only exist in the config file.# This is the number of seconds until we time out a request to# the instance metadata service.# This is the number of request attempts we make until we give# up trying to retrieve data from the instance metadata service.# Client side monitoring configurations.# Note: These configurations are considered internal to botocore.# Do not use them until publicly documented.# Endpoint discovery configuration# We can't have a default here for v1 because we need to defer to# whatever the defaults are in _retry.json.# A mapping for the s3 specific configuration vars. These are the configuration# vars that typically go in the s3 section of the config file. This mapping# follows the same schema as the previous session variable mapping.# A mapping for the proxy specific configuration vars. These are# used to configure how botocore interacts with proxy setups while# sending requests.# Initializing _instance_metadata_region as None so we# can fetch region in a lazy fashion only when needed.b'This module contains the inteface for controlling how configuration
is loaded.
'u'This module contains the inteface for controlling how configuration
is loaded.
'b'AWS_DEFAULT_PROFILE'u'AWS_DEFAULT_PROFILE'b'AWS_PROFILE'u'AWS_PROFILE'b'AWS_DEFAULT_REGION'u'AWS_DEFAULT_REGION'b'data_path'u'data_path'b'AWS_DATA_PATH'u'AWS_DATA_PATH'b'AWS_CONFIG_FILE'u'AWS_CONFIG_FILE'b'~/.aws/config'u'~/.aws/config'b'config_file'u'config_file'b'ca_bundle'u'ca_bundle'b'AWS_CA_BUNDLE'u'AWS_CA_BUNDLE'b'api_versions'u'api_versions'b'AWS_SHARED_CREDENTIALS_FILE'u'AWS_SHARED_CREDENTIALS_FILE'b'~/.aws/credentials'u'~/.aws/credentials'b'credentials_file'u'credentials_file'b'metadata_service_timeout'u'metadata_service_timeout'b'AWS_METADATA_SERVICE_TIMEOUT'u'AWS_METADATA_SERVICE_TIMEOUT'b'metadata_service_num_attempts'u'metadata_service_num_attempts'b'AWS_METADATA_SERVICE_NUM_ATTEMPTS'u'AWS_METADATA_SERVICE_NUM_ATTEMPTS'b'ec2_metadata_service_endpoint'u'ec2_metadata_service_endpoint'b'AWS_EC2_METADATA_SERVICE_ENDPOINT'u'AWS_EC2_METADATA_SERVICE_ENDPOINT'b'ec2_metadata_service_endpoint_mode'u'ec2_metadata_service_endpoint_mode'b'AWS_EC2_METADATA_SERVICE_ENDPOINT_MODE'u'AWS_EC2_METADATA_SERVICE_ENDPOINT_MODE'b'imds_use_ipv6'u'imds_use_ipv6'b'AWS_IMDS_USE_IPV6'u'AWS_IMDS_USE_IPV6'b'AWS_USE_DUALSTACK_ENDPOINT'u'AWS_USE_DUALSTACK_ENDPOINT'b'AWS_USE_FIPS_ENDPOINT'u'AWS_USE_FIPS_ENDPOINT'b'csm_enabled'u'csm_enabled'b'AWS_CSM_ENABLED'u'AWS_CSM_ENABLED'b'csm_host'u'csm_host'b'AWS_CSM_HOST'u'AWS_CSM_HOST'b'127.0.0.1'u'127.0.0.1'b'csm_port'u'csm_port'b'AWS_CSM_PORT'u'AWS_CSM_PORT'b'csm_client_id'u'csm_client_id'b'AWS_CSM_CLIENT_ID'u'AWS_CSM_CLIENT_ID'b'AWS_ENDPOINT_DISCOVERY_ENABLED'u'AWS_ENDPOINT_DISCOVERY_ENABLED'b'AWS_STS_REGIONAL_ENDPOINTS'u'AWS_STS_REGIONAL_ENDPOINTS'b'AWS_RETRY_MODE'u'AWS_RETRY_MODE'b'AWS_DEFAULTS_MODE'u'AWS_DEFAULTS_MODE'b'AWS_MAX_ATTEMPTS'u'AWS_MAX_ATTEMPTS'b's3_use_arn_region'u's3_use_arn_region'b'AWS_S3_USE_ARN_REGION'u'AWS_S3_USE_ARN_REGION'b's3_us_east_1_regional_endpoint'u's3_us_east_1_regional_endpoint'b'AWS_S3_US_EAST_1_REGIONAL_ENDPOINT'u'AWS_S3_US_EAST_1_REGIONAL_ENDPOINT'b'AWS_S3_DISABLE_MULTIREGION_ACCESS_POINTS'u'AWS_S3_DISABLE_MULTIREGION_ACCESS_POINTS'b'proxy_ca_bundle'u'proxy_ca_bundle'b'proxy_client_cert'u'proxy_client_cert'b'proxy_use_forwarding_for_https'u'proxy_use_forwarding_for_https'b'modes'u'modes'b'multiply'u'multiply'b'override'u'override'b'Factory class to create our most common configuration chain case.

    This is a convenience class to construct configuration chains that follow
    our most common pattern. This is to prevent ordering them incorrectly,
    and to make the config chain construction more readable.
    'u'Factory class to create our most common configuration chain case.

    This is a convenience class to construct configuration chains that follow
    our most common pattern. This is to prevent ordering them incorrectly,
    and to make the config chain construction more readable.
    'b'Initialize a ConfigChainFactory.

        :type session: :class:`botocore.session.Session`
        :param session: This is the session that should be used to look up
            values from the config file.

        :type environ: dict
        :param environ: A mapping to use for environment variables. If this
            is not provided it will default to use os.environ.
        'u'Initialize a ConfigChainFactory.

        :type session: :class:`botocore.session.Session`
        :param session: This is the session that should be used to look up
            values from the config file.

        :type environ: dict
        :param environ: A mapping to use for environment variables. If this
            is not provided it will default to use os.environ.
        'b'Build a config chain following the standard botocore pattern.

        In botocore most of our config chains follow the the precendence:
        session_instance_variables, environment, config_file, default_value.

        This is a convenience function for creating a chain that follow
        that precendence.

        :type instance_name: str
        :param instance_name: This indicates what session instance variable
            corresponds to this config value. If it is None it will not be
            added to the chain.

        :type env_var_names: str or list of str or None
        :param env_var_names: One or more environment variable names to
            search for this value. They are searched in order. If it is None
            it will not be added to the chain.

        :type config_property_names: str/tuple or list of str/tuple or None
        :param config_property_names: One of more strings or tuples
            representing the name of the key in the config file for this
            config option. They are searched in order. If it is None it will
            not be added to the chain.

        :type default: Any
        :param default: Any constant value to be returned.

        :type conversion_func: None or callable
        :param conversion_func: If this value is None then it has no effect on
            the return type. Otherwise, it is treated as a function that will
            conversion_func our provided type.

        :rvalue: ConfigChain
        :returns: A ConfigChain that resolves in the order env_var_names ->
            config_property_name -> default. Any values that were none are
            omitted form the chain.
        'u'Build a config chain following the standard botocore pattern.

        In botocore most of our config chains follow the the precendence:
        session_instance_variables, environment, config_file, default_value.

        This is a convenience function for creating a chain that follow
        that precendence.

        :type instance_name: str
        :param instance_name: This indicates what session instance variable
            corresponds to this config value. If it is None it will not be
            added to the chain.

        :type env_var_names: str or list of str or None
        :param env_var_names: One or more environment variable names to
            search for this value. They are searched in order. If it is None
            it will not be added to the chain.

        :type config_property_names: str/tuple or list of str/tuple or None
        :param config_property_names: One of more strings or tuples
            representing the name of the key in the config file for this
            config option. They are searched in order. If it is None it will
            not be added to the chain.

        :type default: Any
        :param default: Any constant value to be returned.

        :type conversion_func: None or callable
        :param conversion_func: If this value is None then it has no effect on
            the return type. Otherwise, it is treated as a function that will
            conversion_func our provided type.

        :rvalue: ConfigChain
        :returns: A ConfigChain that resolves in the order env_var_names ->
            config_property_name -> default. Any values that were none are
            omitted form the chain.
        'b'The ConfigValueStore object stores configuration values.'u'The ConfigValueStore object stores configuration values.'b'Initialize a ConfigValueStore.

        :type mapping: dict
        :param mapping: The mapping parameter is a map of string to a subclass
            of BaseProvider. When a config variable is asked for via the
            get_config_variable method, the corresponding provider will be
            invoked to load the value.
        'u'Initialize a ConfigValueStore.

        :type mapping: dict
        :param mapping: The mapping parameter is a map of string to a subclass
            of BaseProvider. When a config variable is asked for via the
            get_config_variable method, the corresponding provider will be
            invoked to load the value.
        'b'
        Retrieve the value associeated with the specified logical_name
        from the corresponding provider. If no value is found None will
        be returned.

        :type logical_name: str
        :param logical_name: The logical name of the session variable
            you want to retrieve.  This name will be mapped to the
            appropriate environment variable name for this session as
            well as the appropriate config file entry.

        :returns: value of variable or None if not defined.
        'u'
        Retrieve the value associeated with the specified logical_name
        from the corresponding provider. If no value is found None will
        be returned.

        :type logical_name: str
        :param logical_name: The logical name of the session variable
            you want to retrieve.  This name will be mapped to the
            appropriate environment variable name for this session as
            well as the appropriate config file entry.

        :returns: value of variable or None if not defined.
        'b'
        Retrieve the provider associated with the specified logical_name.
        If no provider is found None will be returned.

        :type logical_name: str
        :param logical_name: The logical name of the session variable
            you want to retrieve.  This name will be mapped to the
            appropriate environment variable name for this session as
            well as the appropriate config file entry.

        :returns: configuration provider or None if not defined.
        'u'
        Retrieve the provider associated with the specified logical_name.
        If no provider is found None will be returned.

        :type logical_name: str
        :param logical_name: The logical name of the session variable
            you want to retrieve.  This name will be mapped to the
            appropriate environment variable name for this session as
            well as the appropriate config file entry.

        :returns: configuration provider or None if not defined.
        'b'Set a configuration variable to a specific value.

        By using this method, you can override the normal lookup
        process used in ``get_config_variable`` by explicitly setting
        a value.  Subsequent calls to ``get_config_variable`` will
        use the ``value``.  This gives you per-session specific
        configuration values.

        ::
            >>> # Assume logical name 'foo' maps to env var 'FOO'
            >>> os.environ['FOO'] = 'myvalue'
            >>> s.get_config_variable('foo')
            'myvalue'
            >>> s.set_config_variable('foo', 'othervalue')
            >>> s.get_config_variable('foo')
            'othervalue'

        :type logical_name: str
        :param logical_name: The logical name of the session variable
            you want to set.  These are the keys in ``SESSION_VARIABLES``.

        :param value: The value to associate with the config variable.
        'u'Set a configuration variable to a specific value.

        By using this method, you can override the normal lookup
        process used in ``get_config_variable`` by explicitly setting
        a value.  Subsequent calls to ``get_config_variable`` will
        use the ``value``.  This gives you per-session specific
        configuration values.

        ::
            >>> # Assume logical name 'foo' maps to env var 'FOO'
            >>> os.environ['FOO'] = 'myvalue'
            >>> s.get_config_variable('foo')
            'myvalue'
            >>> s.set_config_variable('foo', 'othervalue')
            >>> s.get_config_variable('foo')
            'othervalue'

        :type logical_name: str
        :param logical_name: The logical name of the session variable
            you want to set.  These are the keys in ``SESSION_VARIABLES``.

        :param value: The value to associate with the config variable.
        'b'Remove an override config variable from the session.

        :type logical_name: str
        :param logical_name: The name of the parameter to clear the override
            value from.
        'u'Remove an override config variable from the session.

        :type logical_name: str
        :param logical_name: The name of the parameter to clear the override
            value from.
        'b'Set the provider for a config value.

        This provides control over how a particular configuration value is
        loaded. This replaces the provider for ``logical_name`` with the new
        ``provider``.

        :type logical_name: str
        :param logical_name: The name of the config value to change the config
            provider for.

        :type provider: :class:`botocore.configprovider.BaseProvider`
        :param provider: The new provider that should be responsible for
            providing a value for the config named ``logical_name``.
        'u'Set the provider for a config value.

        This provides control over how a particular configuration value is
        loaded. This replaces the provider for ``logical_name`` with the new
        ``provider``.

        :type logical_name: str
        :param logical_name: The name of the config value to change the config
            provider for.

        :type provider: :class:`botocore.configprovider.BaseProvider`
        :param provider: The new provider that should be responsible for
            providing a value for the config named ``logical_name``.
        'b'_set_'u'_set_'b'AWS_EXECUTION_ENV'u'AWS_EXECUTION_ENV'b'AWS_REGION'u'AWS_REGION'b'in-region'u'in-region'b'cross-region'u'cross-region'b'Base class for configuration value providers.

    A configuration provider has some method of providing a configuration
    value.
    'u'Base class for configuration value providers.

    A configuration provider has some method of providing a configuration
    value.
    'b'Provide a config value.'u'Provide a config value.'b'provide'u'provide'b'This provider wraps one or more other providers.

    Each provider in the chain is called, the first one returning a non-None
    value is then returned.
    'u'This provider wraps one or more other providers.

    Each provider in the chain is called, the first one returning a non-None
    value is then returned.
    'b'Initalize a ChainProvider.

        :type providers: list
        :param providers: The initial list of providers to check for values
            when invoked.

        :type conversion_func: None or callable
        :param conversion_func: If this value is None then it has no affect on
            the return type. Otherwise, it is treated as a function that will
            transform provided value.
        'u'Initalize a ChainProvider.

        :type providers: list
        :param providers: The initial list of providers to check for values
            when invoked.

        :type conversion_func: None or callable
        :param conversion_func: If this value is None then it has no affect on
            the return type. Otherwise, it is treated as a function that will
            transform provided value.
        'b'Provide the value from the first provider to return non-None.

        Each provider in the chain has its provide method called. The first
        one in the chain to return a non-None value is the returned from the
        ChainProvider. When no non-None value is found, None is returned.
        'u'Provide the value from the first provider to return non-None.

        Each provider in the chain has its provide method called. The first
        one in the chain to return a non-None value is the returned from the
        ChainProvider. When no non-None value is found, None is returned.
        'b'ChainProvider object contains multiple instances of ConstantProvider objects'u'ChainProvider object contains multiple instances of ConstantProvider objects'b'This class loads config values from the session instance vars.'u'This class loads config values from the session instance vars.'b'Initialize InstanceVarProvider.

        :type instance_var: str
        :param instance_var: The instance variable to load from the session.

        :type session: :class:`botocore.session.Session`
        :param session: The botocore session to get the loaded configuration
            file variables from.
        'u'Initialize InstanceVarProvider.

        :type instance_var: str
        :param instance_var: The instance variable to load from the session.

        :type session: :class:`botocore.session.Session`
        :param session: The botocore session to get the loaded configuration
            file variables from.
        'b'Provide a config value from the session instance vars.'u'Provide a config value from the session instance vars.'b'InstanceVarProvider(instance_var={}, session={})'u'InstanceVarProvider(instance_var={}, session={})'b'Initialize ScopedConfigProvider.

        :type config_var_name: str or tuple
        :param config_var_name: The name of the config variable to load from
            the configuration file. If the value is a tuple, it must only
            consist of two items, where the first item represents the section
            and the second item represents the config var name in the section.

        :type session: :class:`botocore.session.Session`
        :param session: The botocore session to get the loaded configuration
            file variables from.
        'u'Initialize ScopedConfigProvider.

        :type config_var_name: str or tuple
        :param config_var_name: The name of the config variable to load from
            the configuration file. If the value is a tuple, it must only
            consist of two items, where the first item represents the section
            and the second item represents the config var name in the section.

        :type session: :class:`botocore.session.Session`
        :param session: The botocore session to get the loaded configuration
            file variables from.
        'b'Provide a value from a config file property.'u'Provide a value from a config file property.'b'ScopedConfigProvider(config_var_name={}, session={})'u'ScopedConfigProvider(config_var_name={}, session={})'b'This class loads config values from environment variables.'u'This class loads config values from environment variables.'b'Initialize with the keys in the dictionary to check.

        :type name: str
        :param name: The key with that name will be loaded and returned.

        :type env: dict
        :param env: Environment variables dictionary to get variables from.
        'u'Initialize with the keys in the dictionary to check.

        :type name: str
        :param name: The key with that name will be loaded and returned.

        :type env: dict
        :param env: Environment variables dictionary to get variables from.
        'b'Provide a config value from a source dictionary.'u'Provide a config value from a source dictionary.'b'EnvironmentProvider(name='u'EnvironmentProvider(name='b', env='u', env='b'Provides a dictionary from a section in the scoped config

    This is useful for retrieving scoped config variables (i.e. s3) that have
    their own set of config variables and resolving logic.
    'u'Provides a dictionary from a section in the scoped config

    This is useful for retrieving scoped config variables (i.e. s3) that have
    their own set of config variables and resolving logic.
    'b'The %s config key is not a dictionary type, ignoring its value of: %s'u'The %s config key is not a dictionary type, ignoring its value of: %s'b'SectionConfigProvider(section_name='u'SectionConfigProvider(section_name='b', session='u', session='b', override_providers='u', override_providers='b'This provider provides a constant value.'u'This provider provides a constant value.'b'Provide the constant value given during initialization.'u'Provide the constant value given during initialization.'b'ConstantProvider(value=%s)'u'ConstantProvider(value=%s)'u'botocore.configprovider'u'configprovider'SocketErrorSocketTimeoutpackages.six.moves.http_client_HTTPConnectioncreate_proxy_ssl_contextBaseSSLErrorSystemTimeWarningutil.ssl_create_urllib3_contextis_ipaddressutil.ssl_match_hostnameCertificateErrormatch_hostname2022RECENT_DATE[^-!#$%&'*+.^_`|~0-9a-zA-Z]_CONTAINS_CONTROL_CHAR_RE
    Based on :class:`http.client.HTTPConnection` but provides an extra constructor
    backwards-compatibility layer between older and newer Pythons.

    Additional keyword parameters are used to configure attributes of the connection.
    Accepted parameters include:

    - ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`
    - ``source_address``: Set the source address for the current connection.
    - ``socket_options``: Set specific options on the underlying socket. If not specified, then
      defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
      Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.

      For example, if you wish to enable TCP Keep Alive in addition to the defaults,
      you might pass:

      .. code-block:: python

         HTTPConnection.default_socket_options + [
             (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
         ]

      Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).
    default_socket_optionsis_verifiedproxy_is_verified
        Getter method to remove any trailing dots that indicate the hostname is an FQDN.

        In general, SSL certificates don't include the trailing dot indicating a
        fully-qualified domain name, and thus, they don't validate properly when
        checked against a domain name that includes the dot. In addition, some
        servers may not expect to receive the trailing dot when provided.

        However, the hostname with trailing dot is critical to DNS resolution; doing a
        lookup with the trailing dot will properly only resolve the appropriate FQDN,
        whereas a lookup without a trailing dot will search the system's search domain
        list. Thus, it's important to keep the original host around for use only in
        those cases where it's appropriate (i.e., when doing DNS lookup to establish the
        actual TCP connection across which we're going to send HTTP requests).
        _dns_host
        Setter for the `host` property.

        We assume that only urllib3 uses the _dns_host attribute; httplib itself
        only uses `host`, and it seems reasonable that other libraries follow suit.
        _new_connEstablish a socket connection and set nodelay settings on it.

        :return: New socket connection.
        extra_kwConnection to %s timed out. (connect timeout=%s)Failed to establish a new connection: %s_is_using_tunnel_prepare_connMethod cannot contain non-token characters %r (found at least %r)ensure_strurllib3.util.SKIP_HEADER only supports '%s'_get_default_user_agentrequest_chunked
        Alternative to the common request method, which sends the
        body with chunked encoding and not as one block
        header_keysstringish_typeslen_strto_send
    Many of the parameters to this constructor are passed to the underlying SSL
    socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.
    ca_cert_datatls_in_tls_requiredset_certassert_hostname
        This method should only be called once, before the connection is used.
        tls_in_tls_connect_tls_proxyis_time_offSystem time is way off (before {0}). This will probably lead to SSL verification errors"System time is way off (before {0}). This will probably ""lead to SSL verification errors"default_ssl_contextload_default_certskeyfilecertfileTLSv1TLSv1.1Negotiating TLSv1/TLSv1.1 by default is deprecated and will be disabled in urllib3 v2.0.0. Connecting to '%s' with '%s' can be enabled by explicitly opting-in with 'ssl_version'"Negotiating TLSv1/TLSv1.1 by default is deprecated ""and will be disabled in urllib3 v2.0.0. Connecting to ""'%s' with '%s' can be enabled by explicitly opting-in ""with 'ssl_version'"binary_formsubjectAltNameCertificate for {0} has no `subjectAltName`, falling back to check for a `commonName` for now. This feature is being removed by major browsers and deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 for details.)"Certificate for {0} has no `subjectAltName`, falling back to check for a ""`commonName` for now. This feature is being removed by major browsers and ""deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 ""for details.)"_match_hostname
        Establish a TLS connection to the proxy using the provided SSL context.
        asserted_hostnameu[]stripped_hostnameCertificate did not match expected hostname: %s. Certificate: %s_peer_certpython-urllib3/%sDummyConnectionUsed to detect a failed ConnectionCls import.# Compiled with SSL?# Platform-specific: No SSL.# Python 3: not a no-op, we're adding this to the namespace so it can be imported.# Python 3:# Not a no-op, we're adding this to the namespace so it can be imported.# Python 2:# noqa (historical, removed in v2)# When it comes time to update this value as a part of regular maintenance# (ie test_recent_date is failing) update it to ~6 months before the current date.#: Disable Nagle's algorithm by default.#: ``[(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]``#: Whether this connection verifies the host's certificate.#: Whether this proxy connection (if used) verifies the proxy host's#: certificate.# Pre-set source_address.#: The socket options provided by the user. If no options are#: provided, we use the default options.# Proxy options provided by the user.# Google App Engine's httplib does not define _tunnel_host# TODO: Fix tunnel so it doesn't depend on self.sock state.# Mark this connection as not reusable# Empty docstring because the indentation of CPython's implementation# is broken but we don't want this method in our documentation.# Avoid modifying the headers passed into .request()# After the if clause, to always have a closed body# Required property for Google AppEngine 1.9.0 which otherwise causes# HTTPS requests to go out as HTTP. (See Issue #356)# If cert_reqs is not provided we'll assume CERT_REQUIRED unless we also# have an SSLContext object in which case we'll use its verify_mode.# Add certificate verification# Calls self._set_hostport(), so self.host is# self._tunnel_host below.# Override the host with the one we're requesting data from.# Wrap socket using verification with the root certs in# trusted_root_certs# Try to load OS default certs if none are given.# Works well on Windows (requires Python3.4+)# If we're using all defaults and the connection# is TLSv1 or TLSv1.1 we throw a DeprecationWarning# for the host.# While urllib3 attempts to always turn off hostname matching from# the TLS library, this cannot always be done. So we check whether# the TLS Library still thinks it's matching hostnames.# If the user provided a proxy context, we assume CA and client# certificates have already been set# If no cert was provided, use only the default options for server# certificate validation# Our upstream implementation of ssl.match_hostname()# only applies this normalization to IP addresses so it doesn't# match DNS SANs so we do the same thing!# Add cert to exception and reraise so client code can inspect# the cert when catching the exception, if they want tob'[^-!#$%&'*+.^_`|~0-9a-zA-Z]'u'[^-!#$%&'*+.^_`|~0-9a-zA-Z]'b'
    Based on :class:`http.client.HTTPConnection` but provides an extra constructor
    backwards-compatibility layer between older and newer Pythons.

    Additional keyword parameters are used to configure attributes of the connection.
    Accepted parameters include:

    - ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`
    - ``source_address``: Set the source address for the current connection.
    - ``socket_options``: Set specific options on the underlying socket. If not specified, then
      defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
      Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.

      For example, if you wish to enable TCP Keep Alive in addition to the defaults,
      you might pass:

      .. code-block:: python

         HTTPConnection.default_socket_options + [
             (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
         ]

      Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).
    'u'
    Based on :class:`http.client.HTTPConnection` but provides an extra constructor
    backwards-compatibility layer between older and newer Pythons.

    Additional keyword parameters are used to configure attributes of the connection.
    Accepted parameters include:

    - ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`
    - ``source_address``: Set the source address for the current connection.
    - ``socket_options``: Set specific options on the underlying socket. If not specified, then
      defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
      Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.

      For example, if you wish to enable TCP Keep Alive in addition to the defaults,
      you might pass:

      .. code-block:: python

         HTTPConnection.default_socket_options + [
             (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
         ]

      Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).
    'b'source_address'u'source_address'b'proxy_config'u'proxy_config'b'
        Getter method to remove any trailing dots that indicate the hostname is an FQDN.

        In general, SSL certificates don't include the trailing dot indicating a
        fully-qualified domain name, and thus, they don't validate properly when
        checked against a domain name that includes the dot. In addition, some
        servers may not expect to receive the trailing dot when provided.

        However, the hostname with trailing dot is critical to DNS resolution; doing a
        lookup with the trailing dot will properly only resolve the appropriate FQDN,
        whereas a lookup without a trailing dot will search the system's search domain
        list. Thus, it's important to keep the original host around for use only in
        those cases where it's appropriate (i.e., when doing DNS lookup to establish the
        actual TCP connection across which we're going to send HTTP requests).
        'u'
        Getter method to remove any trailing dots that indicate the hostname is an FQDN.

        In general, SSL certificates don't include the trailing dot indicating a
        fully-qualified domain name, and thus, they don't validate properly when
        checked against a domain name that includes the dot. In addition, some
        servers may not expect to receive the trailing dot when provided.

        However, the hostname with trailing dot is critical to DNS resolution; doing a
        lookup with the trailing dot will properly only resolve the appropriate FQDN,
        whereas a lookup without a trailing dot will search the system's search domain
        list. Thus, it's important to keep the original host around for use only in
        those cases where it's appropriate (i.e., when doing DNS lookup to establish the
        actual TCP connection across which we're going to send HTTP requests).
        'b'
        Setter for the `host` property.

        We assume that only urllib3 uses the _dns_host attribute; httplib itself
        only uses `host`, and it seems reasonable that other libraries follow suit.
        'u'
        Setter for the `host` property.

        We assume that only urllib3 uses the _dns_host attribute; httplib itself
        only uses `host`, and it seems reasonable that other libraries follow suit.
        'b'Establish a socket connection and set nodelay settings on it.

        :return: New socket connection.
        'u'Establish a socket connection and set nodelay settings on it.

        :return: New socket connection.
        'b'Connection to %s timed out. (connect timeout=%s)'u'Connection to %s timed out. (connect timeout=%s)'b'Failed to establish a new connection: %s'u'Failed to establish a new connection: %s'b'_tunnel_host'u'_tunnel_host'b'Method cannot contain non-token characters %r (found at least %r)'u'Method cannot contain non-token characters %r (found at least %r)'b'urllib3.util.SKIP_HEADER only supports '%s''u'urllib3.util.SKIP_HEADER only supports '%s''b'', ''u'', ''b'
        Alternative to the common request method, which sends the
        body with chunked encoding and not as one block
        'u'
        Alternative to the common request method, which sends the
        body with chunked encoding and not as one block
        'b'
    Many of the parameters to this constructor are passed to the underlying SSL
    socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.
    'u'
    Many of the parameters to this constructor are passed to the underlying SSL
    socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.
    'b'
        This method should only be called once, before the connection is used.
        'u'
        This method should only be called once, before the connection is used.
        'b'System time is way off (before {0}). This will probably lead to SSL verification errors'u'System time is way off (before {0}). This will probably lead to SSL verification errors'b'load_default_certs'u'load_default_certs'b'TLSv1'u'TLSv1'b'TLSv1.1'u'TLSv1.1'b'Negotiating TLSv1/TLSv1.1 by default is deprecated and will be disabled in urllib3 v2.0.0. Connecting to '%s' with '%s' can be enabled by explicitly opting-in with 'ssl_version''u'Negotiating TLSv1/TLSv1.1 by default is deprecated and will be disabled in urllib3 v2.0.0. Connecting to '%s' with '%s' can be enabled by explicitly opting-in with 'ssl_version''b'check_hostname'u'check_hostname'b'subjectAltName'u'subjectAltName'b'Certificate for {0} has no `subjectAltName`, falling back to check for a `commonName` for now. This feature is being removed by major browsers and deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 for details.)'u'Certificate for {0} has no `subjectAltName`, falling back to check for a `commonName` for now. This feature is being removed by major browsers and deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 for details.)'b'
        Establish a TLS connection to the proxy using the provided SSL context.
        'u'
        Establish a TLS connection to the proxy using the provided SSL context.
        'b'u[]'u'u[]'b'Certificate did not match expected hostname: %s. Certificate: %s'u'Certificate did not match expected hostname: %s. Certificate: %s'b'python-urllib3/%s'u'python-urllib3/%s'b'Used to detect a failed ConnectionCls import.'u'Used to detect a failed ConnectionCls import.'u'urllib3.connection'ListenerPipereductionForkingPickler_ForkingPicklerWAIT_OBJECT_0WAIT_ABANDONED_0WAIT_TIMEOUTINFINITEBUFSIZE20.020.CONNECTION_TIMEOUT_mmap_counterdefault_familyfamiliesAF_PIPE_init_timeout_check_timeoutarbitrary_address
    Return an arbitrary free address for the given family
    localhostmktemplistener-get_temp_dir\\.\pipe\pyc-%d-%d-unrecognized family_validate_family
    Checks if the family is valid for the current environment.
    Family %s is not recognized.address_type
    Return the types of the address

    This can be 'AF_INET', 'AF_UNIX', or 'AF_PIPE'
    is_abstract_socket_namespaceaddress type of %r unrecognized_ConnectionBaseinvalid handleat least one of `readable` and `writable` must be True_readable_writable_closehandle is closed_check_readableconnection is write-only_check_writableconnection is read-only_bad_message_lengthbad message lengthTrue if the connection is closedTrue if the connection is readableTrue if the connection is writableFile descriptor or handle of the connectionClose the connectionsend_bytesSend the bytes data from a bytes-like objectoffset is negativebuffer length < offsetsize is negativebuffer length < offset + size_send_bytesSend a (picklable) objectrecv_bytesmaxlength
        Receive bytes data as a bytes object.
        negative maxlength_recv_bytesrecv_bytes_into
        Receive bytes data into a writeable bytes-like object.
        Return the number of bytes read.
        bytesizenegative offsetoffset too largeReceive a (picklable) objectWhether there is any input available to be read_pollPipeConnection
        Connection class based on a Windows named pipe.
        Overlapped I/O is used, so the handles must have been created
        with FILE_FLAG_OVERLAPPED.
        _got_empty_messageCloseHandle_CloseHandleWriteFileoverlappedovERROR_IO_PENDINGWaitForMultipleObjectswaitresGetOverlappedResultnwrittenbsizeReadFilenreadERROR_MORE_DATA_get_more_datawinerrorERROR_BROKEN_PIPEshouldn't get here; expected KeyboardInterruptPeekNamedPiperbytes
    Connection class based on an arbitrary file descriptor (Unix only), or
    a socket handle (Windows).
    closesocket_send_recvgot end of file during message0x7fffffff!ipre_header!Q
    Returns a listener object.

    This is a wrapper for a bound socket which is 'listening' for
    connections, or for a Windows named pipe.
    authkeyPipeListener_listenerSocketListenerauthkey should be a byte string_authkey
        Accept a connection on the bound socket or named pipe of `self`.

        Returns a `Connection` object.
        listener is closeddeliver_challengeanswer_challenge
        Close the bound socket or named pipe of `self`.
        listener_addresslast_accepted_last_accepted
    Returns a connection to the address of a `Listener`
    PipeClientSocketClientduplex
        Returns pair of connection objects at either end of a pipe
        c1c2fd1fd2PIPE_ACCESS_DUPLEXopenmodeGENERIC_READGENERIC_WRITEaccessobsizeibsizePIPE_ACCESS_INBOUNDCreateNamedPipeFILE_FLAG_OVERLAPPEDFILE_FLAG_FIRST_PIPE_INSTANCEPIPE_TYPE_MESSAGEPIPE_READMODE_MESSAGEPIPE_WAITNMPWAIT_WAIT_FOREVERNULLh1CreateFileOPEN_EXISTINGSetNamedPipeHandleStateConnectNamedPipe
    Representation of a socket which is bound to an address and listening
    _familyFinalizeexitpriority_unlink
    Return a connection object connected to the socket given by `address`
    
        Representation of a named pipe
        _new_handle_handle_queuesub_debuglistener created with address=%r_finalize_pipe_listenerPIPE_UNLIMITED_INSTANCESERROR_NO_DATAclosing listener with address=%r
        Return a connection object connected to the pipe given by `address`
        WaitNamedPipeERROR_SEM_TIMEOUTERROR_PIPE_BUSYMESSAGE_LENGTH#CHALLENGE#CHALLENGE#WELCOME#WELCOME#FAILURE#FAILUREAuthkey must be bytes, not {0!s}digest received was wrongmessage = %rdigest sent was rejectedConnectionWrapper_conn_dumps_loads_xml_dumps_xml_loadsXmlListenerXmlClient_exhaustive_waithandlesShould not get hereERROR_NETNAME_DELETED_ready_errorsobject_list
        Wait till an object in object_list is ready/readable.

        Returns list of those objects in object_list which are ready/readable.
        waithandle_to_objov_listready_objectsready_handlesgetwindowsversionERROR_OPERATION_ABORTED_WaitSelectorreduce_connectionresource_sharerDupSocketdsrebuild_connectionreduce_pipe_connectionFILE_GENERIC_READFILE_GENERIC_WRITEDupHandledhrebuild_pipe_connectionDupFddf# A higher level module for using sockets (or Windows named pipes)# multiprocessing/connection.py# A very generous timeout when it comes to local connections...# double check# Connection classes# XXX should we use util.Finalize instead of a __del__?# HACK for byte-indexing of non-bytewise buffers (e.g. array.array)# Get bytesize of arbitrary buffer# Message can fit in dest# For wire compatibility with 3.7 and lower# The payload is large so Nagle's algorithm won't be triggered# and we'd better avoid the cost of concatenation.# Issue #20540: concatenate before sending, to avoid delays due# to Nagle's algorithm on a TCP socket.# Also note we want to avoid sending a 0-length buffer separately,# to avoid "broken pipe" errors if the other end closed the pipe.# Public functions# default security descriptor: the handle cannot be inherited# Definitions for connections based on sockets# SO_REUSEADDR has different semantics on Windows (issue #2550).# Linux abstract socket namespaces do not need to be explicitly unlinked# Definitions for connections based on named pipes# ERROR_NO_DATA can occur if a client has already connected,# written data and then disconnected -- see Issue 14725.# Authentication stuff# reject large message# Support for using xmlrpclib for serialization# Wait# Return ALL handles which are currently signalled.  (Only# returning the first signalled might create starvation issues.)# start an overlapped read of length zero# If o.fileno() is an overlapped pipe handle and# err == 0 then there is a zero length message# in the pipe, but it HAS NOT been consumed...# ... except on Windows 8 and later, where# the message HAS been consumed.# request that overlapped reads stop# wait for all overlapped reads to stop# If o.fileno() is an overlapped pipe handle then# a zero length message HAS been consumed.# poll/select have the advantage of not requiring any extra file# descriptor, contrarily to epoll/kqueue (also, they require a single# syscall).# Make connection and socket objects sharable if possibleb'Listener'u'Listener'b'Pipe'u'Pipe'b'AF_INET'u'AF_INET'b'AF_PIPE'u'AF_PIPE'b'
    Return an arbitrary free address for the given family
    'u'
    Return an arbitrary free address for the given family
    'b'localhost'u'localhost'b'listener-'u'listener-'b'\\.\pipe\pyc-%d-%d-'u'\\.\pipe\pyc-%d-%d-'b'unrecognized family'u'unrecognized family'b'
    Checks if the family is valid for the current environment.
    'u'
    Checks if the family is valid for the current environment.
    'b'Family %s is not recognized.'u'Family %s is not recognized.'b'
    Return the types of the address

    This can be 'AF_INET', 'AF_UNIX', or 'AF_PIPE'
    'u'
    Return the types of the address

    This can be 'AF_INET', 'AF_UNIX', or 'AF_PIPE'
    'b'address type of %r unrecognized'u'address type of %r unrecognized'b'invalid handle'u'invalid handle'b'at least one of `readable` and `writable` must be True'u'at least one of `readable` and `writable` must be True'b'handle is closed'u'handle is closed'b'connection is write-only'u'connection is write-only'b'connection is read-only'u'connection is read-only'b'bad message length'u'bad message length'b'True if the connection is closed'u'True if the connection is closed'b'True if the connection is readable'u'True if the connection is readable'b'True if the connection is writable'u'True if the connection is writable'b'File descriptor or handle of the connection'u'File descriptor or handle of the connection'b'Close the connection'u'Close the connection'b'Send the bytes data from a bytes-like object'u'Send the bytes data from a bytes-like object'b'offset is negative'u'offset is negative'b'buffer length < offset'u'buffer length < offset'b'size is negative'u'size is negative'b'buffer length < offset + size'u'buffer length < offset + size'b'Send a (picklable) object'u'Send a (picklable) object'b'
        Receive bytes data as a bytes object.
        'u'
        Receive bytes data as a bytes object.
        'b'negative maxlength'u'negative maxlength'b'
        Receive bytes data into a writeable bytes-like object.
        Return the number of bytes read.
        'u'
        Receive bytes data into a writeable bytes-like object.
        Return the number of bytes read.
        'b'negative offset'u'negative offset'b'offset too large'u'offset too large'b'Receive a (picklable) object'u'Receive a (picklable) object'b'Whether there is any input available to be read'u'Whether there is any input available to be read'b'
        Connection class based on a Windows named pipe.
        Overlapped I/O is used, so the handles must have been created
        with FILE_FLAG_OVERLAPPED.
        'u'
        Connection class based on a Windows named pipe.
        Overlapped I/O is used, so the handles must have been created
        with FILE_FLAG_OVERLAPPED.
        'b'shouldn't get here; expected KeyboardInterrupt'u'shouldn't get here; expected KeyboardInterrupt'b'
    Connection class based on an arbitrary file descriptor (Unix only), or
    a socket handle (Windows).
    'u'
    Connection class based on an arbitrary file descriptor (Unix only), or
    a socket handle (Windows).
    'b'got end of file during message'u'got end of file during message'b'!i'u'!i'b'!Q'u'!Q'b'
    Returns a listener object.

    This is a wrapper for a bound socket which is 'listening' for
    connections, or for a Windows named pipe.
    'u'
    Returns a listener object.

    This is a wrapper for a bound socket which is 'listening' for
    connections, or for a Windows named pipe.
    'b'authkey should be a byte string'u'authkey should be a byte string'b'
        Accept a connection on the bound socket or named pipe of `self`.

        Returns a `Connection` object.
        'u'
        Accept a connection on the bound socket or named pipe of `self`.

        Returns a `Connection` object.
        'b'listener is closed'u'listener is closed'b'
        Close the bound socket or named pipe of `self`.
        'u'
        Close the bound socket or named pipe of `self`.
        'b'
    Returns a connection to the address of a `Listener`
    'u'
    Returns a connection to the address of a `Listener`
    'b'
        Returns pair of connection objects at either end of a pipe
        'u'
        Returns pair of connection objects at either end of a pipe
        'b'
    Representation of a socket which is bound to an address and listening
    'u'
    Representation of a socket which is bound to an address and listening
    'b'
    Return a connection object connected to the socket given by `address`
    'u'
    Return a connection object connected to the socket given by `address`
    'b'
        Representation of a named pipe
        'u'
        Representation of a named pipe
        'b'listener created with address=%r'u'listener created with address=%r'b'closing listener with address=%r'u'closing listener with address=%r'b'
        Return a connection object connected to the pipe given by `address`
        'u'
        Return a connection object connected to the pipe given by `address`
        'b'#CHALLENGE#'b'#WELCOME#'b'#FAILURE#'b'Authkey must be bytes, not {0!s}'u'Authkey must be bytes, not {0!s}'b'md5'u'md5'b'digest received was wrong'u'digest received was wrong'b'message = %r'u'message = %r'b'digest sent was rejected'u'digest sent was rejected'b'fileno'u'fileno'b'poll'u'poll'b'recv_bytes'u'recv_bytes'b'send_bytes'u'send_bytes'b'Should not get here'u'Should not get here'b'
        Wait till an object in object_list is ready/readable.

        Returns list of those objects in object_list which are ready/readable.
        'u'
        Wait till an object in object_list is ready/readable.

        Returns list of those objects in object_list which are ready/readable.
        'b'_got_empty_message'u'_got_empty_message'contrib_appengine_environLocationParseErrorNoWayToWaitForSocketError
    Returns True if the connection is dropped and should be closed.

    :param conn:
        :class:`http.client.HTTPConnection` object.

    Note: For platforms like AppEngine, this will always return ``False`` to
    let the platform handle connection recycling transparently for us.
    Connect to *address* and return the socket object.

    Convenience function.  Connect to *address* (a 2-tuple ``(host,
    port)``) and return the socket object.  Passing the optional
    *timeout* parameter will set the timeout on the socket instance
    before attempting to connect.  If no *timeout* is supplied, the
    global default timeout setting returned by :func:`socket.getdefaulttimeout`
    is used.  If *source_address* is set it must be a tuple of (host, port)
    for the socket to bind as a source address before making the connection.
    An host of '' or port 0 tells the OS to use the default.
    allowed_gai_family'%s', label empty or too longu"_set_socket_optionsgetaddrinfo returns an empty listThis function is designed to work in the context of
    getaddrinfo, where family=socket.AF_UNSPEC is the default and
    will perform a DNS search for both IPv6 and IPv4 records.HAS_IPV6_has_ipv6Returns True if the system can bind an IPv6 address.::1# Platform-specific# Platform-specific: AppEngine# Connection already closed (such as by httplib).# Returns True if readable, which here means it's been dropped# This function is copied from socket.py in the Python 2.7 standard# library test suite. Added to its signature is only `socket_options`.# One additional modification is that we avoid binding to IPv6 servers# discovered in DNS if the system doesn't have IPv6 functionality.# Using the value from allowed_gai_family() in the context of getaddrinfo lets# us select whether to work with IPv4 DNS records, IPv6 records, or both.# The original create_connection function always returns all records.# If provided, set socket level options before connecting.# App Engine doesn't support IPV6 sockets and actually has a quota on the# number of sockets that can be used, so just early out here instead of# creating a socket needlessly.# See https://github.com/urllib3/urllib3/issues/1446# has_ipv6 returns true if cPython was compiled with IPv6 support.# It does not tell us if the system has IPv6 support enabled. To# determine that we must bind to an IPv6 address.# https://github.com/urllib3/urllib3/pull/611# https://bugs.python.org/issue658327b'
    Returns True if the connection is dropped and should be closed.

    :param conn:
        :class:`http.client.HTTPConnection` object.

    Note: For platforms like AppEngine, this will always return ``False`` to
    let the platform handle connection recycling transparently for us.
    'u'
    Returns True if the connection is dropped and should be closed.

    :param conn:
        :class:`http.client.HTTPConnection` object.

    Note: For platforms like AppEngine, this will always return ``False`` to
    let the platform handle connection recycling transparently for us.
    'b'sock'u'sock'b'Connect to *address* and return the socket object.

    Convenience function.  Connect to *address* (a 2-tuple ``(host,
    port)``) and return the socket object.  Passing the optional
    *timeout* parameter will set the timeout on the socket instance
    before attempting to connect.  If no *timeout* is supplied, the
    global default timeout setting returned by :func:`socket.getdefaulttimeout`
    is used.  If *source_address* is set it must be a tuple of (host, port)
    for the socket to bind as a source address before making the connection.
    An host of '' or port 0 tells the OS to use the default.
    'u'Connect to *address* and return the socket object.

    Convenience function.  Connect to *address* (a 2-tuple ``(host,
    port)``) and return the socket object.  Passing the optional
    *timeout* parameter will set the timeout on the socket instance
    before attempting to connect.  If no *timeout* is supplied, the
    global default timeout setting returned by :func:`socket.getdefaulttimeout`
    is used.  If *source_address* is set it must be a tuple of (host, port)
    for the socket to bind as a source address before making the connection.
    An host of '' or port 0 tells the OS to use the default.
    'u''%s', label empty or too long'b'getaddrinfo returns an empty list'u'getaddrinfo returns an empty list'b'This function is designed to work in the context of
    getaddrinfo, where family=socket.AF_UNSPEC is the default and
    will perform a DNS search for both IPv6 and IPv4 records.'u'This function is designed to work in the context of
    getaddrinfo, where family=socket.AF_UNSPEC is the default and
    will perform a DNS search for both IPv6 and IPv4 records.'b'Returns True if the system can bind an IPv6 address.'u'Returns True if the system can bind an IPv6 address.'b'::1'u'::1'u'urllib3.util.connection'u'util.connection'EmptyPoolErrorHeaderParsingErrorHostChangedErrorInsecureRequestWarningpackages.six.movesutil.connectionutil.queueset_file_positionutil.responseassert_header_parsing_encode_target_normalize_hostnormalize_hostConnectionPool
    Base class for all connection pools, such as
    :class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.

    .. note::
       ConnectionPool.urlopen() does not normalize or percent-encode target URIs
       which is useful if your target server doesn't support percent-encoded
       target URIs.
    QueueCls_proxy_host%s(host=%r, port=%r)
        Close all pooled connections and disable the pool.
        EAGAINEWOULDBLOCK_blocking_errnos
    Thread-safe connection pool for one host.

    :param host:
        Host used for this HTTP Connection (e.g. "localhost"), passed into
        :class:`http.client.HTTPConnection`.

    :param port:
        Port used for this HTTP Connection (None is equivalent to 80), passed
        into :class:`http.client.HTTPConnection`.

    :param strict:
        Causes BadStatusLine to be raised if the status line can't be parsed
        as a valid HTTP/1.0 or 1.1 status line, passed into
        :class:`http.client.HTTPConnection`.

        .. note::
           Only works in Python 2. This parameter is ignored in Python 3.

    :param timeout:
        Socket timeout in seconds for each individual connection. This can
        be a float or integer, which sets the timeout for the HTTP request,
        or an instance of :class:`urllib3.util.Timeout` which gives you more
        fine-grained control over request timeouts. After the constructor has
        been parsed, this is always a `urllib3.util.Timeout` object.

    :param maxsize:
        Number of connections to save that can be reused. More than 1 is useful
        in multithreaded situations. If ``block`` is set to False, more
        connections will be created but they will not be saved once they've
        been used.

    :param block:
        If set to True, no more than ``maxsize`` connections will be used at
        a time. When no free connections are available, the call will block
        until a connection has been released. This is a useful side effect for
        particular multithreaded situations where one does not want to use more
        than maxsize connections per host to prevent flooding.

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.

    :param retries:
        Retry configuration to use by default with requests in this pool.

    :param _proxy:
        Parsed proxy URL, should not be used directly, instead, see
        :class:`urllib3.ProxyManager`

    :param _proxy_headers:
        A dictionary with proxy headers, should not be used directly,
        instead, see :class:`urllib3.ProxyManager`

    :param \**conn_kw:
        Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,
        :class:`urllib3.connection.HTTPSConnection` instances.
    ResponseClsconn_kwnum_connectionsnum_requests
        Return a fresh :class:`HTTPConnection`.
        Starting new HTTP connection (%d): %s:%s
        Get a connection. Will return a pooled connection if one is available.

        If no connections are available and :prop:`.block` is ``False``, then a
        fresh connection is returned.

        :param timeout:
            Seconds to wait before giving up and raising
            :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and
            :prop:`.block` is ``True``.
        Pool is closed.Pool reached maximum size and no more connections are allowed.Resetting dropped connection: %s_put_conn
        Put a connection back into the pool.

        :param conn:
            Connection object for the current host and port as returned by
            :meth:`._new_conn` or :meth:`._get_conn`.

        If the pool is already full, the connection is closed and discarded
        because we exceeded maxsize. If connections are discarded frequently,
        then maxsize should be increased.

        If the pool is closed, then the connection will be closed and discarded.
        Connection pool is full, discarding connection: %s. Connection pool size: %s_validate_conn
        Called right before a request is made, after the socket is created.
        _prepare_proxy_get_timeoutHelper that always returns a :class:`urllib3.util.Timeout`_raise_timeouttimeout_valueIs the error actually a timeout? Will raise a ReadTimeout or passRead timed out. (read timeout=%s)timed outdid not complete (read)httplib_request_kw
        Perform a request on a given urllib connection object taken from our
        pool.

        :param conn:
            a connection from one of our connection pools

        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        timeout_objESHUTDOWNEPROTOTYPEhttplib_responseHTTP/?http_version%s://%s:%s "%s %s %s" %s %shpeFailed to parse headers (url=%s): %s_absolute_urlold_pool
        Check if the given ``url`` is a member of the same host as this
        connection pool.
        pool_timeoutrelease_connbody_posresponse_kw
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.

        .. note::

           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.

        .. note::

           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.

            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.

            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.

        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.

        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.

        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.

        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.

        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.

        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.

        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.

        :param \**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        destination_schemerelease_this_connhttp_tunnel_requiredclean_exitis_new_proxy_connresponse_connrequest_method_is_ssl_error_message_from_http_proxyssl_error[^a-z]wrong version numberunknown protocolYour proxy appears to only use HTTP and not HTTPS, try changing your proxy URL to be HTTP. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#https-proxy-error-http-proxy"Your proxy appears to only use HTTP and not HTTPS, ""try changing your proxy URL to be HTTP. See: ""https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html""#https-proxy-error-http-proxy"Cannot connect to proxy.Connection aborted._stacktraceRetrying (%r) after connection broken by '%r': %ssleep_for_retryRetry-Afterhas_retry_afteris_retryraise_on_statusRetry: %s
    Same as :class:`.HTTPConnectionPool`, but HTTPS.

    :class:`.HTTPSConnection` uses one of ``assert_fingerprint``,
    ``assert_hostname`` and ``host`` in this order to verify connections.
    If ``assert_hostname`` is False, no verification is done.

    The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``,
    ``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
    is available and are fed into :meth:`urllib3.util.ssl_wrap_socket` to upgrade
    the connection socket into an SSL socket.
    
        Prepare the ``connection`` for :meth:`urllib3.util.ssl_wrap_socket`
        and establish the tunnel if proxy is used.
        
        Establishes a tunnel connection through HTTP CONNECT.

        Tunnel connection is established early because otherwise httplib would
        improperly set Host: header to proxy's IP:port.
        
        Return a fresh :class:`http.client.HTTPSConnection`.
        Starting new HTTPS connection (%d): %s:%sCan't connect to HTTPS URL because the SSL module is not available.actual_hostactual_portUnverified HTTPS request is being made to host '%s'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings"Unverified HTTPS request is being made to host '%s'. ""Adding certificate verification is strongly advised. See: ""#ssl-warnings"Unverified HTTPS connection done to an HTTPS proxy. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings"Unverified HTTPS connection done to an HTTPS proxy. "
    Given a url, return an :class:`.ConnectionPool` instance of its host.

    This is a shortcut for not having to parse out the scheme, host, and port
    of the url before creating an :class:`.ConnectionPool` instance.

    :param url:
        Absolute URL string that must include the scheme. Port is optional.

    :param \**kw:
        Passes additional parameters to the constructor of the appropriate
        :class:`.ConnectionPool`. Useful for specifying things like
        timeout, maxsize, headers, etc.

    Example::

        >>> conn = connection_from_url('http://google.com/')
        >>> r = conn.request('GET', '/')
    
    Normalize hosts for comparisons and use with sockets.
    # Pool objects# This is taken from http://hg.python.org/cpython/file/7aaba721ebc0/Lib/socket.py#l252# Fill the queue up so that doing get() on it will block properly# These are mostly for testing and debugging purposes.# Enable Nagle's algorithm for proxies, to avoid packet fragmentation.# We cannot know if the user has added default socket options, so we cannot replace the# list.# self.pool is None# Oh well, we'll create a new connection then# If this is a persistent connection, check if it got disconnected# This is a proxied connection that has been mutated by# http.client._tunnel() and cannot be reused (since it would# attempt to bypass the proxy)# Everything is dandy, done.# self.pool is None.# This should never happen if self.block == True# Connection never got put back into the pool, close it.# Nothing to do for HTTP connections.# User passed us an int/float. This is for backwards compatibility,# can be removed later# See the above comment about EAGAIN in Python 3. In Python 2 we have# to specifically catch it and throw the timeout error# Catch possible read timeouts thrown as SSL errors. If not the# case, rethrow the original. We need to do this because of:# http://bugs.python.org/issue10272# Python < 2.7.4# Trigger any extra validation we need to do.# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.# conn.request() calls http.client.*.request, not the method in# urllib3.request. It also calls makefile (recv) on the socket.# We are swallowing BrokenPipeError (errno.EPIPE) since the server is# legitimately able to close the connection after sending a valid response.# With this behaviour, the received response is still readable.# Python 2 and macOS/Linux# EPIPE and ESHUTDOWN are BrokenPipeError on Python 2, and EPROTOTYPE is needed on macOS# https://erickt.github.io/blog/2014/11/19/adventures-in-debugging-a-potential-osx-kernel-bug/# Reset the timeout for the recv() on the socket# App Engine doesn't have a sock attr# In Python 3 socket.py will catch EAGAIN and return None when you# try and read into the file pointer created by http.client, which# instead raises a BadStatusLine exception. Instead of catching# the exception and assuming all BadStatusLine exceptions are read# timeouts, check for a zero timeout before making the request.# None or a value# Python 2.7, use buffering of HTTP responses# Remove the TypeError from the exception chain in# Python 3 (including for exceptions like SystemExit).# Otherwise it looks like a bug in the code.# AppEngine doesn't have a version attr.# Platform-specific: Python 3# Disable access to the pool# Done.# TODO: Add optional support for socket.gethostbyname checking.# Use explicit default port for comparison when none is given# Check host# Ensure that the URL we're connecting to is properly encoded# Track whether `conn` needs to be released before# returning/raising/recursing. Update this variable if necessary, and# leave `release_conn` constant throughout the function. That way, if# the function recurses, the original value of `release_conn` will be# passed down into the recursive call, and its value will be respected.# See issue #651 [1] for details.# [1] <https://github.com/urllib3/urllib3/issues/651># Merge the proxy headers. Only done when not using HTTP CONNECT. We# have to copy the headers dict so we can safely change it without those# changes being reflected in anyone else's copy.# Must keep the exception bound to a separate variable or else Python 3# complains about UnboundLocalError.# Keep track of whether we cleanly exited the except block. This# ensures we do proper cleanup in finally.# Rewind body position, if needed. Record current position# for future rewinds in the event of a redirect/retry.# Request a connection from the queue.# Make the request on the httplib connection object.# If we're going to release the connection in ``finally:``, then# the response doesn't need to know about the connection. Otherwise# it will also try to release it and we'll have a double-release# mess.# Pass method to Response for length checking# Import httplib's response into our own wrapper object# Everything went great!# Didn't get a connection from the pool, no need to clean up# Discard the connection for these exceptions. It will be# replaced during the next _get_conn() call.# We're trying to detect the message 'WRONG_VERSION_NUMBER' but# SSLErrors are kinda all over the place when it comes to the message,# so we try to cover our bases here!# Try to detect a common user error with proxies which is to# set an HTTP proxy to be HTTPS when it should be 'http://'# (ie {'http': 'http://proxy', 'https': 'https://proxy'})# Instead we add a nice error message and point to a URL.# Keep track of the error for the retry warning.# We hit some kind of exception, handled or otherwise. We need# to throw the connection away unless explicitly told not to.# Close the connection, set the variable to None, and make sure# we put the None back in the pool to avoid leaking it.# Put the connection back to be reused. If the connection is# expired then it will be None, which will get replaced with a# fresh connection during _get_conn.# Try again# Handle redirect?# Check if we should retry the HTTP response.# Force connect early to allow us to validate the connection.# AppEngine might not have  `.sock`# httplib doesn't like it when we include brackets in IPv6 addresses# Specifically, if we include brackets but also pass the port then# httplib crazily doubles up the square brackets on the Host header.# Instead, we need to make sure we never pass ``None`` as the port.# However, for backward compatibility reasons we can't actually# *assert* that.  See http://bugs.python.org/issue28539b'
    Base class for all connection pools, such as
    :class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.

    .. note::
       ConnectionPool.urlopen() does not normalize or percent-encode target URIs
       which is useful if your target server doesn't support percent-encoded
       target URIs.
    'u'
    Base class for all connection pools, such as
    :class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.

    .. note::
       ConnectionPool.urlopen() does not normalize or percent-encode target URIs
       which is useful if your target server doesn't support percent-encoded
       target URIs.
    'b'%s(host=%r, port=%r)'u'%s(host=%r, port=%r)'b'
        Close all pooled connections and disable the pool.
        'u'
        Close all pooled connections and disable the pool.
        'b'
    Thread-safe connection pool for one host.

    :param host:
        Host used for this HTTP Connection (e.g. "localhost"), passed into
        :class:`http.client.HTTPConnection`.

    :param port:
        Port used for this HTTP Connection (None is equivalent to 80), passed
        into :class:`http.client.HTTPConnection`.

    :param strict:
        Causes BadStatusLine to be raised if the status line can't be parsed
        as a valid HTTP/1.0 or 1.1 status line, passed into
        :class:`http.client.HTTPConnection`.

        .. note::
           Only works in Python 2. This parameter is ignored in Python 3.

    :param timeout:
        Socket timeout in seconds for each individual connection. This can
        be a float or integer, which sets the timeout for the HTTP request,
        or an instance of :class:`urllib3.util.Timeout` which gives you more
        fine-grained control over request timeouts. After the constructor has
        been parsed, this is always a `urllib3.util.Timeout` object.

    :param maxsize:
        Number of connections to save that can be reused. More than 1 is useful
        in multithreaded situations. If ``block`` is set to False, more
        connections will be created but they will not be saved once they've
        been used.

    :param block:
        If set to True, no more than ``maxsize`` connections will be used at
        a time. When no free connections are available, the call will block
        until a connection has been released. This is a useful side effect for
        particular multithreaded situations where one does not want to use more
        than maxsize connections per host to prevent flooding.

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.

    :param retries:
        Retry configuration to use by default with requests in this pool.

    :param _proxy:
        Parsed proxy URL, should not be used directly, instead, see
        :class:`urllib3.ProxyManager`

    :param _proxy_headers:
        A dictionary with proxy headers, should not be used directly,
        instead, see :class:`urllib3.ProxyManager`

    :param \**conn_kw:
        Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,
        :class:`urllib3.connection.HTTPSConnection` instances.
    'u'
    Thread-safe connection pool for one host.

    :param host:
        Host used for this HTTP Connection (e.g. "localhost"), passed into
        :class:`http.client.HTTPConnection`.

    :param port:
        Port used for this HTTP Connection (None is equivalent to 80), passed
        into :class:`http.client.HTTPConnection`.

    :param strict:
        Causes BadStatusLine to be raised if the status line can't be parsed
        as a valid HTTP/1.0 or 1.1 status line, passed into
        :class:`http.client.HTTPConnection`.

        .. note::
           Only works in Python 2. This parameter is ignored in Python 3.

    :param timeout:
        Socket timeout in seconds for each individual connection. This can
        be a float or integer, which sets the timeout for the HTTP request,
        or an instance of :class:`urllib3.util.Timeout` which gives you more
        fine-grained control over request timeouts. After the constructor has
        been parsed, this is always a `urllib3.util.Timeout` object.

    :param maxsize:
        Number of connections to save that can be reused. More than 1 is useful
        in multithreaded situations. If ``block`` is set to False, more
        connections will be created but they will not be saved once they've
        been used.

    :param block:
        If set to True, no more than ``maxsize`` connections will be used at
        a time. When no free connections are available, the call will block
        until a connection has been released. This is a useful side effect for
        particular multithreaded situations where one does not want to use more
        than maxsize connections per host to prevent flooding.

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.

    :param retries:
        Retry configuration to use by default with requests in this pool.

    :param _proxy:
        Parsed proxy URL, should not be used directly, instead, see
        :class:`urllib3.ProxyManager`

    :param _proxy_headers:
        A dictionary with proxy headers, should not be used directly,
        instead, see :class:`urllib3.ProxyManager`

    :param \**conn_kw:
        Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,
        :class:`urllib3.connection.HTTPSConnection` instances.
    'b'
        Return a fresh :class:`HTTPConnection`.
        'u'
        Return a fresh :class:`HTTPConnection`.
        'b'Starting new HTTP connection (%d): %s:%s'u'Starting new HTTP connection (%d): %s:%s'b'80'u'80'b'
        Get a connection. Will return a pooled connection if one is available.

        If no connections are available and :prop:`.block` is ``False``, then a
        fresh connection is returned.

        :param timeout:
            Seconds to wait before giving up and raising
            :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and
            :prop:`.block` is ``True``.
        'u'
        Get a connection. Will return a pooled connection if one is available.

        If no connections are available and :prop:`.block` is ``False``, then a
        fresh connection is returned.

        :param timeout:
            Seconds to wait before giving up and raising
            :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and
            :prop:`.block` is ``True``.
        'b'Pool is closed.'u'Pool is closed.'b'Pool reached maximum size and no more connections are allowed.'u'Pool reached maximum size and no more connections are allowed.'b'Resetting dropped connection: %s'u'Resetting dropped connection: %s'b'auto_open'u'auto_open'b'
        Put a connection back into the pool.

        :param conn:
            Connection object for the current host and port as returned by
            :meth:`._new_conn` or :meth:`._get_conn`.

        If the pool is already full, the connection is closed and discarded
        because we exceeded maxsize. If connections are discarded frequently,
        then maxsize should be increased.

        If the pool is closed, then the connection will be closed and discarded.
        'u'
        Put a connection back into the pool.

        :param conn:
            Connection object for the current host and port as returned by
            :meth:`._new_conn` or :meth:`._get_conn`.

        If the pool is already full, the connection is closed and discarded
        because we exceeded maxsize. If connections are discarded frequently,
        then maxsize should be increased.

        If the pool is closed, then the connection will be closed and discarded.
        'b'Connection pool is full, discarding connection: %s. Connection pool size: %s'u'Connection pool is full, discarding connection: %s. Connection pool size: %s'b'
        Called right before a request is made, after the socket is created.
        'u'
        Called right before a request is made, after the socket is created.
        'b'Helper that always returns a :class:`urllib3.util.Timeout`'u'Helper that always returns a :class:`urllib3.util.Timeout`'b'Is the error actually a timeout? Will raise a ReadTimeout or pass'u'Is the error actually a timeout? Will raise a ReadTimeout or pass'b'Read timed out. (read timeout=%s)'u'Read timed out. (read timeout=%s)'b'errno'b'timed out'u'timed out'b'did not complete (read)'u'did not complete (read)'b'
        Perform a request on a given urllib connection object taken from our
        pool.

        :param conn:
            a connection from one of our connection pools

        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        'u'
        Perform a request on a given urllib connection object taken from our
        pool.

        :param conn:
            a connection from one of our connection pools

        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        'b'_http_vsn_str'u'_http_vsn_str'b'HTTP/?'u'HTTP/?'b'%s://%s:%s "%s %s %s" %s %s'u'%s://%s:%s "%s %s %s" %s %s'b'Failed to parse headers (url=%s): %s'u'Failed to parse headers (url=%s): %s'b'
        Check if the given ``url`` is a member of the same host as this
        connection pool.
        'u'
        Check if the given ``url`` is a member of the same host as this
        connection pool.
        'b'
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.

        .. note::

           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.

        .. note::

           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.

            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.

            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.

        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.

        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.

        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.

        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.

        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.

        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.

        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.

        :param \**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        'u'
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.

        .. note::

           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.

        .. note::

           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.

            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.

            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.

        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.

        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.

        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.

        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.

        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.

        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.

        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.

        :param \**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        'b'preload_content'u'preload_content'b'request_method'u'request_method'b'[^a-z]'u'[^a-z]'b'wrong version number'u'wrong version number'b'unknown protocol'u'unknown protocol'b'Your proxy appears to only use HTTP and not HTTPS, try changing your proxy URL to be HTTP. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#https-proxy-error-http-proxy'u'Your proxy appears to only use HTTP and not HTTPS, try changing your proxy URL to be HTTP. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#https-proxy-error-http-proxy'b'Cannot connect to proxy.'u'Cannot connect to proxy.'b'Connection aborted.'b'Retrying (%r) after connection broken by '%r': %s'u'Retrying (%r) after connection broken by '%r': %s'b'Retry-After'u'Retry-After'b'Retry: %s'u'Retry: %s'b'
    Same as :class:`.HTTPConnectionPool`, but HTTPS.

    :class:`.HTTPSConnection` uses one of ``assert_fingerprint``,
    ``assert_hostname`` and ``host`` in this order to verify connections.
    If ``assert_hostname`` is False, no verification is done.

    The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``,
    ``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
    is available and are fed into :meth:`urllib3.util.ssl_wrap_socket` to upgrade
    the connection socket into an SSL socket.
    'u'
    Same as :class:`.HTTPConnectionPool`, but HTTPS.

    :class:`.HTTPSConnection` uses one of ``assert_fingerprint``,
    ``assert_hostname`` and ``host`` in this order to verify connections.
    If ``assert_hostname`` is False, no verification is done.

    The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``,
    ``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
    is available and are fed into :meth:`urllib3.util.ssl_wrap_socket` to upgrade
    the connection socket into an SSL socket.
    'b'
        Prepare the ``connection`` for :meth:`urllib3.util.ssl_wrap_socket`
        and establish the tunnel if proxy is used.
        'u'
        Prepare the ``connection`` for :meth:`urllib3.util.ssl_wrap_socket`
        and establish the tunnel if proxy is used.
        'b'
        Establishes a tunnel connection through HTTP CONNECT.

        Tunnel connection is established early because otherwise httplib would
        improperly set Host: header to proxy's IP:port.
        'u'
        Establishes a tunnel connection through HTTP CONNECT.

        Tunnel connection is established early because otherwise httplib would
        improperly set Host: header to proxy's IP:port.
        'b'
        Return a fresh :class:`http.client.HTTPSConnection`.
        'u'
        Return a fresh :class:`http.client.HTTPSConnection`.
        'b'Starting new HTTPS connection (%d): %s:%s'u'Starting new HTTPS connection (%d): %s:%s'b'443'u'443'b'Can't connect to HTTPS URL because the SSL module is not available.'u'Can't connect to HTTPS URL because the SSL module is not available.'b'Unverified HTTPS request is being made to host '%s'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings'u'Unverified HTTPS request is being made to host '%s'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings'b'proxy_is_verified'u'proxy_is_verified'b'Unverified HTTPS connection done to an HTTPS proxy. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings'u'Unverified HTTPS connection done to an HTTPS proxy. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings'b'
    Given a url, return an :class:`.ConnectionPool` instance of its host.

    This is a shortcut for not having to parse out the scheme, host, and port
    of the url before creating an :class:`.ConnectionPool` instance.

    :param url:
        Absolute URL string that must include the scheme. Port is optional.

    :param \**kw:
        Passes additional parameters to the constructor of the appropriate
        :class:`.ConnectionPool`. Useful for specifying things like
        timeout, maxsize, headers, etc.

    Example::

        >>> conn = connection_from_url('http://google.com/')
        >>> r = conn.request('GET', '/')
    'u'
    Given a url, return an :class:`.ConnectionPool` instance of its host.

    This is a shortcut for not having to parse out the scheme, host, and port
    of the url before creating an :class:`.ConnectionPool` instance.

    :param url:
        Absolute URL string that must include the scheme. Port is optional.

    :param \**kw:
        Passes additional parameters to the constructor of the appropriate
        :class:`.ConnectionPool`. Useful for specifying things like
        timeout, maxsize, headers, etc.

    Example::

        >>> conn = connection_from_url('http://google.com/')
        >>> r = conn.request('GET', '/')
    'b'
    Normalize hosts for comparisons and use with sockets.
    'u'
    Normalize hosts for comparisons and use with sockets.
    'u'urllib3.connectionpool'u'connectionpool'encodings.aliasesre_compile+/v8+/v9+/v++/v/+/v8-13ENCODING_MARKS10000000.010e61112064UTF8_MAXIMAL_ALLOCATIONControl characterBasic LatinLatin-1 Supplement383Latin Extended-A384591Latin Extended-B592687IPA Extensions688767Spacing Modifier Letters879Combining Diacritical Marks880Greek and Coptic1279Cyrillic12801327Cyrillic Supplement13281423Armenian14241535179117921871Syriac18721919Arabic Supplement19201983Thaana19842047NKo2111Samaritan21122143Mandaic21442159Syriac Supplement22082303Arabic Extended-A23042431Devanagari24322559Bengali25602687Gurmukhi26882815Gujarati28162943Oriya2944307130723199Telugu32003327Kannada33283455Malayalam34563583Sinhala3584371137123839Lao3840Tibetan4255Myanmar42564351Georgian43524607Hangul Jamo46084991Ethiopic49925023Ethiopic Supplement50245119Cherokee51205759Unified Canadian Aboriginal Syllabics57605791Ogham57925887Runic58885919Tagalog59205951Hanunoo59525983Buhid59846015Tagbanwa60166143Khmer61446319Mongolian63206399Unified Canadian Aboriginal Syllabics Extended64006479Limbu64806527Tai Le65286623New Tai Lue66246655Khmer Symbols66566687Buginese66886831Tai Tham68326911Combining Diacritical Marks Extended69127039Balinese70407103Sundanese71047167Batak71687247Lepcha72487295Ol Chiki72967311Cyrillic Extended C73607375Sundanese Supplement73767423Vedic Extensions74247551Phonetic Extensions75527615Phonetic Extensions Supplement76167679Combining Diacritical Marks Supplement76807935Latin Extended Additional79368191Greek Extended8303General Punctuation83048351Superscripts and Subscripts83528399Currency Symbols84008447Combining Diacritical Marks for Symbols84488527Letterlike Symbols85288591Number Forms85928703Arrows87048959Mathematical Operators89609215Miscellaneous Technical92169279Control Pictures92809311Optical Character Recognition93129471Enclosed Alphanumerics94729599Box Drawing96009631Block Elements96329727Geometric Shapes97289983Miscellaneous Symbols998410175Dingbats1017610223Miscellaneous Mathematical Symbols-A1022410239Supplemental Arrows-A1024010495Braille Patterns1049610623Supplemental Arrows-B1062410751Miscellaneous Mathematical Symbols-B1075211007Supplemental Mathematical Operators1100811263Miscellaneous Symbols and Arrows1126411359Glagolitic1136011391Latin Extended-C1139211519Coptic1152011567Georgian Supplement1156811647Tifinagh1164811743Ethiopic Extended1174411775Cyrillic Extended-A1177611903Supplemental Punctuation1190412031CJK Radicals Supplement1203212255Kangxi Radicals1227212287Ideographic Description Characters1228812351CJK Symbols and Punctuation1235212447Hiragana1244812543Katakana1254412591Bopomofo1259212687Hangul Compatibility Jamo1268812703Kanbun1270412735Bopomofo Extended1273612783CJK Strokes1278412799Katakana Phonetic Extensions1280013055Enclosed CJK Letters and Months1305613311CJK Compatibility1331219903CJK Unified Ideographs Extension A1990419967Yijing Hexagram Symbols1996840959CJK Unified Ideographs42127Yi Syllables4212842191Yi Radicals4219242239Lisu4224042559Vai4256042655Cyrillic Extended-B4265642751Bamum4275242783Modifier Tone Letters4278443007Latin Extended-D4300843055Syloti Nagri4305643071Common Indic Number Forms4307243135Phags-pa4313643231Saurashtra4323243263Devanagari Extended4326443311Kayah Li4331243359Rejang4336043391Hangul Jamo Extended-A4339243487Javanese4348843519Myanmar Extended-B4352043615Cham4361643647Myanmar Extended-A4364843743Tai Viet4374443775Meetei Mayek Extensions4377643823Ethiopic Extended-A4382443887Latin Extended-E4388843967Cherokee Supplement4396844031Meetei Mayek4403255215Hangul Syllables5521655295Hangul Jamo Extended-B56191High Surrogates5619256319High Private Use Surrogates56320Low Surrogates63743Private Use Area6374464255CJK Compatibility Ideographs6425664335Alphabetic Presentation Forms6433665023Arabic Presentation Forms-A6502465039Variation Selectors6504065055Vertical Forms6505665071Combining Half Marks6507265103CJK Compatibility Forms6510465135Small Form Variants6513665279Arabic Presentation Forms-B6528065519Halfwidth and Fullwidth Forms65520Specials65663Linear B Syllabary6566465791Linear B Ideograms6579265855Aegean Numbers6585665935Ancient Greek Numbers6593665999Ancient Symbols6600066047Phaistos Disc6617666207Lycian6620866271Carian6627266303Coptic Epact Numbers6630466351Old Italic6635266383Gothic6638466431Old Permic6643266463Ugaritic6646466527Old Persian6656066639Deseret6664066687Shavian6668866735Osmanya6673666815Osage6681666863Elbasan6686466927Caucasian Albanian6707267455Linear A6758467647Cypriot Syllabary6764867679Imperial Aramaic6768067711Palmyrene6771267759Nabataean6780867839Hatran6784067871Phoenician6787267903Lydian6796867999Meroitic Hieroglyphs6800068095Meroitic Cursive6809668191Kharoshthi6819268223Old South Arabian6822468255Old North Arabian6828868351Manichaean6835268415Avestan6841668447Inscriptional Parthian6844868479Inscriptional Pahlavi6848068527Psalter Pahlavi6860868687Old Turkic6873668863Old Hungarian6921669247Rumi Numeral Symbols6963269759Brahmi6976069839Kaithi6984069887Sora Sompeng6988869967Chakma6996870015Mahajani7001670111Sharada7011270143Sinhala Archaic Numbers7014470223Khojki7027270319Multani7032070399Khudawadi7040070527Grantha7065670783Newa7078470879Tirhuta7104071167Siddham7116871263Modi7126471295Mongolian Supplement7129671375Takri7142471487Ahom7184071935Warang Citi7219272271Zanabazar Square7227272367Soyombo7238472447Pau Cin Hau7270472815Bhaiksuki7281672895Marchen7296073055Masaram Gondi7372874751Cuneiform7475274879Cuneiform Numbers and Punctuation7488075087Early Dynastic Cuneiform7782478895Egyptian Hieroglyphs8294483583Anatolian Hieroglyphs9216092735Bamum Supplement9273692783Mro9288092927Bassa Vah9292893071Pahawh Hmong9395294111Miao9417694207Ideographic Symbols and Punctuation94208100351Tangut100352101119Tangut Components110592110847Kana Supplement110848110895Kana Extended-A110960111359Nushu113664113823Duployan113824113839Shorthand Format Controls118784119039Byzantine Musical Symbols119040119295Musical Symbols119296119375Ancient Greek Musical Notation119552119647Tai Xuan Jing Symbols119648119679Counting Rod Numerals119808120831Mathematical Alphanumeric Symbols120832121519Sutton SignWriting122880122927Glagolitic Supplement124928125151Mende Kikakui125184125279Adlam126464126719Arabic Mathematical Alphabetic Symbols126976127023Mahjong Tiles127024127135Domino Tiles127136127231Playing Cards127232127487Enclosed Alphanumeric Supplement127488127743Enclosed Ideographic Supplement127744128511Miscellaneous Symbols and Pictographs128512128591Emoticons range(Emoji)128592128639Ornamental Dingbats128640128767Transport and Map Symbols128768128895Alchemical Symbols128896129023Geometric Shapes Extended129024129279Supplemental Arrows-C129280129535Supplemental Symbols and Pictographs173791CJK Unified Ideographs Extension B173824177983CJK Unified Ideographs Extension C177984178207CJK Unified Ideographs Extension D178208183983CJK Unified Ideographs Extension E183984191471CJK Unified Ideographs Extension F194560195103CJK Compatibility Ideographs Supplement917504917631Tags917760917999Variation Selectors SupplementUNICODE_RANGES_COMBINEDSupplementExtendedExtensionsModifierMarksPunctuationSymbolsFormsOperatorsMiscellaneousDrawingBlockShapesSupplementalUNICODE_SECONDARY_RANGE_KEYWORD(?:(?:encoding)|(?:charset)|(?:coding))(?:[\:= ]{1,10})(?:[\"\']?)([a-zA-Z0-9\-_]+)(?:[\"\']?)RE_POSSIBLE_ENCODING_INDICATION_codectactisIANA_SUPPORTED_COUNTIANA_SUPPORTED_SIMILARISO-2022-KRISO-2022-JPEUC-KRTIS-620UTF-32EUC-JPKOI8-RISO-8859-1ISO-8859-2ISO-8859-5ISO-8859-6ISO-8859-7ISO-8859-8UTF-16IBM855MacCyrillicGB2312GB18030CP932IBM866UTF-8-SIGutf_8_sigSHIFT_JISBig5windows-1250windows-1251Windows-1252windows-1253windows-1255windows-1256Windows-1254CP949CHARDET_CORRESPONDENCECOMMON_SAFE_ASCII_CHARACTERS# Contain for each eligible encoding a list of/item bytes SIG/BOM# pre-computed code page that are similar using the function cp_similarity.# Logging LEVEL below DEBUGb'+/v8'b'+/v9'b'+/v+'b'+/v/'b'+/v8-'b'13'b'Control character'u'Control character'b'Basic Latin'u'Basic Latin'b'Latin-1 Supplement'u'Latin-1 Supplement'b'Latin Extended-A'u'Latin Extended-A'b'Latin Extended-B'u'Latin Extended-B'b'IPA Extensions'u'IPA Extensions'b'Spacing Modifier Letters'u'Spacing Modifier Letters'b'Combining Diacritical Marks'u'Combining Diacritical Marks'b'Greek and Coptic'u'Greek and Coptic'b'Cyrillic'u'Cyrillic'b'Cyrillic Supplement'u'Cyrillic Supplement'b'Armenian'u'Armenian'b'Syriac'u'Syriac'b'Arabic Supplement'u'Arabic Supplement'b'Thaana'u'Thaana'b'NKo'u'NKo'b'Samaritan'u'Samaritan'b'Mandaic'u'Mandaic'b'Syriac Supplement'u'Syriac Supplement'b'Arabic Extended-A'u'Arabic Extended-A'b'Devanagari'u'Devanagari'b'Bengali'u'Bengali'b'Gurmukhi'u'Gurmukhi'b'Gujarati'u'Gujarati'b'Oriya'u'Oriya'b'Telugu'u'Telugu'b'Kannada'u'Kannada'b'Malayalam'u'Malayalam'b'Sinhala'u'Sinhala'b'Lao'u'Lao'b'Tibetan'u'Tibetan'b'Myanmar'u'Myanmar'b'Georgian'u'Georgian'b'Hangul Jamo'u'Hangul Jamo'b'Ethiopic'u'Ethiopic'b'Ethiopic Supplement'u'Ethiopic Supplement'b'Cherokee'u'Cherokee'b'Unified Canadian Aboriginal Syllabics'u'Unified Canadian Aboriginal Syllabics'b'Ogham'u'Ogham'b'Runic'u'Runic'b'Tagalog'u'Tagalog'b'Hanunoo'u'Hanunoo'b'Buhid'u'Buhid'b'Tagbanwa'u'Tagbanwa'b'Khmer'u'Khmer'b'Mongolian'u'Mongolian'b'Unified Canadian Aboriginal Syllabics Extended'u'Unified Canadian Aboriginal Syllabics Extended'b'Limbu'u'Limbu'b'Tai Le'u'Tai Le'b'New Tai Lue'u'New Tai Lue'b'Khmer Symbols'u'Khmer Symbols'b'Buginese'u'Buginese'b'Tai Tham'u'Tai Tham'b'Combining Diacritical Marks Extended'u'Combining Diacritical Marks Extended'b'Balinese'u'Balinese'b'Sundanese'u'Sundanese'b'Batak'u'Batak'b'Lepcha'u'Lepcha'b'Ol Chiki'u'Ol Chiki'b'Cyrillic Extended C'u'Cyrillic Extended C'b'Sundanese Supplement'u'Sundanese Supplement'b'Vedic Extensions'u'Vedic Extensions'b'Phonetic Extensions'u'Phonetic Extensions'b'Phonetic Extensions Supplement'u'Phonetic Extensions Supplement'b'Combining Diacritical Marks Supplement'u'Combining Diacritical Marks Supplement'b'Latin Extended Additional'u'Latin Extended Additional'b'Greek Extended'u'Greek Extended'b'General Punctuation'u'General Punctuation'b'Superscripts and Subscripts'u'Superscripts and Subscripts'b'Currency Symbols'u'Currency Symbols'b'Combining Diacritical Marks for Symbols'u'Combining Diacritical Marks for Symbols'b'Letterlike Symbols'u'Letterlike Symbols'b'Number Forms'u'Number Forms'b'Arrows'u'Arrows'b'Mathematical Operators'u'Mathematical Operators'b'Miscellaneous Technical'u'Miscellaneous Technical'b'Control Pictures'u'Control Pictures'b'Optical Character Recognition'u'Optical Character Recognition'b'Enclosed Alphanumerics'u'Enclosed Alphanumerics'b'Box Drawing'u'Box Drawing'b'Block Elements'u'Block Elements'b'Geometric Shapes'u'Geometric Shapes'b'Miscellaneous Symbols'u'Miscellaneous Symbols'b'Dingbats'u'Dingbats'b'Miscellaneous Mathematical Symbols-A'u'Miscellaneous Mathematical Symbols-A'b'Supplemental Arrows-A'u'Supplemental Arrows-A'b'Braille Patterns'u'Braille Patterns'b'Supplemental Arrows-B'u'Supplemental Arrows-B'b'Miscellaneous Mathematical Symbols-B'u'Miscellaneous Mathematical Symbols-B'b'Supplemental Mathematical Operators'u'Supplemental Mathematical Operators'b'Miscellaneous Symbols and Arrows'u'Miscellaneous Symbols and Arrows'b'Glagolitic'u'Glagolitic'b'Latin Extended-C'u'Latin Extended-C'b'Coptic'u'Coptic'b'Georgian Supplement'u'Georgian Supplement'b'Tifinagh'u'Tifinagh'b'Ethiopic Extended'u'Ethiopic Extended'b'Cyrillic Extended-A'u'Cyrillic Extended-A'b'Supplemental Punctuation'u'Supplemental Punctuation'b'CJK Radicals Supplement'u'CJK Radicals Supplement'b'Kangxi Radicals'u'Kangxi Radicals'b'Ideographic Description Characters'u'Ideographic Description Characters'b'CJK Symbols and Punctuation'u'CJK Symbols and Punctuation'b'Hiragana'u'Hiragana'b'Katakana'u'Katakana'b'Bopomofo'u'Bopomofo'b'Hangul Compatibility Jamo'u'Hangul Compatibility Jamo'b'Kanbun'u'Kanbun'b'Bopomofo Extended'u'Bopomofo Extended'b'CJK Strokes'u'CJK Strokes'b'Katakana Phonetic Extensions'u'Katakana Phonetic Extensions'b'Enclosed CJK Letters and Months'u'Enclosed CJK Letters and Months'b'CJK Compatibility'u'CJK Compatibility'b'CJK Unified Ideographs Extension A'u'CJK Unified Ideographs Extension A'b'Yijing Hexagram Symbols'u'Yijing Hexagram Symbols'b'CJK Unified Ideographs'u'CJK Unified Ideographs'b'Yi Syllables'u'Yi Syllables'b'Yi Radicals'u'Yi Radicals'b'Lisu'u'Lisu'b'Vai'u'Vai'b'Cyrillic Extended-B'u'Cyrillic Extended-B'b'Bamum'u'Bamum'b'Modifier Tone Letters'u'Modifier Tone Letters'b'Latin Extended-D'u'Latin Extended-D'b'Syloti Nagri'u'Syloti Nagri'b'Common Indic Number Forms'u'Common Indic Number Forms'b'Phags-pa'u'Phags-pa'b'Saurashtra'u'Saurashtra'b'Devanagari Extended'u'Devanagari Extended'b'Kayah Li'u'Kayah Li'b'Rejang'u'Rejang'b'Hangul Jamo Extended-A'u'Hangul Jamo Extended-A'b'Javanese'u'Javanese'b'Myanmar Extended-B'u'Myanmar Extended-B'b'Cham'u'Cham'b'Myanmar Extended-A'u'Myanmar Extended-A'b'Tai Viet'u'Tai Viet'b'Meetei Mayek Extensions'u'Meetei Mayek Extensions'b'Ethiopic Extended-A'u'Ethiopic Extended-A'b'Latin Extended-E'u'Latin Extended-E'b'Cherokee Supplement'u'Cherokee Supplement'b'Meetei Mayek'u'Meetei Mayek'b'Hangul Syllables'u'Hangul Syllables'b'Hangul Jamo Extended-B'u'Hangul Jamo Extended-B'b'High Surrogates'u'High Surrogates'b'High Private Use Surrogates'u'High Private Use Surrogates'b'Low Surrogates'u'Low Surrogates'b'Private Use Area'u'Private Use Area'b'CJK Compatibility Ideographs'u'CJK Compatibility Ideographs'b'Alphabetic Presentation Forms'u'Alphabetic Presentation Forms'b'Arabic Presentation Forms-A'u'Arabic Presentation Forms-A'b'Variation Selectors'u'Variation Selectors'b'Vertical Forms'u'Vertical Forms'b'Combining Half Marks'u'Combining Half Marks'b'CJK Compatibility Forms'u'CJK Compatibility Forms'b'Small Form Variants'u'Small Form Variants'b'Arabic Presentation Forms-B'u'Arabic Presentation Forms-B'b'Halfwidth and Fullwidth Forms'u'Halfwidth and Fullwidth Forms'b'Specials'u'Specials'b'Linear B Syllabary'u'Linear B Syllabary'b'Linear B Ideograms'u'Linear B Ideograms'b'Aegean Numbers'u'Aegean Numbers'b'Ancient Greek Numbers'u'Ancient Greek Numbers'b'Ancient Symbols'u'Ancient Symbols'b'Phaistos Disc'u'Phaistos Disc'b'Lycian'u'Lycian'b'Carian'u'Carian'b'Coptic Epact Numbers'u'Coptic Epact Numbers'b'Old Italic'u'Old Italic'b'Gothic'u'Gothic'b'Old Permic'u'Old Permic'b'Ugaritic'u'Ugaritic'b'Old Persian'u'Old Persian'b'Deseret'u'Deseret'b'Shavian'u'Shavian'b'Osmanya'u'Osmanya'b'Osage'u'Osage'b'Elbasan'u'Elbasan'b'Caucasian Albanian'u'Caucasian Albanian'b'Linear A'u'Linear A'b'Cypriot Syllabary'u'Cypriot Syllabary'b'Imperial Aramaic'u'Imperial Aramaic'b'Palmyrene'u'Palmyrene'b'Nabataean'u'Nabataean'b'Hatran'u'Hatran'b'Phoenician'u'Phoenician'b'Lydian'u'Lydian'b'Meroitic Hieroglyphs'u'Meroitic Hieroglyphs'b'Meroitic Cursive'u'Meroitic Cursive'b'Kharoshthi'u'Kharoshthi'b'Old South Arabian'u'Old South Arabian'b'Old North Arabian'u'Old North Arabian'b'Manichaean'u'Manichaean'b'Avestan'u'Avestan'b'Inscriptional Parthian'u'Inscriptional Parthian'b'Inscriptional Pahlavi'u'Inscriptional Pahlavi'b'Psalter Pahlavi'u'Psalter Pahlavi'b'Old Turkic'u'Old Turkic'b'Old Hungarian'u'Old Hungarian'b'Rumi Numeral Symbols'u'Rumi Numeral Symbols'b'Brahmi'u'Brahmi'b'Kaithi'u'Kaithi'b'Sora Sompeng'u'Sora Sompeng'b'Chakma'u'Chakma'b'Mahajani'u'Mahajani'b'Sharada'u'Sharada'b'Sinhala Archaic Numbers'u'Sinhala Archaic Numbers'b'Khojki'u'Khojki'b'Multani'u'Multani'b'Khudawadi'u'Khudawadi'b'Grantha'u'Grantha'b'Newa'u'Newa'b'Tirhuta'u'Tirhuta'b'Siddham'u'Siddham'b'Modi'u'Modi'b'Mongolian Supplement'u'Mongolian Supplement'b'Takri'u'Takri'b'Ahom'u'Ahom'b'Warang Citi'u'Warang Citi'b'Zanabazar Square'u'Zanabazar Square'b'Soyombo'u'Soyombo'b'Pau Cin Hau'u'Pau Cin Hau'b'Bhaiksuki'u'Bhaiksuki'b'Marchen'u'Marchen'b'Masaram Gondi'u'Masaram Gondi'b'Cuneiform'u'Cuneiform'b'Cuneiform Numbers and Punctuation'u'Cuneiform Numbers and Punctuation'b'Early Dynastic Cuneiform'u'Early Dynastic Cuneiform'b'Egyptian Hieroglyphs'u'Egyptian Hieroglyphs'b'Anatolian Hieroglyphs'u'Anatolian Hieroglyphs'b'Bamum Supplement'u'Bamum Supplement'b'Mro'u'Mro'b'Bassa Vah'u'Bassa Vah'b'Pahawh Hmong'u'Pahawh Hmong'b'Miao'u'Miao'b'Ideographic Symbols and Punctuation'u'Ideographic Symbols and Punctuation'b'Tangut'u'Tangut'b'Tangut Components'u'Tangut Components'b'Kana Supplement'u'Kana Supplement'b'Kana Extended-A'u'Kana Extended-A'b'Nushu'u'Nushu'b'Duployan'u'Duployan'b'Shorthand Format Controls'u'Shorthand Format Controls'b'Byzantine Musical Symbols'u'Byzantine Musical Symbols'b'Musical Symbols'u'Musical Symbols'b'Ancient Greek Musical Notation'u'Ancient Greek Musical Notation'b'Tai Xuan Jing Symbols'u'Tai Xuan Jing Symbols'b'Counting Rod Numerals'u'Counting Rod Numerals'b'Mathematical Alphanumeric Symbols'u'Mathematical Alphanumeric Symbols'b'Sutton SignWriting'u'Sutton SignWriting'b'Glagolitic Supplement'u'Glagolitic Supplement'b'Mende Kikakui'u'Mende Kikakui'b'Adlam'u'Adlam'b'Arabic Mathematical Alphabetic Symbols'u'Arabic Mathematical Alphabetic Symbols'b'Mahjong Tiles'u'Mahjong Tiles'b'Domino Tiles'u'Domino Tiles'b'Playing Cards'u'Playing Cards'b'Enclosed Alphanumeric Supplement'u'Enclosed Alphanumeric Supplement'b'Enclosed Ideographic Supplement'u'Enclosed Ideographic Supplement'b'Miscellaneous Symbols and Pictographs'u'Miscellaneous Symbols and Pictographs'b'Emoticons range(Emoji)'u'Emoticons range(Emoji)'b'Ornamental Dingbats'u'Ornamental Dingbats'b'Transport and Map Symbols'u'Transport and Map Symbols'b'Alchemical Symbols'u'Alchemical Symbols'b'Geometric Shapes Extended'u'Geometric Shapes Extended'b'Supplemental Arrows-C'u'Supplemental Arrows-C'b'Supplemental Symbols and Pictographs'u'Supplemental Symbols and Pictographs'b'CJK Unified Ideographs Extension B'u'CJK Unified Ideographs Extension B'b'CJK Unified Ideographs Extension C'u'CJK Unified Ideographs Extension C'b'CJK Unified Ideographs Extension D'u'CJK Unified Ideographs Extension D'b'CJK Unified Ideographs Extension E'u'CJK Unified Ideographs Extension E'b'CJK Unified Ideographs Extension F'u'CJK Unified Ideographs Extension F'b'CJK Compatibility Ideographs Supplement'u'CJK Compatibility Ideographs Supplement'b'Tags'u'Tags'b'Variation Selectors Supplement'u'Variation Selectors Supplement'b'Supplement'u'Supplement'b'Extended'u'Extended'b'Extensions'u'Extensions'b'Modifier'u'Modifier'b'Marks'u'Marks'b'Punctuation'u'Punctuation'b'Symbols'u'Symbols'b'Forms'u'Forms'b'Operators'u'Operators'b'Miscellaneous'u'Miscellaneous'b'Drawing'u'Drawing'b'Block'u'Block'b'Shapes'u'Shapes'b'Supplemental'u'Supplemental'b'(?:(?:encoding)|(?:charset)|(?:coding))(?:[\:= ]{1,10})(?:[\"\']?)([a-zA-Z0-9\-_]+)(?:[\"\']?)'u'(?:(?:encoding)|(?:charset)|(?:coding))(?:[\:= ]{1,10})(?:[\"\']?)([a-zA-Z0-9\-_]+)(?:[\"\']?)'b'_codec'u'_codec'b'tactis'u'tactis'b'ISO-2022-KR'u'ISO-2022-KR'b'ISO-2022-JP'u'ISO-2022-JP'b'EUC-KR'u'EUC-KR'b'TIS-620'u'TIS-620'b'UTF-32'u'UTF-32'b'EUC-JP'u'EUC-JP'b'KOI8-R'u'KOI8-R'b'ISO-8859-1'u'ISO-8859-1'b'ISO-8859-2'u'ISO-8859-2'b'ISO-8859-5'u'ISO-8859-5'b'ISO-8859-6'u'ISO-8859-6'b'ISO-8859-7'u'ISO-8859-7'b'ISO-8859-8'u'ISO-8859-8'b'UTF-16'u'UTF-16'b'IBM855'u'IBM855'b'MacCyrillic'u'MacCyrillic'b'GB2312'u'GB2312'b'GB18030'u'GB18030'b'CP932'u'CP932'b'IBM866'u'IBM866'b'UTF-8-SIG'u'UTF-8-SIG'b'utf_8_sig'u'utf_8_sig'b'SHIFT_JIS'u'SHIFT_JIS'b'Big5'u'Big5'b'windows-1250'u'windows-1250'b'windows-1251'u'windows-1251'b'Windows-1252'u'Windows-1252'b'windows-1253'u'windows-1253'b'windows-1255'u'windows-1255'b'windows-1256'u'windows-1256'b'Windows-1254'u'Windows-1254'b'CP949'u'CP949'u'charset_normalizer.constant'u'constant'NOFALSEOFFYESTRUEONSnwNWswSWNEseSENSEWnsewNSEWCENTERbothBOTHLEFTtopTOPRIGHTbottomBOTTOMraisedsunkenSUNKENflatFLATridgeRIDGEgrooveGROOVEsolidSOLIDhorizontalHORIZONTALverticalVERTICALnumericNUMERICCHARWORDbaselineBASELINEinsideINSIDEoutsideOUTSIDEselSELsel.firstSEL_FIRSTsel.lastSEL_LASTENDINSERTCURRENTANCHORALLnormalNORMALDISABLEDactiveACTIVEhiddenHIDDENCASCADECHECKBUTTONCOMMANDRADIOBUTTONSEPARATORSINGLEbrowseBROWSEmultipleMULTIPLEEXTENDEDdotboxDOTBOXunderlineUNDERLINEpieslicePIESLICEchordCHORDARCFIRSTLASTbuttBUTTprojectingPROJECTINGROUNDbevelBEVELmiterMITERMOVETOSCROLLunitsUNITSPAGES# Symbolic constants for Tk# Booleans# -anchor and -sticky# -fill# -side# -relief# -orient# -tabs# -wrap# -align# -bordermode# Special tags, marks and insert positions# e.g. Canvas.delete(ALL)# Text widget and button states# Canvas state# Menu item types# Selection modes for list boxes# Activestyle for list boxes# NONE='none' is also valid# Various canvas styles# Arguments to xview/yviewb'nw'u'nw'b'sw'u'sw'b'ne'u'ne'b'se'u'se'b'ns'u'ns'b'ew'u'ew'b'nsew'u'nsew'b'center'u'center'b'both'u'both'b'left'b'top'u'top'b'right'b'bottom'u'bottom'b'raised'u'raised'b'sunken'u'sunken'b'flat'u'flat'b'ridge'u'ridge'b'groove'u'groove'b'solid'u'solid'b'horizontal'u'horizontal'b'vertical'u'vertical'b'numeric'u'numeric'b'baseline'u'baseline'b'inside'u'inside'b'outside'u'outside'b'sel'u'sel'b'sel.first'u'sel.first'b'sel.last'u'sel.last'b'normal'u'normal'b'disabled'u'disabled'b'active'u'active'b'hidden'u'hidden'b'browse'u'browse'b'multiple'u'multiple'b'extended'u'extended'b'dotbox'u'dotbox'b'underline'u'underline'b'pieslice'u'pieslice'b'chord'u'chord'b'first'u'first'b'butt'u'butt'b'projecting'u'projecting'b'round'u'round'b'bevel'u'bevel'b'miter'u'miter'b'units'u'units'b'pages'u'pages'u'constants'LOG_THRESHOLD_FOR_CONNLOST_WRITESACCEPT_RETRY_DELAYSSL_HANDSHAKE_TIMEOUTFALLBACK# After the connection is lost, log warnings after this many write()s.# Seconds to wait before retrying accept().# Number of stack entries to capture in debug mode.# The larger the number, the slower the operation in debug mode# (see extract_stack() in format_helpers.py).# Number of seconds to wait for SSL handshake to complete# The default timeout matches that of Nginx.# Used in sendfile fallback code.  We use fallback for platforms# that don't support sendfile, or for TLS connections.# The enum should be here to break circular dependencies between# base_events and sslprotou'asyncio.constants'email.charsetemail.errorsContentManagerget_handlersset_handlersadd_get_handlerget_contentget_content_typeget_content_maintypeadd_set_handlertypekeyset_contentmultipartset_content not valid on multipart_find_set_handlerclear_contentfull_path_for_errorraw_data_managerget_text_contentget_payloadget_paramget_non_text_contentaudio image video applicationget_message_contentrfc822 external-bodymessage/get_and_fixup_unknown_message_content_prepare_setheader_factoryHeaderDefectInvalid header: {}_finalize_setdispositioncidattachmentContent-Dispositionset_paramContent-ID_encode_base64encoded_linesunencoded_bytes_per_linethisline_encode_textembedded_bodynormal_bodysniffsniff_qpsniff_base64Unknown content transfer encoding {}set_text_contentset_payloadContent-Transfer-Encodingset_message_contentrfc822message/partial is not supported for Message objectsbinarymessage/rfc822 parts do not support cte={}external-bodymessage/external-body parts do not support cte={}set_bytes_contentistextquotetabs# XXX: is this error a good idea or not?  We can remove it later,# but we can't add it later, so do it for now.# If we don't understand a message subtype, we are supposed to treat it as# if it were application/octet-stream, per# tools.ietf.org/html/rfc2046#section-5.2.4.  Feedparser doesn't do that,# so do our best to fix things up.  Note that it is *not* appropriate to# model message/partial content as Message objects, so they are handled# here as well.  (How to reassemble them is out of scope for this comment :)# XXX: This is a cleaned-up version of base64mime.body_encode (including a bug# fix in the calculation of unencoded_bytes_per_line).  It would be nice to# drop both this and quoprimime.body_encode in favor of enhanced binascii# routines that accepted a max_line_length parameter.# Use heuristics to decide on the "best" encoding.# This is a little unfair to qp; it includes lineseps, base64 doesn't.# http://tools.ietf.org/html/rfc2046#section-5.2.1 mandate.# 8bit will get coerced on serialization if policy.cte_type='7bit'.  We# may end up claiming 8bit when it isn't needed, but the only negative# result of that should be a gateway that needs to coerce to 7bit# having to look through the whole embedded message to discover whether# or not it actually has to do anything.# http://tools.ietf.org/html/rfc2046#section-5.2.3 mandate.# http://tools.ietf.org/html/rfc2046#section-5.2.4 says all future# subtypes should be restricted to 7bit, so assume that.# XXX: quoprimime.body_encode won't encode newline characters in data,# so we can't use it.  This means max_line_length is ignored.  Another# bug to fix later.  (Note: encoders.quopri is broken on line ends.)b'multipart'u'multipart'b'set_content not valid on multipart'u'set_content not valid on multipart'b'ASCII'u'ASCII'b'audio image video application'u'audio image video application'b'rfc822 external-body'u'rfc822 external-body'b'message/'u'message/'b'Invalid header: {}'u'Invalid header: {}'b'attachment'u'attachment'b'Content-Disposition'u'Content-Disposition'b'Content-ID'u'Content-ID'b'Unknown content transfer encoding {}'u'Unknown content transfer encoding {}'b'Content-Transfer-Encoding'u'Content-Transfer-Encoding'b'rfc822'u'rfc822'b'partial'u'partial'b'message/partial is not supported for Message objects'u'message/partial is not supported for Message objects'b'binary'u'binary'b'message/rfc822 parts do not support cte={}'u'message/rfc822 parts do not support cte={}'b'external-body'u'external-body'b'message/external-body parts do not support cte={}'u'message/external-body parts do not support cte={}'u'email.contentmanager'u'contentmanager'BaseContextparent_processcpu_countReturns the number of CPUs in the systemcannot determine number of cpusReturns a manager associated with a running server process

        The managers methods such as `Lock()`, `Condition()` and `Queue()`
        can be used to create shared objects.
        managersSyncManagerget_contextReturns two connection object connected by a pipeReturns a non-recursive lock objectReturns a recursive lock objectReturns a condition objectReturns a semaphore objectBoundedSemaphoreReturns a bounded semaphore objectReturns an event objectBarrierpartiesReturns a barrier objectReturns a queue objectJoinableQueuePoolprocessesinitargsmaxtasksperchildReturns a process pool objectRawValuetypecode_or_typeReturns a shared objectsharedctypesRawArraysize_or_initializerReturns a shared arrayReturns a synchronized shared objectReturns a synchronized shared arrayfreeze_supportCheck whether this is a fake forked process in a frozen executable.
        If so then run code specified by commandline and exit.
        get_loggerReturn package logger -- if it does not already exist then
        it is created.
        log_to_stderrTurn on logging and add a handler which prints to stderrallow_connection_picklingInstall support for sending connections and sockets
        between processes
        Sets the path to a python.exe or pythonw.exe binary used to run
        child processes instead of sys.executable when using the 'spawn'
        start method.  Useful for people embedding Python.
        set_forkserver_preloadmodule_namesSet list of module names to try to load in forkserver process.
        This is really just a hint.
        forkserver_concrete_contextscannot find context for %r_check_availableget_start_methodset_start_methodcannot set start method of concrete contextreducerControls how objects will be reduced to a form that can be
        shared with other processes.BaseProcess_start_method_Popenprocess_obj_actual_contextcontext has already been setget_all_start_methodsHAVE_SEND_HANDLEForkProcesspopen_forkSpawnProcesspopen_spawn_posixForkServerProcesspopen_forkserverForkContextSpawnContextForkServerContextforkserver start method not availablepopen_spawn_win32_force_start_method_tlsget_spawning_popenspawning_popenset_spawning_popenpopenassert_spawning%s objects should only be shared between processes through inheritance'%s objects should only be shared between processes'' through inheritance'# Base type for contexts. Bound methods of an instance of this type are included in __all__ of __init__.py# This is undocumented.  In previous versions of multiprocessing# its only effect was to make socket objects inheritable on Windows.# Type of default context -- underlying context can be set at most once# Context types for fixed start method# process is spawned, nothing to do# bpo-33725: running arbitrary code after fork() is no longer reliable# on macOS since macOS 10.14 (Mojave). Use spawn by default instead.# Force the start method# Check that the current thread is spawning a child processb'Returns the number of CPUs in the system'u'Returns the number of CPUs in the system'b'cannot determine number of cpus'u'cannot determine number of cpus'b'Returns a manager associated with a running server process

        The managers methods such as `Lock()`, `Condition()` and `Queue()`
        can be used to create shared objects.
        'u'Returns a manager associated with a running server process

        The managers methods such as `Lock()`, `Condition()` and `Queue()`
        can be used to create shared objects.
        'b'Returns two connection object connected by a pipe'u'Returns two connection object connected by a pipe'b'Returns a non-recursive lock object'u'Returns a non-recursive lock object'b'Returns a recursive lock object'u'Returns a recursive lock object'b'Returns a condition object'u'Returns a condition object'b'Returns a semaphore object'u'Returns a semaphore object'b'Returns a bounded semaphore object'u'Returns a bounded semaphore object'b'Returns an event object'u'Returns an event object'b'Returns a barrier object'u'Returns a barrier object'b'Returns a queue object'u'Returns a queue object'b'Returns a process pool object'u'Returns a process pool object'b'Returns a shared object'u'Returns a shared object'b'Returns a shared array'u'Returns a shared array'b'Returns a synchronized shared object'u'Returns a synchronized shared object'b'Returns a synchronized shared array'u'Returns a synchronized shared array'b'Check whether this is a fake forked process in a frozen executable.
        If so then run code specified by commandline and exit.
        'u'Check whether this is a fake forked process in a frozen executable.
        If so then run code specified by commandline and exit.
        'b'Return package logger -- if it does not already exist then
        it is created.
        'u'Return package logger -- if it does not already exist then
        it is created.
        'b'Turn on logging and add a handler which prints to stderr'u'Turn on logging and add a handler which prints to stderr'b'Install support for sending connections and sockets
        between processes
        'u'Install support for sending connections and sockets
        between processes
        'b'Sets the path to a python.exe or pythonw.exe binary used to run
        child processes instead of sys.executable when using the 'spawn'
        start method.  Useful for people embedding Python.
        'u'Sets the path to a python.exe or pythonw.exe binary used to run
        child processes instead of sys.executable when using the 'spawn'
        start method.  Useful for people embedding Python.
        'b'Set list of module names to try to load in forkserver process.
        This is really just a hint.
        'u'Set list of module names to try to load in forkserver process.
        This is really just a hint.
        'b'cannot find context for %r'u'cannot find context for %r'b'cannot set start method of concrete context'u'cannot set start method of concrete context'b'Controls how objects will be reduced to a form that can be
        shared with other processes.'u'Controls how objects will be reduced to a form that can be
        shared with other processes.'b'reduction'u'reduction'b'context has already been set'u'context has already been set'b'spawn'u'spawn'b'forkserver'u'forkserver'b'forkserver start method not available'u'forkserver start method not available'b'spawning_popen'u'spawning_popen'b'%s objects should only be shared between processes through inheritance'u'%s objects should only be shared between processes through inheritance'Utilities for with-statement contexts.  See PEP 343.asynccontextmanagerAbstractContextManagerAbstractAsyncContextManagerAsyncExitStackContextDecoratorredirect_stdoutredirect_stderraclosingAn abstract base class for context managers.Return `self` upon entering the runtime context.Raise any exception triggered within the runtime context.An abstract base class for asynchronous context managers.__aenter____aexit__A base class or mixin that enables context managers to work as decorators._recreate_cmReturn a recreated instance of self.

        Allows an otherwise one-shot context manager like
        _GeneratorContextManager to support use as
        a decorator via implicit recreation.

        This is a private interface just for _GeneratorContextManager.
        See issue #11647 for details.
        AsyncContextDecoratorA base class or mixin that enables async context managers to work as decorators.Return a recreated instance of self.
        _GeneratorContextManagerBaseShared functionality for @contextmanager and @asynccontextmanager._GeneratorContextManagerHelper for @contextmanager decorator.generator didn't yieldgenerator didn't stopgenerator didn't stop after throw()_AsyncGeneratorContextManagerHelper for @asynccontextmanager decorator.generator didn't stop after athrow()@contextmanager decorator.

    Typical usage:

        @contextmanager
        def some_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        with some_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    helper@asynccontextmanager decorator.

    Typical usage:

        @asynccontextmanager
        async def some_async_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        async with some_async_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    Context to automatically close something at the end of a block.

    Code like this:

        with closing(<module>.open(<arguments>)) as f:
            <block>

    is equivalent to this:

        f = <module>.open(<arguments>)
        try:
            <block>
        finally:
            f.close()

    thingAsync context manager for safely finalizing an asynchronously cleaned-up
    resource such as an async generator, calling its ``aclose()`` method.

    Code like this:

        async with aclosing(<module>.fetch(<arguments>)) as agen:
            <block>

    is equivalent to this:

        agen = <module>.fetch(<arguments>)
        try:
            <block>
        finally:
            await agen.aclose()

    _RedirectStream_streamnew_target_new_target_old_targetsexctypeexcinstexctbContext manager for temporarily redirecting stdout to another file.

        # How to send help() to stderr
        with redirect_stdout(sys.stderr):
            help(dir)

        # How to write help() to a file
        with open('help.txt', 'w') as f:
            with redirect_stdout(f):
                help(pow)
    Context manager for temporarily redirecting stderr to another file.Context manager to suppress specified exceptions

    After the exception is suppressed, execution proceeds with the next
    statement following the with statement.

         with suppress(FileNotFoundError):
             os.remove(somefile)
         # Execution still resumes here if the file was already removed
    _BaseExitStackA base class for ExitStack and AsyncExitStack._create_exit_wrappercm_exit_create_cb_wrapper_exit_wrapper_exit_callbacksPreserve the context stack by transferring it to a new instance.new_stackRegisters a callback with the standard __exit__ method signature.

        Can suppress exceptions the same way __exit__ method can.
        Also accepts any object with an __exit__ method (registering a call
        to the method instead of the object itself).
        _cb_typeexit_method_push_cm_exit_push_exit_callbackenter_contextEnters the supplied context manager.

        If successful, also pushes its __exit__ method as a callback and
        returns the result of the __enter__ method.
        _cm_typeRegisters an arbitrary callback and arguments.

        Cannot suppress exceptions.
        Helper to correctly register callbacks to __exit__ methods.is_syncContext manager for dynamic management of a stack of exit callbacks.

    For example:
        with ExitStack() as stack:
            files = [stack.enter_context(open(fname)) for fname in filenames]
            # All opened files will automatically be closed at the end of
            # the with statement, even if attempts to open files later
            # in the list raise an exception.
    received_excframe_exc_fix_exception_contextnew_excold_excexc_contextsuppressed_excpending_raisenew_exc_detailsfixed_ctxImmediately unwind the context stack.Async context manager for dynamic management of a stack of exit
    callbacks.

    For example:
        async with AsyncExitStack() as stack:
            connections = [await stack.enter_async_context(get_connection())
                for i in range(5)]
            # All opened connections will automatically be released at the
            # end of the async with statement, even if attempts to open a
            # connection later in the list raise an exception.
    _create_async_exit_wrapper_create_async_cb_wrapperenter_async_contextEnters the supplied async context manager.

        If successful, also pushes its __aexit__ method as a callback and
        returns the result of the __aenter__ method.
        _push_async_cm_exitpush_async_exitRegisters a coroutine function with the standard __aexit__ method
        signature.

        Can suppress exceptions the same way __aexit__ method can.
        Also accepts any object with an __aexit__ method (registering a call
        to the method instead of the object itself).
        push_async_callbackRegisters an arbitrary coroutine function and arguments.

        Cannot suppress exceptions.
        Helper to correctly register coroutine function to __aexit__
        method.cb_suppressContext manager that does no additional processing.

    Used as a stand-in for a normal context manager, when a particular
    block of code is only sometimes used with a normal context manager:

    cm = optional_cm if condition else nullcontext()
    with cm:
        # Perform operation, using optional_cm if condition is True
    enter_resultexcinfo# Issue 19330: ensure context manager instances have good docstrings# Unfortunately, this still doesn't provide good help output when# inspecting the created context manager instances, since pydoc# currently bypasses the instance docstring and shows the docstring# for the class instead.# See http://bugs.python.org/issue19404 for more details.# _GCMB instances are one-shot context managers, so the# CM must be recreated each time a decorated function is# called# do not keep args and kwds alive unnecessarily# they are only needed for recreation, which is not possible anymore# Need to force instantiation so we can reliably# tell if we get the same exception back# Suppress StopIteration *unless* it's the same exception that# was passed to throw().  This prevents a StopIteration# raised inside the "with" statement from being suppressed.# Don't re-raise the passed in exception. (issue27122)# Avoid suppressing if a StopIteration exception# was passed to throw() and later wrapped into a RuntimeError# (see PEP 479 for sync generators; async generators also# have this behavior). But do this only if the exception wrapped# by the RuntimeError is actually Stop(Async)Iteration (see# issue29692).# only re-raise if it's *not* the exception that was# passed to throw(), because __exit__() must not raise# an exception unless __exit__() itself failed.  But throw()# has to raise the exception to signal propagation, so this# fixes the impedance mismatch between the throw() protocol# and the __exit__() protocol.# Avoid suppressing if a Stop(Async)Iteration exception# was passed to athrow() and later wrapped into a RuntimeError# by the RuntimeError is actully Stop(Async)Iteration (see# We use a list of old targets to make this CM re-entrant# Unlike isinstance and issubclass, CPython exception handling# currently only looks at the concrete type hierarchy (ignoring# the instance and subclass checking hooks). While Guido considers# that a bug rather than a feature, it's a fairly hard one to fix# due to various internal implementation details. suppress provides# the simpler issubclass based semantics, rather than trying to# exactly reproduce the limitations of the CPython interpreter.# See http://bugs.python.org/issue12029 for more details# We use an unbound method rather than a bound method to follow# the standard lookup behaviour for special methods.# Not a context manager, so assume it's a callable.# Allow use as a decorator.# We look up the special methods on the type to match the with# statement.# We changed the signature, so using @wraps is not appropriate, but# setting __wrapped__ may still help with introspection.# Allow use as a decorator# Inspired by discussions on http://bugs.python.org/issue13585# We manipulate the exception state so it behaves as though# we were actually nesting multiple with statements# Context may not be correct, so find the end of the chain# Context is already set correctly (see issue 20317)# Change the end of the chain to point to the exception# we expect it to reference# Callbacks are invoked in LIFO order to match the behaviour of# nested context managers# simulate the stack of exceptions by setting the context# bare "raise exc_details[1]" replaces our carefully# set-up context# Inspired by discussions on https://bugs.python.org/issue29302# Not an async context manager, so assume it's a coroutine functionb'Utilities for with-statement contexts.  See PEP 343.'u'Utilities for with-statement contexts.  See PEP 343.'b'asynccontextmanager'u'asynccontextmanager'b'contextmanager'u'contextmanager'b'closing'u'closing'b'nullcontext'u'nullcontext'b'AbstractContextManager'u'AbstractContextManager'b'AbstractAsyncContextManager'u'AbstractAsyncContextManager'b'AsyncExitStack'u'AsyncExitStack'b'ContextDecorator'u'ContextDecorator'b'ExitStack'u'ExitStack'b'redirect_stdout'u'redirect_stdout'b'redirect_stderr'u'redirect_stderr'b'suppress'u'suppress'b'aclosing'u'aclosing'b'An abstract base class for context managers.'u'An abstract base class for context managers.'b'Return `self` upon entering the runtime context.'u'Return `self` upon entering the runtime context.'b'Raise any exception triggered within the runtime context.'u'Raise any exception triggered within the runtime context.'b'__enter__'u'__enter__'b'__exit__'u'__exit__'b'An abstract base class for asynchronous context managers.'u'An abstract base class for asynchronous context managers.'b'__aenter__'u'__aenter__'b'__aexit__'u'__aexit__'b'A base class or mixin that enables context managers to work as decorators.'u'A base class or mixin that enables context managers to work as decorators.'b'Return a recreated instance of self.

        Allows an otherwise one-shot context manager like
        _GeneratorContextManager to support use as
        a decorator via implicit recreation.

        This is a private interface just for _GeneratorContextManager.
        See issue #11647 for details.
        'u'Return a recreated instance of self.

        Allows an otherwise one-shot context manager like
        _GeneratorContextManager to support use as
        a decorator via implicit recreation.

        This is a private interface just for _GeneratorContextManager.
        See issue #11647 for details.
        'b'A base class or mixin that enables async context managers to work as decorators.'u'A base class or mixin that enables async context managers to work as decorators.'b'Return a recreated instance of self.
        'u'Return a recreated instance of self.
        'b'Shared functionality for @contextmanager and @asynccontextmanager.'u'Shared functionality for @contextmanager and @asynccontextmanager.'b'Helper for @contextmanager decorator.'u'Helper for @contextmanager decorator.'b'generator didn't yield'u'generator didn't yield'b'generator didn't stop'u'generator didn't stop'b'generator didn't stop after throw()'u'generator didn't stop after throw()'b'Helper for @asynccontextmanager decorator.'u'Helper for @asynccontextmanager decorator.'b'generator didn't stop after athrow()'u'generator didn't stop after athrow()'b'@contextmanager decorator.

    Typical usage:

        @contextmanager
        def some_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        with some_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    'u'@contextmanager decorator.

    Typical usage:

        @contextmanager
        def some_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        with some_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    'b'@asynccontextmanager decorator.

    Typical usage:

        @asynccontextmanager
        async def some_async_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        async with some_async_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    'u'@asynccontextmanager decorator.

    Typical usage:

        @asynccontextmanager
        async def some_async_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        async with some_async_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>
    'b'Context to automatically close something at the end of a block.

    Code like this:

        with closing(<module>.open(<arguments>)) as f:
            <block>

    is equivalent to this:

        f = <module>.open(<arguments>)
        try:
            <block>
        finally:
            f.close()

    'u'Context to automatically close something at the end of a block.

    Code like this:

        with closing(<module>.open(<arguments>)) as f:
            <block>

    is equivalent to this:

        f = <module>.open(<arguments>)
        try:
            <block>
        finally:
            f.close()

    'b'Async context manager for safely finalizing an asynchronously cleaned-up
    resource such as an async generator, calling its ``aclose()`` method.

    Code like this:

        async with aclosing(<module>.fetch(<arguments>)) as agen:
            <block>

    is equivalent to this:

        agen = <module>.fetch(<arguments>)
        try:
            <block>
        finally:
            await agen.aclose()

    'u'Async context manager for safely finalizing an asynchronously cleaned-up
    resource such as an async generator, calling its ``aclose()`` method.

    Code like this:

        async with aclosing(<module>.fetch(<arguments>)) as agen:
            <block>

    is equivalent to this:

        agen = <module>.fetch(<arguments>)
        try:
            <block>
        finally:
            await agen.aclose()

    'b'Context manager for temporarily redirecting stdout to another file.

        # How to send help() to stderr
        with redirect_stdout(sys.stderr):
            help(dir)

        # How to write help() to a file
        with open('help.txt', 'w') as f:
            with redirect_stdout(f):
                help(pow)
    'u'Context manager for temporarily redirecting stdout to another file.

        # How to send help() to stderr
        with redirect_stdout(sys.stderr):
            help(dir)

        # How to write help() to a file
        with open('help.txt', 'w') as f:
            with redirect_stdout(f):
                help(pow)
    'b'Context manager for temporarily redirecting stderr to another file.'u'Context manager for temporarily redirecting stderr to another file.'b'Context manager to suppress specified exceptions

    After the exception is suppressed, execution proceeds with the next
    statement following the with statement.

         with suppress(FileNotFoundError):
             os.remove(somefile)
         # Execution still resumes here if the file was already removed
    'u'Context manager to suppress specified exceptions

    After the exception is suppressed, execution proceeds with the next
    statement following the with statement.

         with suppress(FileNotFoundError):
             os.remove(somefile)
         # Execution still resumes here if the file was already removed
    'b'A base class for ExitStack and AsyncExitStack.'u'A base class for ExitStack and AsyncExitStack.'b'Preserve the context stack by transferring it to a new instance.'u'Preserve the context stack by transferring it to a new instance.'b'Registers a callback with the standard __exit__ method signature.

        Can suppress exceptions the same way __exit__ method can.
        Also accepts any object with an __exit__ method (registering a call
        to the method instead of the object itself).
        'u'Registers a callback with the standard __exit__ method signature.

        Can suppress exceptions the same way __exit__ method can.
        Also accepts any object with an __exit__ method (registering a call
        to the method instead of the object itself).
        'b'Enters the supplied context manager.

        If successful, also pushes its __exit__ method as a callback and
        returns the result of the __enter__ method.
        'u'Enters the supplied context manager.

        If successful, also pushes its __exit__ method as a callback and
        returns the result of the __enter__ method.
        'b'Registers an arbitrary callback and arguments.

        Cannot suppress exceptions.
        'u'Registers an arbitrary callback and arguments.

        Cannot suppress exceptions.
        'b'Helper to correctly register callbacks to __exit__ methods.'u'Helper to correctly register callbacks to __exit__ methods.'b'Context manager for dynamic management of a stack of exit callbacks.

    For example:
        with ExitStack() as stack:
            files = [stack.enter_context(open(fname)) for fname in filenames]
            # All opened files will automatically be closed at the end of
            # the with statement, even if attempts to open files later
            # in the list raise an exception.
    'u'Context manager for dynamic management of a stack of exit callbacks.

    For example:
        with ExitStack() as stack:
            files = [stack.enter_context(open(fname)) for fname in filenames]
            # All opened files will automatically be closed at the end of
            # the with statement, even if attempts to open files later
            # in the list raise an exception.
    'b'Immediately unwind the context stack.'u'Immediately unwind the context stack.'b'Async context manager for dynamic management of a stack of exit
    callbacks.

    For example:
        async with AsyncExitStack() as stack:
            connections = [await stack.enter_async_context(get_connection())
                for i in range(5)]
            # All opened connections will automatically be released at the
            # end of the async with statement, even if attempts to open a
            # connection later in the list raise an exception.
    'u'Async context manager for dynamic management of a stack of exit
    callbacks.

    For example:
        async with AsyncExitStack() as stack:
            connections = [await stack.enter_async_context(get_connection())
                for i in range(5)]
            # All opened connections will automatically be released at the
            # end of the async with statement, even if attempts to open a
            # connection later in the list raise an exception.
    'b'Enters the supplied async context manager.

        If successful, also pushes its __aexit__ method as a callback and
        returns the result of the __aenter__ method.
        'u'Enters the supplied async context manager.

        If successful, also pushes its __aexit__ method as a callback and
        returns the result of the __aenter__ method.
        'b'Registers a coroutine function with the standard __aexit__ method
        signature.

        Can suppress exceptions the same way __aexit__ method can.
        Also accepts any object with an __aexit__ method (registering a call
        to the method instead of the object itself).
        'u'Registers a coroutine function with the standard __aexit__ method
        signature.

        Can suppress exceptions the same way __aexit__ method can.
        Also accepts any object with an __aexit__ method (registering a call
        to the method instead of the object itself).
        'b'Registers an arbitrary coroutine function and arguments.

        Cannot suppress exceptions.
        'u'Registers an arbitrary coroutine function and arguments.

        Cannot suppress exceptions.
        'b'Helper to correctly register coroutine function to __aexit__
        method.'u'Helper to correctly register coroutine function to __aexit__
        method.'b'Context manager that does no additional processing.

    Used as a stand-in for a normal context manager, when a particular
    block of code is only sometimes used with a normal context manager:

    cm = optional_cm if condition else nullcontext()
    with cm:
        # Perform operation, using optional_cm if condition is True
    'u'Context manager that does no additional processing.

    Used as a stand-in for a normal context manager, when a particular
    block of code is only sometimes used with a normal context manager:

    cm = optional_cm if condition else nullcontext()
    with cm:
        # Perform operation, using optional_cm if condition is True
    'u'contextlib'b'ContextVar'u'ContextVar'b'Token'u'Token'b'copy_context'u'copy_context'u'contextvars'HTTP cookie handling for web clients.

This module has (now fairly distant) origins in Gisle Aas' Perl module
HTTP::Cookies, from the libwww-perl library.

Docstrings, comments and debug strings in this code refer to the
attributes of the HTTP cookie system as cookie-attributes, to distinguish
them clearly from Python attributes.

Class diagram (note that BSDDBCookieJar and the MSIE* classes are not
distributed with the Python standard library, but are available from
http://wwwsearch.sf.net/):

                        CookieJar____
                        /     \      \
            FileCookieJar      \      \
             /    |   \         \      \
 MozillaCookieJar | LWPCookieJar \      \
                  |               |      \
                  |   ---MSIEBase |       \
                  |  /      |     |        \
                  | /   MSIEDBCookieJar BSDDBCookieJar
                  |/
               MSIECookieJar

CookieJarCookiePolicyDefaultCookiePolicyFileCookieJarLWPCookieJarLoadErrorMozillaCookieJar_threadingHTTPOnlyHTTPONLY_ATTR#HttpOnly_HTTPONLY_PREFIXDEFAULT_HTTP_PORT#( Netscape)? HTTP Cookie FileNETSCAPE_MAGIC_RGXa filename was not supplied (nor was the CookieJar instance initialised with one)"a filename was not supplied (nor was the CookieJar ""instance initialised with one)"MISSING_FILENAME_TEXT# Netscape HTTP Cookie File
# http://curl.haxx.se/rfc/cookie_spec.html
# This is a generated file!  Do not edit.

NETSCAPE_HEADER_TEXT_warn_unhandled_exceptionhttp.cookiejar bug!
%sEPOCH_YEAR_timegmttmdaysecDAYSMONTHS_LOWERtime2isozReturn a string representing time in seconds since epoch, t.

    If the function is called without an argument, it will use the current
    time.

    The format of the returned string is like "YYYY-MM-DD hh:mm:ssZ",
    representing Universal Time (UTC, aka GMT).  An example of this format is:

    1994-11-24 08:49:37Z

    %04d-%02d-%02d %02d:%02d:%02dZtime2netscapeReturn a string representing time in seconds since epoch, t.

    If the function is called without an argument, it will use the current
    time.

    The format of the returned string is like this:

    Wed, DD-Mon-YYYY HH:MM:SS GMT

    %s, %02d-%s-%04d %02d:%02d:%02d GMTUTC_ZONES^([-+])?(\d\d?):?(\d\d)?$TIMEZONE_REoffset_from_tz_string_str2timeyrimoncur_yr^[SMTWF][a-z][a-z], (\d\d) ([JFMASOND][a-z][a-z]) (\d\d\d\d) (\d\d):(\d\d):(\d\d) GMT$r"^[SMTWF][a-z][a-z], (\d\d) ([JFMASOND][a-z][a-z]) "r"(\d\d\d\d) (\d\d):(\d\d):(\d\d) GMT$"STRICT_DATE_RE^(?:Sun|Mon|Tue|Wed|Thu|Fri|Sat)[a-z]*,?\s*WEEKDAY_RE^
    (\d\d?)            # day
       (?:\s+|[-\/])
    (\w+)              # month
        (?:\s+|[-\/])
    (\d+)              # year
    (?:
          (?:\s+|:)    # separator before clock
       (\d\d?):(\d\d)  # hour:min
       (?::(\d\d))?    # optional seconds
    )?                 # optional clock
       \s*
    (?:
       ([-+]?\d{2,4}|(?![APap][Mm]\b)[A-Za-z]+) # timezone
       \s*
    )?
    (?:
       \(\w+\)         # ASCII representation of timezone in parens.
       \s*
    )?$LOOSE_HTTP_DATE_REhttp2timeReturns time in seconds since epoch of time represented by a string.

    Return value is an integer.

    None is returned if the format of str is unrecognized, the time is outside
    the representable range, or the timezone string is not recognized.  If the
    string contains no timezone, UTC is assumed.

    The timezone in the string may be numerical (like "-0800" or "+0100") or a
    string timezone (like "UTC", "GMT", "BST" or "EST").  Currently, only the
    timezone strings equivalent to UTC (zero offset) are known to the function.

    The function loosely parses the following formats:

    Wed, 09 Feb 1994 22:23:32 GMT       -- HTTP format
    Tuesday, 08-Feb-94 14:15:29 GMT     -- old rfc850 HTTP format
    Tuesday, 08-Feb-1994 14:15:29 GMT   -- broken rfc850 HTTP format
    09 Feb 1994 22:23:32 GMT            -- HTTP format (no weekday)
    08-Feb-94 14:15:29 GMT              -- rfc850 format (no weekday)
    08-Feb-1994 14:15:29 GMT            -- broken rfc850 format (no weekday)

    The parser ignores leading and trailing whitespace.  The time may be
    absent.

    If the year is given with only 2 digits, the function will select the
    century that makes the year closest to the current date.

    ^
    (\d{4})              # year
       [-\/]?
    (\d\d?)              # numerical month
       [-\/]?
    (\d\d?)              # day
   (?:
         (?:\s+|[-:Tt])  # separator before clock
      (\d\d?):?(\d\d)    # hour:min
      (?::?(\d\d(?:\.\d*)?))?  # optional seconds (and fractional)
   )?                    # optional clock
      \s*
   (?:
      ([-+]?\d\d?:?(:?\d\d)?
       |Z|z)             # timezone  (Z is "zero meridian", i.e. GMT)
      \s*
   )?$ISO_DATE_REiso2time
    As for http2time, but parses the ISO 8601 formats:

    1994-02-03 14:15:29 -0100    -- ISO 8601 format
    1994-02-03 14:15:29          -- zone is optional
    1994-02-03                   -- only date
    1994-02-03T14:15:29          -- Use T as separator
    19940203T141529Z             -- ISO 8601 compact format
    19940203                     -- only date

    unmatchedReturn unmatched part of re.Match object.span^\s*([^=\s;,]+)HEADER_TOKEN_RE^\s*=\s*\"([^\"\\]*(?:\\.[^\"\\]*)*)\"HEADER_QUOTED_VALUE_RE^\s*=\s*([^\s;,]*)HEADER_VALUE_RE\\(.)HEADER_ESCAPE_REsplit_header_wordsheader_valuesParse header values into a list of lists containing key,value pairs.

    The function knows how to deal with ",", ";" and "=" as well as quoted
    values after "=".  A list of space separated tokens are parsed as if they
    were separated by ";".

    If the header_values passed as argument contains multiple values, then they
    are treated as if they were a single value separated by comma ",".

    This means that this function is useful for parsing header fields that
    follow this syntax (BNF as from the HTTP/1.1 specification, but we relax
    the requirement for tokens).

      headers           = #header
      header            = (token | parameter) *( [";"] (token | parameter))

      token             = 1*<any CHAR except CTLs or separators>
      separators        = "(" | ")" | "<" | ">" | "@"
                        | "," | ";" | ":" | "\" | <">
                        | "/" | "[" | "]" | "?" | "="
                        | "{" | "}" | SP | HT

      quoted-string     = ( <"> *(qdtext | quoted-pair ) <"> )
      qdtext            = <any TEXT except <">>
      quoted-pair       = "\" CHAR

      parameter         = attribute "=" value
      attribute         = token
      value             = token | quoted-string

    Each header is represented by a list of key/value pairs.  The value for a
    simple token (not part of a parameter) is None.  Syntactically incorrect
    headers will not necessarily be parsed as you would want.

    This is easier to describe with some examples:

    >>> split_header_words(['foo="bar"; port="80,81"; discard, bar=baz'])
    [[('foo', 'bar'), ('port', '80,81'), ('discard', None)], [('bar', 'baz')]]
    >>> split_header_words(['text/html; charset="iso-8859-1"'])
    [[('text/html', None), ('charset', 'iso-8859-1')]]
    >>> split_header_words([r'Basic realm="\"foo\bar\""'])
    [[('Basic', None), ('realm', '"foobar"')]]

    orig_textsubn^[=\s;]*non_junknr_junk_charssplit_header_words bug: '%s', '%s', %s([\"\\])HEADER_JOIN_ESCAPE_REjoin_header_wordsDo the inverse (almost) of the conversion done by split_header_words.

    Takes a list of lists of (key, value) pairs and produces a single header
    value.  Attribute values are quoted if needed.

    >>> join_header_words([[("text/plain", None), ("charset", "iso-8859-1")]])
    'text/plain; charset="iso-8859-1"'
    >>> join_header_words([[("text/plain", None)], [("charset", "iso-8859-1")]])
    'text/plain, charset="iso-8859-1"'

    ^\w+$strip_quotesparse_ns_headersns_headersAd-hoc parser for Netscape protocol cookie-attributes.

    The old Netscape cookie format for Set-Cookie can for instance contain
    an unquoted "," in the expires field, so we have to use this ad-hoc
    parser instead of split_header_words.

    XXX This may not make the best possible effort to parse all the crap
    that Netscape Cookie headers contain.  Ronald Tschalar's HTTPClient
    parser is probably better, so could do worse than following that if
    this ever gives any trouble.

    Currently, this is also used for parsing RFC 2109 cookies.

    securemax-ageknown_attrsns_headerversion_setlc\.\d+$is_HDNReturn True if text is a host domain name.domain_matchReturn True if domain A domain-matches domain B, according to RFC 2965.

    A and B may be host domain names or IP addresses.

    RFC 2965, section 1:

    Host names can be specified either as an IP address or a HDN string.
    Sometimes we compare one host name with another.  (Such comparisons SHALL
    be case-insensitive.)  Host A's name domain-matches host B's if

         *  their host name strings string-compare equal; or

         * A is a HDN string and has the form NB, where N is a non-empty
            name string, B has the form .B', and B' is a HDN string.  (So,
            x.y.com domain-matches .Y.com but not Y.com.)

    Note that domain-match is not a commutative operation: a.b.c.com
    domain-matches .c.com, but not the reverse.

    liberal_is_HDNReturn True if text is a sort-of-like a host domain name.

    For accepting/blocking domains.

    user_domain_matchFor blocking/accepting domains.

    A and B may be host domain names or IP addresses.

    initial_dot:\d+$cut_port_rerequest_hostReturn request-host, as defined by RFC 2965.

    Variation from RFC: returned value is lowercased, for convenient
    comparison.

    get_full_urlget_headereff_request_hostReturn a tuple (request-host, effective request-host name).

    As defined by RFC 2965, except both are lowercased.

    erhnreq_host.localrequest_pathPath component of request-URI, as defined by RFC 2965.escape_pathrequest_port%/;:@&=+$,!~*'()HTTP_PATH_SAFE%([0-9a-fA-F][0-9a-fA-F])ESCAPED_CHAR_REuppercase_escaped_char%%%sEscape any invalid characters in HTTP URL, and uppercase all escapes.reachReturn reach of host h, as defined by RFC 2965, section 1.

    The reach R of a host name H is defined as follows:

       *  If

          -  H is the host domain name of a host; and,

          -  H has the form A.B; and

          -  A has no embedded (that is, interior) dots; and

          -  B has at least one embedded dot, or B is the string "local".
             then the reach of H is .B.

       *  Otherwise, the reach of H is H.

    >>> reach("www.acme.com")
    '.acme.com'
    >>> reach("acme.com")
    'acme.com'
    >>> reach("acme.local")
    '.local'

    is_third_party

    RFC 2965, section 3.3.6:

        An unverifiable transaction is to a third-party host if its request-
        host U does not domain-match the reach R of the request-host O in the
        origin transaction.

    origin_req_hostHTTP Cookie.

    This class represents both Netscape and RFC 2965 cookies.

    This is deliberately a very simple class.  It just holds attributes.  It's
    possible to construct Cookie instances that don't comply with the cookie
    standards.  CookieJar.make_cookies is the factory function for Cookie
    objects -- it deals with cookie parsing, supplying defaults, and
    normalising to the representation used in this class.  CookiePolicy is
    responsible for checking them to see whether they should be accepted from
    and returned to the server.

    Note that the port may be present in the headers, but unspecified ("Port"
    rather than"Port=80", for example); if this is the case, port is None.

    port_specifieddomain_specifieddomain_initial_dotpath_specifiedcomment_urlrfc2109if port is None, port_specified must be false_resthas_nonstandard_attrget_nonstandard_attrset_nonstandard_attris_expirednamevalue<Cookie %s for %s>rest=%srfc2109=%sDefines which cookies get accepted from and returned to server.

    May also modify cookies, though this is probably a bad idea.

    The subclass DefaultCookiePolicy defines the standard rules for Netscape
    and RFC 2965 cookies -- override that if you want a customized policy.

    set_okcookieReturn true if (and only if) cookie should be accepted from server.

        Currently, pre-expired cookies never get this far -- the CookieJar
        class deletes such cookies itself.

        return_okReturn true if (and only if) cookie should be returned to server.domain_return_okReturn false if cookies should not be returned, given cookie domain.
        path_return_okReturn false if cookies should not be returned, given cookie path.
        Implements the standard rules for accepting and returning cookies.DomainStrictNoDotsDomainStrictNonDomainDomainRFC2965MatchDomainLiberalDomainStrictwssblocked_domainsallowed_domainsnetscaperfc2965rfc2109_as_netscapehide_cookie2strict_domainstrict_rfc2965_unverifiablestrict_ns_unverifiablestrict_ns_domainstrict_ns_set_initial_dollarstrict_ns_set_pathsecure_protocolsConstructor arguments should be passed as keyword arguments only._blocked_domains_allowed_domainsReturn the sequence of blocked domains (as a tuple).set_blocked_domainsSet the sequence of blocked domains.is_blockedblocked_domainReturn None, or the sequence of allowed domains (as a tuple).set_allowed_domainsSet the sequence of allowed domains, or None.is_not_allowedallowed_domain
        If you override .set_ok(), be sure to call this method.  If it returns
        false, so should your subclass (assuming your subclass wants to be more
        strict about which cookies to accept).

         - checking cookie %s=%sverifiabilityset_ok_fn_nameset_ok_version   Set-Cookie2 without version attribute (%s=%s)   RFC 2965 cookies are switched off   Netscape cookies are switched offset_ok_verifiabilityunverifiable   third-party RFC 2965 cookie during unverifiable transaction"   third-party RFC 2965 cookie during ""unverifiable transaction"   third-party Netscape cookie during unverifiable transaction"   third-party Netscape cookie during "set_ok_name   illegal name (starts with '$'): '%s'set_ok_pathreq_path   path attribute %s is not a prefix of request path %s"   path attribute %s is not a prefix of request ""path %s"set_ok_domain   domain %s is in user block-list   domain %s is not in user allow-listtldsldaccomeduorgnetgovmilaerobizcatcoopjobsmobimuseumtraveleu   country-code second level domain %sundotted_domainembedded_dots   non-local domain %s contains no embedded dot   effective request-host %s (even with added initial dot) does not end with %s"   effective request-host %s (even with added ""initial dot) does not end with %s"   effective request-host %s does not domain-match %s"   effective request-host %s does not domain-match "   host prefix %s for domain %s contains a dotset_ok_portreq_port   bad port %s (not numeric)   request port (%s) not found in %s
        If you override .return_ok(), be sure to call this method.  If it
        returns false, so should your subclass (assuming your subclass wants to
        be more strict about which cookies to return).

        return_ok_return_ok_versionreturn_ok_verifiability"   third-party RFC 2965 cookie during unverifiable ""transaction""   third-party Netscape cookie during unverifiable "return_ok_secure   secure cookie with non-secure requestreturn_ok_expires_now   cookie expiredreturn_ok_port   request port %s does not match cookie port %sreturn_ok_domaindotdomain   cookie with unspecified domain does not string-compare equal to request domain"   cookie with unspecified domain does not string-compare ""equal to request domain"   effective request-host name %s does not domain-match RFC 2965 cookie domain %s"   effective request-host name %s does not domain-match ""RFC 2965 cookie domain %s"   request-host %s does not match Netscape cookie domain %s"   request-host %s does not match Netscape cookie domain "- checking cookie path=%spathlen  %s does not path-match %svals_sorted_by_keyadictdeepvaluesIterates over nested mapping, depth-first, in sorted order by key.AbsentCollection of HTTP cookies.

    You may not need to know about this class: try
    urllib.request.build_opener(HTTPCookieProcessor).open(url).
    \Wnon_word_requote_re\.?[^.]*strict_domain_re[^.]*domain_re^\.+dots_re^\#LWP-Cookies-(\d+\.\d+)magic_re_policy_cookies_lockset_policy_cookies_for_domainChecking %s for cookies to returncookies_by_pathcookies_by_name   not returning cookie   it's a match_cookies_for_requestReturn a list of cookies to be returned to server._cookie_attrsReturn a list of cookie-attributes to be returned to server.

        like ['foo="bar"; $Path="/"', ...]

        The $Version attribute is also added when appropriate (currently only
        once per request).

        $Version=%s$Path="%s"$Domain="%s"$Port="%s"add_cookie_headerAdd correct Cookie: header to request (urllib.request.Request object).

        The Cookie2 header is also added unless policy.hide_cookie2 is true.

        has_headeradd_unredirected_headerCookie2$Version="1"clear_expired_cookies_normalized_cookie_tuplesattrs_setReturn list of tuples containing normalised cookie information.

        attrs_set is the list of lists of key,value pairs extracted from
        the Set-Cookie or Set-Cookie2 headers.

        Tuples are name, value, standard, rest, where name and value are the
        cookie name and value, standard is a dictionary containing the standard
        cookie-attributes (discard, secure, version, expires or max-age,
        domain, path and port) and rest is a dictionary containing the rest of
        the cookie-attributes.

        cookie_tuplesboolean_attrscommenturlvalue_attrscookie_attrsmax_age_setbad_cookie   missing value for domain attribute   missing or invalid value for expires attribute: treating as session cookie"   missing or invalid value for expires ""attribute: treating as session cookie"   missing or invalid (non-numeric) value for max-age attribute"   missing or invalid (non-numeric) value for ""max-age attribute"   missing value for %s attribute_cookie_from_cookie_tupleExpiring cookie, domain='%s', path='%s', name='%s'_cookies_from_attrs_set_process_rfc2109_cookiesrfc2109_as_nsmake_cookiesReturn sequence of Cookie objects extracted from response object.Set-Cookie2rfc2965_hdrsSet-Cookiens_hdrsns_cookiesno_matching_rfc2965ns_cookieset_cookie_if_okSet a cookie if policy says it's OK to do so.set_cookieSet a cookie, without checking whether or not it should be set.c3extract_cookiesExtract cookies from response, where allowable given the request.extract_cookies: %s setting cookie: %sClear some cookies.

        Invoking this method without arguments will clear all cookies.  If
        given a single argument, only cookies belonging to that domain will be
        removed.  If given two arguments, cookies belonging to the specified
        path within that domain are removed.  If given three arguments, then
        the cookie with the specified name, path and domain is removed.

        Raises KeyError if no matching cookie exists.

        domain and path must be given to remove a cookie by namedomain must be given to remove cookies by pathclear_session_cookiesDiscard all session cookies.

        Note that the .save() method won't save session cookies anyway, unless
        you ask otherwise by passing a true ignore_discard argument.

        Discard all expired cookies.

        You probably don't need to call this method: expired cookies are never
        sent back to the server (provided you're using DefaultCookiePolicy),
        this method is called by CookieJar itself every so often, and the
        .save() method won't save expired cookies anyway (unless you ask
        otherwise by passing a true ignore_expires argument).

        Return number of contained cookies.<%s[%s]>CookieJar that can be loaded from and saved to a file.delayload
        Cookies are NOT loaded from the named file until either the .load() or
        .revert() method is called.

        ignore_discardignore_expiresSave cookies to a file.Load cookies from a file._really_loadrevertClear all cookies and reload cookies from a saved file.

        Raises LoadError (or OSError) if reversion is not successful; the
        object's state will not be altered if this happens.

        old_statelwp_cookie_strReturn string representation of Cookie in the LWP cookie file format.

    Actually, the format is extended a bit -- see module docstring.

    path_specport_specdomain_dot
    The LWPCookieJar saves a sequence of "Set-Cookie3" lines.
    "Set-Cookie3" is the format used by the libwww-perl library, not known
    to be compatible with any browser, but which is easy to read and
    doesn't lose information about RFC 2965 cookies.

    Additional methods

    as_lwp_str(ignore_discard=True, ignore_expired=True)

    as_lwp_strReturn cookies as a string of "\n"-separated "Set-Cookie3" headers.

        ignore_discard and ignore_expires: see docstring for FileCookieJar.save

        Set-Cookie3: %s#LWP-Cookies-2.0
%r does not look like a Set-Cookie3 (LWP) format file"%r does not look like a Set-Cookie3 (LWP) format ""file"Set-Cookie3:invalid Set-Cookie3 format file %r: %r

    WARNING: you may want to backup your browser's cookies file if you use
    this class to save cookies.  I *think* it works, but there have been
    bugs in the past!

    This class differs from CookieJar only in the format it uses to save and
    load cookies to and from a file.  This class uses the Mozilla/Netscape
    `cookies.txt' format.  curl and lynx use this file format, too.

    Don't expect cookies saved while the browser is running to be noticed by
    the browser (in fact, Mozilla on unix will overwrite your saved cookies if
    you change them on disk while it's running; on Windows, you probably can't
    save at all while the browser is running).

    Note that the Mozilla/Netscape format will downgrade RFC2965 cookies to
    Netscape cookies on saving.

    In particular, the cookie version and port number information is lost,
    together with information about whether or not Path, Port and Discard were
    specified by the Set-Cookie2 (or Set-Cookie) header, and whether or not the
    domain as set in the HTTP header started with a dot (yes, I'm aware some
    domains in Netscape files start with a dot and some don't -- trust me, you
    really don't want to know any more about this).

    Note that though Mozilla and Netscape use the same format, they use
    slightly different headers.  The class saves cookies using the Netscape
    header by default (Mozilla can cope with that).

    %r does not look like a Netscape format cookies fileinvalid Netscape format cookies file %r: %r# only for the default HTTP port# set to True to enable debugging via the logging module# There are a few catch-all except: statements in this module, for# catching input that's bad in unexpected ways.  Warn if any# exceptions are caught there.# Date/time conversion# -----------------------------------------------------------------------------# translate month name to number# month numbers start with 1 (January)# maybe it's already a number# make sure clock elements are defined# find "obvious" year# convert UTC time tuple to seconds since epoch (not timezone-adjusted)# adjust time using timezone string, to get absolute time since epoch# fast exit for strictly conforming string# No, we need some messy parsing...# Useless weekday# tz is time zone specifier string# loose regexp parse# bad format# XXX there's an extra bit of the timezone I'm ignoring here: is#   this the right thing to do?# Header parsing# quoted value# unquoted value# no value, a lone token# concatenated headers, as per RFC 2616 section 4.2# skip junk# escape " and \# RFC 2109 attrs (may turn up in Netscape cookies, too)# XXX: The following does not strictly adhere to RFCs in that empty# names and values are legal (the former will only appear once and will# be overwritten if multiple occurrences are present). This is# mostly to deal with backwards compatibility.# allow for a distinction between present and empty and missing# altogether# This is an RFC 2109 cookie.# convert expires date to seconds since epoch# None if invalid# XXX# This may well be wrong.  Which RFC is HDN defined in, if any (for#  the purposes of RFC 2965)?# For the current implementation, what about IPv6?  Remember to look#  at other uses of IPV4_RE also, if change this.# Note that, if A or B are IP addresses, the only relevant part of the# definition of the domain-match algorithm is the direct string-compare.# A does not have form NB, or N is the empty string# equal IP addresses# remove port, if present# fix bad RFC 2396 absoluteURI# Characters in addition to A-Z, a-z, 0-9, '_', '.', and '-' that don't# need to be escaped to form a valid HTTP URL (RFCs 2396 and 1738).# There's no knowing what character encoding was used to create URLs# containing %-escapes, but since we have to pick one to escape invalid# path characters, we pick UTF-8, as recommended in the HTML 4.0# specification:# http://www.w3.org/TR/REC-html40/appendix/notes.html#h-B.2.1# And here, kind of: draft-fielding-uri-rfc2396bis-03# (And in draft IRI specification: draft-duerst-iri-05)# (And here, for new URI schemes: RFC 2718)#a = h[:i]  # this line is only here to show what a is# normalise case, as per RFC 2965 section 3.3.3# Sigh.  We need to know whether the domain given in the# cookie-attribute had an initial dot, in order to follow RFC 2965# (as clarified in draft errata).  Needed for the returned $Domain# value.# Version is always set to 0 by parse_ns_headers if it's a Netscape# cookie, so this must be an invalid RFC 2965 cookie.# Try and stop servers setting V0 cookies designed to hack other# servers that know both V0 and V1 protocols.# XXX This should probably be compared with the Konqueror# (kcookiejar.cpp) and Mozilla implementations, but it's a# losing battle.# domain like .foo.bar# domain like .co.uk# Path has already been checked by .path_return_ok(), and domain# blocking done by .domain_return_ok().# strict check of non-domain cookies: Mozilla does this, MSIE5 doesn't# Liberal check of.  This is here as an optimization to avoid# having to load lots of MSIE cookie files unless necessary.#_debug("   request domain %s does not match cookie domain %s",#       req_host, domain)# Used as second parameter to dict.get() method, to distinguish absent# dict key from one with a None value.# add cookies in order of most specific (ie. longest) path first# set version of Cookie header# What should it be if multiple matching Set-Cookie headers have#  different versions themselves?# Answer: there is no answer; was supposed to be settled by#  RFC 2965 errata, but that may never appear...# quote cookie value if necessary# (not for Netscape protocol, which already has any quotes#  intact, due to the poorly-specified Netscape Cookie: syntax)# add cookie-attributes to be returned in Cookie header# if necessary, advertise that we know RFC 2965# Build dictionary of standard cookie-attributes (standard) and# dictionary of other cookie-attributes (rest).# Note: expiry time is normalised to seconds since epoch.  V0# cookies should have the Expires cookie-attribute, and V1 cookies# should have Max-Age, but since V1 includes RFC 2109 cookies (and# since V0 cookies may be a mish-mash of Netscape and RFC 2109), we# accept either (but prefer Max-Age).# don't lose case distinction for unknown fields# boolean cookie-attribute is present, but has no value# (like "discard", rather than "port=80")# only first value is significant# RFC 2965 section 3.3.3# Prefer max-age to expires (like Mozilla)# convert RFC 2965 Max-Age to seconds since epoch# XXX Strictly you're supposed to follow RFC 2616#   age-calculation rules.  Remember that zero Max-Age#   is a request to discard (old and new) cookie, though.# standard is dict of standard cookie-attributes, rest is dict of the# rest of them# set the easy defaults# invalid version, ignore cookie# (discard is also set if expires is Absent)# set default path# Netscape spec parts company from reality here# set default domain# but first we have to remember whether it starts with a dot# set default port# Port attr present, but has no value: default to request port.# Cookie should then only be sent back on that port.# No port attr present.  Cookie can be sent back on any port.# set default expires and discard# Expiry date in past is request to delete cookie.  This can't be# in DefaultCookiePolicy, because can't delete cookies there.# treat 2109 cookies as Netscape cookies rather than# as RFC2965 cookies# get cookie-attributes for RFC 2965 and Netscape protocols# no relevant cookie headers: quick exit# RFC 2109 and Netscape cookies# Look for Netscape cookies (from Set-Cookie headers) that match# corresponding RFC 2965 cookies (from Set-Cookie2 headers).# For each match, keep the RFC 2965 cookie and ignore the Netscape# cookie (RFC 2965 section 9.1).  Actually, RFC 2109 cookies are# bundled in with the Netscape cookies for this purpose, which is# reasonable behaviour.# derives from OSError for backwards-compatibility with Python 2.4.0# There really isn't an LWP Cookies 2.0 format, but this indicates# that there is extra information in here (domain_dot and# port_spec) while still being compatible with libwww-perl, I hope.# httponly is a cookie flag as defined in rfc6265# when encoded in a netscape cookie file,# the line is prepended with "#HttpOnly_"# last field may be absent, so keep any trailing tab# skip comments and blank lines XXX what is $ for?# cookies.txt regards 'Set-Cookie: foo' as a cookie# with no name, whereas http.cookiejar regards it as a# cookie with no value.# assume path_specified is falseb'HTTP cookie handling for web clients.

This module has (now fairly distant) origins in Gisle Aas' Perl module
HTTP::Cookies, from the libwww-perl library.

Docstrings, comments and debug strings in this code refer to the
attributes of the HTTP cookie system as cookie-attributes, to distinguish
them clearly from Python attributes.

Class diagram (note that BSDDBCookieJar and the MSIE* classes are not
distributed with the Python standard library, but are available from
http://wwwsearch.sf.net/):

                        CookieJar____
                        /     \      \
            FileCookieJar      \      \
             /    |   \         \      \
 MozillaCookieJar | LWPCookieJar \      \
                  |               |      \
                  |   ---MSIEBase |       \
                  |  /      |     |        \
                  | /   MSIEDBCookieJar BSDDBCookieJar
                  |/
               MSIECookieJar

'u'HTTP cookie handling for web clients.

This module has (now fairly distant) origins in Gisle Aas' Perl module
HTTP::Cookies, from the libwww-perl library.

Docstrings, comments and debug strings in this code refer to the
attributes of the HTTP cookie system as cookie-attributes, to distinguish
them clearly from Python attributes.

Class diagram (note that BSDDBCookieJar and the MSIE* classes are not
distributed with the Python standard library, but are available from
http://wwwsearch.sf.net/):

                        CookieJar____
                        /     \      \
            FileCookieJar      \      \
             /    |   \         \      \
 MozillaCookieJar | LWPCookieJar \      \
                  |               |      \
                  |   ---MSIEBase |       \
                  |  /      |     |        \
                  | /   MSIEDBCookieJar BSDDBCookieJar
                  |/
               MSIECookieJar

'b'CookieJar'u'CookieJar'b'CookiePolicy'u'CookiePolicy'b'DefaultCookiePolicy'u'DefaultCookiePolicy'b'FileCookieJar'u'FileCookieJar'b'LWPCookieJar'u'LWPCookieJar'b'LoadError'u'LoadError'b'MozillaCookieJar'u'MozillaCookieJar'b'HTTPOnly'u'HTTPOnly'b'#HttpOnly_'u'#HttpOnly_'b'#( Netscape)? HTTP Cookie File'u'#( Netscape)? HTTP Cookie File'b'a filename was not supplied (nor was the CookieJar instance initialised with one)'u'a filename was not supplied (nor was the CookieJar instance initialised with one)'b'# Netscape HTTP Cookie File
# http://curl.haxx.se/rfc/cookie_spec.html
# This is a generated file!  Do not edit.

'u'# Netscape HTTP Cookie File
# http://curl.haxx.se/rfc/cookie_spec.html
# This is a generated file!  Do not edit.

'b'http.cookiejar bug!
%s'u'http.cookiejar bug!
%s'b'Return a string representing time in seconds since epoch, t.

    If the function is called without an argument, it will use the current
    time.

    The format of the returned string is like "YYYY-MM-DD hh:mm:ssZ",
    representing Universal Time (UTC, aka GMT).  An example of this format is:

    1994-11-24 08:49:37Z

    'u'Return a string representing time in seconds since epoch, t.

    If the function is called without an argument, it will use the current
    time.

    The format of the returned string is like "YYYY-MM-DD hh:mm:ssZ",
    representing Universal Time (UTC, aka GMT).  An example of this format is:

    1994-11-24 08:49:37Z

    'b'%04d-%02d-%02d %02d:%02d:%02dZ'u'%04d-%02d-%02d %02d:%02d:%02dZ'b'Return a string representing time in seconds since epoch, t.

    If the function is called without an argument, it will use the current
    time.

    The format of the returned string is like this:

    Wed, DD-Mon-YYYY HH:MM:SS GMT

    'u'Return a string representing time in seconds since epoch, t.

    If the function is called without an argument, it will use the current
    time.

    The format of the returned string is like this:

    Wed, DD-Mon-YYYY HH:MM:SS GMT

    'b'%s, %02d-%s-%04d %02d:%02d:%02d GMT'u'%s, %02d-%s-%04d %02d:%02d:%02d GMT'b'^([-+])?(\d\d?):?(\d\d)?$'u'^([-+])?(\d\d?):?(\d\d)?$'b'^[SMTWF][a-z][a-z], (\d\d) ([JFMASOND][a-z][a-z]) (\d\d\d\d) (\d\d):(\d\d):(\d\d) GMT$'u'^[SMTWF][a-z][a-z], (\d\d) ([JFMASOND][a-z][a-z]) (\d\d\d\d) (\d\d):(\d\d):(\d\d) GMT$'b'^(?:Sun|Mon|Tue|Wed|Thu|Fri|Sat)[a-z]*,?\s*'u'^(?:Sun|Mon|Tue|Wed|Thu|Fri|Sat)[a-z]*,?\s*'b'^
    (\d\d?)            # day
       (?:\s+|[-\/])
    (\w+)              # month
        (?:\s+|[-\/])
    (\d+)              # year
    (?:
          (?:\s+|:)    # separator before clock
       (\d\d?):(\d\d)  # hour:min
       (?::(\d\d))?    # optional seconds
    )?                 # optional clock
       \s*
    (?:
       ([-+]?\d{2,4}|(?![APap][Mm]\b)[A-Za-z]+) # timezone
       \s*
    )?
    (?:
       \(\w+\)         # ASCII representation of timezone in parens.
       \s*
    )?$'u'^
    (\d\d?)            # day
       (?:\s+|[-\/])
    (\w+)              # month
        (?:\s+|[-\/])
    (\d+)              # year
    (?:
          (?:\s+|:)    # separator before clock
       (\d\d?):(\d\d)  # hour:min
       (?::(\d\d))?    # optional seconds
    )?                 # optional clock
       \s*
    (?:
       ([-+]?\d{2,4}|(?![APap][Mm]\b)[A-Za-z]+) # timezone
       \s*
    )?
    (?:
       \(\w+\)         # ASCII representation of timezone in parens.
       \s*
    )?$'b'Returns time in seconds since epoch of time represented by a string.

    Return value is an integer.

    None is returned if the format of str is unrecognized, the time is outside
    the representable range, or the timezone string is not recognized.  If the
    string contains no timezone, UTC is assumed.

    The timezone in the string may be numerical (like "-0800" or "+0100") or a
    string timezone (like "UTC", "GMT", "BST" or "EST").  Currently, only the
    timezone strings equivalent to UTC (zero offset) are known to the function.

    The function loosely parses the following formats:

    Wed, 09 Feb 1994 22:23:32 GMT       -- HTTP format
    Tuesday, 08-Feb-94 14:15:29 GMT     -- old rfc850 HTTP format
    Tuesday, 08-Feb-1994 14:15:29 GMT   -- broken rfc850 HTTP format
    09 Feb 1994 22:23:32 GMT            -- HTTP format (no weekday)
    08-Feb-94 14:15:29 GMT              -- rfc850 format (no weekday)
    08-Feb-1994 14:15:29 GMT            -- broken rfc850 format (no weekday)

    The parser ignores leading and trailing whitespace.  The time may be
    absent.

    If the year is given with only 2 digits, the function will select the
    century that makes the year closest to the current date.

    'u'Returns time in seconds since epoch of time represented by a string.

    Return value is an integer.

    None is returned if the format of str is unrecognized, the time is outside
    the representable range, or the timezone string is not recognized.  If the
    string contains no timezone, UTC is assumed.

    The timezone in the string may be numerical (like "-0800" or "+0100") or a
    string timezone (like "UTC", "GMT", "BST" or "EST").  Currently, only the
    timezone strings equivalent to UTC (zero offset) are known to the function.

    The function loosely parses the following formats:

    Wed, 09 Feb 1994 22:23:32 GMT       -- HTTP format
    Tuesday, 08-Feb-94 14:15:29 GMT     -- old rfc850 HTTP format
    Tuesday, 08-Feb-1994 14:15:29 GMT   -- broken rfc850 HTTP format
    09 Feb 1994 22:23:32 GMT            -- HTTP format (no weekday)
    08-Feb-94 14:15:29 GMT              -- rfc850 format (no weekday)
    08-Feb-1994 14:15:29 GMT            -- broken rfc850 format (no weekday)

    The parser ignores leading and trailing whitespace.  The time may be
    absent.

    If the year is given with only 2 digits, the function will select the
    century that makes the year closest to the current date.

    'b'^
    (\d{4})              # year
       [-\/]?
    (\d\d?)              # numerical month
       [-\/]?
    (\d\d?)              # day
   (?:
         (?:\s+|[-:Tt])  # separator before clock
      (\d\d?):?(\d\d)    # hour:min
      (?::?(\d\d(?:\.\d*)?))?  # optional seconds (and fractional)
   )?                    # optional clock
      \s*
   (?:
      ([-+]?\d\d?:?(:?\d\d)?
       |Z|z)             # timezone  (Z is "zero meridian", i.e. GMT)
      \s*
   )?$'u'^
    (\d{4})              # year
       [-\/]?
    (\d\d?)              # numerical month
       [-\/]?
    (\d\d?)              # day
   (?:
         (?:\s+|[-:Tt])  # separator before clock
      (\d\d?):?(\d\d)    # hour:min
      (?::?(\d\d(?:\.\d*)?))?  # optional seconds (and fractional)
   )?                    # optional clock
      \s*
   (?:
      ([-+]?\d\d?:?(:?\d\d)?
       |Z|z)             # timezone  (Z is "zero meridian", i.e. GMT)
      \s*
   )?$'b'
    As for http2time, but parses the ISO 8601 formats:

    1994-02-03 14:15:29 -0100    -- ISO 8601 format
    1994-02-03 14:15:29          -- zone is optional
    1994-02-03                   -- only date
    1994-02-03T14:15:29          -- Use T as separator
    19940203T141529Z             -- ISO 8601 compact format
    19940203                     -- only date

    'u'
    As for http2time, but parses the ISO 8601 formats:

    1994-02-03 14:15:29 -0100    -- ISO 8601 format
    1994-02-03 14:15:29          -- zone is optional
    1994-02-03                   -- only date
    1994-02-03T14:15:29          -- Use T as separator
    19940203T141529Z             -- ISO 8601 compact format
    19940203                     -- only date

    'b'Return unmatched part of re.Match object.'u'Return unmatched part of re.Match object.'b'^\s*([^=\s;,]+)'u'^\s*([^=\s;,]+)'b'^\s*=\s*\"([^\"\\]*(?:\\.[^\"\\]*)*)\"'u'^\s*=\s*\"([^\"\\]*(?:\\.[^\"\\]*)*)\"'b'^\s*=\s*([^\s;,]*)'u'^\s*=\s*([^\s;,]*)'b'\\(.)'u'\\(.)'b'Parse header values into a list of lists containing key,value pairs.

    The function knows how to deal with ",", ";" and "=" as well as quoted
    values after "=".  A list of space separated tokens are parsed as if they
    were separated by ";".

    If the header_values passed as argument contains multiple values, then they
    are treated as if they were a single value separated by comma ",".

    This means that this function is useful for parsing header fields that
    follow this syntax (BNF as from the HTTP/1.1 specification, but we relax
    the requirement for tokens).

      headers           = #header
      header            = (token | parameter) *( [";"] (token | parameter))

      token             = 1*<any CHAR except CTLs or separators>
      separators        = "(" | ")" | "<" | ">" | "@"
                        | "," | ";" | ":" | "\" | <">
                        | "/" | "[" | "]" | "?" | "="
                        | "{" | "}" | SP | HT

      quoted-string     = ( <"> *(qdtext | quoted-pair ) <"> )
      qdtext            = <any TEXT except <">>
      quoted-pair       = "\" CHAR

      parameter         = attribute "=" value
      attribute         = token
      value             = token | quoted-string

    Each header is represented by a list of key/value pairs.  The value for a
    simple token (not part of a parameter) is None.  Syntactically incorrect
    headers will not necessarily be parsed as you would want.

    This is easier to describe with some examples:

    >>> split_header_words(['foo="bar"; port="80,81"; discard, bar=baz'])
    [[('foo', 'bar'), ('port', '80,81'), ('discard', None)], [('bar', 'baz')]]
    >>> split_header_words(['text/html; charset="iso-8859-1"'])
    [[('text/html', None), ('charset', 'iso-8859-1')]]
    >>> split_header_words([r'Basic realm="\"foo\bar\""'])
    [[('Basic', None), ('realm', '"foobar"')]]

    'u'Parse header values into a list of lists containing key,value pairs.

    The function knows how to deal with ",", ";" and "=" as well as quoted
    values after "=".  A list of space separated tokens are parsed as if they
    were separated by ";".

    If the header_values passed as argument contains multiple values, then they
    are treated as if they were a single value separated by comma ",".

    This means that this function is useful for parsing header fields that
    follow this syntax (BNF as from the HTTP/1.1 specification, but we relax
    the requirement for tokens).

      headers           = #header
      header            = (token | parameter) *( [";"] (token | parameter))

      token             = 1*<any CHAR except CTLs or separators>
      separators        = "(" | ")" | "<" | ">" | "@"
                        | "," | ";" | ":" | "\" | <">
                        | "/" | "[" | "]" | "?" | "="
                        | "{" | "}" | SP | HT

      quoted-string     = ( <"> *(qdtext | quoted-pair ) <"> )
      qdtext            = <any TEXT except <">>
      quoted-pair       = "\" CHAR

      parameter         = attribute "=" value
      attribute         = token
      value             = token | quoted-string

    Each header is represented by a list of key/value pairs.  The value for a
    simple token (not part of a parameter) is None.  Syntactically incorrect
    headers will not necessarily be parsed as you would want.

    This is easier to describe with some examples:

    >>> split_header_words(['foo="bar"; port="80,81"; discard, bar=baz'])
    [[('foo', 'bar'), ('port', '80,81'), ('discard', None)], [('bar', 'baz')]]
    >>> split_header_words(['text/html; charset="iso-8859-1"'])
    [[('text/html', None), ('charset', 'iso-8859-1')]]
    >>> split_header_words([r'Basic realm="\"foo\bar\""'])
    [[('Basic', None), ('realm', '"foobar"')]]

    'b'^[=\s;]*'u'^[=\s;]*'b'split_header_words bug: '%s', '%s', %s'u'split_header_words bug: '%s', '%s', %s'b'([\"\\])'u'([\"\\])'b'Do the inverse (almost) of the conversion done by split_header_words.

    Takes a list of lists of (key, value) pairs and produces a single header
    value.  Attribute values are quoted if needed.

    >>> join_header_words([[("text/plain", None), ("charset", "iso-8859-1")]])
    'text/plain; charset="iso-8859-1"'
    >>> join_header_words([[("text/plain", None)], [("charset", "iso-8859-1")]])
    'text/plain, charset="iso-8859-1"'

    'u'Do the inverse (almost) of the conversion done by split_header_words.

    Takes a list of lists of (key, value) pairs and produces a single header
    value.  Attribute values are quoted if needed.

    >>> join_header_words([[("text/plain", None), ("charset", "iso-8859-1")]])
    'text/plain; charset="iso-8859-1"'
    >>> join_header_words([[("text/plain", None)], [("charset", "iso-8859-1")]])
    'text/plain, charset="iso-8859-1"'

    'b'^\w+$'u'^\w+$'b'Ad-hoc parser for Netscape protocol cookie-attributes.

    The old Netscape cookie format for Set-Cookie can for instance contain
    an unquoted "," in the expires field, so we have to use this ad-hoc
    parser instead of split_header_words.

    XXX This may not make the best possible effort to parse all the crap
    that Netscape Cookie headers contain.  Ronald Tschalar's HTTPClient
    parser is probably better, so could do worse than following that if
    this ever gives any trouble.

    Currently, this is also used for parsing RFC 2109 cookies.

    'u'Ad-hoc parser for Netscape protocol cookie-attributes.

    The old Netscape cookie format for Set-Cookie can for instance contain
    an unquoted "," in the expires field, so we have to use this ad-hoc
    parser instead of split_header_words.

    XXX This may not make the best possible effort to parse all the crap
    that Netscape Cookie headers contain.  Ronald Tschalar's HTTPClient
    parser is probably better, so could do worse than following that if
    this ever gives any trouble.

    Currently, this is also used for parsing RFC 2109 cookies.

    'b'expires'u'expires'b'secure'u'secure'b'max-age'u'max-age'b'\.\d+$'u'\.\d+$'b'Return True if text is a host domain name.'u'Return True if text is a host domain name.'b'Return True if domain A domain-matches domain B, according to RFC 2965.

    A and B may be host domain names or IP addresses.

    RFC 2965, section 1:

    Host names can be specified either as an IP address or a HDN string.
    Sometimes we compare one host name with another.  (Such comparisons SHALL
    be case-insensitive.)  Host A's name domain-matches host B's if

         *  their host name strings string-compare equal; or

         * A is a HDN string and has the form NB, where N is a non-empty
            name string, B has the form .B', and B' is a HDN string.  (So,
            x.y.com domain-matches .Y.com but not Y.com.)

    Note that domain-match is not a commutative operation: a.b.c.com
    domain-matches .c.com, but not the reverse.

    'u'Return True if domain A domain-matches domain B, according to RFC 2965.

    A and B may be host domain names or IP addresses.

    RFC 2965, section 1:

    Host names can be specified either as an IP address or a HDN string.
    Sometimes we compare one host name with another.  (Such comparisons SHALL
    be case-insensitive.)  Host A's name domain-matches host B's if

         *  their host name strings string-compare equal; or

         * A is a HDN string and has the form NB, where N is a non-empty
            name string, B has the form .B', and B' is a HDN string.  (So,
            x.y.com domain-matches .Y.com but not Y.com.)

    Note that domain-match is not a commutative operation: a.b.c.com
    domain-matches .c.com, but not the reverse.

    'b'Return True if text is a sort-of-like a host domain name.

    For accepting/blocking domains.

    'u'Return True if text is a sort-of-like a host domain name.

    For accepting/blocking domains.

    'b'For blocking/accepting domains.

    A and B may be host domain names or IP addresses.

    'u'For blocking/accepting domains.

    A and B may be host domain names or IP addresses.

    'b':\d+$'u':\d+$'b'Return request-host, as defined by RFC 2965.

    Variation from RFC: returned value is lowercased, for convenient
    comparison.

    'u'Return request-host, as defined by RFC 2965.

    Variation from RFC: returned value is lowercased, for convenient
    comparison.

    'b'Return a tuple (request-host, effective request-host name).

    As defined by RFC 2965, except both are lowercased.

    'u'Return a tuple (request-host, effective request-host name).

    As defined by RFC 2965, except both are lowercased.

    'b'.local'u'.local'b'Path component of request-URI, as defined by RFC 2965.'u'Path component of request-URI, as defined by RFC 2965.'b'%/;:@&=+$,!~*'()'u'%/;:@&=+$,!~*'()'b'%([0-9a-fA-F][0-9a-fA-F])'u'%([0-9a-fA-F][0-9a-fA-F])'b'%%%s'u'%%%s'b'Escape any invalid characters in HTTP URL, and uppercase all escapes.'u'Escape any invalid characters in HTTP URL, and uppercase all escapes.'b'Return reach of host h, as defined by RFC 2965, section 1.

    The reach R of a host name H is defined as follows:

       *  If

          -  H is the host domain name of a host; and,

          -  H has the form A.B; and

          -  A has no embedded (that is, interior) dots; and

          -  B has at least one embedded dot, or B is the string "local".
             then the reach of H is .B.

       *  Otherwise, the reach of H is H.

    >>> reach("www.acme.com")
    '.acme.com'
    >>> reach("acme.com")
    'acme.com'
    >>> reach("acme.local")
    '.local'

    'u'Return reach of host h, as defined by RFC 2965, section 1.

    The reach R of a host name H is defined as follows:

       *  If

          -  H is the host domain name of a host; and,

          -  H has the form A.B; and

          -  A has no embedded (that is, interior) dots; and

          -  B has at least one embedded dot, or B is the string "local".
             then the reach of H is .B.

       *  Otherwise, the reach of H is H.

    >>> reach("www.acme.com")
    '.acme.com'
    >>> reach("acme.com")
    'acme.com'
    >>> reach("acme.local")
    '.local'

    'b'

    RFC 2965, section 3.3.6:

        An unverifiable transaction is to a third-party host if its request-
        host U does not domain-match the reach R of the request-host O in the
        origin transaction.

    'u'

    RFC 2965, section 3.3.6:

        An unverifiable transaction is to a third-party host if its request-
        host U does not domain-match the reach R of the request-host O in the
        origin transaction.

    'b'HTTP Cookie.

    This class represents both Netscape and RFC 2965 cookies.

    This is deliberately a very simple class.  It just holds attributes.  It's
    possible to construct Cookie instances that don't comply with the cookie
    standards.  CookieJar.make_cookies is the factory function for Cookie
    objects -- it deals with cookie parsing, supplying defaults, and
    normalising to the representation used in this class.  CookiePolicy is
    responsible for checking them to see whether they should be accepted from
    and returned to the server.

    Note that the port may be present in the headers, but unspecified ("Port"
    rather than"Port=80", for example); if this is the case, port is None.

    'u'HTTP Cookie.

    This class represents both Netscape and RFC 2965 cookies.

    This is deliberately a very simple class.  It just holds attributes.  It's
    possible to construct Cookie instances that don't comply with the cookie
    standards.  CookieJar.make_cookies is the factory function for Cookie
    objects -- it deals with cookie parsing, supplying defaults, and
    normalising to the representation used in this class.  CookiePolicy is
    responsible for checking them to see whether they should be accepted from
    and returned to the server.

    Note that the port may be present in the headers, but unspecified ("Port"
    rather than"Port=80", for example); if this is the case, port is None.

    'b'if port is None, port_specified must be false'u'if port is None, port_specified must be false'b'<Cookie %s for %s>'u'<Cookie %s for %s>'b'port_specified'u'port_specified'b'domain_specified'u'domain_specified'b'domain_initial_dot'u'domain_initial_dot'b'path_specified'u'path_specified'b'discard'u'discard'b'comment_url'u'comment_url'b'rest=%s'u'rest=%s'b'rfc2109=%s'u'rfc2109=%s'b'Defines which cookies get accepted from and returned to server.

    May also modify cookies, though this is probably a bad idea.

    The subclass DefaultCookiePolicy defines the standard rules for Netscape
    and RFC 2965 cookies -- override that if you want a customized policy.

    'u'Defines which cookies get accepted from and returned to server.

    May also modify cookies, though this is probably a bad idea.

    The subclass DefaultCookiePolicy defines the standard rules for Netscape
    and RFC 2965 cookies -- override that if you want a customized policy.

    'b'Return true if (and only if) cookie should be accepted from server.

        Currently, pre-expired cookies never get this far -- the CookieJar
        class deletes such cookies itself.

        'u'Return true if (and only if) cookie should be accepted from server.

        Currently, pre-expired cookies never get this far -- the CookieJar
        class deletes such cookies itself.

        'b'Return true if (and only if) cookie should be returned to server.'u'Return true if (and only if) cookie should be returned to server.'b'Return false if cookies should not be returned, given cookie domain.
        'u'Return false if cookies should not be returned, given cookie domain.
        'b'Return false if cookies should not be returned, given cookie path.
        'u'Return false if cookies should not be returned, given cookie path.
        'b'Implements the standard rules for accepting and returning cookies.'u'Implements the standard rules for accepting and returning cookies.'b'wss'u'wss'b'Constructor arguments should be passed as keyword arguments only.'u'Constructor arguments should be passed as keyword arguments only.'b'Return the sequence of blocked domains (as a tuple).'u'Return the sequence of blocked domains (as a tuple).'b'Set the sequence of blocked domains.'u'Set the sequence of blocked domains.'b'Return None, or the sequence of allowed domains (as a tuple).'u'Return None, or the sequence of allowed domains (as a tuple).'b'Set the sequence of allowed domains, or None.'u'Set the sequence of allowed domains, or None.'b'
        If you override .set_ok(), be sure to call this method.  If it returns
        false, so should your subclass (assuming your subclass wants to be more
        strict about which cookies to accept).

        'u'
        If you override .set_ok(), be sure to call this method.  If it returns
        false, so should your subclass (assuming your subclass wants to be more
        strict about which cookies to accept).

        'b' - checking cookie %s=%s'u' - checking cookie %s=%s'b'verifiability'u'verifiability'b'set_ok_'u'set_ok_'b'   Set-Cookie2 without version attribute (%s=%s)'u'   Set-Cookie2 without version attribute (%s=%s)'b'   RFC 2965 cookies are switched off'u'   RFC 2965 cookies are switched off'b'   Netscape cookies are switched off'u'   Netscape cookies are switched off'b'   third-party RFC 2965 cookie during unverifiable transaction'u'   third-party RFC 2965 cookie during unverifiable transaction'b'   third-party Netscape cookie during unverifiable transaction'u'   third-party Netscape cookie during unverifiable transaction'b'   illegal name (starts with '$'): '%s''u'   illegal name (starts with '$'): '%s''b'   path attribute %s is not a prefix of request path %s'u'   path attribute %s is not a prefix of request path %s'b'   domain %s is in user block-list'u'   domain %s is in user block-list'b'   domain %s is not in user allow-list'u'   domain %s is not in user allow-list'b'co'u'co'b'ac'u'ac'b'com'u'com'b'edu'u'edu'b'org'u'org'b'net'u'net'b'gov'u'gov'b'mil'u'mil'b'aero'u'aero'b'biz'u'biz'b'cat'u'cat'b'coop'u'coop'b'jobs'u'jobs'b'mobi'u'mobi'b'museum'u'museum'b'pro'u'pro'b'travel'u'travel'b'eu'u'eu'b'   country-code second level domain %s'u'   country-code second level domain %s'b'   non-local domain %s contains no embedded dot'u'   non-local domain %s contains no embedded dot'b'   effective request-host %s (even with added initial dot) does not end with %s'u'   effective request-host %s (even with added initial dot) does not end with %s'b'   effective request-host %s does not domain-match %s'u'   effective request-host %s does not domain-match %s'b'   host prefix %s for domain %s contains a dot'u'   host prefix %s for domain %s contains a dot'b'   bad port %s (not numeric)'u'   bad port %s (not numeric)'b'   request port (%s) not found in %s'u'   request port (%s) not found in %s'b'
        If you override .return_ok(), be sure to call this method.  If it
        returns false, so should your subclass (assuming your subclass wants to
        be more strict about which cookies to return).

        'u'
        If you override .return_ok(), be sure to call this method.  If it
        returns false, so should your subclass (assuming your subclass wants to
        be more strict about which cookies to return).

        'b'return_ok_'u'return_ok_'b'   secure cookie with non-secure request'u'   secure cookie with non-secure request'b'   cookie expired'u'   cookie expired'b'   request port %s does not match cookie port %s'u'   request port %s does not match cookie port %s'b'   cookie with unspecified domain does not string-compare equal to request domain'u'   cookie with unspecified domain does not string-compare equal to request domain'b'   effective request-host name %s does not domain-match RFC 2965 cookie domain %s'u'   effective request-host name %s does not domain-match RFC 2965 cookie domain %s'b'   request-host %s does not match Netscape cookie domain %s'u'   request-host %s does not match Netscape cookie domain %s'b'- checking cookie path=%s'u'- checking cookie path=%s'b'  %s does not path-match %s'u'  %s does not path-match %s'b'Iterates over nested mapping, depth-first, in sorted order by key.'u'Iterates over nested mapping, depth-first, in sorted order by key.'b'Collection of HTTP cookies.

    You may not need to know about this class: try
    urllib.request.build_opener(HTTPCookieProcessor).open(url).
    'u'Collection of HTTP cookies.

    You may not need to know about this class: try
    urllib.request.build_opener(HTTPCookieProcessor).open(url).
    'b'\W'u'\W'b'\.?[^.]*'u'\.?[^.]*'b'[^.]*'u'[^.]*'b'^\.+'u'^\.+'b'^\#LWP-Cookies-(\d+\.\d+)'u'^\#LWP-Cookies-(\d+\.\d+)'b'Checking %s for cookies to return'u'Checking %s for cookies to return'b'   not returning cookie'u'   not returning cookie'b'   it's a match'u'   it's a match'b'Return a list of cookies to be returned to server.'u'Return a list of cookies to be returned to server.'b'Return a list of cookie-attributes to be returned to server.

        like ['foo="bar"; $Path="/"', ...]

        The $Version attribute is also added when appropriate (currently only
        once per request).

        'u'Return a list of cookie-attributes to be returned to server.

        like ['foo="bar"; $Path="/"', ...]

        The $Version attribute is also added when appropriate (currently only
        once per request).

        'b'$Version=%s'u'$Version=%s'b'$Path="%s"'u'$Path="%s"'b'$Domain="%s"'u'$Domain="%s"'b'$Port'u'$Port'b'="%s"'u'="%s"'b'Add correct Cookie: header to request (urllib.request.Request object).

        The Cookie2 header is also added unless policy.hide_cookie2 is true.

        'u'Add correct Cookie: header to request (urllib.request.Request object).

        The Cookie2 header is also added unless policy.hide_cookie2 is true.

        'b'add_cookie_header'u'add_cookie_header'b'Cookie2'u'Cookie2'b'$Version="1"'u'$Version="1"'b'Return list of tuples containing normalised cookie information.

        attrs_set is the list of lists of key,value pairs extracted from
        the Set-Cookie or Set-Cookie2 headers.

        Tuples are name, value, standard, rest, where name and value are the
        cookie name and value, standard is a dictionary containing the standard
        cookie-attributes (discard, secure, version, expires or max-age,
        domain, path and port) and rest is a dictionary containing the rest of
        the cookie-attributes.

        'u'Return list of tuples containing normalised cookie information.

        attrs_set is the list of lists of key,value pairs extracted from
        the Set-Cookie or Set-Cookie2 headers.

        Tuples are name, value, standard, rest, where name and value are the
        cookie name and value, standard is a dictionary containing the standard
        cookie-attributes (discard, secure, version, expires or max-age,
        domain, path and port) and rest is a dictionary containing the rest of
        the cookie-attributes.

        'b'commenturl'u'commenturl'b'   missing value for domain attribute'u'   missing value for domain attribute'b'   missing or invalid value for expires attribute: treating as session cookie'u'   missing or invalid value for expires attribute: treating as session cookie'b'   missing or invalid (non-numeric) value for max-age attribute'u'   missing or invalid (non-numeric) value for max-age attribute'b'   missing value for %s attribute'u'   missing value for %s attribute'b'Expiring cookie, domain='%s', path='%s', name='%s''u'Expiring cookie, domain='%s', path='%s', name='%s''b'rfc2109_as_netscape'u'rfc2109_as_netscape'b'Return sequence of Cookie objects extracted from response object.'u'Return sequence of Cookie objects extracted from response object.'b'Set-Cookie2'u'Set-Cookie2'b'Set-Cookie'u'Set-Cookie'b'Set a cookie if policy says it's OK to do so.'u'Set a cookie if policy says it's OK to do so.'b'Set a cookie, without checking whether or not it should be set.'u'Set a cookie, without checking whether or not it should be set.'b'Extract cookies from response, where allowable given the request.'u'Extract cookies from response, where allowable given the request.'b'extract_cookies: %s'u'extract_cookies: %s'b' setting cookie: %s'u' setting cookie: %s'b'Clear some cookies.

        Invoking this method without arguments will clear all cookies.  If
        given a single argument, only cookies belonging to that domain will be
        removed.  If given two arguments, cookies belonging to the specified
        path within that domain are removed.  If given three arguments, then
        the cookie with the specified name, path and domain is removed.

        Raises KeyError if no matching cookie exists.

        'u'Clear some cookies.

        Invoking this method without arguments will clear all cookies.  If
        given a single argument, only cookies belonging to that domain will be
        removed.  If given two arguments, cookies belonging to the specified
        path within that domain are removed.  If given three arguments, then
        the cookie with the specified name, path and domain is removed.

        Raises KeyError if no matching cookie exists.

        'b'domain and path must be given to remove a cookie by name'u'domain and path must be given to remove a cookie by name'b'domain must be given to remove cookies by path'u'domain must be given to remove cookies by path'b'Discard all session cookies.

        Note that the .save() method won't save session cookies anyway, unless
        you ask otherwise by passing a true ignore_discard argument.

        'u'Discard all session cookies.

        Note that the .save() method won't save session cookies anyway, unless
        you ask otherwise by passing a true ignore_discard argument.

        'b'Discard all expired cookies.

        You probably don't need to call this method: expired cookies are never
        sent back to the server (provided you're using DefaultCookiePolicy),
        this method is called by CookieJar itself every so often, and the
        .save() method won't save expired cookies anyway (unless you ask
        otherwise by passing a true ignore_expires argument).

        'u'Discard all expired cookies.

        You probably don't need to call this method: expired cookies are never
        sent back to the server (provided you're using DefaultCookiePolicy),
        this method is called by CookieJar itself every so often, and the
        .save() method won't save expired cookies anyway (unless you ask
        otherwise by passing a true ignore_expires argument).

        'b'Return number of contained cookies.'u'Return number of contained cookies.'b'<%s[%s]>'u'<%s[%s]>'b'CookieJar that can be loaded from and saved to a file.'u'CookieJar that can be loaded from and saved to a file.'b'
        Cookies are NOT loaded from the named file until either the .load() or
        .revert() method is called.

        'u'
        Cookies are NOT loaded from the named file until either the .load() or
        .revert() method is called.

        'b'Save cookies to a file.'u'Save cookies to a file.'b'Load cookies from a file.'u'Load cookies from a file.'b'Clear all cookies and reload cookies from a saved file.

        Raises LoadError (or OSError) if reversion is not successful; the
        object's state will not be altered if this happens.

        'u'Clear all cookies and reload cookies from a saved file.

        Raises LoadError (or OSError) if reversion is not successful; the
        object's state will not be altered if this happens.

        'b'Return string representation of Cookie in the LWP cookie file format.

    Actually, the format is extended a bit -- see module docstring.

    'u'Return string representation of Cookie in the LWP cookie file format.

    Actually, the format is extended a bit -- see module docstring.

    'b'path_spec'u'path_spec'b'port_spec'u'port_spec'b'domain_dot'u'domain_dot'b'
    The LWPCookieJar saves a sequence of "Set-Cookie3" lines.
    "Set-Cookie3" is the format used by the libwww-perl library, not known
    to be compatible with any browser, but which is easy to read and
    doesn't lose information about RFC 2965 cookies.

    Additional methods

    as_lwp_str(ignore_discard=True, ignore_expired=True)

    'u'
    The LWPCookieJar saves a sequence of "Set-Cookie3" lines.
    "Set-Cookie3" is the format used by the libwww-perl library, not known
    to be compatible with any browser, but which is easy to read and
    doesn't lose information about RFC 2965 cookies.

    Additional methods

    as_lwp_str(ignore_discard=True, ignore_expired=True)

    'b'Return cookies as a string of "\n"-separated "Set-Cookie3" headers.

        ignore_discard and ignore_expires: see docstring for FileCookieJar.save

        'u'Return cookies as a string of "\n"-separated "Set-Cookie3" headers.

        ignore_discard and ignore_expires: see docstring for FileCookieJar.save

        'b'Set-Cookie3: %s'u'Set-Cookie3: %s'b'#LWP-Cookies-2.0
'u'#LWP-Cookies-2.0
'b'%r does not look like a Set-Cookie3 (LWP) format file'u'%r does not look like a Set-Cookie3 (LWP) format file'b'Set-Cookie3:'u'Set-Cookie3:'b'invalid Set-Cookie3 format file %r: %r'u'invalid Set-Cookie3 format file %r: %r'b'

    WARNING: you may want to backup your browser's cookies file if you use
    this class to save cookies.  I *think* it works, but there have been
    bugs in the past!

    This class differs from CookieJar only in the format it uses to save and
    load cookies to and from a file.  This class uses the Mozilla/Netscape
    `cookies.txt' format.  curl and lynx use this file format, too.

    Don't expect cookies saved while the browser is running to be noticed by
    the browser (in fact, Mozilla on unix will overwrite your saved cookies if
    you change them on disk while it's running; on Windows, you probably can't
    save at all while the browser is running).

    Note that the Mozilla/Netscape format will downgrade RFC2965 cookies to
    Netscape cookies on saving.

    In particular, the cookie version and port number information is lost,
    together with information about whether or not Path, Port and Discard were
    specified by the Set-Cookie2 (or Set-Cookie) header, and whether or not the
    domain as set in the HTTP header started with a dot (yes, I'm aware some
    domains in Netscape files start with a dot and some don't -- trust me, you
    really don't want to know any more about this).

    Note that though Mozilla and Netscape use the same format, they use
    slightly different headers.  The class saves cookies using the Netscape
    header by default (Mozilla can cope with that).

    'u'

    WARNING: you may want to backup your browser's cookies file if you use
    this class to save cookies.  I *think* it works, but there have been
    bugs in the past!

    This class differs from CookieJar only in the format it uses to save and
    load cookies to and from a file.  This class uses the Mozilla/Netscape
    `cookies.txt' format.  curl and lynx use this file format, too.

    Don't expect cookies saved while the browser is running to be noticed by
    the browser (in fact, Mozilla on unix will overwrite your saved cookies if
    you change them on disk while it's running; on Windows, you probably can't
    save at all while the browser is running).

    Note that the Mozilla/Netscape format will downgrade RFC2965 cookies to
    Netscape cookies on saving.

    In particular, the cookie version and port number information is lost,
    together with information about whether or not Path, Port and Discard were
    specified by the Set-Cookie2 (or Set-Cookie) header, and whether or not the
    domain as set in the HTTP header started with a dot (yes, I'm aware some
    domains in Netscape files start with a dot and some don't -- trust me, you
    really don't want to know any more about this).

    Note that though Mozilla and Netscape use the same format, they use
    slightly different headers.  The class saves cookies using the Netscape
    header by default (Mozilla can cope with that).

    'b'%r does not look like a Netscape format cookies file'u'%r does not look like a Netscape format cookies file'b'TRUE'u'TRUE'b'invalid Netscape format cookies file %r: %r'u'invalid Netscape format cookies file %r: %r'b'FALSE'u'FALSE'u'cookiejar'
Here's a sample session to show how to use this module.
At the moment, this is the only documentation.

The Basics
----------

Importing is easy...

   >>> from http import cookies

Most of the time you start by creating a cookie.

   >>> C = cookies.SimpleCookie()

Once you've created your Cookie, you can add values just as if it were
a dictionary.

   >>> C = cookies.SimpleCookie()
   >>> C["fig"] = "newton"
   >>> C["sugar"] = "wafer"
   >>> C.output()
   'Set-Cookie: fig=newton\r\nSet-Cookie: sugar=wafer'

Notice that the printable representation of a Cookie is the
appropriate format for a Set-Cookie: header.  This is the
default behavior.  You can change the header and printed
attributes by using the .output() function

   >>> C = cookies.SimpleCookie()
   >>> C["rocky"] = "road"
   >>> C["rocky"]["path"] = "/cookie"
   >>> print(C.output(header="Cookie:"))
   Cookie: rocky=road; Path=/cookie
   >>> print(C.output(attrs=[], header="Cookie:"))
   Cookie: rocky=road

The load() method of a Cookie extracts cookies from a string.  In a
CGI script, you would use this method to extract the cookies from the
HTTP_COOKIE environment variable.

   >>> C = cookies.SimpleCookie()
   >>> C.load("chips=ahoy; vienna=finger")
   >>> C.output()
   'Set-Cookie: chips=ahoy\r\nSet-Cookie: vienna=finger'

The load() method is darn-tootin smart about identifying cookies
within a string.  Escaped quotation marks, nested semicolons, and other
such trickeries do not confuse it.

   >>> C = cookies.SimpleCookie()
   >>> C.load('keebler="E=everybody; L=\\"Loves\\"; fudge=\\012;";')
   >>> print(C)
   Set-Cookie: keebler="E=everybody; L=\"Loves\"; fudge=\012;"

Each element of the Cookie also supports all of the RFC 2109
Cookie attributes.  Here's an example which sets the Path
attribute.

   >>> C = cookies.SimpleCookie()
   >>> C["oreo"] = "doublestuff"
   >>> C["oreo"]["path"] = "/"
   >>> print(C)
   Set-Cookie: oreo=doublestuff; Path=/

Each dictionary element has a 'value' attribute, which gives you
back the value associated with the key.

   >>> C = cookies.SimpleCookie()
   >>> C["twix"] = "none for you"
   >>> C["twix"].value
   'none for you'

The SimpleCookie expects that all values should be standard strings.
Just to be sure, SimpleCookie invokes the str() builtin to convert
the value to a string, when the values are set dictionary-style.

   >>> C = cookies.SimpleCookie()
   >>> C["number"] = 7
   >>> C["string"] = "seven"
   >>> C["number"].value
   '7'
   >>> C["string"].value
   'seven'
   >>> C.output()
   'Set-Cookie: number=7\r\nSet-Cookie: string=seven'

Finis.
CookieErrorBaseCookieSimpleCookie_nulljoin_semispacejoin_spacejoin!#$%&'*+-.^_`|~:_LegalChars ()/<=>?@[]{}_UnescapedChars\%03o_Translator[%s]+_is_legal_key_quoteQuote a string for use in a cookie header.

    If the string does not need to be double-quoted, then just return the
    string.  Otherwise, surround the string in doublequotes and quote
    (with a \) special characters.
    \\[0-3][0-7][0-7]_OctalPatt[\\]._QuotePatt_unquoteo_matchq_match_weekdayname_monthname_getdateweekdaynamemonthnamehh%s, %02d %3s %4d %02d:%02d:%02d GMTA class to hold ONE (key, value) pair.

    In a cookie, each such pair may have several attributes, so this class is
    used to keep the attributes associated with the appropriate key,value pair.
    This class also includes a coded_value attribute, which is used to hold
    the network representation of the value.
    Max-AgeSecureHttpOnlyhttponlyVersionSameSitesamesite_reserved_flags_coded_valuecoded_valueVInvalid attribute %rmorselisReservedKeycoded_valAttempt to set a reserved key %rIllegal key %rSet-Cookie:OutputString<%s: %s>js_output
        <script type="text/javascript">
        <!-- begin hiding
        document.cookie = "%s";
        // end hiding -->
        </script>
        %s=%d\w\d!#%&'~_`><@,:/\$\*\+\-\.\^\|\)\(\?\}\{\=_LegalKeyChars\[\]_LegalValueChars
    \s*                            # Optional whitespace at start of cookie
    (?P<key>                       # Start of group 'key'
    []+?   # Any word of at least one letter
    )                              # End of group 'key'
    (                              # Optional group: there may not be a value.
    \s*=\s*                          # Equal Sign
    (?P<val>                         # Start of group 'val'
    "(?:[^\\"]|\\.)*"                  # Any doublequoted string
    |                                  # or
    \w{3},\s[\w\d\s-]{9,11}\s[\d:]{8}\sGMT  # Special case for "expires" attr
    |                                  # or
    []*      # Any word or empty string
    )                                # End of group 'val'
    )?                             # End of optional value group
    \s*                            # Any number of spaces.
    (\s+|;|$)                      # Ending either at space, semicolon, or EOS.
    _CookiePatternA container class for a set of Morsels.value_decodereal_value, coded_value = value_decode(STRING)
        Called prior to setting a cookie's value from the network
        representation.  The VALUE is the value read from HTTP
        header.
        Override this function to modify the behavior of cookies.
        value_encodereal_value, coded_value = value_encode(VALUE)
        Called prior to setting a cookie's value from the dictionary
        representation.  The VALUE is the value being assigned.
        Override this function to modify the behavior of cookies.
        strval__setreal_valuePrivate method for setting a cookie's valueDictionary style assignment.cvalReturn a string suitable for HTTP.Return a string suitable for JavaScript.Load cookies from a string (presumably HTTP_COOKIE) or
        from a dictionary.  Loading cookies from a dictionary 'd'
        is equivalent to calling:
            map(Cookie.__setitem__, d.keys(), d.values())
        __parse_stringpattparsed_itemsmorsel_seenTYPE_ATTRIBUTETYPE_KEYVALUE
    SimpleCookie supports strings as cookie values.  When setting
    the value using the dictionary assignment notation, SimpleCookie
    calls the builtin str() to convert the value to a string.  Values
    received from HTTP are kept as strings.
    ##### Copyright 2000 by Timothy O'Malley <timo@alum.mit.edu>#                All Rights Reserved# Permission to use, copy, modify, and distribute this software# and its documentation for any purpose and without fee is hereby# granted, provided that the above copyright notice appear in all# copies and that both that copyright notice and this permission# Timothy O'Malley  not be used in advertising or publicity# Timothy O'Malley DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS# SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY# AND FITNESS, IN NO EVENT SHALL Timothy O'Malley BE LIABLE FOR# ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,# ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR# PERFORMANCE OF THIS SOFTWARE.# Id: Cookie.py,v 2.29 2000/08/23 05:28:49 timo Exp#   by Timothy O'Malley <timo@alum.mit.edu>#  Cookie.py is a Python module for the handling of HTTP#  cookies as a Python dictionary.  See RFC 2109 for more#  information on cookies.#  The original idea to treat Cookies as a dictionary came from#  Dave Mitchell (davem@magnet.com) in 1995, when he released the#  first version of nscookie.py.# Import our required modules# Define an exception visible to External modules# These quoting routines conform to the RFC2109 specification, which in# turn references the character definitions from RFC2068.  They provide# a two-way quoting algorithm.  Any non-text character is translated# into a 4 character sequence: a forward-slash followed by the# three-digit octal equivalent of the character.  Any '\' or '"' is# quoted with a preceding '\' slash.# Because of the way browsers really handle cookies (as opposed to what# the RFC says) we also encode "," and ";".# These are taken from RFC2068 and RFC2109.#       _LegalChars       is the list of chars which don't require "'s#       _Translator       hash-table for fast quoting# If there aren't any doublequotes,# then there can't be any special characters.  See RFC 2109.# We have to assume that we must decode this string.# Down to work.# Remove the "s# Check for special sequences.  Examples:#    \012 --> \n#    \"   --> "# Neither matched# QuotePatt matched# OctalPatt matched# The _getdate() routine is used to set the expiration time in the cookie's HTTP# header.  By default, _getdate() returns the current time in the appropriate# "expires" format for a Set-Cookie header.  The one optional argument is an# offset from now, in seconds.  For example, an offset of -3600 means "one hour# ago".  The offset may be a floating point number.# RFC 2109 lists these attributes as reserved:#   path       comment         domain#   max-age    secure      version# For historical reasons, these attributes are also reserved:#   expires# This is an extension from Microsoft:#   httponly# This dictionary provides a mapping from the lowercase# variant on the left to the appropriate traditional# formatting on the right.# Set defaults# Set default attributes# It's a good key, so save it.# Print javascript# Build up our result# First, the key=value pair# Now add any defined attributes# Return the result# Pattern for finding cookie# This used to be strict parsing based on the RFC2109 and RFC2068# specifications.  I have since discovered that MSIE 3.0x doesn't# follow the character rules outlined in those specs.  As a# result, the parsing rules here are less strict.# re.ASCII may be removed if safe.# At long last, here is the cookie class.  Using this class is almost just like# using a dictionary.  See this module's docstring for example usage.# allow assignment of constructed Morsels (e.g. for pickling)# self.update() wouldn't call our custom __setitem__# Our starting point# Length of string# Parsed (type, key, value) triples# A key=value pair was previously encountered# We first parse the whole cookie string and reject it if it's# syntactically invalid (this helps avoid some classes of injection# attacks).# Start looking for a cookie# No more cookies# We ignore attributes which pertain to the cookie# mechanism as a whole, such as "$Version".# See RFC 2965. (Does anyone care?)# Invalid cookie string# The cookie string is valid, apply it.# current morselb'
Here's a sample session to show how to use this module.
At the moment, this is the only documentation.

The Basics
----------

Importing is easy...

   >>> from http import cookies

Most of the time you start by creating a cookie.

   >>> C = cookies.SimpleCookie()

Once you've created your Cookie, you can add values just as if it were
a dictionary.

   >>> C = cookies.SimpleCookie()
   >>> C["fig"] = "newton"
   >>> C["sugar"] = "wafer"
   >>> C.output()
   'Set-Cookie: fig=newton\r\nSet-Cookie: sugar=wafer'

Notice that the printable representation of a Cookie is the
appropriate format for a Set-Cookie: header.  This is the
default behavior.  You can change the header and printed
attributes by using the .output() function

   >>> C = cookies.SimpleCookie()
   >>> C["rocky"] = "road"
   >>> C["rocky"]["path"] = "/cookie"
   >>> print(C.output(header="Cookie:"))
   Cookie: rocky=road; Path=/cookie
   >>> print(C.output(attrs=[], header="Cookie:"))
   Cookie: rocky=road

The load() method of a Cookie extracts cookies from a string.  In a
CGI script, you would use this method to extract the cookies from the
HTTP_COOKIE environment variable.

   >>> C = cookies.SimpleCookie()
   >>> C.load("chips=ahoy; vienna=finger")
   >>> C.output()
   'Set-Cookie: chips=ahoy\r\nSet-Cookie: vienna=finger'

The load() method is darn-tootin smart about identifying cookies
within a string.  Escaped quotation marks, nested semicolons, and other
such trickeries do not confuse it.

   >>> C = cookies.SimpleCookie()
   >>> C.load('keebler="E=everybody; L=\\"Loves\\"; fudge=\\012;";')
   >>> print(C)
   Set-Cookie: keebler="E=everybody; L=\"Loves\"; fudge=\012;"

Each element of the Cookie also supports all of the RFC 2109
Cookie attributes.  Here's an example which sets the Path
attribute.

   >>> C = cookies.SimpleCookie()
   >>> C["oreo"] = "doublestuff"
   >>> C["oreo"]["path"] = "/"
   >>> print(C)
   Set-Cookie: oreo=doublestuff; Path=/

Each dictionary element has a 'value' attribute, which gives you
back the value associated with the key.

   >>> C = cookies.SimpleCookie()
   >>> C["twix"] = "none for you"
   >>> C["twix"].value
   'none for you'

The SimpleCookie expects that all values should be standard strings.
Just to be sure, SimpleCookie invokes the str() builtin to convert
the value to a string, when the values are set dictionary-style.

   >>> C = cookies.SimpleCookie()
   >>> C["number"] = 7
   >>> C["string"] = "seven"
   >>> C["number"].value
   '7'
   >>> C["string"].value
   'seven'
   >>> C.output()
   'Set-Cookie: number=7\r\nSet-Cookie: string=seven'

Finis.
'u'
Here's a sample session to show how to use this module.
At the moment, this is the only documentation.

The Basics
----------

Importing is easy...

   >>> from http import cookies

Most of the time you start by creating a cookie.

   >>> C = cookies.SimpleCookie()

Once you've created your Cookie, you can add values just as if it were
a dictionary.

   >>> C = cookies.SimpleCookie()
   >>> C["fig"] = "newton"
   >>> C["sugar"] = "wafer"
   >>> C.output()
   'Set-Cookie: fig=newton\r\nSet-Cookie: sugar=wafer'

Notice that the printable representation of a Cookie is the
appropriate format for a Set-Cookie: header.  This is the
default behavior.  You can change the header and printed
attributes by using the .output() function

   >>> C = cookies.SimpleCookie()
   >>> C["rocky"] = "road"
   >>> C["rocky"]["path"] = "/cookie"
   >>> print(C.output(header="Cookie:"))
   Cookie: rocky=road; Path=/cookie
   >>> print(C.output(attrs=[], header="Cookie:"))
   Cookie: rocky=road

The load() method of a Cookie extracts cookies from a string.  In a
CGI script, you would use this method to extract the cookies from the
HTTP_COOKIE environment variable.

   >>> C = cookies.SimpleCookie()
   >>> C.load("chips=ahoy; vienna=finger")
   >>> C.output()
   'Set-Cookie: chips=ahoy\r\nSet-Cookie: vienna=finger'

The load() method is darn-tootin smart about identifying cookies
within a string.  Escaped quotation marks, nested semicolons, and other
such trickeries do not confuse it.

   >>> C = cookies.SimpleCookie()
   >>> C.load('keebler="E=everybody; L=\\"Loves\\"; fudge=\\012;";')
   >>> print(C)
   Set-Cookie: keebler="E=everybody; L=\"Loves\"; fudge=\012;"

Each element of the Cookie also supports all of the RFC 2109
Cookie attributes.  Here's an example which sets the Path
attribute.

   >>> C = cookies.SimpleCookie()
   >>> C["oreo"] = "doublestuff"
   >>> C["oreo"]["path"] = "/"
   >>> print(C)
   Set-Cookie: oreo=doublestuff; Path=/

Each dictionary element has a 'value' attribute, which gives you
back the value associated with the key.

   >>> C = cookies.SimpleCookie()
   >>> C["twix"] = "none for you"
   >>> C["twix"].value
   'none for you'

The SimpleCookie expects that all values should be standard strings.
Just to be sure, SimpleCookie invokes the str() builtin to convert
the value to a string, when the values are set dictionary-style.

   >>> C = cookies.SimpleCookie()
   >>> C["number"] = 7
   >>> C["string"] = "seven"
   >>> C["number"].value
   '7'
   >>> C["string"].value
   'seven'
   >>> C.output()
   'Set-Cookie: number=7\r\nSet-Cookie: string=seven'

Finis.
'b'CookieError'u'CookieError'b'BaseCookie'u'BaseCookie'b'SimpleCookie'u'SimpleCookie'b'!#$%&'*+-.^_`|~:'u'!#$%&'*+-.^_`|~:'b' ()/<=>?@[]{}'u' ()/<=>?@[]{}'b'\%03o'u'\%03o'b'[%s]+'u'[%s]+'b'Quote a string for use in a cookie header.

    If the string does not need to be double-quoted, then just return the
    string.  Otherwise, surround the string in doublequotes and quote
    (with a \) special characters.
    'u'Quote a string for use in a cookie header.

    If the string does not need to be double-quoted, then just return the
    string.  Otherwise, surround the string in doublequotes and quote
    (with a \) special characters.
    'b'\\[0-3][0-7][0-7]'u'\\[0-3][0-7][0-7]'b'[\\].'u'[\\].'b'%s, %02d %3s %4d %02d:%02d:%02d GMT'u'%s, %02d %3s %4d %02d:%02d:%02d GMT'b'A class to hold ONE (key, value) pair.

    In a cookie, each such pair may have several attributes, so this class is
    used to keep the attributes associated with the appropriate key,value pair.
    This class also includes a coded_value attribute, which is used to hold
    the network representation of the value.
    'u'A class to hold ONE (key, value) pair.

    In a cookie, each such pair may have several attributes, so this class is
    used to keep the attributes associated with the appropriate key,value pair.
    This class also includes a coded_value attribute, which is used to hold
    the network representation of the value.
    'b'Path'u'Path'b'Domain'u'Domain'b'Max-Age'u'Max-Age'b'Secure'u'Secure'b'HttpOnly'u'HttpOnly'b'httponly'u'httponly'b'Version'u'Version'b'SameSite'u'SameSite'b'samesite'u'samesite'b'Invalid attribute %r'u'Invalid attribute %r'b'Attempt to set a reserved key %r'u'Attempt to set a reserved key %r'b'Illegal key %r'u'Illegal key %r'b'coded_value'u'coded_value'b'Set-Cookie:'u'Set-Cookie:'b'<%s: %s>'u'<%s: %s>'b'
        <script type="text/javascript">
        <!-- begin hiding
        document.cookie = "%s";
        // end hiding -->
        </script>
        'u'
        <script type="text/javascript">
        <!-- begin hiding
        document.cookie = "%s";
        // end hiding -->
        </script>
        'b'%s=%d'u'%s=%d'b'\w\d!#%&'~_`><@,:/\$\*\+\-\.\^\|\)\(\?\}\{\='u'\w\d!#%&'~_`><@,:/\$\*\+\-\.\^\|\)\(\?\}\{\='b'\[\]'u'\[\]'b'
    \s*                            # Optional whitespace at start of cookie
    (?P<key>                       # Start of group 'key'
    ['u'
    \s*                            # Optional whitespace at start of cookie
    (?P<key>                       # Start of group 'key'
    ['b']+?   # Any word of at least one letter
    )                              # End of group 'key'
    (                              # Optional group: there may not be a value.
    \s*=\s*                          # Equal Sign
    (?P<val>                         # Start of group 'val'
    "(?:[^\\"]|\\.)*"                  # Any doublequoted string
    |                                  # or
    \w{3},\s[\w\d\s-]{9,11}\s[\d:]{8}\sGMT  # Special case for "expires" attr
    |                                  # or
    ['u']+?   # Any word of at least one letter
    )                              # End of group 'key'
    (                              # Optional group: there may not be a value.
    \s*=\s*                          # Equal Sign
    (?P<val>                         # Start of group 'val'
    "(?:[^\\"]|\\.)*"                  # Any doublequoted string
    |                                  # or
    \w{3},\s[\w\d\s-]{9,11}\s[\d:]{8}\sGMT  # Special case for "expires" attr
    |                                  # or
    ['b']*      # Any word or empty string
    )                                # End of group 'val'
    )?                             # End of optional value group
    \s*                            # Any number of spaces.
    (\s+|;|$)                      # Ending either at space, semicolon, or EOS.
    'u']*      # Any word or empty string
    )                                # End of group 'val'
    )?                             # End of optional value group
    \s*                            # Any number of spaces.
    (\s+|;|$)                      # Ending either at space, semicolon, or EOS.
    'b'A container class for a set of Morsels.'u'A container class for a set of Morsels.'b'real_value, coded_value = value_decode(STRING)
        Called prior to setting a cookie's value from the network
        representation.  The VALUE is the value read from HTTP
        header.
        Override this function to modify the behavior of cookies.
        'u'real_value, coded_value = value_decode(STRING)
        Called prior to setting a cookie's value from the network
        representation.  The VALUE is the value read from HTTP
        header.
        Override this function to modify the behavior of cookies.
        'b'real_value, coded_value = value_encode(VALUE)
        Called prior to setting a cookie's value from the dictionary
        representation.  The VALUE is the value being assigned.
        Override this function to modify the behavior of cookies.
        'u'real_value, coded_value = value_encode(VALUE)
        Called prior to setting a cookie's value from the dictionary
        representation.  The VALUE is the value being assigned.
        Override this function to modify the behavior of cookies.
        'b'Private method for setting a cookie's value'u'Private method for setting a cookie's value'b'Dictionary style assignment.'u'Dictionary style assignment.'b'Return a string suitable for HTTP.'u'Return a string suitable for HTTP.'b'Return a string suitable for JavaScript.'u'Return a string suitable for JavaScript.'b'Load cookies from a string (presumably HTTP_COOKIE) or
        from a dictionary.  Loading cookies from a dictionary 'd'
        is equivalent to calling:
            map(Cookie.__setitem__, d.keys(), d.values())
        'u'Load cookies from a string (presumably HTTP_COOKIE) or
        from a dictionary.  Loading cookies from a dictionary 'd'
        is equivalent to calling:
            map(Cookie.__setitem__, d.keys(), d.values())
        'b'val'u'val'b'
    SimpleCookie supports strings as cookie values.  When setting
    the value using the dictionary assignment notation, SimpleCookie
    calls the builtin str() to convert the value to a string.  Values
    received from HTTP are kept as strings.
    'u'
    SimpleCookie supports strings as cookie values.  When setting
    the value using the dictionary assignment notation, SimpleCookie
    calls the builtin str() to convert the value to a string.  Values
    received from HTTP are kept as strings.
    'u'cookies'
requests.cookies
~~~~~~~~~~~~~~~~

Compatibility code to be able to use `cookielib.CookieJar` with requests.

requests.utils imports from here, so be careful with imports.
dummy_threadingMockRequestWraps a `requests.Request` to mimic a `urllib2.Request`.

    The code in `cookielib.CookieJar` expects this interface in order to correctly
    manage cookie policies, i.e., determine whether a cookie can be set, given the
    domains of the request and the cookie.

    The original request object is read-only. The client is responsible for collecting
    the new headers via `get_new_headers()` and interpreting them appropriately. You
    probably want `get_cookie_header`, defined below.
    _new_headersget_typeget_origin_req_hostis_unverifiablecookielib has no legitimate use for this method; add it back if you find one.Cookie headers should be added with add_unredirected_header()get_new_headersMockResponseWraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.

    ...what? Basically, expose the parsed HTTP headers from the server response
    the way `cookielib` expects to see them.
    Make a MockResponse for `cookielib` to read.

        :param headers: a httplib.HTTPMessage or analogous carrying the headers
        jarExtract the cookies from the response into a CookieJar.

    :param jar: cookielib.CookieJar (not necessarily a RequestsCookieJar)
    :param request: our own requests.Request object
    :param response: urllib3.HTTPResponse object
    _original_responseget_cookie_header
    Produce an appropriate Cookie header string to be sent with `request`, or None.

    :rtype: str
    remove_cookie_by_nameUnsets a cookie by name, by default over all domains and paths.

    Wraps CookieJar.clear(), is O(n).
    clearablesCookieConflictErrorThere are two cookies that meet the criteria specified in the cookie jar.
    Use .get and .set and include domain and path args in order to be more specific.
    RequestsCookieJarCompatibility class; is a cookielib.CookieJar, but exposes a dict
    interface.

    This is the CookieJar we create by default for requests and sessions that
    don't specify one, since some clients may expect response.cookies and
    session.cookies to support dict operations.

    Requests does not use the dict interface internally; it's just for
    compatibility with external client code. All requests code should work
    out of the box with externally provided instances of ``CookieJar``, e.g.
    ``LWPCookieJar`` and ``FileCookieJar``.

    Unlike a regular CookieJar, this class is pickleable.

    .. warning:: dictionary operations that are normally O(1) may be O(n).
    Dict-like get() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.

        .. warning:: operation is O(n), not O(1).
        _find_no_duplicatesDict-like set() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.
        morsel_to_cookiecreate_cookieDict-like iterkeys() that returns an iterator of names of cookies
        from the jar.

        .. seealso:: itervalues() and iteritems().
        Dict-like keys() that returns a list of names of cookies from the
        jar.

        .. seealso:: values() and items().
        Dict-like itervalues() that returns an iterator of values of cookies
        from the jar.

        .. seealso:: iterkeys() and iteritems().
        Dict-like values() that returns a list of values of cookies from the
        jar.

        .. seealso:: keys() and items().
        Dict-like iteritems() that returns an iterator of name-value tuples
        from the jar.

        .. seealso:: iterkeys() and itervalues().
        Dict-like items() that returns a list of name-value tuples from the
        jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
        vanilla python dict of key value pairs.

        .. seealso:: keys() and values().
        list_domainsUtility method to list all the domains in the jar.list_pathsUtility method to list all the paths in the jar.multiple_domainsReturns True if there are multiple domains in the jar.
        Returns False otherwise.

        :rtype: bool
        Takes as an argument an optional domain and path and returns a plain
        old Python dict of name-value pairs of cookies that meet the
        requirements.

        :rtype: dict
        Dict-like __getitem__() for compatibility with client code. Throws
        exception if there are more than one cookie with name. In that case,
        use the more explicit get() method instead.

        .. warning:: operation is O(n), not O(1).
        Dict-like __setitem__ for compatibility with client code. Throws
        exception if there is already a cookie of that name in the jar. In that
        case, use the more explicit set() method instead.
        Deletes a cookie given a name. Wraps ``cookielib.CookieJar``'s
        ``remove_cookie_by_name()``.
        Updates this jar with cookies from another CookieJar or dict-like_findRequests uses this method internally to get cookie values.

        If there are conflicting cookies, _find arbitrarily chooses one.
        See _find_no_duplicates if you want an exception thrown if there are
        conflicting cookies.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :return: cookie.value
        name=, domain=, path=Both ``__get_item__`` and ``get`` call this function: it's never
        used elsewhere in Requests.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :raises KeyError: if cookie is not found
        :raises CookieConflictError: if there are multiple cookies
            that match name and optionally domain and path
        :return: cookie.value
        toReturnThere are multiple cookies with name, Unlike a normal CookieJar, this class is pickleable.Return a copy of this RequestsCookieJar.new_cjget_policyReturn the CookiePolicy instance used._copy_cookie_jarnew_jarMake a cookie from underspecified parameters.

    By default, the pair of `name` and `value` will be set for the domain ''
    and sent on every request (this is sometimes called a "supercookie").
    badargscreate_cookie() got unexpected keyword arguments: Convert a Morsel object into a Cookie containing the one k/v pair.max-age:  must be integer%a, %d-%b-%Y %H:%M:%S GMTtime_templatecookiejar_from_dictcookie_dictoverwriteReturns a CookieJar from a key/value dictionary.

    :param cookie_dict: Dict of key/values to insert into CookieJar.
    :param cookiejar: (optional) A cookiejar to add the cookies to.
    :param overwrite: (optional) If False, will not replace cookies
        already in the jar with new ones.
    :rtype: CookieJar
    names_from_jarmerge_cookiesAdd cookies to cookiejar and returns a merged CookieJar.

    :param cookiejar: CookieJar object to add the cookies to.
    :param cookies: Dictionary or CookieJar object to be added.
    :rtype: CookieJar
    You can only merge into CookieJarcookie_in_jar# Only return the response's URL if the user hadn't set the Host# header# If they did set it, retrieve it and reconstruct the expected domain# Reconstruct the URL as we expect it# the _original_response field is the wrapped httplib.HTTPResponse object,# pull out the HTTPMessage with the headers and put it in the mock:# support client code that unsets cookies by assignment of a None value:# there is only one domain in jar# if there are multiple cookies that meet passed in criteria# we will eventually return this as long as no cookie conflict# remove the unpickleable RLock object# We're dealing with an instance of RequestsCookieJar# We're dealing with a generic CookieJar instanceb'
requests.cookies
~~~~~~~~~~~~~~~~

Compatibility code to be able to use `cookielib.CookieJar` with requests.

requests.utils imports from here, so be careful with imports.
'u'
requests.cookies
~~~~~~~~~~~~~~~~

Compatibility code to be able to use `cookielib.CookieJar` with requests.

requests.utils imports from here, so be careful with imports.
'b'Wraps a `requests.Request` to mimic a `urllib2.Request`.

    The code in `cookielib.CookieJar` expects this interface in order to correctly
    manage cookie policies, i.e., determine whether a cookie can be set, given the
    domains of the request and the cookie.

    The original request object is read-only. The client is responsible for collecting
    the new headers via `get_new_headers()` and interpreting them appropriately. You
    probably want `get_cookie_header`, defined below.
    'u'Wraps a `requests.Request` to mimic a `urllib2.Request`.

    The code in `cookielib.CookieJar` expects this interface in order to correctly
    manage cookie policies, i.e., determine whether a cookie can be set, given the
    domains of the request and the cookie.

    The original request object is read-only. The client is responsible for collecting
    the new headers via `get_new_headers()` and interpreting them appropriately. You
    probably want `get_cookie_header`, defined below.
    'b'cookielib has no legitimate use for this method; add it back if you find one.'u'cookielib has no legitimate use for this method; add it back if you find one.'b'Cookie headers should be added with add_unredirected_header()'u'Cookie headers should be added with add_unredirected_header()'b'Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.

    ...what? Basically, expose the parsed HTTP headers from the server response
    the way `cookielib` expects to see them.
    'u'Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.

    ...what? Basically, expose the parsed HTTP headers from the server response
    the way `cookielib` expects to see them.
    'b'Make a MockResponse for `cookielib` to read.

        :param headers: a httplib.HTTPMessage or analogous carrying the headers
        'u'Make a MockResponse for `cookielib` to read.

        :param headers: a httplib.HTTPMessage or analogous carrying the headers
        'b'Extract the cookies from the response into a CookieJar.

    :param jar: cookielib.CookieJar (not necessarily a RequestsCookieJar)
    :param request: our own requests.Request object
    :param response: urllib3.HTTPResponse object
    'u'Extract the cookies from the response into a CookieJar.

    :param jar: cookielib.CookieJar (not necessarily a RequestsCookieJar)
    :param request: our own requests.Request object
    :param response: urllib3.HTTPResponse object
    'b'_original_response'u'_original_response'b'
    Produce an appropriate Cookie header string to be sent with `request`, or None.

    :rtype: str
    'u'
    Produce an appropriate Cookie header string to be sent with `request`, or None.

    :rtype: str
    'b'Unsets a cookie by name, by default over all domains and paths.

    Wraps CookieJar.clear(), is O(n).
    'u'Unsets a cookie by name, by default over all domains and paths.

    Wraps CookieJar.clear(), is O(n).
    'b'There are two cookies that meet the criteria specified in the cookie jar.
    Use .get and .set and include domain and path args in order to be more specific.
    'u'There are two cookies that meet the criteria specified in the cookie jar.
    Use .get and .set and include domain and path args in order to be more specific.
    'b'Compatibility class; is a cookielib.CookieJar, but exposes a dict
    interface.

    This is the CookieJar we create by default for requests and sessions that
    don't specify one, since some clients may expect response.cookies and
    session.cookies to support dict operations.

    Requests does not use the dict interface internally; it's just for
    compatibility with external client code. All requests code should work
    out of the box with externally provided instances of ``CookieJar``, e.g.
    ``LWPCookieJar`` and ``FileCookieJar``.

    Unlike a regular CookieJar, this class is pickleable.

    .. warning:: dictionary operations that are normally O(1) may be O(n).
    'u'Compatibility class; is a cookielib.CookieJar, but exposes a dict
    interface.

    This is the CookieJar we create by default for requests and sessions that
    don't specify one, since some clients may expect response.cookies and
    session.cookies to support dict operations.

    Requests does not use the dict interface internally; it's just for
    compatibility with external client code. All requests code should work
    out of the box with externally provided instances of ``CookieJar``, e.g.
    ``LWPCookieJar`` and ``FileCookieJar``.

    Unlike a regular CookieJar, this class is pickleable.

    .. warning:: dictionary operations that are normally O(1) may be O(n).
    'b'Dict-like get() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.

        .. warning:: operation is O(n), not O(1).
        'u'Dict-like get() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.

        .. warning:: operation is O(n), not O(1).
        'b'Dict-like set() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.
        'u'Dict-like set() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.
        'b'Dict-like iterkeys() that returns an iterator of names of cookies
        from the jar.

        .. seealso:: itervalues() and iteritems().
        'u'Dict-like iterkeys() that returns an iterator of names of cookies
        from the jar.

        .. seealso:: itervalues() and iteritems().
        'b'Dict-like keys() that returns a list of names of cookies from the
        jar.

        .. seealso:: values() and items().
        'u'Dict-like keys() that returns a list of names of cookies from the
        jar.

        .. seealso:: values() and items().
        'b'Dict-like itervalues() that returns an iterator of values of cookies
        from the jar.

        .. seealso:: iterkeys() and iteritems().
        'u'Dict-like itervalues() that returns an iterator of values of cookies
        from the jar.

        .. seealso:: iterkeys() and iteritems().
        'b'Dict-like values() that returns a list of values of cookies from the
        jar.

        .. seealso:: keys() and items().
        'u'Dict-like values() that returns a list of values of cookies from the
        jar.

        .. seealso:: keys() and items().
        'b'Dict-like iteritems() that returns an iterator of name-value tuples
        from the jar.

        .. seealso:: iterkeys() and itervalues().
        'u'Dict-like iteritems() that returns an iterator of name-value tuples
        from the jar.

        .. seealso:: iterkeys() and itervalues().
        'b'Dict-like items() that returns a list of name-value tuples from the
        jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
        vanilla python dict of key value pairs.

        .. seealso:: keys() and values().
        'u'Dict-like items() that returns a list of name-value tuples from the
        jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
        vanilla python dict of key value pairs.

        .. seealso:: keys() and values().
        'b'Utility method to list all the domains in the jar.'u'Utility method to list all the domains in the jar.'b'Utility method to list all the paths in the jar.'u'Utility method to list all the paths in the jar.'b'Returns True if there are multiple domains in the jar.
        Returns False otherwise.

        :rtype: bool
        'u'Returns True if there are multiple domains in the jar.
        Returns False otherwise.

        :rtype: bool
        'b'Takes as an argument an optional domain and path and returns a plain
        old Python dict of name-value pairs of cookies that meet the
        requirements.

        :rtype: dict
        'u'Takes as an argument an optional domain and path and returns a plain
        old Python dict of name-value pairs of cookies that meet the
        requirements.

        :rtype: dict
        'b'Dict-like __getitem__() for compatibility with client code. Throws
        exception if there are more than one cookie with name. In that case,
        use the more explicit get() method instead.

        .. warning:: operation is O(n), not O(1).
        'u'Dict-like __getitem__() for compatibility with client code. Throws
        exception if there are more than one cookie with name. In that case,
        use the more explicit get() method instead.

        .. warning:: operation is O(n), not O(1).
        'b'Dict-like __setitem__ for compatibility with client code. Throws
        exception if there is already a cookie of that name in the jar. In that
        case, use the more explicit set() method instead.
        'u'Dict-like __setitem__ for compatibility with client code. Throws
        exception if there is already a cookie of that name in the jar. In that
        case, use the more explicit set() method instead.
        'b'Deletes a cookie given a name. Wraps ``cookielib.CookieJar``'s
        ``remove_cookie_by_name()``.
        'u'Deletes a cookie given a name. Wraps ``cookielib.CookieJar``'s
        ``remove_cookie_by_name()``.
        'b'startswith'u'startswith'b'Updates this jar with cookies from another CookieJar or dict-like'u'Updates this jar with cookies from another CookieJar or dict-like'b'Requests uses this method internally to get cookie values.

        If there are conflicting cookies, _find arbitrarily chooses one.
        See _find_no_duplicates if you want an exception thrown if there are
        conflicting cookies.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :return: cookie.value
        'u'Requests uses this method internally to get cookie values.

        If there are conflicting cookies, _find arbitrarily chooses one.
        See _find_no_duplicates if you want an exception thrown if there are
        conflicting cookies.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :return: cookie.value
        'b'name='u'name='b', domain='u', domain='b', path='u', path='b'Both ``__get_item__`` and ``get`` call this function: it's never
        used elsewhere in Requests.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :raises KeyError: if cookie is not found
        :raises CookieConflictError: if there are multiple cookies
            that match name and optionally domain and path
        :return: cookie.value
        'u'Both ``__get_item__`` and ``get`` call this function: it's never
        used elsewhere in Requests.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :raises KeyError: if cookie is not found
        :raises CookieConflictError: if there are multiple cookies
            that match name and optionally domain and path
        :return: cookie.value
        'b'There are multiple cookies with name, 'u'There are multiple cookies with name, 'b'Unlike a normal CookieJar, this class is pickleable.'u'Unlike a normal CookieJar, this class is pickleable.'b'_cookies_lock'u'_cookies_lock'b'Return a copy of this RequestsCookieJar.'u'Return a copy of this RequestsCookieJar.'b'Return the CookiePolicy instance used.'u'Return the CookiePolicy instance used.'b'Make a cookie from underspecified parameters.

    By default, the pair of `name` and `value` will be set for the domain ''
    and sent on every request (this is sometimes called a "supercookie").
    'u'Make a cookie from underspecified parameters.

    By default, the pair of `name` and `value` will be set for the domain ''
    and sent on every request (this is sometimes called a "supercookie").
    'b'rest'b'rfc2109'u'rfc2109'b'create_cookie() got unexpected keyword arguments: 'u'create_cookie() got unexpected keyword arguments: 'b'Convert a Morsel object into a Cookie containing the one k/v pair.'u'Convert a Morsel object into a Cookie containing the one k/v pair.'b'max-age: 'u'max-age: 'b' must be integer'u' must be integer'b'%a, %d-%b-%Y %H:%M:%S GMT'u'%a, %d-%b-%Y %H:%M:%S GMT'b'Returns a CookieJar from a key/value dictionary.

    :param cookie_dict: Dict of key/values to insert into CookieJar.
    :param cookiejar: (optional) A cookiejar to add the cookies to.
    :param overwrite: (optional) If False, will not replace cookies
        already in the jar with new ones.
    :rtype: CookieJar
    'u'Returns a CookieJar from a key/value dictionary.

    :param cookie_dict: Dict of key/values to insert into CookieJar.
    :param cookiejar: (optional) A cookiejar to add the cookies to.
    :param overwrite: (optional) If False, will not replace cookies
        already in the jar with new ones.
    :rtype: CookieJar
    'b'Add cookies to cookiejar and returns a merged CookieJar.

    :param cookiejar: CookieJar object to add the cookies to.
    :param cookies: Dictionary or CookieJar object to be added.
    :rtype: CookieJar
    'u'Add cookies to cookiejar and returns a merged CookieJar.

    :param cookiejar: CookieJar object to add the cookies to.
    :param cookies: Dictionary or CookieJar object to be added.
    :rtype: CookieJar
    'b'You can only merge into CookieJar'u'You can only merge into CookieJar'u'requests.cookies'Generic (shallow and deep) copying operations.

Interface summary:

        import copy

        x = copy.copy(y)        # make a shallow copy of y
        x = copy.deepcopy(y)    # make a deep copy of y

For module specific errors, copy.Error is raised.

The difference between shallow and deep copying is only relevant for
compound objects (objects that contain other objects, like lists or
class instances).

- A shallow copy constructs a new compound object and then (to the
  extent possible) inserts *the same objects* into it that the
  original contains.

- A deep copy constructs a new compound object and then, recursively,
  inserts *copies* into it of the objects found in the original.

Two problems often exist with deep copy operations that don't exist
with shallow copy operations:

 a) recursive objects (compound objects that, directly or indirectly,
    contain a reference to themselves) may cause a recursive loop

 b) because deep copy copies *everything* it may copy too much, e.g.
    administrative data structures that should be shared even between
    copies

Python's deep copy operation avoids these problems by:

 a) keeping a table of objects already copied during the current
    copying pass

 b) letting user-defined classes override the copying operation or the
    set of components copied

This version does not copy types like module, class, function, method,
nor stack trace, stack frame, nor file, socket, window, nor any
similar types.

Classes can use the same interfaces to control copying that they use
to control pickling: they can define methods called __getinitargs__(),
__getstate__() and __setstate__().  See the documentation for module
"pickle" for information on these methods.
org.python.corePyStringMapShallow copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    _copy_dispatchcopier_copy_immutablereductorun(shallow)copyable object of type %s_reconstructCodeType_nilDeep copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    _deepcopy_dispatch_deepcopy_atomicun(deep)copyable object of type %s_keep_alive_deepcopy_list_deepcopy_tuple_deepcopy_dict_deepcopy_methodKeeps a reference to the object x in the memo.

    Because we remember objects by their id, we have
    to assure that possibly temporary objects are kept
    alive by referencing them.
    We store a reference at the id of the memo, which should
    normally not be used unless someone tries to deepcopy
    the memo itself...
    listiterdictiterdeepslotstate# backward compatibility# treat it as a regular class:# If is its own copy, don't memoize.# Make sure x lives at least as long as d# We're not going to put the tuple in the memo, but it's still important we# check for it, in case the tuple contains recursive mutable structures.# Copy instance methods# aha, this is the first one :-)b'Generic (shallow and deep) copying operations.

Interface summary:

        import copy

        x = copy.copy(y)        # make a shallow copy of y
        x = copy.deepcopy(y)    # make a deep copy of y

For module specific errors, copy.Error is raised.

The difference between shallow and deep copying is only relevant for
compound objects (objects that contain other objects, like lists or
class instances).

- A shallow copy constructs a new compound object and then (to the
  extent possible) inserts *the same objects* into it that the
  original contains.

- A deep copy constructs a new compound object and then, recursively,
  inserts *copies* into it of the objects found in the original.

Two problems often exist with deep copy operations that don't exist
with shallow copy operations:

 a) recursive objects (compound objects that, directly or indirectly,
    contain a reference to themselves) may cause a recursive loop

 b) because deep copy copies *everything* it may copy too much, e.g.
    administrative data structures that should be shared even between
    copies

Python's deep copy operation avoids these problems by:

 a) keeping a table of objects already copied during the current
    copying pass

 b) letting user-defined classes override the copying operation or the
    set of components copied

This version does not copy types like module, class, function, method,
nor stack trace, stack frame, nor file, socket, window, nor any
similar types.

Classes can use the same interfaces to control copying that they use
to control pickling: they can define methods called __getinitargs__(),
__getstate__() and __setstate__().  See the documentation for module
"pickle" for information on these methods.
'u'Generic (shallow and deep) copying operations.

Interface summary:

        import copy

        x = copy.copy(y)        # make a shallow copy of y
        x = copy.deepcopy(y)    # make a deep copy of y

For module specific errors, copy.Error is raised.

The difference between shallow and deep copying is only relevant for
compound objects (objects that contain other objects, like lists or
class instances).

- A shallow copy constructs a new compound object and then (to the
  extent possible) inserts *the same objects* into it that the
  original contains.

- A deep copy constructs a new compound object and then, recursively,
  inserts *copies* into it of the objects found in the original.

Two problems often exist with deep copy operations that don't exist
with shallow copy operations:

 a) recursive objects (compound objects that, directly or indirectly,
    contain a reference to themselves) may cause a recursive loop

 b) because deep copy copies *everything* it may copy too much, e.g.
    administrative data structures that should be shared even between
    copies

Python's deep copy operation avoids these problems by:

 a) keeping a table of objects already copied during the current
    copying pass

 b) letting user-defined classes override the copying operation or the
    set of components copied

This version does not copy types like module, class, function, method,
nor stack trace, stack frame, nor file, socket, window, nor any
similar types.

Classes can use the same interfaces to control copying that they use
to control pickling: they can define methods called __getinitargs__(),
__getstate__() and __setstate__().  See the documentation for module
"pickle" for information on these methods.
'b'deepcopy'u'deepcopy'b'Shallow copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    'u'Shallow copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    'b'__copy__'u'__copy__'b'__reduce_ex__'u'__reduce_ex__'b'__reduce__'u'__reduce__'b'un(shallow)copyable object of type %s'u'un(shallow)copyable object of type %s'b'CodeType'u'CodeType'b'Deep copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    'u'Deep copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    'b'__deepcopy__'u'__deepcopy__'b'un(deep)copyable object of type %s'u'un(deep)copyable object of type %s'b'Keeps a reference to the object x in the memo.

    Because we remember objects by their id, we have
    to assure that possibly temporary objects are kept
    alive by referencing them.
    We store a reference at the id of the memo, which should
    normally not be used unless someone tries to deepcopy
    the memo itself...
    'u'Keeps a reference to the object x in the memo.

    Because we remember objects by their id, we have
    to assure that possibly temporary objects are kept
    alive by referencing them.
    We store a reference at the id of the memo, which should
    normally not be used unless someone tries to deepcopy
    the memo itself...
    'b'__setstate__'u'__setstate__'Helper to provide extensibility for pickle.

This is only useful to add pickle support for extension types defined in
C, not for instances of user-defined classes.
constructoradd_extensionremove_extensionclear_extension_cacheob_typepickle_functionconstructor_obreduction functions must be callableconstructors must be callablepickle_complexpickle_union_reconstructor_HEAPTYPE_new_type_reduce_excannot pickle  object object: a class that defines __slots__ without defining __getstate__ cannot be pickled with protocol " object: ""a class that defines __slots__ without ""defining __getstate__ cannot be pickled ""with protocol "__newobj____newobj_ex__Used by pickle protocol 4, instead of __newobj__ to allow classes with
    keyword-only arguments to be pickled correctly.
    _slotnamesReturn a list of slot names for a given class.

    This needs to find slots defined by the class and its bases, so we
    can't simply return the __slots__ attribute.  We must walk down
    the Method Resolution Order and concatenate the __slots__ of each
    class found there.  (This assumes classes don't modify their
    __slots__ attribute to misrepresent their slots after the class is
    defined.)
    __slotnames___%s%s_extension_registry_inverted_registry_extension_cacheRegister an extension code.code out of rangekey %s is already registered with code %scode %s is already in use for key %sUnregister an extension code.  For testing only.key %s is not registered with code %s# The constructor_ob function is a vestige of safe for unpickling.# There is no reason for the caller to pass it anymore.# Example: provide pickling support for complex numbers.# Support for pickling new-style objects# Python code for object.__reduce_ex__ for protocols 0 and 1# not really reachable# Helper for __reduce_ex__ protocol 2# Get the value from a cache in the class if possible# Not cached -- calculate the value# This class has no slots# Slots found -- gather slot names from all base classes# if class has a single slot, it can be given as a string# special descriptors# mangled names# Cache the outcome in the class if at all possible# But don't die if we can't# A registry of extension codes.  This is an ad-hoc compression# mechanism.  Whenever a global reference to <module>, <name> is about# to be pickled, the (<module>, <name>) tuple is looked up here to see# if it is a registered extension code for it.  Extension codes are# universal, so that the meaning of a pickle does not depend on# context.  (There are also some codes reserved for local use that# don't have this restriction.)  Codes are positive ints; 0 is# reserved.# key -> code# code -> key# code -> object# Don't ever rebind those names:  pickling grabs a reference to them when# it's initialized, and won't see a rebinding.# Redundant registrations are benign# Standard extension code assignments# Reserved ranges# First  Last Count  Purpose#     1   127   127  Reserved for Python standard library#   128   191    64  Reserved for Zope#   192   239    48  Reserved for 3rd parties#   240   255    16  Reserved for private use (will never be assigned)#   256   Inf   Inf  Reserved for future assignment# Extension codes are assigned by the Python Software Foundation.b'Helper to provide extensibility for pickle.

This is only useful to add pickle support for extension types defined in
C, not for instances of user-defined classes.
'u'Helper to provide extensibility for pickle.

This is only useful to add pickle support for extension types defined in
C, not for instances of user-defined classes.
'b'constructor'u'constructor'b'add_extension'u'add_extension'b'remove_extension'u'remove_extension'b'clear_extension_cache'u'clear_extension_cache'b'reduction functions must be callable'u'reduction functions must be callable'b'constructors must be callable'u'constructors must be callable'b'__flags__'u'__flags__'b'cannot pickle 'u'cannot pickle 'b' object'u' object'b' object: a class that defines __slots__ without defining __getstate__ cannot be pickled with protocol 'u' object: a class that defines __slots__ without defining __getstate__ cannot be pickled with protocol 'b'Used by pickle protocol 4, instead of __newobj__ to allow classes with
    keyword-only arguments to be pickled correctly.
    'u'Used by pickle protocol 4, instead of __newobj__ to allow classes with
    keyword-only arguments to be pickled correctly.
    'b'Return a list of slot names for a given class.

    This needs to find slots defined by the class and its bases, so we
    can't simply return the __slots__ attribute.  We must walk down
    the Method Resolution Order and concatenate the __slots__ of each
    class found there.  (This assumes classes don't modify their
    __slots__ attribute to misrepresent their slots after the class is
    defined.)
    'u'Return a list of slot names for a given class.

    This needs to find slots defined by the class and its bases, so we
    can't simply return the __slots__ attribute.  We must walk down
    the Method Resolution Order and concatenate the __slots__ of each
    class found there.  (This assumes classes don't modify their
    __slots__ attribute to misrepresent their slots after the class is
    defined.)
    'b'__slotnames__'u'__slotnames__'b'_%s%s'u'_%s%s'b'Register an extension code.'u'Register an extension code.'b'code out of range'u'code out of range'b'key %s is already registered with code %s'u'key %s is already registered with code %s'b'code %s is already in use for key %s'u'code %s is already in use for key %s'b'Unregister an extension code.  For testing only.'u'Unregister an extension code.  For testing only.'b'key %s is not registered with code %s'u'key %s is not registered with code %s'idnadataunicodedata_virama_combining_classxn--_alabel_prefix[.]_unicode_dots_re Base exception for all IDNA-encoding related problems  Exception when bidirectional requirements are not satisfied  Exception when a disallowed or unallocated codepoint is used  Exception when the codepoint is not valid in the context it is used _combining_classcombiningUnknown character in unicodedata_is_scriptscripts_punycodepunycode_unotU+{:04X}trailing_dot254253check_ltrbidi_labelbidirectionalUnknown directionality in label {} at position {}ALANrtlFirst codepoint in label {} must be directionality L, R or ALvalid_endingnumber_typeENESCSETBNNSMInvalid direction for codepoint at position {} in a right-to-left labelCan not mix numeral types in a right-to-left labelInvalid direction for codepoint at position {} in a left-to-right labelLabel ends with illegal codepoint directionalityLabel begins with an illegal combining characterLabel has disallowed hyphens in 3rd and 4th positionLabel must not start or end with a hyphenNFCLabel must be in Normalization Form Ccp_value82040x200cjoining_typesjoining_type82050x200d1830x00b70x006c8850x037515230x05f315240x05f4125390x30fbHan16320x66016410x66917760x6f017850x06f90x6f90x0669Empty Labelcodepoint_classesPVALIDCONTEXTJJoiner {} not allowed at position {} in {}Unknown codepoint adjacent to joiner {} at position {} in {}CONTEXTOCodepoint {} not allowed at position {} in {}Codepoint {} at position {} of {} not allowedlabel_bytesLabel too longNo InputMalformed A-label, no Punycode eligible content foundA-label must not end with a hyphenInvalid A-labelstd3_rulestransitionalRe-map the characters in the string according to UTS46 processing.uts46datacode_pointuts46rowreplacementuts46should pass a unicode string to the function rather than a byte string.labelsEmpty domainEmpty labelDomain too longInvalid ASCII in A-label# Bidi rules should only be applied if string contains RTL characters# String likely comes from a newer version of Unicode# Bidi rule 1# type: Optional[str]# Bidi rule 2# Bidi rule 3# Bidi rule 4# Bidi rule 5# Bidi rule 6b'xn--'u'[.]'b' Base exception for all IDNA-encoding related problems 'u' Base exception for all IDNA-encoding related problems 'b' Exception when bidirectional requirements are not satisfied 'u' Exception when bidirectional requirements are not satisfied 'b' Exception when a disallowed or unallocated codepoint is used 'u' Exception when a disallowed or unallocated codepoint is used 'b' Exception when the codepoint is not valid in the context it is used 'u' Exception when the codepoint is not valid in the context it is used 'b'Unknown character in unicodedata'u'Unknown character in unicodedata'b'punycode'u'punycode'b'U+{:04X}'u'U+{:04X}'b'Unknown directionality in label {} at position {}'u'Unknown directionality in label {} at position {}'b'R'u'R'b'AL'u'AL'b'AN'u'AN'b'First codepoint in label {} must be directionality L, R or AL'u'First codepoint in label {} must be directionality L, R or AL'b'EN'u'EN'b'ES'u'ES'b'CS'u'CS'b'ET'u'ET'b'ON'u'ON'b'BN'u'BN'b'NSM'u'NSM'b'Invalid direction for codepoint at position {} in a right-to-left label'u'Invalid direction for codepoint at position {} in a right-to-left label'b'Can not mix numeral types in a right-to-left label'u'Can not mix numeral types in a right-to-left label'b'Invalid direction for codepoint at position {} in a left-to-right label'u'Invalid direction for codepoint at position {} in a left-to-right label'b'Label ends with illegal codepoint directionality'u'Label ends with illegal codepoint directionality'b'Label begins with an illegal combining character'u'Label begins with an illegal combining character'b'Label has disallowed hyphens in 3rd and 4th position'u'Label has disallowed hyphens in 3rd and 4th position'b'Label must not start or end with a hyphen'u'Label must not start or end with a hyphen'b'NFC'u'NFC'b'Label must be in Normalization Form C'u'Label must be in Normalization Form C'b'T'u'T'b'Han'u'Han'b'Empty Label'u'Empty Label'b'PVALID'u'PVALID'b'CONTEXTJ'u'CONTEXTJ'b'Joiner {} not allowed at position {} in {}'u'Joiner {} not allowed at position {} in {}'b'Unknown codepoint adjacent to joiner {} at position {} in {}'u'Unknown codepoint adjacent to joiner {} at position {} in {}'b'CONTEXTO'u'CONTEXTO'b'Codepoint {} not allowed at position {} in {}'u'Codepoint {} not allowed at position {} in {}'b'Codepoint {} at position {} of {} not allowed'u'Codepoint {} at position {} of {} not allowed'b'Label too long'u'Label too long'b'No Input'u'No Input'b'Malformed A-label, no Punycode eligible content found'u'Malformed A-label, no Punycode eligible content found'b'A-label must not end with a hyphen'u'A-label must not end with a hyphen'b'Invalid A-label'u'Invalid A-label'b'Re-map the characters in the string according to UTS46 processing.'u'Re-map the characters in the string according to UTS46 processing.'b'V'u'V'b'should pass a unicode string to the function rather than a byte string.'u'should pass a unicode string to the function rather than a byte string.'b'Empty domain'u'Empty domain'b'Empty label'u'Empty label'b'Domain too long'u'Domain too long'b'Invalid ASCII in A-label'u'Invalid ASCII in A-label'u'idna.core'u'core'
certifi.py
~~~~~~~~~~

This module returns the installation location of cacert.pem or its contents.
importlib.resources_CACERT_CTX_CACERT_PATHcacert.pemget_pathos.PathLikeResource# This is slightly terrible, but we want to delay extracting the file# in cases where we're inside of a zipimport situation until someone# actually calls where(), but we don't want to re-extract the file# on every call of where(), so we'll do it once then store it in a# global variable.# This is slightly janky, the importlib.resources API wants you to# manage the cleanup of this file, so it doesn't actually return a# path, it returns a context manager that will give you the path# when you enter it and will do any cleanup when you leave it. In# the common case of not needing a temporary file, it will just# return the file system location and the __exit__() is a no-op.# We also have to hold onto the actual context manager, because# it will do the cleanup whenever it gets garbage collected, so# we will also store that at the global level as well.# This is slightly terrible, but we want to delay extracting the# file in cases where we're inside of a zipimport situation until# someone actually calls where(), but we don't want to re-extract# the file on every call of where(), so we'll do it once then store# it in a global variable.# This is slightly janky, the importlib.resources API wants you# to manage the cleanup of this file, so it doesn't actually# return a path, it returns a context manager that will give# you the path when you enter it and will do any cleanup when# you leave it. In the common case of not needing a temporary# file, it will just return the file system location and the# __exit__() is a no-op.# This fallback will work for Python versions prior to 3.7 that lack the# importlib.resources module but relies on the existing `where` function# so won't address issues with environments like PyOxidizer that don't set# __file__ on modules.# If we don't have importlib.resources, then we will just do the old logic# of assuming we're on the filesystem and munge the path directly.b'
certifi.py
~~~~~~~~~~

This module returns the installation location of cacert.pem or its contents.
'u'
certifi.py
~~~~~~~~~~

This module returns the installation location of cacert.pem or its contents.
'b'certifi'b'cacert.pem'u'cacert.pem'b'os.PathLike'u'os.PathLike'u'certifi.core'PYTHONASYNCIODEBUG_DEBUGCoroWrapperisgeneratorextract_stackcoro_repr, created at f_lasti was never yielded from
Coroutine object created at (most recent call last, truncated to '\nCoroutine object created at ''(most recent call last, truncated to ' last lines):
Decorator to mark coroutines.

    If the coroutine is not yielded from before it is destroyed,
    an error message is logged.
    "@coroutine" decorator is deprecated since Python 3.8, use "async def" insteadisgeneratorfunctionawait_meth_is_coroutineReturn True if func is a decorated coroutine function.CoroutineTypeGeneratorType_COROUTINE_TYPES_iscoroutine_typecacheReturn True if obj is a coroutine object.is_corowrapper_format_callbackcoro_name without __name__>cr_runningcoro_codecr_code runningcoro_frame<empty co_filename>_get_function_source done, defined at  running, defined at  running at # If you set _DEBUG to true, @coroutine will wrap the resulting# generator objects in a CoroWrapper instance (defined below).  That# instance will log a message when the generator is never iterated# over, which may happen when you forget to use "await" or "yield from"# with a coroutine call.# Note that the value of the _DEBUG flag is taken# when the decorator is used, so to be of any use it must be set# before you define your coroutines.  A downside of using this feature# is that tracebacks show entries for the CoroWrapper.__next__ method# when _DEBUG is true.# Wrapper for coroutine object in _DEBUG mode.# Used to unwrap @coroutine decorator# Be careful accessing self.gen.frame -- self.gen might not exist.# In Python 3.5 that's all we need to do for coroutines# defined with "async def".# If 'res' is an awaitable, run it.# Python < 3.5 does not implement __qualname__# on generator objects, so we set it manually.# We use getattr as some callables (such as# functools.partial may lack __qualname__).# For iscoroutinefunction().# A marker for iscoroutinefunction.# Prioritize native coroutine check to speed-up# asyncio.iscoroutine.# Just in case we don't want to cache more than 100# positive types.  That shouldn't ever happen, unless# someone stressing the system on purpose.# Coroutines compiled with Cython sometimes don't have# proper __qualname__ or __name__.  While that is a bug# in Cython, asyncio shouldn't crash with an AttributeError# in its __repr__ functions.# Stop masking Cython bugs, expose them in a friendly way.# Built-in types might not have __qualname__ or __name__.# If Cython's coroutine has a fake code object without proper# co_filename -- expose that.b'coroutine'u'coroutine'b'iscoroutinefunction'u'iscoroutinefunction'b'iscoroutine'u'iscoroutine'b'PYTHONASYNCIODEBUG'u'PYTHONASYNCIODEBUG'b', created at 'u', created at 'b'gen'u'gen'b' was never yielded from'u' was never yielded from'b'_source_traceback'u'_source_traceback'b'
Coroutine object created at (most recent call last, truncated to 'u'
Coroutine object created at (most recent call last, truncated to 'b' last lines):
'u' last lines):
'b'Decorator to mark coroutines.

    If the coroutine is not yielded from before it is destroyed,
    an error message is logged.
    'u'Decorator to mark coroutines.

    If the coroutine is not yielded from before it is destroyed,
    an error message is logged.
    'b'"@coroutine" decorator is deprecated since Python 3.8, use "async def" instead'u'"@coroutine" decorator is deprecated since Python 3.8, use "async def" instead'b'Return True if func is a decorated coroutine function.'u'Return True if func is a decorated coroutine function.'b'_is_coroutine'u'_is_coroutine'b'Return True if obj is a coroutine object.'u'Return True if obj is a coroutine object.'b' without __name__>'u' without __name__>'b'cr_code'u'cr_code'b'gi_code'u'gi_code'b' running'u' running'b'<empty co_filename>'u'<empty co_filename>'b' done, defined at 'u' done, defined at 'b' running, defined at 'u' running, defined at 'b' running at 'u' running at 'u'asyncio.coroutines'u'coroutines'getpassdateutil.parserbotocore.configloaderCredentialRetrievalErrorInfiniteLoopConfigErrorInvalidConfigErrorMetadataRetrievalErrorPartialCredentialsErrorRefreshWithMFAUnsupportedErrorUnauthorizedSSOTokenErrorUnknownCredentialErrorbotocore.tokensSSOTokenProviderContainerMetadataFetcherFileWebIdentityTokenLoaderInstanceMetadataFetcherJSONFileCacheSSOTokenLoaderparse_key_val_fileresolve_imds_endpoint_modeReadOnlyCredentials_DEFAULT_MANDATORY_REFRESH_TIMEOUT_DEFAULT_ADVISORY_REFRESH_TIMEOUTcreate_credential_resolverCreate a default credential resolver.

    This creates a pre-configured credential resolver
    that includes the default lookup chain for
    credentials.

    profile_namemetadata_timeoutnum_attemptsdisable_env_varsec2_credential_refresh_windowimds_configEnvProviderenv_providerContainerProvidercontainer_providerInstanceMetadataProvideriam_role_fetcherinstance_metadata_providerProfileProviderBuilderprofile_provider_builderAssumeRoleProviderfull_config_get_client_creatorclient_creatorCanonicalNameCredentialSourcercredential_sourcerassume_role_providerpre_profileprofile_providersOriginalEC2ProviderBotoProviderpost_profileSkipping environment variable credential check because profile name was explicitly set.'Skipping environment variable credential check'' because profile name was explicitly set.'CredentialResolverresolverThis class handles the creation of profile based providers.

    NOTE: This class is only intended for internal use.

    This class handles the creation and ordering of the various credential
    providers that primarly source their configuration from the shared config.
    This is needed to enable sharing between the default credential chain and
    the source profile chain created by the assume role provider.
    sso_token_cache_sso_token_cache_create_web_identity_provider_create_sso_provider_create_shared_credential_provider_create_process_provider_create_config_providerProcessProvidercredential_fileSharedCredentialProvidercreds_filenameConfigProviderAssumeRoleWithWebIdentityProviderSSOProvidertoken_cachetoken_providerget_credentialsload_credentials_local_now_parse_if_needed_serialize_if_needediso%Y-%m-%dT%H:%M:%S%Zcreate_client_kwargscreate_assume_role_refresherrefreshassume_roleCredentialsAccessKeyIdSecretAccessKeySessionTokenExpirationexpiry_timecreate_mfa_serial_refresheractual_refresh_Refresher_refresh_has_been_called
    Holds the credentials needed to authenticate requests.

    :param str access_key: The access key part of the credentials.
    :param str secret_key: The secret key part of the credentials.
    :param str token: The security token, valid only for session credentials.
    :param str method: A string which identifies where the credentials
        were found.
    explicitget_frozen_credentialsRefreshableCredentials
    Holds the credentials needed to authenticate requests. In addition, it
    knows how to refresh itself.

    :param str access_key: The access key part of the credentials.
    :param str secret_key: The secret key part of the credentials.
    :param str token: The security token, valid only for session credentials.
    :param function refresh_using: Callback function to refresh the credentials.
    :param str method: A string which identifies where the credentials
        were found.
    :param function time_fetcher: Callback function to retrieve current time.
    _advisory_refresh_timeout_mandatory_refresh_timeoutrefresh_usingtime_fetcher_refresh_using_access_key_secret_key_token_expiry_time_time_fetcher_refresh_lock_frozen_credentialscreate_from_metadata_expiry_datetimeWarning: Using this property can lead to race conditions if you
        access another property subsequently along the refresh boundary.
        Please use get_frozen_credentials instead.
        _seconds_remainingrefresh_neededrefresh_inCheck if a refresh is needed.

        A refresh is needed if the expiry time associated
        with the temporary credentials is less than the
        provided ``refresh_in``.  If ``time_delta`` is not
        provided, ``self.advisory_refresh_needed`` will be used.

        For example, if your temporary credentials expire
        in 10 minutes and the provided ``refresh_in`` is
        ``15 * 60``, then this function will return ``True``.

        :type refresh_in: int
        :param refresh_in: The number of seconds before the
            credentials expire in which refresh attempts should
            be made.

        :return: True if refresh needed, False otherwise.

        Credentials need to be refreshed._is_expiredis_mandatory_refresh_protected_refreshis_mandatoryadvisoryperiod_nameRefreshing temporary credentials failed during %s refresh period."Refreshing temporary credentials failed ""during %s refresh period."_set_from_dataCredentials were refreshed, but the refreshed credentials are still expired."Credentials were refreshed, but the ""refreshed credentials are still expired."time_strexpected_keysmissing_keysCredential refresh failed, response did not contain: %serror_msgRetrieved credentials will expire at: %sReturn immutable credentials.

        The ``access_key``, ``secret_key``, and ``token`` properties
        on this class will always check and refresh credentials if
        needed before returning the particular credentials.

        This has an edge case where you can get inconsistent
        credentials.  Imagine this:

            # Current creds are "t1"
            tmp.access_key  ---> expired? no, so return t1.access_key
            # ---- time is now expired, creds need refreshing to "t2" ----
            tmp.secret_key  ---> expired? yes, refresh and return t2.secret_key

        This means we're using the access key from t1 with the secret key
        from t2.  To fix this issue, you can request a frozen credential object
        which is guaranteed not to change.

        The frozen credentials returned from this method should be used
        immediately and then discarded.  The typical usage pattern would
        be::

            creds = RefreshableCredentials(...)
            some_code = SomeSignerObject()
            # I'm about to sign the request.
            # The frozen credentials are only used for the
            # duration of generate_presigned_url and will be
            # immediately thrown away.
            request = some_code.sign_some_request(
                with_credentials=creds.get_frozen_credentials())
            print("Signed request:", request)

        DeferredRefreshableCredentialsRefreshable credentials that don't require initial credentials.

    refresh_using will be called upon first access.
    CachedCredentialFetcherDEFAULT_EXPIRY_WINDOW_SECONDSexpiry_window_seconds_create_cache_key_cache_key_expiry_window_seconds_create_cache_key()_make_file_safe_get_credentials_get_credentials()fetch_credentials_get_cached_credentialsGet up-to-date credentials.

        This will check the cache for up-to-date credentials, calling assume
        role if none are available.
        _load_from_cache_write_to_cacheCredentials for role retrieved from cache.credsexpirationCredentials were found in cache, but they are expired.Check if credentials are expired.BaseAssumeRoleCredentialFetcherrole_arn_client_creator_role_arn_assume_kwargsRoleArnRoleSessionName_role_session_name_using_default_session_name_generate_assume_role_namebotocore-session-%sCreate a predictable cache key for the current configuration.

        The cache key is intended to be compatible with file names.
        argument_hashAssumeRoleCredentialFetchersource_credentialsmfa_prompter
        :type client_creator: callable
        :param client_creator: A callable that creates a client taking
            arguments like ``Session.create_client``.

        :type source_credentials: Credentials
        :param source_credentials: The credentials to use to create the
            client for the call to AssumeRole.

        :type role_arn: str
        :param role_arn: The ARN of the role to be assumed.

        :type extra_args: dict
        :param extra_args: Any additional arguments to add to the assume
            role request using the format of the botocore operation.
            Possible keys include, but may not be limited to,
            DurationSeconds, Policy, SerialNumber, ExternalId and
            RoleSessionName.

        :type mfa_prompter: callable
        :param mfa_prompter: A callable that returns input provided by the
            user (i.e raw_input, getpass.getpass, etc.).

        :type cache: dict
        :param cache: An object that supports ``__getitem__``,
            ``__setitem__``, and ``__contains__``.  An example of this is
            the ``JSONFileCache`` class in aws-cli.

        :type expiry_window_seconds: int
        :param expiry_window_seconds: The amount of time, in seconds,
        _source_credentials_mfa_prompterGet credentials by calling assume role._assume_role_kwargs_create_clientGet the arguments for assume role based on current configuration.assume_role_kwargsSerialNumbermfa_serialEnter MFA code for %s: token_codeTokenCodeDurationSecondsduration_secondsCreate an STS client using the source credentials.frozen_credentialsaws_access_key_idaws_secret_access_keyaws_session_tokenAssumeRoleWithWebIdentityCredentialFetcherweb_identity_token_loader
        :type client_creator: callable
        :param client_creator: A callable that creates a client taking
            arguments like ``Session.create_client``.

        :type web_identity_token_loader: callable
        :param web_identity_token_loader: A callable that takes no arguments
        and returns a web identity token str.

        :type role_arn: str
        :param role_arn: The ARN of the role to be assumed.

        :type extra_args: dict
        :param extra_args: Any additional arguments to add to the assume
            role request using the format of the botocore operation.
            Possible keys include, but may not be limited to,
            DurationSeconds, Policy, SerialNumber, ExternalId and
            RoleSessionName.

        :type cache: dict
        :param cache: An object that supports ``__getitem__``,
            ``__setitem__``, and ``__contains__``.  An example of this is
            the ``JSONFileCache`` class in aws-cli.

        :type expiry_window_seconds: int
        :param expiry_window_seconds: The amount of time, in seconds,
        _web_identity_token_loaderassume_role_with_web_identityidentity_tokenWebIdentityTokenCredentialProviderMETHODCANONICAL_NAME
        Loads the credentials from their source & sets them on the object.

        Subclasses should implement this method (by reading from disk, the
        environment, the network or wherever), returning ``True`` if they were
        found & loaded.

        If not found, this method should return ``False``, indictating that the
        ``CredentialResolver`` should fall back to the next available method.

        The default implementation does nothing, assuming the user has set the
        ``access_key/secret_key/token`` themselves.

        :returns: Whether credentials were found & set
        :rtype: Credentials
        _extract_creds_from_mappingkey_namescred_varcustom-process_profile_name_load_config_loaded_config_popen_credential_processcredential_process_retrieve_credentials_usingcreds_dictprocess_list<Version key not provided>Unsupported version '' for credential process provider, supported versions: 1"' for credential process ""provider, supported versions: 1"Missing required key in response: profile_configiam-roleEc2InstanceMetadata_role_fetcherfetcherretrieve_iam_role_credentialsFound credentials from IAM Role: %srole_nameEnvironmentAWS_ACCESS_KEY_IDACCESS_KEYAWS_SECRET_ACCESS_KEYSECRET_KEYAWS_SECURITY_TOKENAWS_SESSION_TOKENTOKENSAWS_CREDENTIAL_EXPIRATIONEXPIRY_TIME

        :param environ: The environment variables (defaults to
            ``os.environ`` if no value is provided).
        :param mapping: An optional mapping of variable names to
            environment variable names.  Use this if you want to
            change the mapping of access_key->AWS_ACCESS_KEY_ID, etc.
            The dict can have up to 3 keys: ``access_key``, ``secret_key``,
            ``session_token``.
        _build_mappingvar_mapping
        Search for credentials in explicit environment variables.
        Found credentials in environment variables._create_credentials_fetcherrequire_expirytoken_env_varec2-credentials-fileEc2ConfigAWS_CREDENTIAL_FILECRED_FILE_ENVAWSSecretKey
        Search for a credential file used by original EC2 CLI tools.
        Found credentials in AWS_CREDENTIAL_FILE.shared-credentials-fileSharedCredentialsaws_security_tokenini_parser_creds_filenameconfigloader_ini_parseravailable_credsFound credentials in shared credentials file: %s_get_session_tokentoken_envvarINI based config provider with profile sections.config-fileSharedConfigconfig_parser

        :param config_filename: The session configuration scoped to the current
            profile.  This is available via ``session.config``.
        :param profile_name: The name of the current profile.
        :param config_parser: A config parser callable.

        _config_filename_config_parser
        If there is are credentials in the configuration associated with
        the session, use those.
        Credentials found in config file: %stoken_nameboto-configBoto2ConfigBOTO_CONFIGBOTO_CONFIG_ENV/etc/boto.cfg~/.botoDEFAULT_CONFIG_FILENAMES
        Look for credentials in boto config file.
        potential_locationsFound credentials in boto config file: %sassume-roleROLE_CONFIG_VARweb_identity_token_fileWEB_IDENTITY_TOKE_FILE_VAREXPIRY_WINDOW_SECONDSprompter
        :type load_config: callable
        :param load_config: A function that accepts no arguments, and
            when called, will return the full configuration dictionary
            for the session (``session.full_config``).

        :type client_creator: callable
        :param client_creator: A factory function that will create
            a client when called.  Has the same interface as
            ``botocore.session.Session.create_client``.

        :type cache: dict
        :param cache: An object that supports ``__getitem__``,
            ``__setitem__``, and ``__contains__``.  An example
            of this is the ``JSONFileCache`` class in the CLI.

        :type profile_name: str
        :param profile_name: The name of the profile.

        :type prompter: callable
        :param prompter: A callable that returns input provided
            by the user (i.e raw_input, getpass.getpass, etc.).

        :type credential_sourcer: CanonicalNameCredentialSourcer
        :param credential_sourcer: A credential provider that takes a
            configuration, which is used to provide the source credentials
            for the STS call.
        _prompter_credential_sourcer_profile_provider_builder_visited_profiles_has_assume_role_config_vars_load_creds_via_assume_role_get_role_configrole_config_resolve_source_credentialsrole_session_nameexternal_idExternalIdrefresherRetrieves and validates the role configuration for the profile.source_profilecredential_sourceThe profile "%s" contains both source_profile and credential_source.'The profile "%s" contains both source_profile and ''credential_source.'source_profile or credential_source_validate_credential_source_validate_source_profileparent_profileThe credential_source "" is specified in profile ""\" is specified ""in profile \""", but no source provider was configured."\", ""but no source provider was configured."is_supportedThe credential source "" referenced in profile ""\" referenced "" is not valid._source_profile_has_credentials_has_static_credentialsparent_profile_namesource_profile_nameThe source_profile "" referenced in the profile ""\" referenced in ""the profile \""" does not exist.visited_profilesstatic_keysstatic_key_resolve_credentials_from_source_resolve_credentials_from_profile_resolve_static_credentials_from_profileprofile_chainThe source profile "%s" must have credentials.error_messageNo credentials found in credential_source referenced in profile %s'No credentials found in credential_source referenced ''in profile %s'assume-role-with-web-identityAWS_WEB_IDENTITY_TOKEN_FILEAWS_ROLE_SESSION_NAMEAWS_ROLE_ARN_CONFIG_TO_ENV_VARtoken_loader_cls_profile_config_disable_env_vars_token_loader_cls_assume_role_with_web_identity_get_profile_configloaded_config_get_env_configenv_key_get_configenv_valuetoken_pathtoken_loaderThe provided profile or the current environment is configured to assume role with web identity but has no role ARN configured. Ensure that the profile has the role_arnconfiguration set or the AWS_ROLE_ARN env var is set.'The provided profile or the current environment is ''configured to assume role with web identity but has no ''role ARN configured. Ensure that the profile has the role_arn''configuration set or the AWS_ROLE_ARN env var is set.'source_nameValidates a given source name.

        :type source_name: str
        :param source_name: The value of credential_source in the config
            file. This is the canonical name of the credential provider.

        :rtype: bool
        :returns: True if the credential provider is supported,
            False otherwise.
        Loads source credentials based on the provided configuration.

        :type source_name: str
        :param source_name: The value of credential_source in the config
            file. This is the canonical name of the credential provider.

        :rtype: Credentials
        _get_providercanonical_nameReturn a credential provider by its canonical name.

        :type canonical_name: str
        :param canonical_name: The canonical name of the provider.

        :raises UnknownCredentialError: Raised if no
            credential provider by the provided name
            is found.
        _get_provider_by_canonical_namesharedconfigsharedcredentials_get_provider_by_methodReturn a credential provider by its canonical name.

        This function is strict, it does not attempt to address
        compatibility issues.
        Return a credential provider by its METHOD name.container-roleEcsContainerAWS_CONTAINER_CREDENTIALS_RELATIVE_URIENV_VARAWS_CONTAINER_CREDENTIALS_FULL_URIENV_VAR_FULLAWS_CONTAINER_AUTHORIZATION_TOKENENV_VAR_AUTH_TOKEN_fetcher_retrieve_or_fail_provided_relative_urifull_urlfull_uri_build_headers_create_fetcherfetch_credsretrieve_full_uriError retrieving container metadata: %s

        :param providers: A list of ``CredentialProvider`` instances.

        insert_beforecredential_provider
        Inserts a new instance of ``CredentialProvider`` into the chain that
        will be tried before an existing one.

        :param name: The short name of the credentials you'd like to insert the
            new credentials before. (ex. ``env`` or ``config``). Existing names
            & ordering can be discovered via ``self.available_methods``.
        :type name: string

        :param cred_instance: An instance of the new ``Credentials`` object
            you'd like to add to the chain.
        :type cred_instance: A subclass of ``Credentials``
        insert_after
        Inserts a new type of ``Credentials`` instance into the chain that will
        be tried after an existing one.

        :param name: The short name of the credentials you'd like to insert the
            new credentials after. (ex. ``env`` or ``config``). Existing names
            & ordering can be discovered via ``self.available_methods``.
        :type name: string

        :param cred_instance: An instance of the new ``Credentials`` object
            you'd like to add to the chain.
        :type cred_instance: A subclass of ``Credentials``
        _get_provider_offset
        Removes a given ``Credentials`` instance from the chain.

        :param name: The short name of the credentials instance to remove.
        :type name: string
        available_methodsget_providerReturn a credential provider by name.

        :type name: str
        :param name: The name of the provider.

        :raises UnknownCredentialError: Raised if no
            credential provider by the provided name
            is found.
        
        Goes through the credentials chain, returning the first ``Credentials``
        that could be loaded.
        Looking for credentials via: %sSSOCredentialFetcher_UTC_DATE_FORMATstart_urlsso_regionaccount_idsso_session_name_sso_region_role_name_account_id_start_url_token_loader_token_provider_sso_session_nameroleNameaccountIdsessionNamestartUrl_parse_timestamptimestamp_mstimestamp_secondsGet credentials by calling SSO get role credentials.ssoload_tokeninitial_token_dataget_frozen_tokenaccessTokenget_role_credentialsUnauthorizedExceptionroleCredentialsProviderTypeaccessKeyIdsecretAccessKeysessionToken.aws_SSO_TOKEN_CACHE_DIRsso_role_namesso_account_id_PROFILE_REQUIRED_CONFIG_VARSsso_start_url_SSO_REQUIRED_CONFIG_VARS_ALL_REQUIRED_CONFIG_VARS_token_cache_load_sso_config_resolve_sso_session_referenceresolved_configextra_reqsmissing_config_varsall_required_configsThe profile "%s" is configured to use SSO but is missing required configuration: %s'The profile "%s" is configured to use SSO but is missing ''required configuration: %s'sso_sessionThe specified sso-session does not exist: "The value for  is inconsistent between profile (" is inconsistent between ""profile (") and sso-session ().sso_configfetcher_kwargssso_fetcher# 10 min# 15 min# An explicitly provided profile will negate an EnvProvider.# We will defer to providers that understand the "profile"# concept to retrieve credentials.# The one edge case if is all three values are provided via# env vars:# export AWS_ACCESS_KEY_ID=foo# export AWS_SECRET_ACCESS_KEY=bar# export AWS_PROFILE=baz# Then, just like our client() calls, the explicit credentials# will take precedence.# This precedence is enforced by leaving the EnvProvider in the chain.# This means that the only way a "profile" would win is if the# EnvProvider does not return credentials, which is what we want# in this scenario.# We need to normalize the credential names to# the values expected by the refresh creds.# We can explore an option in the future to support# reprompting for MFA, but for now we just error out# when the temp creds expire.# Keys would sometimes (accidentally) contain non-ascii characters.# It would cause a confusing UnicodeDecodeError in Python 2.# We explicitly convert them into unicode to avoid such error.# Eventually the service will decide whether to accept the credential.# This also complies with the behavior in Python 3.# The time at which we'll attempt to refresh, but not# block if someone else is refreshing.# The time at which all threads will block waiting for# refreshed credentials.# No expiration, so assume we don't need to refresh.# The credentials should be refreshed if they're going to expire# in less than 5 minutes.# There's enough time left. Don't refresh.# Checks if the current credentials are expired.# In the common case where we don't need a refresh, we# can immediately exit and not require acquiring the# refresh lock.# acquire() doesn't accept kwargs, but False is indicating# that we should not block if we can't acquire the lock.# If we aren't able to acquire the lock, we'll trigger# the else clause.# If we're within the mandatory refresh window,# we must block until we get refreshed credentials.# precondition: this method should only be called if you've acquired# the self._refresh_lock.# If this is a mandatory refresh, then# all errors that occur when we attempt to refresh# credentials are propagated back to the user.# Otherwise we'll just return.# The end result will be that we'll use the current# set of temporary credentials we have.# We successfully refreshed credentials but for whatever# reason, our refreshing function returned credentials# that are still expired.  In this scenario, the only# thing we can do is let the user know and raise# an exception.# Replace :, path sep, and / to make it the string filename safe.# The role session name gets randomly generated, so we don't want it# in the hash.# To have a predictable hash, the keys of the policy must be# sorted, so we have to load it here to make sure it gets sorted# later on.# Assume role with web identity does not require credentials other than# the token, explicitly configure the client to not sign requests.# A short name to identify the provider within botocore.# A name to identify the provider for use in cross-sdk features like# assume role's `credential_source` configuration option. These names# are to be treated in a case-insensitive way. NOTE: any providers not# implemented in botocore MUST prefix their canonical names with# 'custom' or we DO NOT guarantee that it will work with any features# that this provides.# We're not using shell=True, so we need to pass the# command and all arguments as a list.# We do the first request, to see if we get useful data back.# If not, we'll pass & move on to whatever's next in the credential# chain.# We manually set the data here, since we already made the request &# have it. When the expiry is hit, the credentials will auto-refresh# themselves.# The token can come from either of these env var.# AWS_SESSION_TOKEN is what other AWS SDKs have standardized on.# Mapping of variable name to env var name.# Use the class var default.# EC2 creds file doesn't support session tokens.# Same deal as the EnvProvider above.  Botocore originally supported# aws_security_token, but the SDKs are standardizing on aws_session_token# so we support both.# Move on to the next potential config file name.# The AssumeRole provider is logically part of the SharedConfig and# SharedCredentials providers. Since the purpose of the canonical name# is to provide cross-sdk compatibility, calling code will need to be# aware that either of those providers should be tied to the AssumeRole# provider as much as possible.# Credentials are considered expired (and will be refreshed) once the total# remaining time left until the credentials expires is less than the# EXPIRY_WINDOW.#: The cache used to first check for assumed credentials.#: This is checked before making the AssumeRole API#: calls and can be useful if you have short lived#: scripts and you'd like to avoid calling AssumeRole#: until the credentials are expired.# client_creator is a callable that creates function.# It's basically session.create_client# The _loaded_config attribute will be populated from the# load_config() function once the configuration is actually# loaded.  The reason we go through all this instead of just# requiring that the loaded_config be passed to us is to that# we can defer configuration loaded until we actually try# to load credentials (as opposed to when the object is# instantiated).# We need to ensure this provider doesn't look at a profile when# the profile has configuration for web identity. Simply relying on# the order in the credential chain is insufficient as it doesn't# prevent the case when we're doing an assume role chain.# The initial credentials are empty and the expiration time is set# to now so that we can delay the call to assume role until it is# strictly needed.# Either the credential source or the source profile must be# specified, but not both.# Make sure we aren't going into an infinite loop. If we haven't# visited the profile yet, we're good.# If we have visited the profile and the profile isn't simply# referencing itself, that's an infinite loop.# A profile is allowed to reference itself so that it can source# static credentials and have configuration all in the same# profile. This will only ever work for the top level assume# role because the static credentials will otherwise take# precedence.# This is only here for backwards compatibility. If this provider# isn't given a profile provider builder we still want to be able# handle the basic static credential case as we would before the# provile provider builder parameter was added.# The AssumeRole provider should really be part of the SharedConfig# provider rather than being its own thing, but it is not. It is# effectively part of both the SharedConfig provider and the# SharedCredentials provider now due to the way it behaves.# Therefore if we want either of those providers we should return# the AssumeRole provider with it.# The SharedConfig or SharedCredentials provider may not be# present if it was removed for some reason, but the# AssumeRole provider could still be present. In that case,# return the assume role provider by itself.# If both are present, return them both as a# CredentialResolver so that calling code can treat them as# a single entity.# Canonical names are case-insensitive# This cred provider is only triggered if the self.ENV_VAR is set,# which only happens if you opt into this feature.# It's not present. Fail silently.# First provider to return a non-None response wins.# If we got here, no credentials could be found.# This feels like it should be an exception, but historically, ``None``# is returned.# +1# -js# NOTE: It would be good to hoist this cache key construction logic# into the CachedCredentialFetcher class as we should be consistent.# Unfortunately, the current assume role fetchers that sub class don't# pass separators resulting in non-minified JSON. In the long term,# all fetchers should use the below caching scheme.# fromtimestamp expects seconds so: milliseconds / 1000 = seconds# Role name & Account ID indicate the cred provider should be used# No reference to resolve, proceed with legacy flow# Validate any keys referenced in both profile and sso_session matchb'ReadOnlyCredentials'u'ReadOnlyCredentials'b'access_key'u'access_key'b'secret_key'u'secret_key'b'Create a default credential resolver.

    This creates a pre-configured credential resolver
    that includes the default lookup chain for
    credentials.

    'u'Create a default credential resolver.

    This creates a pre-configured credential resolver
    that includes the default lookup chain for
    credentials.

    'b'ec2_credential_refresh_window'u'ec2_credential_refresh_window'b'Skipping environment variable credential check because profile name was explicitly set.'u'Skipping environment variable credential check because profile name was explicitly set.'b'This class handles the creation of profile based providers.

    NOTE: This class is only intended for internal use.

    This class handles the creation and ordering of the various credential
    providers that primarly source their configuration from the shared config.
    This is needed to enable sharing between the default credential chain and
    the source profile chain created by the assume role provider.
    'u'This class handles the creation of profile based providers.

    NOTE: This class is only intended for internal use.

    This class handles the creation and ordering of the various credential
    providers that primarly source their configuration from the shared config.
    This is needed to enable sharing between the default credential chain and
    the source profile chain created by the assume role provider.
    'b'%Y-%m-%dT%H:%M:%S%Z'u'%Y-%m-%dT%H:%M:%S%Z'b'Credentials'u'Credentials'b'AccessKeyId'u'AccessKeyId'b'SecretAccessKey'u'SecretAccessKey'b'SessionToken'u'SessionToken'b'Expiration'u'Expiration'b'expiry_time'u'expiry_time'b'
    Holds the credentials needed to authenticate requests.

    :param str access_key: The access key part of the credentials.
    :param str secret_key: The secret key part of the credentials.
    :param str token: The security token, valid only for session credentials.
    :param str method: A string which identifies where the credentials
        were found.
    'u'
    Holds the credentials needed to authenticate requests.

    :param str access_key: The access key part of the credentials.
    :param str secret_key: The secret key part of the credentials.
    :param str token: The security token, valid only for session credentials.
    :param str method: A string which identifies where the credentials
        were found.
    'b'explicit'u'explicit'b'
    Holds the credentials needed to authenticate requests. In addition, it
    knows how to refresh itself.

    :param str access_key: The access key part of the credentials.
    :param str secret_key: The secret key part of the credentials.
    :param str token: The security token, valid only for session credentials.
    :param function refresh_using: Callback function to refresh the credentials.
    :param str method: A string which identifies where the credentials
        were found.
    :param function time_fetcher: Callback function to retrieve current time.
    'u'
    Holds the credentials needed to authenticate requests. In addition, it
    knows how to refresh itself.

    :param str access_key: The access key part of the credentials.
    :param str secret_key: The secret key part of the credentials.
    :param str token: The security token, valid only for session credentials.
    :param function refresh_using: Callback function to refresh the credentials.
    :param str method: A string which identifies where the credentials
        were found.
    :param function time_fetcher: Callback function to retrieve current time.
    'b'Warning: Using this property can lead to race conditions if you
        access another property subsequently along the refresh boundary.
        Please use get_frozen_credentials instead.
        'u'Warning: Using this property can lead to race conditions if you
        access another property subsequently along the refresh boundary.
        Please use get_frozen_credentials instead.
        'b'Check if a refresh is needed.

        A refresh is needed if the expiry time associated
        with the temporary credentials is less than the
        provided ``refresh_in``.  If ``time_delta`` is not
        provided, ``self.advisory_refresh_needed`` will be used.

        For example, if your temporary credentials expire
        in 10 minutes and the provided ``refresh_in`` is
        ``15 * 60``, then this function will return ``True``.

        :type refresh_in: int
        :param refresh_in: The number of seconds before the
            credentials expire in which refresh attempts should
            be made.

        :return: True if refresh needed, False otherwise.

        'u'Check if a refresh is needed.

        A refresh is needed if the expiry time associated
        with the temporary credentials is less than the
        provided ``refresh_in``.  If ``time_delta`` is not
        provided, ``self.advisory_refresh_needed`` will be used.

        For example, if your temporary credentials expire
        in 10 minutes and the provided ``refresh_in`` is
        ``15 * 60``, then this function will return ``True``.

        :type refresh_in: int
        :param refresh_in: The number of seconds before the
            credentials expire in which refresh attempts should
            be made.

        :return: True if refresh needed, False otherwise.

        'b'Credentials need to be refreshed.'u'Credentials need to be refreshed.'b'mandatory'u'mandatory'b'advisory'u'advisory'b'Refreshing temporary credentials failed during %s refresh period.'u'Refreshing temporary credentials failed during %s refresh period.'b'Credentials were refreshed, but the refreshed credentials are still expired.'u'Credentials were refreshed, but the refreshed credentials are still expired.'b'Credential refresh failed, response did not contain: %s'u'Credential refresh failed, response did not contain: %s'b'Retrieved credentials will expire at: %s'u'Retrieved credentials will expire at: %s'b'Return immutable credentials.

        The ``access_key``, ``secret_key``, and ``token`` properties
        on this class will always check and refresh credentials if
        needed before returning the particular credentials.

        This has an edge case where you can get inconsistent
        credentials.  Imagine this:

            # Current creds are "t1"
            tmp.access_key  ---> expired? no, so return t1.access_key
            # ---- time is now expired, creds need refreshing to "t2" ----
            tmp.secret_key  ---> expired? yes, refresh and return t2.secret_key

        This means we're using the access key from t1 with the secret key
        from t2.  To fix this issue, you can request a frozen credential object
        which is guaranteed not to change.

        The frozen credentials returned from this method should be used
        immediately and then discarded.  The typical usage pattern would
        be::

            creds = RefreshableCredentials(...)
            some_code = SomeSignerObject()
            # I'm about to sign the request.
            # The frozen credentials are only used for the
            # duration of generate_presigned_url and will be
            # immediately thrown away.
            request = some_code.sign_some_request(
                with_credentials=creds.get_frozen_credentials())
            print("Signed request:", request)

        'u'Return immutable credentials.

        The ``access_key``, ``secret_key``, and ``token`` properties
        on this class will always check and refresh credentials if
        needed before returning the particular credentials.

        This has an edge case where you can get inconsistent
        credentials.  Imagine this:

            # Current creds are "t1"
            tmp.access_key  ---> expired? no, so return t1.access_key
            # ---- time is now expired, creds need refreshing to "t2" ----
            tmp.secret_key  ---> expired? yes, refresh and return t2.secret_key

        This means we're using the access key from t1 with the secret key
        from t2.  To fix this issue, you can request a frozen credential object
        which is guaranteed not to change.

        The frozen credentials returned from this method should be used
        immediately and then discarded.  The typical usage pattern would
        be::

            creds = RefreshableCredentials(...)
            some_code = SomeSignerObject()
            # I'm about to sign the request.
            # The frozen credentials are only used for the
            # duration of generate_presigned_url and will be
            # immediately thrown away.
            request = some_code.sign_some_request(
                with_credentials=creds.get_frozen_credentials())
            print("Signed request:", request)

        'b'Refreshable credentials that don't require initial credentials.

    refresh_using will be called upon first access.
    'u'Refreshable credentials that don't require initial credentials.

    refresh_using will be called upon first access.
    'b'_create_cache_key()'u'_create_cache_key()'b'_get_credentials()'u'_get_credentials()'b'Get up-to-date credentials.

        This will check the cache for up-to-date credentials, calling assume
        role if none are available.
        'u'Get up-to-date credentials.

        This will check the cache for up-to-date credentials, calling assume
        role if none are available.
        'b'Credentials for role retrieved from cache.'u'Credentials for role retrieved from cache.'b'Credentials were found in cache, but they are expired.'u'Credentials were found in cache, but they are expired.'b'Check if credentials are expired.'u'Check if credentials are expired.'b'RoleArn'u'RoleArn'b'RoleSessionName'u'RoleSessionName'b'botocore-session-%s'u'botocore-session-%s'b'Create a predictable cache key for the current configuration.

        The cache key is intended to be compatible with file names.
        'u'Create a predictable cache key for the current configuration.

        The cache key is intended to be compatible with file names.
        'b'
        :type client_creator: callable
        :param client_creator: A callable that creates a client taking
            arguments like ``Session.create_client``.

        :type source_credentials: Credentials
        :param source_credentials: The credentials to use to create the
            client for the call to AssumeRole.

        :type role_arn: str
        :param role_arn: The ARN of the role to be assumed.

        :type extra_args: dict
        :param extra_args: Any additional arguments to add to the assume
            role request using the format of the botocore operation.
            Possible keys include, but may not be limited to,
            DurationSeconds, Policy, SerialNumber, ExternalId and
            RoleSessionName.

        :type mfa_prompter: callable
        :param mfa_prompter: A callable that returns input provided by the
            user (i.e raw_input, getpass.getpass, etc.).

        :type cache: dict
        :param cache: An object that supports ``__getitem__``,
            ``__setitem__``, and ``__contains__``.  An example of this is
            the ``JSONFileCache`` class in aws-cli.

        :type expiry_window_seconds: int
        :param expiry_window_seconds: The amount of time, in seconds,
        'u'
        :type client_creator: callable
        :param client_creator: A callable that creates a client taking
            arguments like ``Session.create_client``.

        :type source_credentials: Credentials
        :param source_credentials: The credentials to use to create the
            client for the call to AssumeRole.

        :type role_arn: str
        :param role_arn: The ARN of the role to be assumed.

        :type extra_args: dict
        :param extra_args: Any additional arguments to add to the assume
            role request using the format of the botocore operation.
            Possible keys include, but may not be limited to,
            DurationSeconds, Policy, SerialNumber, ExternalId and
            RoleSessionName.

        :type mfa_prompter: callable
        :param mfa_prompter: A callable that returns input provided by the
            user (i.e raw_input, getpass.getpass, etc.).

        :type cache: dict
        :param cache: An object that supports ``__getitem__``,
            ``__setitem__``, and ``__contains__``.  An example of this is
            the ``JSONFileCache`` class in aws-cli.

        :type expiry_window_seconds: int
        :param expiry_window_seconds: The amount of time, in seconds,
        'b'Get credentials by calling assume role.'u'Get credentials by calling assume role.'b'Get the arguments for assume role based on current configuration.'u'Get the arguments for assume role based on current configuration.'b'SerialNumber'u'SerialNumber'b'Enter MFA code for %s: 'u'Enter MFA code for %s: 'b'TokenCode'u'TokenCode'b'DurationSeconds'u'DurationSeconds'b'Create an STS client using the source credentials.'u'Create an STS client using the source credentials.'b'
        :type client_creator: callable
        :param client_creator: A callable that creates a client taking
            arguments like ``Session.create_client``.

        :type web_identity_token_loader: callable
        :param web_identity_token_loader: A callable that takes no arguments
        and returns a web identity token str.

        :type role_arn: str
        :param role_arn: The ARN of the role to be assumed.

        :type extra_args: dict
        :param extra_args: Any additional arguments to add to the assume
            role request using the format of the botocore operation.
            Possible keys include, but may not be limited to,
            DurationSeconds, Policy, SerialNumber, ExternalId and
            RoleSessionName.

        :type cache: dict
        :param cache: An object that supports ``__getitem__``,
            ``__setitem__``, and ``__contains__``.  An example of this is
            the ``JSONFileCache`` class in aws-cli.

        :type expiry_window_seconds: int
        :param expiry_window_seconds: The amount of time, in seconds,
        'u'
        :type client_creator: callable
        :param client_creator: A callable that creates a client taking
            arguments like ``Session.create_client``.

        :type web_identity_token_loader: callable
        :param web_identity_token_loader: A callable that takes no arguments
        and returns a web identity token str.

        :type role_arn: str
        :param role_arn: The ARN of the role to be assumed.

        :type extra_args: dict
        :param extra_args: Any additional arguments to add to the assume
            role request using the format of the botocore operation.
            Possible keys include, but may not be limited to,
            DurationSeconds, Policy, SerialNumber, ExternalId and
            RoleSessionName.

        :type cache: dict
        :param cache: An object that supports ``__getitem__``,
            ``__setitem__``, and ``__contains__``.  An example of this is
            the ``JSONFileCache`` class in aws-cli.

        :type expiry_window_seconds: int
        :param expiry_window_seconds: The amount of time, in seconds,
        'b'WebIdentityToken'u'WebIdentityToken'b'
        Loads the credentials from their source & sets them on the object.

        Subclasses should implement this method (by reading from disk, the
        environment, the network or wherever), returning ``True`` if they were
        found & loaded.

        If not found, this method should return ``False``, indictating that the
        ``CredentialResolver`` should fall back to the next available method.

        The default implementation does nothing, assuming the user has set the
        ``access_key/secret_key/token`` themselves.

        :returns: Whether credentials were found & set
        :rtype: Credentials
        'u'
        Loads the credentials from their source & sets them on the object.

        Subclasses should implement this method (by reading from disk, the
        environment, the network or wherever), returning ``True`` if they were
        found & loaded.

        If not found, this method should return ``False``, indictating that the
        ``CredentialResolver`` should fall back to the next available method.

        The default implementation does nothing, assuming the user has set the
        ``access_key/secret_key/token`` themselves.

        :returns: Whether credentials were found & set
        :rtype: Credentials
        'b'custom-process'u'custom-process'b'<Version key not provided>'u'<Version key not provided>'b'Unsupported version ''u'Unsupported version ''b'' for credential process provider, supported versions: 1'u'' for credential process provider, supported versions: 1'b'Missing required key in response: 'u'Missing required key in response: 'b'credential_process'u'credential_process'b'iam-role'u'iam-role'b'Ec2InstanceMetadata'u'Ec2InstanceMetadata'b'Found credentials from IAM Role: %s'u'Found credentials from IAM Role: %s'b'role_name'u'role_name'b'env'u'env'b'Environment'u'Environment'b'AWS_ACCESS_KEY_ID'u'AWS_ACCESS_KEY_ID'b'AWS_SECRET_ACCESS_KEY'u'AWS_SECRET_ACCESS_KEY'b'AWS_SECURITY_TOKEN'u'AWS_SECURITY_TOKEN'b'AWS_SESSION_TOKEN'u'AWS_SESSION_TOKEN'b'AWS_CREDENTIAL_EXPIRATION'u'AWS_CREDENTIAL_EXPIRATION'b'

        :param environ: The environment variables (defaults to
            ``os.environ`` if no value is provided).
        :param mapping: An optional mapping of variable names to
            environment variable names.  Use this if you want to
            change the mapping of access_key->AWS_ACCESS_KEY_ID, etc.
            The dict can have up to 3 keys: ``access_key``, ``secret_key``,
            ``session_token``.
        'u'

        :param environ: The environment variables (defaults to
            ``os.environ`` if no value is provided).
        :param mapping: An optional mapping of variable names to
            environment variable names.  Use this if you want to
            change the mapping of access_key->AWS_ACCESS_KEY_ID, etc.
            The dict can have up to 3 keys: ``access_key``, ``secret_key``,
            ``session_token``.
        'b'
        Search for credentials in explicit environment variables.
        'u'
        Search for credentials in explicit environment variables.
        'b'Found credentials in environment variables.'u'Found credentials in environment variables.'b'ec2-credentials-file'u'ec2-credentials-file'b'Ec2Config'u'Ec2Config'b'AWS_CREDENTIAL_FILE'u'AWS_CREDENTIAL_FILE'b'AWSSecretKey'u'AWSSecretKey'b'
        Search for a credential file used by original EC2 CLI tools.
        'u'
        Search for a credential file used by original EC2 CLI tools.
        'b'Found credentials in AWS_CREDENTIAL_FILE.'u'Found credentials in AWS_CREDENTIAL_FILE.'b'shared-credentials-file'u'shared-credentials-file'b'SharedCredentials'u'SharedCredentials'b'aws_access_key_id'u'aws_access_key_id'b'aws_secret_access_key'u'aws_secret_access_key'b'aws_security_token'u'aws_security_token'b'aws_session_token'u'aws_session_token'b'Found credentials in shared credentials file: %s'u'Found credentials in shared credentials file: %s'b'INI based config provider with profile sections.'u'INI based config provider with profile sections.'b'config-file'u'config-file'b'SharedConfig'u'SharedConfig'b'

        :param config_filename: The session configuration scoped to the current
            profile.  This is available via ``session.config``.
        :param profile_name: The name of the current profile.
        :param config_parser: A config parser callable.

        'u'

        :param config_filename: The session configuration scoped to the current
            profile.  This is available via ``session.config``.
        :param profile_name: The name of the current profile.
        :param config_parser: A config parser callable.

        'b'
        If there is are credentials in the configuration associated with
        the session, use those.
        'u'
        If there is are credentials in the configuration associated with
        the session, use those.
        'b'Credentials found in config file: %s'u'Credentials found in config file: %s'b'boto-config'u'boto-config'b'Boto2Config'u'Boto2Config'b'BOTO_CONFIG'u'BOTO_CONFIG'b'/etc/boto.cfg'u'/etc/boto.cfg'b'~/.boto'u'~/.boto'b'
        Look for credentials in boto config file.
        'u'
        Look for credentials in boto config file.
        'b'Found credentials in boto config file: %s'u'Found credentials in boto config file: %s'b'assume-role'u'assume-role'b'role_arn'u'role_arn'b'web_identity_token_file'u'web_identity_token_file'b'
        :type load_config: callable
        :param load_config: A function that accepts no arguments, and
            when called, will return the full configuration dictionary
            for the session (``session.full_config``).

        :type client_creator: callable
        :param client_creator: A factory function that will create
            a client when called.  Has the same interface as
            ``botocore.session.Session.create_client``.

        :type cache: dict
        :param cache: An object that supports ``__getitem__``,
            ``__setitem__``, and ``__contains__``.  An example
            of this is the ``JSONFileCache`` class in the CLI.

        :type profile_name: str
        :param profile_name: The name of the profile.

        :type prompter: callable
        :param prompter: A callable that returns input provided
            by the user (i.e raw_input, getpass.getpass, etc.).

        :type credential_sourcer: CanonicalNameCredentialSourcer
        :param credential_sourcer: A credential provider that takes a
            configuration, which is used to provide the source credentials
            for the STS call.
        'u'
        :type load_config: callable
        :param load_config: A function that accepts no arguments, and
            when called, will return the full configuration dictionary
            for the session (``session.full_config``).

        :type client_creator: callable
        :param client_creator: A factory function that will create
            a client when called.  Has the same interface as
            ``botocore.session.Session.create_client``.

        :type cache: dict
        :param cache: An object that supports ``__getitem__``,
            ``__setitem__``, and ``__contains__``.  An example
            of this is the ``JSONFileCache`` class in the CLI.

        :type profile_name: str
        :param profile_name: The name of the profile.

        :type prompter: callable
        :param prompter: A callable that returns input provided
            by the user (i.e raw_input, getpass.getpass, etc.).

        :type credential_sourcer: CanonicalNameCredentialSourcer
        :param credential_sourcer: A credential provider that takes a
            configuration, which is used to provide the source credentials
            for the STS call.
        'b'role_session_name'u'role_session_name'b'external_id'u'external_id'b'ExternalId'u'ExternalId'b'mfa_serial'u'mfa_serial'b'duration_seconds'u'duration_seconds'b'Retrieves and validates the role configuration for the profile.'u'Retrieves and validates the role configuration for the profile.'b'source_profile'u'source_profile'b'credential_source'u'credential_source'b'The profile "%s" contains both source_profile and credential_source.'u'The profile "%s" contains both source_profile and credential_source.'b'source_profile or credential_source'u'source_profile or credential_source'b'The credential_source "'u'The credential_source "'b'" is specified in profile "'u'" is specified in profile "'b'", but no source provider was configured.'u'", but no source provider was configured.'b'The credential source "'u'The credential source "'b'" referenced in profile "'u'" referenced in profile "'b'" is not valid.'u'" is not valid.'b'The source_profile "'u'The source_profile "'b'" referenced in the profile "'u'" referenced in the profile "'b'" does not exist.'u'" does not exist.'b'The source profile "%s" must have credentials.'u'The source profile "%s" must have credentials.'b'No credentials found in credential_source referenced in profile %s'u'No credentials found in credential_source referenced in profile %s'b'assume-role-with-web-identity'u'assume-role-with-web-identity'b'AWS_WEB_IDENTITY_TOKEN_FILE'u'AWS_WEB_IDENTITY_TOKEN_FILE'b'AWS_ROLE_SESSION_NAME'u'AWS_ROLE_SESSION_NAME'b'AWS_ROLE_ARN'u'AWS_ROLE_ARN'b'The provided profile or the current environment is configured to assume role with web identity but has no role ARN configured. Ensure that the profile has the role_arnconfiguration set or the AWS_ROLE_ARN env var is set.'u'The provided profile or the current environment is configured to assume role with web identity but has no role ARN configured. Ensure that the profile has the role_arnconfiguration set or the AWS_ROLE_ARN env var is set.'b'Validates a given source name.

        :type source_name: str
        :param source_name: The value of credential_source in the config
            file. This is the canonical name of the credential provider.

        :rtype: bool
        :returns: True if the credential provider is supported,
            False otherwise.
        'u'Validates a given source name.

        :type source_name: str
        :param source_name: The value of credential_source in the config
            file. This is the canonical name of the credential provider.

        :rtype: bool
        :returns: True if the credential provider is supported,
            False otherwise.
        'b'Loads source credentials based on the provided configuration.

        :type source_name: str
        :param source_name: The value of credential_source in the config
            file. This is the canonical name of the credential provider.

        :rtype: Credentials
        'u'Loads source credentials based on the provided configuration.

        :type source_name: str
        :param source_name: The value of credential_source in the config
            file. This is the canonical name of the credential provider.

        :rtype: Credentials
        'b'Return a credential provider by its canonical name.

        :type canonical_name: str
        :param canonical_name: The canonical name of the provider.

        :raises UnknownCredentialError: Raised if no
            credential provider by the provided name
            is found.
        'u'Return a credential provider by its canonical name.

        :type canonical_name: str
        :param canonical_name: The canonical name of the provider.

        :raises UnknownCredentialError: Raised if no
            credential provider by the provided name
            is found.
        'b'sharedconfig'u'sharedconfig'b'sharedcredentials'u'sharedcredentials'b'Return a credential provider by its canonical name.

        This function is strict, it does not attempt to address
        compatibility issues.
        'u'Return a credential provider by its canonical name.

        This function is strict, it does not attempt to address
        compatibility issues.
        'b'Return a credential provider by its METHOD name.'u'Return a credential provider by its METHOD name.'b'container-role'u'container-role'b'EcsContainer'u'EcsContainer'b'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI'u'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI'b'AWS_CONTAINER_CREDENTIALS_FULL_URI'u'AWS_CONTAINER_CREDENTIALS_FULL_URI'b'AWS_CONTAINER_AUTHORIZATION_TOKEN'u'AWS_CONTAINER_AUTHORIZATION_TOKEN'b'Error retrieving container metadata: %s'u'Error retrieving container metadata: %s'b'

        :param providers: A list of ``CredentialProvider`` instances.

        'u'

        :param providers: A list of ``CredentialProvider`` instances.

        'b'
        Inserts a new instance of ``CredentialProvider`` into the chain that
        will be tried before an existing one.

        :param name: The short name of the credentials you'd like to insert the
            new credentials before. (ex. ``env`` or ``config``). Existing names
            & ordering can be discovered via ``self.available_methods``.
        :type name: string

        :param cred_instance: An instance of the new ``Credentials`` object
            you'd like to add to the chain.
        :type cred_instance: A subclass of ``Credentials``
        'u'
        Inserts a new instance of ``CredentialProvider`` into the chain that
        will be tried before an existing one.

        :param name: The short name of the credentials you'd like to insert the
            new credentials before. (ex. ``env`` or ``config``). Existing names
            & ordering can be discovered via ``self.available_methods``.
        :type name: string

        :param cred_instance: An instance of the new ``Credentials`` object
            you'd like to add to the chain.
        :type cred_instance: A subclass of ``Credentials``
        'b'
        Inserts a new type of ``Credentials`` instance into the chain that will
        be tried after an existing one.

        :param name: The short name of the credentials you'd like to insert the
            new credentials after. (ex. ``env`` or ``config``). Existing names
            & ordering can be discovered via ``self.available_methods``.
        :type name: string

        :param cred_instance: An instance of the new ``Credentials`` object
            you'd like to add to the chain.
        :type cred_instance: A subclass of ``Credentials``
        'u'
        Inserts a new type of ``Credentials`` instance into the chain that will
        be tried after an existing one.

        :param name: The short name of the credentials you'd like to insert the
            new credentials after. (ex. ``env`` or ``config``). Existing names
            & ordering can be discovered via ``self.available_methods``.
        :type name: string

        :param cred_instance: An instance of the new ``Credentials`` object
            you'd like to add to the chain.
        :type cred_instance: A subclass of ``Credentials``
        'b'
        Removes a given ``Credentials`` instance from the chain.

        :param name: The short name of the credentials instance to remove.
        :type name: string
        'u'
        Removes a given ``Credentials`` instance from the chain.

        :param name: The short name of the credentials instance to remove.
        :type name: string
        'b'Return a credential provider by name.

        :type name: str
        :param name: The name of the provider.

        :raises UnknownCredentialError: Raised if no
            credential provider by the provided name
            is found.
        'u'Return a credential provider by name.

        :type name: str
        :param name: The name of the provider.

        :raises UnknownCredentialError: Raised if no
            credential provider by the provided name
            is found.
        'b'
        Goes through the credentials chain, returning the first ``Credentials``
        that could be loaded.
        'u'
        Goes through the credentials chain, returning the first ``Credentials``
        that could be loaded.
        'b'Looking for credentials via: %s'u'Looking for credentials via: %s'b'roleName'u'roleName'b'accountId'u'accountId'b'sessionName'u'sessionName'b'startUrl'u'startUrl'b'Get credentials by calling SSO get role credentials.'u'Get credentials by calling SSO get role credentials.'b'sso'u'sso'b'accessToken'u'accessToken'b'roleCredentials'u'roleCredentials'b'ProviderType'u'ProviderType'b'accessKeyId'u'accessKeyId'b'secretAccessKey'u'secretAccessKey'b'sessionToken'u'sessionToken'b'expiration'u'expiration'b'.aws'u'.aws'b'cache'u'cache'b'sso_role_name'u'sso_role_name'b'sso_account_id'u'sso_account_id'b'sso_start_url'u'sso_start_url'b'sso_region'u'sso_region'b'The profile "%s" is configured to use SSO but is missing required configuration: %s'u'The profile "%s" is configured to use SSO but is missing required configuration: %s'b'sso_session'u'sso_session'b'The specified sso-session does not exist: "'u'The specified sso-session does not exist: "'b'The value for 'u'The value for 'b' is inconsistent between profile ('u' is inconsistent between profile ('b') and sso-session ('u') and sso-session ('b').'u').'b'start_url'u'start_url'b'account_id'u'account_id'b'client_creator'u'client_creator'b'token_loader'u'token_loader'b'sso_session_name'u'sso_session_name'b'token_provider'u'token_provider'u'botocore.credentials'u'credentials'dataclassFieldFrozenInstanceErrorInitVarKW_ONLYasdictastuplemake_dataclassis_dataclass_HAS_DEFAULT_FACTORY_CLASS<factory>_HAS_DEFAULT_FACTORY_MISSING_TYPE_KW_ONLY_TYPEMappingProxyType_EMPTY_METADATA_FIELD_BASE_FIELD_FIELD_CLASSVAR_FIELD_INITVAR__dataclass_fields___FIELDS__dataclass_params___PARAMS__post_init___POST_INIT_NAME^(?:\s*(\w+)\s*\.)?\s*(\w+)_MODULE_IDENTIFIER_REdataclasses.InitVar[kw_only_field_typeField(name='Field(''name=',type=',''type=',default='default=',default_factory='default_factory=',init='init=',repr='repr=',hash='hash=',compare='compare=',metadata='metadata=',kw_only='kw_only=',_field_type='_field_type='')'_DataclassParamsorderunsafe_hash_DataclassParams(init='_DataclassParams(',eq='eq=',order='order=',unsafe_hash='unsafe_hash=',frozen='frozen='Return an object to identify dataclass fields.

    default is the default value of the field.  default_factory is a
    0-argument function called to initialize a field's value.  If init
    is true, the field will be a parameter to the class's __init__()
    function.  If repr is true, the field will be included in the
    object's repr().  If hash is true, the field will be included in the
    object's hash().  If compare is true, the field will be used in
    comparison functions.  metadata, if specified, must be a mapping
    which is stored but not otherwise examined by dataclass.  If kw_only
    is true, the field will become a keyword-only parameter to
    __init__().

    It is an error to specify both default and default_factory.
    cannot specify both default and default_factory_fields_in_init_order_tuple_str,)user_functionrepr_running_create_fnreturn_typereturn_annotation_return_type->_return_type def :
txtlocal_varsdef __create_fn__():

 return __create_fn___field_assignself_name__dataclass_builtins_object__.__setattr__(_field_init_dflt_default_name() if '() ''if ' is _HAS_DEFAULT_FACTORY else ' is _HAS_DEFAULT_FACTORY ''else '_init_param=_dflt_=_HAS_DEFAULT_FACTORY:_type__init_fnstd_fieldskw_only_fieldshas_post_initseen_defaultnon-default argument  follows default argument'follows default argument'__dataclass_builtins_object__body_linesparams_str_init_params_repr_fnreturn self.__class__.__qualname__ + f"(={{self.!r}})"_frozen_get_del_attrfields_strif type(self) is cls or name in  raise FrozenInstanceError(f"cannot assign to field {name!r}")super(cls, self).__setattr__(name, value) raise FrozenInstanceError(f"cannot delete field {name!r}")super(cls, self).__delattr__(name)_cmp_fnself_tupleother_tupleif other.__class__ is self.__class__: return return NotImplemented_hash_fnreturn hash(_is_classvara_typeClassVar_GenericAlias__origin___is_initvardataclasses_is_kw_only_is_typea_moduleis_type_predicate_get_fielda_namedefault_kw_onlyMemberDescriptorTypefield  cannot have a default factory' cannot have a ''default factory' is a ClassVar but specifies kw_only' is a ClassVar but specifies ''kw_only'mutable default  for field ' for field ' is not allowed: use default_factory_set_qualname_set_new_attribute_hash_set_none_hash_addflds_hash_exceptionCannot overwrite attribute __hash__ in class 'Cannot overwrite attribute __hash__ ''in class '_hash_action_process_classmatch_argsany_frozen_basehas_dataclass_basesbase_fieldscls_annotationscls_fieldsKW_ONLY_seen is KW_ONLY, but KW_ONLY has already been specified' is KW_ONLY, but KW_ONLY ''has already been specified' is a field but has no type annotationcannot inherit non-frozen dataclass from a frozen one'cannot inherit non-frozen dataclass from a ''frozen one'cannot inherit frozen dataclass from a non-frozen one'cannot inherit frozen dataclass from a ''non-frozen one'class_hashhas_explicit_hasheq must be true if order is trueall_init_fieldsstd_init_fieldskw_only_init_fields__dataclass_self__field_listCannot overwrite attribute  in class . Consider using functools.total_ordering'. Consider using ''functools.total_ordering'hash_action -> None_add_slots_dataclass_getstate_dataclass_setstate already specifies __slots__cls_dictfield_nameReturns the same class as was passed in, with dunder methods
    added based on the fields defined in the class.

    Examines PEP 526 __annotations__ to determine fields.

    If init is true, an __init__() method is added to the class. If
    repr is true, a __repr__() method is added. If order is true, rich
    comparison dunder methods are added. If unsafe_hash is true, a
    __hash__() method function is added. If frozen is true, fields may
    not be assigned to after instance creation. If match_args is true,
    the __match_args__ tuple is added. If kw_only is true, then by
    default all fields are keyword-only. If slots is true, an
    __slots__ attribute is added.
    class_or_instanceReturn a tuple describing the fields of this dataclass.

    Accepts a dataclass or an instance of one. Tuple elements are of
    type Field.
    must be called with a dataclass type or instance_is_dataclass_instanceReturns True if obj is an instance of a dataclass.Returns True if obj is a dataclass or an instance of a
    dataclass.dict_factoryReturn the fields of a dataclass instance as a new dictionary mapping
    field names to field values.

    Example usage:

      @dataclass
      class C:
          x: int
          y: int

      c = C(1, 2)
      assert asdict(c) == {'x': 1, 'y': 2}

    If given, 'dict_factory' will be used instead of built-in dict.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts.
    asdict() should be called on dataclass instances_asdict_innertuple_factoryReturn the fields of a dataclass instance as a new tuple of field values.

    Example usage::

      @dataclass
      class C:
          x: int
          y: int

    c = C(1, 2)
    assert astuple(c) == (1, 2)

    If given, 'tuple_factory' will be used instead of built-in tuple.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts.
    astuple() should be called on dataclass instances_astuple_innerReturn a new dynamically created dataclass.

    The dataclass name will be 'cls_name'.  'fields' is an iterable
    of either (name), (name, type) or (name, type, Field) objects. If type is
    omitted, use the string 'typing.Any'.  Field objects are created by
    the equivalent of calling 'field(name, type [, Field-info])'.

      C = make_dataclass('C', ['x', ('y', int), ('z', int, field(init=False))], bases=(Base,))

    is equivalent to:

      @dataclass
      class C(Base):
          x: 'typing.Any'
          y: int
          z: int = field(init=False)

    For the bases and namespace parameters, see the builtin type() function.

    The parameters init, repr, eq, order, unsafe_hash, and frozen are passed to
    dataclass().
    typing.AnyInvalid field: Field names must be valid identifiers: Field names must not be keywords: Field name duplicated: exec_body_callbacknew_classchangesReturn a new object replacing specified fields with new values.

    This is especially useful for frozen classes.  Example usage:

      @dataclass(frozen=True)
      class C:
          x: int
          y: int

      c = C(1, 2)
      c1 = replace(c, x=3)
      assert c1.x == 3 and c1.y == 2
      replace() should be called on dataclass instances is declared with init=False, it cannot be specified with replace()' is declared with ''init=False, it cannot be specified with ''replace()'InitVar  must be specified with replace()'must be specified with replace()'# Helper functions.# Conditions for adding methods.  The boxes indicate what action the# dataclass decorator takes.  For all of these tables, when I talk# about init=, repr=, eq=, order=, unsafe_hash=, or frozen=, I'm# referring to the arguments to the @dataclass decorator.  When# checking if a dunder method already exists, I mean check for an# entry in the class's __dict__.  I never check to see if an attribute# is defined in a base class.# Key:# +=========+=========================================+# + Value   | Meaning                                 |# | <blank> | No action: no method is added.          |# +---------+-----------------------------------------+# | add     | Generated method is added.              |# | raise   | TypeError is raised.                    |# | None    | Attribute is set to None.               |# __init__#   +--- init= parameter#   |#   v     |       |       |#         |  no   |  yes  |  <--- class has __init__ in __dict__?# +=======+=======+=======+# | False |       |       |# +-------+-------+-------+# | True  | add   |       |  <- the default# __repr__#    +--- repr= parameter#    |#    v    |       |       |#         |  no   |  yes  |  <--- class has __repr__ in __dict__?# __setattr__# __delattr__#    +--- frozen= parameter#         |  no   |  yes  |  <--- class has __setattr__ or __delattr__ in __dict__?# | False |       |       |  <- the default# | True  | add   | raise |# Raise because not adding these methods would break the "frozen-ness"# of the class.# __eq__#    +--- eq= parameter#         |  no   |  yes  |  <--- class has __eq__ in __dict__?# __lt__# __le__# __gt__# __ge__#    +--- order= parameter#         |  no   |  yes  |  <--- class has any comparison method in __dict__?# Raise because to allow this case would interfere with using# functools.total_ordering.# __hash__#    +------------------- unsafe_hash= parameter#    |       +----------- eq= parameter#    |       |       +--- frozen= parameter#    |       |       |#    v       v       v    |        |        |#                         |   no   |  yes   |  <--- class has explicitly defined __hash__# +=======+=======+=======+========+========+# | False | False | False |        |        | No __eq__, use the base class __hash__# +-------+-------+-------+--------+--------+# | False | False | True  |        |        | No __eq__, use the base class __hash__# | False | True  | False | None   |        | <-- the default, not hashable# | False | True  | True  | add    |        | Frozen, so hashable, allows override# | True  | False | False | add    | raise  | Has no __eq__, but hashable# | True  | False | True  | add    | raise  | Has no __eq__, but hashable# | True  | True  | False | add    | raise  | Not frozen, but hashable# | True  | True  | True  | add    | raise  | Frozen, so hashable# For boxes that are blank, __hash__ is untouched and therefore# inherited from the base class.  If the base is object, then# id-based hashing is used.# Note that a class may already have __hash__=None if it specified an# __eq__ method in the class body (not one that was created by# @dataclass).# See _hash_action (below) for a coded version of this table.# __match_args__#    +--- match_args= parameter#         |  no   |  yes  |  <--- class has __match_args__ in __dict__?# __match_args__ is always added unless the class already defines it. It is a# tuple of __init__ parameter names; non-init fields must be matched by keyword.# Raised when an attempt is made to modify a frozen class.# A sentinel object for default values to signal that a default# factory will be used.  This is given a nice repr() which will appear# in the function signature of dataclasses' constructors.# A sentinel object to detect if a parameter is supplied or not.  Use# a class to give it a better repr.# A sentinel object to indicate that following fields are keyword-only by# default.  Use a class to give it a better repr.# Since most per-field metadata will be unused, create an empty# read-only proxy that can be shared among all fields.# Markers for the various kinds of fields and pseudo-fields.# The name of an attribute on the class where we store the Field# objects.  Also used to check if a class is a Data Class.# The name of an attribute on the class that stores the parameters to# @dataclass.# The name of the function, that if it exists, is called at the end of# __init__.# String regex that string annotations for ClassVar or InitVar must match.# Allows "identifier.identifier[" or "identifier[".# https://bugs.python.org/issue33453 for details.# typing objects, e.g. List[int]# Instances of Field are only ever created from within this module,# and only from the field() function, although Field instances are# exposed externally as (conceptually) read-only objects.# name and type are filled in after the fact, not in __init__.# They're not known at the time this class is instantiated, but it's# convenient if they're available later.# When cls._FIELDS is filled in with a list of Field objects, the name# and type fields will have been populated.# Private: not to be used by user code.# This is used to support the PEP 487 __set_name__ protocol in the# case where we're using a field that contains a descriptor as a# default value.  For details on __set_name__, see# https://www.python.org/dev/peps/pep-0487/#implementation-details.# Note that in _process_class, this Field object is overwritten# with the default value, so the end result is a descriptor that# had __set_name__ called on it at the right time.# There is a __set_name__ method on the descriptor, call# This function is used instead of exposing Field creation directly,# so that a type checker can be told (via overloads) that this is a# function whose type depends on its parameters.# Returns the fields as __init__ will output them.  It returns 2 tuples:# the first for normal args, and the second for keyword args.# Return a string representing each field of obj_name as a tuple# member.  So, if fields is ['x', 'y'] and obj_name is "self",# return "(self.x,self.y)".# Special case for the 0-tuple.# Note the trailing comma, needed if this turns out to be a 1-tuple.# This function's logic is copied from "recursive_repr" function in# reprlib module to avoid dependency.# Decorator to make a repr function return "..." for a recursive# call.# Note that we may mutate locals. Callers beware!# The only callers are internal to this module, so no# worries about external callers.# Compute the text of the entire function.# If we're a frozen class, then assign to our fields in __init__# via object.__setattr__.  Otherwise, just use a simple# assignment.# self_name is what "self" is called in this function: don't# hard-code "self", since that might be a field name.# Return the text of the line in the body of __init__ that will# initialize this field.# This field has a default factory.  If a parameter is# given, use it.  If not, call the factory.# This is a field that's not in the __init__ params, but# has a default factory function.  It needs to be# initialized here by calling the factory function,# because there's no other way to initialize it.# For a field initialized with a default=defaultvalue, the# class dict just has the default value# (cls.fieldname=defaultvalue).  But that won't work for a# default factory, the factory must be called in __init__# and we must assign that to self.fieldname.  We can't# fall back to the class dict's value, both because it's# not set, and because it might be different per-class# (which, after all, is why we have a factory function!).# No default factory.# There's no default, just do an assignment.# If the class has slots, then initialize this field.# This field does not need initialization: reading from it will# just use the class attribute that contains the default.# Signify that to the caller by returning None.# Only test this now, so that we can create variables for the# default.  However, return None to signify that we're not going# to actually do the assignment statement for InitVars.# Now, actually generate the field assignment.# Return the __init__ parameter string for this field.  For# example, the equivalent of 'x:int=3' (except instead of 'int',# reference a variable set to int, and instead of '3', reference a# variable set to 3).# There's no default, and no default_factory, just output the# variable name and type.# There's a default, this will be the name that's used to look# it up.# There's a factory function.  Set a marker.# fields contains both real fields and InitVar pseudo-fields.# Make sure we don't have fields without defaults following fields# with defaults.  This actually would be caught when exec-ing the# function source code, but catching it here gives a better error# message, and future-proofs us in case we build up the function# using ast.# Only consider the non-kw-only fields in the __init__ call.# line is None means that this field doesn't require# initialization (it's a pseudo-field).  Just skip it.# Does this class have a post-init function?# If no body lines, use 'pass'.# Add the keyword-only args.  Because the * can only be added if# there's at least one keyword-only arg, there needs to be a test here# (instead of just concatenting the lists together).# Special case for the zero-length tuple.# Create a comparison function.  If the fields in the object are# named 'x' and 'y', then self_tuple is the string# '(self.x,self.y)' and other_tuple is the string# '(other.x,other.y)'.# This test uses a typing internal class, but it's the best way to# test if this is a ClassVar.# The module we're checking against is the module we're# currently in (dataclasses.py).# Given a type annotation string, does it refer to a_type in# a_module?  For example, when checking that annotation denotes a# ClassVar, then a_module is typing, and a_type is# typing.ClassVar.# It's possible to look up a_module given a_type, but it involves# looking in sys.modules (again!), and seems like a waste since# the caller already knows a_module.# - annotation is a string type annotation# - cls is the class that this annotation was found in# - a_module is the module we want to match# - a_type is the type in that module we want to match# - is_type_predicate is a function called with (obj, a_module)#   that determines if obj is of the desired type.# Since this test does not do a local namespace lookup (and# instead only a module (global) lookup), there are some things it# gets wrong.# With string annotations, cv0 will be detected as a ClassVar:#   CV = ClassVar#   @dataclass#   class C0:#     cv0: CV# But in this example cv1 will not be detected as a ClassVar:#   class C1:#     CV = ClassVar#     cv1: CV# In C1, the code in this function (_is_type) will look up "CV" in# the module and not find it, so it will not consider cv1 as a# ClassVar.  This is a fairly obscure corner case, and the best# way to fix it would be to eval() the string "CV" with the# correct global and local namespaces.  However that would involve# a eval() penalty for every single field of every dataclass# that's defined.  It was judged not worth it.# No module name, assume the class's module did# "from dataclasses import InitVar".# Look up module_name in the class's module.# Return a Field object for this field name and type.  ClassVars and# InitVars are also returned, but marked as such (see f._field_type).# default_kw_only is the value of kw_only to use if there isn't a field()# that defines it.# If the default value isn't derived from Field, then it's only a# normal default value.  Convert it to a Field().# This is a field in __slots__, so it has no default value.# Only at this point do we know the name and the type.  Set them.# Assume it's a normal field until proven otherwise.  We're next# going to decide if it's a ClassVar or InitVar, everything else# is just a normal field.# In addition to checking for actual types here, also check for# string annotations.  get_type_hints() won't always work for us# (see https://github.com/python/typing/issues/508 for example),# plus it's expensive and would require an eval for every string# annotation.  So, make a best effort to see if this is a ClassVar# or InitVar using regex's and checking that the thing referenced# is actually of the correct type.# For the complete discussion, see https://bugs.python.org/issue33453# If typing has not been imported, then it's impossible for any# annotation to be a ClassVar.  So, only look for ClassVar if# typing has been imported by any module (not necessarily cls's# module).# If the type is InitVar, or if it's a matching string annotation,# then it's an InitVar.# Validations for individual fields.  This is delayed until now,# instead of in the Field() constructor, since only here do we# know the field name, which allows for better error reporting.# Special restrictions for ClassVar and InitVar.# Should I check for other field settings? default_factory# seems the most serious to check for.  Maybe add others.  For# example, how about init=False (or really,# init=<not-the-default-init-value>)?  It makes no sense for# ClassVar and InitVar to specify init=<anything>.# kw_only validation and assignment.# For real and InitVar fields, if kw_only wasn't specified use the# default value.# Make sure kw_only isn't set for ClassVars# For real fields, disallow mutable defaults for known types.# Ensure that the functions returned from _create_fn uses the proper# __qualname__ (the class they belong to).# Never overwrites an existing attribute.  Returns True if the# attribute already exists.# Decide if/how we're going to create a hash function.  Key is# (unsafe_hash, eq, frozen, does-hash-exist).  Value is the action to# take.  The common case is to do nothing, so instead of providing a# function that is a no-op, use None to signify that.# Raise an exception.#                +-------------------------------------- unsafe_hash?#                |      +------------------------------- eq?#                |      |      +------------------------ frozen?#                |      |      |      +----------------  has-explicit-hash?#                |      |      |      |#                |      |      |      |        +-------  action#                |      |      |      |        |#                v      v      v      v        v# See https://bugs.python.org/issue32929#msg312829 for an if-statement# version of this table.# Now that dicts retain insertion order, there's no reason to use# an ordered dict.  I am leveraging that ordering here, because# derived class fields overwrite base class fields, but the order# is defined by the base class, which is found first.# Theoretically this can happen if someone writes# a custom string to cls.__module__.  In which case# such dataclass won't be fully introspectable# (w.r.t. typing.get_type_hints) but will still function# correctly.# Find our base classes in reverse MRO order, and exclude# ourselves.  In reversed order so that more derived classes# override earlier field definitions in base classes.  As long as# we're iterating over them, see if any are frozen.# Only process classes that have been processed by our# decorator.  That is, they have a _FIELDS attribute.# Annotations that are defined in this class (not in base# classes).  If __annotations__ isn't present, then this class# adds no new annotations.  We use this to compute fields that are# added by this class.# Fields are found from cls_annotations, which is guaranteed to be# ordered.  Default values are from class attributes, if a field# has a default.  If the default value is a Field(), then it# contains additional info beyond (and possibly including) the# actual default value.  Pseudo-fields ClassVars and InitVars are# included, despite the fact that they're not real fields.  That's# dealt with later.# Now find fields in our class.  While doing so, validate some# things, and set the default values (as class attributes) where# we can.# Get a reference to this module for the _is_kw_only() test.# See if this is a marker to change the value of kw_only.# Switch the default to kw_only=True, and ignore this# annotation: it's not a real field.# Otherwise it's a field of some type.# If the class attribute (which is the default value for this# field) exists and is of type 'Field', replace it with the# real default.  This is so that normal class introspection# sees a real default value, not a Field.# If there's no default, delete the class attribute.# This happens if we specify field(repr=False), for# example (that is, we specified a field object, but# no default value).  Also if we're using a default# factory.  The class attribute should not be set at# all in the post-processed class.# Do we have any Field members that don't also have annotations?# Check rules that apply if we are derived from any dataclasses.# Raise an exception if any of our bases are frozen, but we're not.# Raise an exception if we're frozen, but none of our bases are.# Remember all of the fields on our class (including bases).  This# also marks this class as being a dataclass.# Was this class defined with an explicit __hash__?  Note that if# __eq__ is defined in this class, then python will automatically# set __hash__ to None.  This is a heuristic, as it's possible# that such a __hash__ == None was not auto-generated, but it# close enough.# If we're generating ordering methods, we must be generating the# eq methods.# Include InitVars and regular fields (so, not ClassVars).  This is# initialized here, outside of the "if init:" test, because std_init_fields# is used with match_args, below.# The name to use for the "self"# param in __init__.  Use "self"# if possible.# Get the fields as a list, and include only real fields.  This is# used in all of the following methods.# Create __eq__ method.  There's no need for a __ne__ method,# since python will call __eq__ and negate it.# Create and set the ordering methods.# Decide if/how we're going to create a hash function.# No need to call _set_new_attribute here, since by the time# we're here the overwriting is unconditional.# Create a class doc-string.# I could probably compute this once# _dataclass_getstate and _dataclass_setstate are needed for pickling frozen# classes with slots.  These could be slighly more performant if we generated# the code instead of iterating over fields.  But that can be a project for# another day, if performance becomes an issue.# use setattr because dataclass may be frozen# Need to create a new class, since we can't set __slots__#  after a class has been created.# Make sure __slots__ isn't already set.# Create a new dict for our new class.# Remove our attributes, if present. They'll still be#  available in _MARKER.# Remove __dict__ itself.# And finally create the class.# Need this for pickling frozen classes with slots.# See if we're being called as @dataclass or @dataclass().# We're called with parens.# We're called as @dataclass without parens.# Might it be worth caching this, per class?# Exclude pseudo-fields.  Note that fields is sorted by insertion# order, so the order of the tuple is as the fields were defined.# obj is a namedtuple.  Recurse into it, but the returned# object is another namedtuple of the same type.  This is# similar to how other list- or tuple-derived classes are# treated (see below), but we just need to create them# differently because a namedtuple's __init__ needs to be# called differently (see bpo-34363).# I'm not using namedtuple's _asdict()# method, because:# - it does not recurse in to the namedtuple fields and#   convert them to dicts (using dict_factory).# - I don't actually want to return a dict here.  The main#   use case here is json.dumps, and it handles converting#   namedtuples to lists.  Admittedly we're losing some#   information here when we produce a json list instead of a#   dict.  Note that if we returned dicts here instead of#   namedtuples, we could no longer call asdict() on a data#   structure where a namedtuple was used as a dict key.# Assume we can create an object of this type by passing in a# generator (which is not true for namedtuples, handled# above).# While we're looking through the field names, validate that they# are identifiers, are not keywords, and not duplicates.# Update 'ns' with the user-supplied namespace plus our calculated values.# We use `types.new_class()` instead of simply `type()` to allow dynamic creation# of generic dataclasses.# Apply the normal decorator.# We're going to mutate 'changes', but that's okay because it's a# new dict, even if called with 'replace(obj, **my_changes)'.# It's an error to have init=False fields in 'changes'.# If a field is not in 'changes', read its value from the provided obj.# Only consider normal fields or InitVars.# Error if this field is specified in changes.# Create the new object, which calls __init__() and# __post_init__() (if defined), using all of the init fields we've# added and/or left in 'changes'.  If there are values supplied in# changes that aren't fields, this will correctly raise a# TypeError.b'dataclass'u'dataclass'b'Field'u'Field'b'FrozenInstanceError'u'FrozenInstanceError'b'InitVar'u'InitVar'b'KW_ONLY'u'KW_ONLY'b'MISSING'u'MISSING'b'fields'u'fields'b'asdict'u'asdict'b'astuple'u'astuple'b'make_dataclass'u'make_dataclass'b'is_dataclass'u'is_dataclass'b'<factory>'u'<factory>'b'_FIELD'u'_FIELD'b'_FIELD_CLASSVAR'u'_FIELD_CLASSVAR'b'_FIELD_INITVAR'u'_FIELD_INITVAR'b'__dataclass_fields__'u'__dataclass_fields__'b'__dataclass_params__'u'__dataclass_params__'b'__post_init__'u'__post_init__'b'^(?:\s*(\w+)\s*\.)?\s*(\w+)'u'^(?:\s*(\w+)\s*\.)?\s*(\w+)'b'dataclasses.InitVar['u'dataclasses.InitVar['b'default_factory'u'default_factory'b'hash'u'hash'b'kw_only'u'kw_only'b'_field_type'u'_field_type'b'Field(name='u'Field(name='b',type='u',type='b',default='u',default='b',default_factory='u',default_factory='b',init='u',init='b',repr='u',repr='b',hash='u',hash='b',compare='u',compare='b',metadata='u',metadata='b',kw_only='u',kw_only='b',_field_type='u',_field_type='b'__set_name__'u'__set_name__'b'eq'u'eq'b'order'u'order'b'unsafe_hash'u'unsafe_hash'b'_DataclassParams(init='u'_DataclassParams(init='b',eq='u',eq='b',order='u',order='b',unsafe_hash='u',unsafe_hash='b',frozen='u',frozen='b'Return an object to identify dataclass fields.

    default is the default value of the field.  default_factory is a
    0-argument function called to initialize a field's value.  If init
    is true, the field will be a parameter to the class's __init__()
    function.  If repr is true, the field will be included in the
    object's repr().  If hash is true, the field will be included in the
    object's hash().  If compare is true, the field will be used in
    comparison functions.  metadata, if specified, must be a mapping
    which is stored but not otherwise examined by dataclass.  If kw_only
    is true, the field will become a keyword-only parameter to
    __init__().

    It is an error to specify both default and default_factory.
    'u'Return an object to identify dataclass fields.

    default is the default value of the field.  default_factory is a
    0-argument function called to initialize a field's value.  If init
    is true, the field will be a parameter to the class's __init__()
    function.  If repr is true, the field will be included in the
    object's repr().  If hash is true, the field will be included in the
    object's hash().  If compare is true, the field will be used in
    comparison functions.  metadata, if specified, must be a mapping
    which is stored but not otherwise examined by dataclass.  If kw_only
    is true, the field will become a keyword-only parameter to
    __init__().

    It is an error to specify both default and default_factory.
    'b'cannot specify both default and default_factory'u'cannot specify both default and default_factory'b',)'u',)'b'_return_type'u'_return_type'b'->_return_type'u'->_return_type'b' def 'u' def 'b':
'u':
'b'def __create_fn__('u'def __create_fn__('b'):
'u'):
'b'
 return 'u'
 return 'b'__create_fn__'u'__create_fn__'b'__dataclass_builtins_object__.__setattr__('u'__dataclass_builtins_object__.__setattr__('b'_dflt_'u'_dflt_'b'() if 'u'() if 'b' is _HAS_DEFAULT_FACTORY else 'u' is _HAS_DEFAULT_FACTORY else 'b'=_dflt_'u'=_dflt_'b'=_HAS_DEFAULT_FACTORY'u'=_HAS_DEFAULT_FACTORY'b':_type_'u':_type_'b'non-default argument 'u'non-default argument 'b' follows default argument'u' follows default argument'b'_type_'u'_type_'b'_HAS_DEFAULT_FACTORY'u'_HAS_DEFAULT_FACTORY'b'__dataclass_builtins_object__'u'__dataclass_builtins_object__'b'return self.__class__.__qualname__ + f"('u'return self.__class__.__qualname__ + f"('b'={{self.'u'={{self.'b'!r}}'u'!r}}'b')"'u')"'b'cls'b'__setattr__'u'__setattr__'b'if type(self) is cls or name in 'u'if type(self) is cls or name in 'b' raise FrozenInstanceError(f"cannot assign to field {name!r}")'u' raise FrozenInstanceError(f"cannot assign to field {name!r}")'b'super(cls, self).__setattr__(name, value)'u'super(cls, self).__setattr__(name, value)'b'__delattr__'u'__delattr__'b' raise FrozenInstanceError(f"cannot delete field {name!r}")'u' raise FrozenInstanceError(f"cannot delete field {name!r}")'b'super(cls, self).__delattr__(name)'u'super(cls, self).__delattr__(name)'b'other'u'other'b'if other.__class__ is self.__class__:'u'if other.__class__ is self.__class__:'b' return 'u' return 'b'return NotImplemented'u'return NotImplemented'b'return hash('u'return hash('b'field 'u'field 'b' cannot have a default factory'u' cannot have a default factory'b' is a ClassVar but specifies kw_only'u' is a ClassVar but specifies kw_only'b'mutable default 'u'mutable default 'b' for field 'u' for field 'b' is not allowed: use default_factory'u' is not allowed: use default_factory'b'Cannot overwrite attribute __hash__ in class 'u'Cannot overwrite attribute __hash__ in class 'b'__annotations__'u'__annotations__'b' is KW_ONLY, but KW_ONLY has already been specified'u' is KW_ONLY, but KW_ONLY has already been specified'b' is a field but has no type annotation'u' is a field but has no type annotation'b'cannot inherit non-frozen dataclass from a frozen one'u'cannot inherit non-frozen dataclass from a frozen one'b'cannot inherit frozen dataclass from a non-frozen one'u'cannot inherit frozen dataclass from a non-frozen one'b'__eq__'u'__eq__'b'eq must be true if order is true'u'eq must be true if order is true'b'__dataclass_self__'u'__dataclass_self__'b'__lt__'u'__lt__'b'__le__'u'__le__'b'__gt__'u'__gt__'b'__ge__'u'__ge__'b'Cannot overwrite attribute 'u'Cannot overwrite attribute 'b' in class 'u' in class 'b'. Consider using functools.total_ordering'u'. Consider using functools.total_ordering'b' -> None'u' -> None'b' already specifies __slots__'u' already specifies __slots__'b'Returns the same class as was passed in, with dunder methods
    added based on the fields defined in the class.

    Examines PEP 526 __annotations__ to determine fields.

    If init is true, an __init__() method is added to the class. If
    repr is true, a __repr__() method is added. If order is true, rich
    comparison dunder methods are added. If unsafe_hash is true, a
    __hash__() method function is added. If frozen is true, fields may
    not be assigned to after instance creation. If match_args is true,
    the __match_args__ tuple is added. If kw_only is true, then by
    default all fields are keyword-only. If slots is true, an
    __slots__ attribute is added.
    'u'Returns the same class as was passed in, with dunder methods
    added based on the fields defined in the class.

    Examines PEP 526 __annotations__ to determine fields.

    If init is true, an __init__() method is added to the class. If
    repr is true, a __repr__() method is added. If order is true, rich
    comparison dunder methods are added. If unsafe_hash is true, a
    __hash__() method function is added. If frozen is true, fields may
    not be assigned to after instance creation. If match_args is true,
    the __match_args__ tuple is added. If kw_only is true, then by
    default all fields are keyword-only. If slots is true, an
    __slots__ attribute is added.
    'b'Return a tuple describing the fields of this dataclass.

    Accepts a dataclass or an instance of one. Tuple elements are of
    type Field.
    'u'Return a tuple describing the fields of this dataclass.

    Accepts a dataclass or an instance of one. Tuple elements are of
    type Field.
    'b'must be called with a dataclass type or instance'u'must be called with a dataclass type or instance'b'Returns True if obj is an instance of a dataclass.'u'Returns True if obj is an instance of a dataclass.'b'Returns True if obj is a dataclass or an instance of a
    dataclass.'u'Returns True if obj is a dataclass or an instance of a
    dataclass.'b'Return the fields of a dataclass instance as a new dictionary mapping
    field names to field values.

    Example usage:

      @dataclass
      class C:
          x: int
          y: int

      c = C(1, 2)
      assert asdict(c) == {'x': 1, 'y': 2}

    If given, 'dict_factory' will be used instead of built-in dict.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts.
    'u'Return the fields of a dataclass instance as a new dictionary mapping
    field names to field values.

    Example usage:

      @dataclass
      class C:
          x: int
          y: int

      c = C(1, 2)
      assert asdict(c) == {'x': 1, 'y': 2}

    If given, 'dict_factory' will be used instead of built-in dict.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts.
    'b'asdict() should be called on dataclass instances'u'asdict() should be called on dataclass instances'b'Return the fields of a dataclass instance as a new tuple of field values.

    Example usage::

      @dataclass
      class C:
          x: int
          y: int

    c = C(1, 2)
    assert astuple(c) == (1, 2)

    If given, 'tuple_factory' will be used instead of built-in tuple.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts.
    'u'Return the fields of a dataclass instance as a new tuple of field values.

    Example usage::

      @dataclass
      class C:
          x: int
          y: int

    c = C(1, 2)
    assert astuple(c) == (1, 2)

    If given, 'tuple_factory' will be used instead of built-in tuple.
    The function applies recursively to field values that are
    dataclass instances. This will also look into built-in containers:
    tuples, lists, and dicts.
    'b'astuple() should be called on dataclass instances'u'astuple() should be called on dataclass instances'b'Return a new dynamically created dataclass.

    The dataclass name will be 'cls_name'.  'fields' is an iterable
    of either (name), (name, type) or (name, type, Field) objects. If type is
    omitted, use the string 'typing.Any'.  Field objects are created by
    the equivalent of calling 'field(name, type [, Field-info])'.

      C = make_dataclass('C', ['x', ('y', int), ('z', int, field(init=False))], bases=(Base,))

    is equivalent to:

      @dataclass
      class C(Base):
          x: 'typing.Any'
          y: int
          z: int = field(init=False)

    For the bases and namespace parameters, see the builtin type() function.

    The parameters init, repr, eq, order, unsafe_hash, and frozen are passed to
    dataclass().
    'u'Return a new dynamically created dataclass.

    The dataclass name will be 'cls_name'.  'fields' is an iterable
    of either (name), (name, type) or (name, type, Field) objects. If type is
    omitted, use the string 'typing.Any'.  Field objects are created by
    the equivalent of calling 'field(name, type [, Field-info])'.

      C = make_dataclass('C', ['x', ('y', int), ('z', int, field(init=False))], bases=(Base,))

    is equivalent to:

      @dataclass
      class C(Base):
          x: 'typing.Any'
          y: int
          z: int = field(init=False)

    For the bases and namespace parameters, see the builtin type() function.

    The parameters init, repr, eq, order, unsafe_hash, and frozen are passed to
    dataclass().
    'b'typing.Any'u'typing.Any'b'Invalid field: 'u'Invalid field: 'b'Field names must be valid identifiers: 'u'Field names must be valid identifiers: 'b'Field names must not be keywords: 'u'Field names must not be keywords: 'b'Field name duplicated: 'u'Field name duplicated: 'b'Return a new object replacing specified fields with new values.

    This is especially useful for frozen classes.  Example usage:

      @dataclass(frozen=True)
      class C:
          x: int
          y: int

      c = C(1, 2)
      c1 = replace(c, x=3)
      assert c1.x == 3 and c1.y == 2
      'u'Return a new object replacing specified fields with new values.

    This is especially useful for frozen classes.  Example usage:

      @dataclass(frozen=True)
      class C:
          x: int
          y: int

      c = C(1, 2)
      c1 = replace(c, x=3)
      assert c1.x == 3 and c1.y == 2
      'b'replace() should be called on dataclass instances'u'replace() should be called on dataclass instances'b' is declared with init=False, it cannot be specified with replace()'u' is declared with init=False, it cannot be specified with replace()'b'InitVar 'u'InitVar 'b' must be specified with replace()'u' must be specified with replace()'u'dataclasses'Concrete date/time and related types.

See http://www.iana.org/time-zones/repository/tz-link.html for
time zone and DST data sources.
_time_index3652059_MAXORDINAL_DAYS_IN_MONTH_DAYS_BEFORE_MONTHdim_is_leapyear -> 1 if leap year, else 0._days_before_yearyear -> number of days before January 1st of year.365_days_in_monthyear, month -> number of days in that month in that year._days_before_monthyear, month -> number of days in year preceding first day of month.month must be in 1..12_ymd2ordyear, month, day -> ordinal, considering 01-Jan-0001 as day 1.day must be in 1..%d_DI400Y_DI100Y_DI4Y_ord2ymdordinal -> (year, month, day), considering 01-Jan-0001 as day 1.n400n100n4n1leapyearpreceding_MONTHNAMES_DAYNAMES_build_struct_timedstflagwdaydnum_format_timetimespec{:02d}{:02d}:{:02d}{:02d}:{:02d}:{:02d}{:02d}:{:02d}:{:02d}.{:03d}milliseconds{:02d}:{:02d}:{:02d}.{:06d}specsUnknown timespec value_format_offset%s%02d:%02d:%02d.%06d_wrap_strftimefreplacezreplaceZreplacenewformat%06d%c%02d%02d%02d.%06d%c%02d%02d%02d%c%02d%02d_parse_isoformat_datedtstrInvalid date separator: %sInvalid date separator_parse_hh_mm_ss_fftime_compsIncomplete time componentnext_charInvalid time separator: %cInvalid microsecond componentlen_remainder_parse_isoformat_timeIsoformat time too shorttz_postziMalformed time zone stringtz_compstd_check_tznametzinfo.tzname() must return None or string, not '%s'"tzinfo.tzname() must return None or string, ""not '%s'"_check_utc_offsettzinfo.%s() must return None or timedelta, not '%s'"tzinfo.%s() must return None ""or timedelta, not '%s'"%s()=%s, must be strictly between -timedelta(hours=24) and timedelta(hours=24)"%s()=%s, must be strictly between ""-timedelta(hours=24) and timedelta(hours=24)"_check_date_fieldsyear must be in %d..%d_check_time_fieldshour must be in 0..23minute must be in 0..59second must be in 0..59microsecond must be in 0..999999fold must be either 0 or 1_check_tzinfo_argtzinfo argument must be None or of a tzinfo subclass_cmperrorcan't compare '%s' to '%s'_divide_and_rounddivide a by b and round result to the nearest integer

    When the ratio is exactly half-way between two integers,
    the even integer is returned.
    greater_than_halfRepresent the difference between two datetime objects.

    Supported operators:

    - add, subtract timedelta
    - unary plus, minus, abs
    - compare to timedelta
    - multiply, divide by int

    In addition, datetime supports subtraction of two datetime objects
    returning a timedelta, and addition or subtraction of a datetime
    and a timedelta giving a datetime.

    Representation: (days, seconds, microseconds).  Why?  Because I
    felt like it.
    _seconds_microseconds_hashcodemodfdayfrac24.024.3600.03600.daysecondsfracdaysecondswholesecondsfrac1000000.01e6usdouble2100000.02.1e610000003100000.03.1e6999999999timedelta # of days is too large: %ddays=%dseconds=%dmicroseconds=%d%s.%s(%s)%d:%02d:%02dplural%d day%s, Total seconds in the duration.86400_to_microsecondsusec_getstateConcrete date type.

    Constructors:

    __new__()
    fromtimestamp()
    today()
    fromordinal()

    Operators:

    __repr__, __str__
    __eq__, __le__, __lt__, __ge__, __gt__, __hash__
    __add__, __radd__, __sub__ (add/radd only with timedelta arg)

    Methods:

    timetuple()
    toordinal()
    weekday()
    isoweekday(), isocalendar(), isoformat()
    ctime()
    strftime()

    Properties (readonly):
    year, month, day
    _month_dayConstructor.

        Arguments:

        year, month, day (required, base 1)
        Failed to encode latin1 string when unpickling a date object. pickle.load(data, encoding='latin1') is assumed."Failed to encode latin1 string when unpickling ""a date object. ""pickle.load(data, encoding='latin1') is assumed."__setstateConstruct a date from a POSIX timestamp (like time.time()).jdayConstruct a date from time.time().Construct a date from a proleptic Gregorian ordinal.

        January 1 of year 1 is day 1.  Only the year, month and day are
        non-zero in the result.
        date_stringConstruct a date from the output of date.isoformat().fromisoformat: argument must be strInvalid isoformat string: Construct a date from the ISO year, week number and weekday.

        This is the inverse of the date.isocalendar() functionYear is out of range: out_of_rangefirst_weekdayInvalid week: Invalid weekday:  (range is [1, 7])day_offset_isoweek1mondayday_1ord_dayConvert to formal string, for repr().

        >>> dt = datetime(2010, 1, 1)
        >>> repr(dt)
        'datetime.datetime(2010, 1, 1, 0, 0)'

        >>> dt = datetime(2010, 1, 1, tzinfo=timezone.utc)
        >>> repr(dt)
        'datetime.datetime(2010, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)'
        %s.%s(%d, %d, %d)Return ctime() style string.%s %s %2d 00:00:00 %04dFormat using strftime().must be str, not %sReturn the date formatted according to ISO.

        This is 'YYYY-MM-DD'.

        References:
        - http://www.w3.org/TR/NOTE-datetime
        - http://www.cl.cam.ac.uk/~mgk25/iso-time.html
        %04d-%02d-%02dyear (1-9999)month (1-12)day (1-31)Return local time tuple compatible with time.localtime().Return proleptic Gregorian ordinal for the year, month and day.

        January 1 of year 1 is day 1.  Only the year, month and day values
        contribute to the result.
        Return a new date with new values for the specified fields.m2Hash.Add a date to a timedelta.result out of rangeSubtract two dates, or a date and a timedelta.days1days2Return day of the week, where Monday == 0 ... Sunday == 6.Return day of the week, where Monday == 1 ... Sunday == 7.Return a named tuple containing ISO year, week number, and weekday.

        The first ISO week of the year is the (Mon-Sun) week
        containing the year's first Thursday; everything else derives
        from that.

        The first week is 1; Monday is 1 ... Sunday is 7.

        ISO calendar algorithm taken from
        http://www.phys.uu.nl/~vgent/calendar/isocalendar.htm
        (used with permission)
        week1monday_IsoCalendarDateyhiylo_date_classAbstract base class for time zone info classes.

    Subclasses must override the name(), utcoffset() and dst() methods.
    datetime -> string name of time zone.tzinfo subclass must override tzname()datetime -> timedelta, positive for east of UTC, negative for west of UTCtzinfo subclass must override utcoffset()datetime -> DST offset as timedelta, positive for east of UTC.

        Return 0 if DST not in effect.  utcoffset() must include the DST
        offset.
        tzinfo subclass must override dst()datetime in UTC -> datetime in local time.getinitargsIsoCalendarDate(year='(year=', week=, weekday=_tzinfo_classTime with time zone.

    Constructors:

    __new__()

    Operators:

    __repr__, __str__
    __eq__, __le__, __lt__, __ge__, __gt__, __hash__

    Methods:

    strftime()
    isoformat()
    utcoffset()
    tzname()
    dst()

    Properties (readonly):
    hour, minute, second, microsecond, tzinfo, fold
    _hour_minute_second_microsecondConstructor.

        Arguments:

        hour, minute (required)
        second, microsecond (default to zero)
        tzinfo (default to None)
        fold (keyword only, default to zero)
        0x7FFailed to encode latin1 string when unpickling a time object. pickle.load(data, encoding='latin1') is assumed."a time object. "hour (0-23)minute (0-59)second (0-59)microsecond (0-999999)timezone info objectallow_mixedmytzottzmyoffotoffbase_comparecannot compare naive and aware timesmyhhmmothhmmtzoffwhole minute_tzstrReturn formatted timezone offset (+xx:xx) or an empty string.Convert to formal string, for repr()., %d, %d, %d%s.%s(%d, %d%s), tzinfo=%r, fold=1)Return the time formatted according to ISO.

        The full format is 'HH:MM:SS.mmmmmm+zz:zz'. By default, the fractional
        part is omitted if self.microsecond == 0.

        The optional argument timespec specifies the number of additional
        terms of the time to include. Valid options are 'auto', 'hours',
        'minutes', 'seconds', 'milliseconds' and 'microseconds'.
        time_stringConstruct a time from the output of isoformat().Format using strftime().  The date part of the timestamp passed
        to underlying strftime should not be used.
        Return the timezone offset as timedelta, positive east of UTC
         (negative west of UTC).Return the timezone name.

        Note that the name is 100% informational -- there's no requirement that
        it mean anything in particular. For example, "GMT", "UTC", "-500",
        "-5:00", "EDT", "US/Eastern", "America/New York" are all valid replies.
        Return 0 if DST is not in effect, or the DST offset (as timedelta
        positive eastward) if DST is in effect.

        This is purely informational; the DST offset has already been added to
        the UTC offset returned by utcoffset() if applicable, so there's no
        need to consult dst() unless you're interested in displaying the DST
        info.
        Return a new time with new values for the specified fields.us2us3us1basestatebad tzinfo state arg_time_classdatetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])

    The year, month and day arguments are required. tzinfo may be None, or an
    instance of a tzinfo subclass. The remaining arguments may be ints.
    Failed to encode latin1 string when unpickling a datetime object. pickle.load(data, encoding='latin1') is assumed."a datetime object. "_fromtimestampConstruct a datetime from a POSIX timestamp (like time.time()).

        A timezone info object may be passed in as well.
        max_fold_secondsprobe1transprobe2Construct a naive UTC datetime from a POSIX timestamp.Construct a datetime from time.time() and optional time zone info.Construct a UTC datetime from time.time().Construct a datetime from a given date and a given time.date argument must be a date instancetime argument must be a time instanceConstruct a datetime from the output of datetime.isoformat().dstrdate_componentstime_components_mktimeReturn integer POSIX timestamp.epochu1t1t2Return POSIX timestamp as float_EPOCHReturn UTC time tuple compatible with time.gmtime().Return the date part.Return the time part, with tzinfo None.Return the time part, with same tzinfo.Return a new datetime with new values for the specified fields._local_timezonetslocaltmtm_gmtoffgmtoffzonetz argument must be an instance of tzinfomyoffset%s %s %2d %02d:%02d:%02d %04dReturn the time formatted according to ISO.

        The full format looks like 'YYYY-MM-DD HH:MM:SS.mmmmmm'.
        By default, the fractional part is omitted if self.microsecond == 0.

        If self.tzinfo is not None, the UTC offset is also attached, giving
        giving a full format of 'YYYY-MM-DD HH:MM:SS.mmmmmm+HH:MM'.

        Optional argument sep specifies the separator between date and
        time, default 'T'.

        The optional argument timespec specifies the number of additional
        terms of the time to include. Valid options are 'auto', 'hours',
        'minutes', 'seconds', 'milliseconds' and 'microseconds'.
        %04d-%02d-%02d%cConvert to string, for str().string, format -> new datetime parsed from a string (like time.strptime())._strptime_strptime_datetimeReturn the timezone offset as timedelta positive east of UTC (negative west of
        UTC).cannot compare naive and aware datetimesAdd a datetime and a timedelta.Subtract two datetimes, or a datetime and a timedelta.secs1secs2cannot mix naive and timezone-aware timefirstday_offset_Omittedoffset must be a timedelta_minoffset_maxoffsetoffset must be a timedelta strictly between -timedelta(hours=24) and timedelta(hours=24)."offset must be a timedelta ""strictly between -timedelta(hours=24) and ""timedelta(hours=24)."pickle supportConvert to formal string, for repr().

        >>> tz = timezone.utc
        >>> repr(tz)
        'datetime.timezone.utc'
        >>> tz = timezone(timedelta(hours=-5), 'EST')
        >>> repr(tz)
        "datetime.timezone(datetime.timedelta(-1, 68400), 'EST')"
        datetime.timezone.utc%s.%s(%r)%s.%s(%r, %r)utcoffset() argument must be a datetime instance or None"utcoffset() argument must be a datetime instance"" or None"_name_from_offsettzname() argument must be a datetime instance or None"tzname() argument must be a datetime instance"dst() argument must be a datetime instance or None"dst() argument must be a datetime instance"fromutc: dt.tzinfo is not self"fromutc: dt.tzinfo ""is not self"fromutc() argument must be a datetime instance or None"fromutc() argument must be a datetime instance"'.'# date.max.toordinal()# Utility functions, adapted from Python's Demo/classes/Dates.py, which# also assumes the current Gregorian calendar indefinitely extended in# both directions.  Difference:  Dates.py calls January 1 of year 0 day# number 1.  The code here calls January 1 of year 1 day number 1.  This is# to match the definition of the "proleptic Gregorian" calendar in Dershowitz# and Reingold's "Calendrical Calculations", where it's the base calendar# for all computations.  See the book for algorithms for converting between# proleptic Gregorian ordinals and many other calendar systems.# -1 is a placeholder for indexing purposes.# number of days in 400 years#    "    "   "   " 100   "#    "    "   "   "   4   "# A 4-year cycle has an extra leap day over what we'd get from pasting# together 4 single years.# Similarly, a 400-year cycle has an extra leap day over what we'd get from# pasting together 4 100-year cycles.# OTOH, a 100-year cycle has one fewer leap day than we'd get from# pasting together 25 4-year cycles.# n is a 1-based index, starting at 1-Jan-1.  The pattern of leap years# repeats exactly every 400 years.  The basic strategy is to find the# closest 400-year boundary at or before n, then work with the offset# from that boundary to n.  Life is much clearer if we subtract 1 from# n first -- then the values of n at 400-year boundaries are exactly# those divisible by _DI400Y:#     D  M   Y            n              n-1#     -- --- ----        ----------     ----------------#     31 Dec -400        -_DI400Y       -_DI400Y -1#      1 Jan -399         -_DI400Y +1   -_DI400Y      400-year boundary#     ...#     30 Dec  000        -1             -2#     31 Dec  000         0             -1#      1 Jan  001         1              0            400-year boundary#      2 Jan  001         2              1#      3 Jan  001         3              2#     31 Dec  400         _DI400Y        _DI400Y -1#      1 Jan  401         _DI400Y +1     _DI400Y      400-year boundary# ..., -399, 1, 401, ...# Now n is the (non-negative) offset, in days, from January 1 of year, to# the desired date.  Now compute how many 100-year cycles precede n.# Note that it's possible for n100 to equal 4!  In that case 4 full# 100-year cycles precede the desired day, which implies the desired# day is December 31 at the end of a 400-year cycle.# Now compute how many 4-year cycles precede it.# And now how many single years.  Again n1 can be 4, and again meaning# that the desired day is December 31 at the end of the 4-year cycle.# Now the year is correct, and n is the offset from January 1.  We find# the month via an estimate that's either exact or one too large.# estimate is too large# Now the year and month are correct, and n is the offset from the# start of that month:  we're done!# Month and day names.  For localized versions, see the calendar module.# Skip trailing microseconds when us==0.# Correctly substitute for %z and %Z escapes in strftime formats.# Don't call utcoffset() or tzname() unless actually needed.# the string to use for %f# the string to use for %z# the string to use for %Z# Scan format for %z and %Z escapes, replacing as needed.# strftime is going to have at this: escape %# Helpers for parsing the result of isoformat()# It is assumed that this function will only be called with a# string of length exactly 10, and (though this is not used) ASCII-only# Parses things of the form HH[:MM[:SS[.fff[fff]]]]# Format supported is HH[:MM[:SS[.fff[fff]]]][+HH:MM[:SS[.ffffff]]]# This is equivalent to re.search('[+-]', tstr), but faster# Valid time zone strings are:# HH:MM               len: 5# HH:MM:SS            len: 8# HH:MM:SS.ffffff     len: 15# Just raise TypeError if the arg isn't None or a string.# name is the offset-producing method, "utcoffset" or "dst".# offset is what it returned.# If offset isn't None or timedelta, raises TypeError.# If offset is None, returns None.# Else offset is checked for being in range.# If it is, its integer value is returned.  Else ValueError is raised.# Based on the reference implementation for divmod_near# in Objects/longobject.c.# round up if either r / b > 0.5, or r / b == 0.5 and q is odd.# The expression r / b > 0.5 is equivalent to 2 * r > b if b is# positive, 2 * r < b if b negative.# Doing this efficiently and accurately in C is going to be difficult# and error-prone, due to ubiquitous overflow possibilities, and that# C double doesn't have enough bits of precision to represent# microseconds over 10K years faithfully.  The code here tries to make# explicit where go-fast assumptions can be relied on, in order to# guide the C implementation; it's way more convoluted than speed-# ignoring auto-overflow-to-long idiomatic Python could be.# XXX Check that all inputs are ints or floats.# Final values, all integer.# s and us fit in 32-bit signed ints; d isn't bounded.# Normalize everything to days, seconds, microseconds.# Get rid of all fractions, and normalize s and us.# Take a deep breath <wink>.# can't overflow# days isn't referenced again before redefinition# daysecondsfrac isn't referenced again# seconds isn't referenced again before redefinition# exact value not critical# secondsfrac isn't referenced again# Just a little bit of carrying possible for microseconds and seconds.# Read-only field accessors# for CPython compatibility, we cannot use# our __class__ here, but need a real timedelta# Comparisons of timedelta objects with other.# Pickle support.# Pickle support# More informative error message.# Additional constructors# Year is bounded this way because 9999-12-31 is (9999, 52, 5)# ISO years have 53 weeks in them on years starting with a# Thursday and leap years starting on a Wednesday# Now compute the offset from (Y, 1, 1) in days:# Calculate the ordinal day for monday, week 1# Conversions to string# XXX These shouldn't depend on time.localtime(), because that# clips the usable dates to [1970 .. 2038).  At least ctime() is# easily done without using strftime() -- that's better too because# strftime("%c", ...) is locale specific.# Standard conversions, __eq__, __le__, __lt__, __ge__, __gt__,# __hash__ (and helpers)# Comparisons of date objects with other.# Computations# Day-of-the-week and week-of-the-year, according to ISO# 1-Jan-0001 is a Monday# Internally, week and day have origin 0# so functions w/ args named "date" can get at the class# See the long comment block at the end of this file for an# explanation of this algorithm.# This code is intended to pickle the object without making the# class public. See https://bugs.python.org/msg352381# Standard conversions, __hash__ (and helpers)# Comparisons of time objects with other.# arbitrary non-zero value# zero or None# Conversion to string# The year must be >= 1000 else Python's strftime implementation# can raise a bogus exception.# Timezone functions# so functions w/ args named "time" can get at the class# clamp out leap seconds if the platform has them# As of version 2015f max fold in IANA database is# 23 hours at 1969-09-30 13:00:00 in Kwajalein.# Let's probe 24 hours in the past to detect a transition:# On Windows localtime_s throws an OSError for negative values,# thus we can't perform fold detection for values of time less# than the max time fold. See comments in _datetimemodule's# version of this method for more details.# Split this at the separator# Our goal is to solve t = local(u) for u.# We found one solution, but it may not be the one we need.# Look for an earlier solution (if `fold` is 0), or a# later one (if `fold` is 1).# We have found both offsets a and b, but neither t - a nor t - b is# a solution.  This means t is in the gap.# Extract TZ data# Convert self to UTC, and attach the new time zone object.# Convert from UTC to tz's local time.# Ways to produce a string.# These are never zero# Comparisons of datetime objects with other.# Assume that allow_mixed means that we are called from __eq__# XXX What follows could be done more efficiently...# this will take offsets into account# Helper to calculate the day number of the Monday starting week 1# XXX This could be done more efficiently# See weekday() above# Sentinel value to disallow None# bpo-37642: These attributes are rounded to the nearest minute for backwards# compatibility, even though the constructor will accept a wider range of# values. This may change in the future.# Some time zone algebra.  For a datetime x, let#     x.n = x stripped of its timezone -- its naive time.#     x.o = x.utcoffset(), and assuming that doesn't raise an exception or#           return None#     x.d = x.dst(), and assuming that doesn't raise an exception or#     x.s = x's standard offset, x.o - x.d# Now some derived rules, where k is a duration (timedelta).# 1. x.o = x.s + x.d#    This follows from the definition of x.s.# 2. If x and y have the same tzinfo member, x.s = y.s.#    This is actually a requirement, an assumption we need to make about#    sane tzinfo classes.# 3. The naive UTC time corresponding to x is x.n - x.o.#    This is again a requirement for a sane tzinfo class.# 4. (x+k).s = x.s#    This follows from #2, and that datetime.timetz+timedelta preserves tzinfo.# 5. (x+k).n = x.n + k#    Again follows from how arithmetic is defined.# Now we can explain tz.fromutc(x).  Let's assume it's an interesting case# (meaning that the various tzinfo methods exist, and don't blow up or return# None when called).# The function wants to return a datetime y with timezone tz, equivalent to x.# x is already in UTC.# By #3, we want#     y.n - y.o = x.n                             [1]# The algorithm starts by attaching tz to x.n, and calling that y.  So# x.n = y.n at the start.  Then it wants to add a duration k to y, so that [1]# becomes true; in effect, we want to solve [2] for k:#    (y+k).n - (y+k).o = x.n                      [2]# By #1, this is the same as#    (y+k).n - ((y+k).s + (y+k).d) = x.n          [3]# By #5, (y+k).n = y.n + k, which equals x.n + k because x.n=y.n at the start.# Substituting that into [3],#    x.n + k - (y+k).s - (y+k).d = x.n; the x.n terms cancel, leaving#    k - (y+k).s - (y+k).d = 0; rearranging,#    k = (y+k).s - (y+k).d; by #4, (y+k).s == y.s, so#    k = y.s - (y+k).d# On the RHS, (y+k).d can't be computed directly, but y.s can be, and we# approximate k by ignoring the (y+k).d term at first.  Note that k can't be# very large, since all offset-returning methods return a duration of magnitude# less than 24 hours.  For that reason, if y is firmly in std time, (y+k).d must# be 0, so ignoring it has no consequence then.# In any case, the new value is#     z = y + y.s                                 [4]# It's helpful to step back at look at [4] from a higher level:  it's simply# mapping from UTC to tz's standard time.# At this point, if#     z.n - z.o = x.n                             [5]# we have an equivalent time, and are almost done.  The insecurity here is# at the start of daylight time.  Picture US Eastern for concreteness.  The wall# time jumps from 1:59 to 3:00, and wall hours of the form 2:MM don't make good# sense then.  The docs ask that an Eastern tzinfo class consider such a time to# be EDT (because it's "after 2"), which is a redundant spelling of 1:MM EST# on the day DST starts.  We want to return the 1:MM EST spelling because that's# the only spelling that makes sense on the local wall clock.# In fact, if [5] holds at this point, we do have the standard-time spelling,# but that takes a bit of proof.  We first prove a stronger result.  What's the# difference between the LHS and RHS of [5]?  Let#     diff = x.n - (z.n - z.o)                    [6]# Now#     z.n =                       by [4]#     (y + y.s).n =               by #5#     y.n + y.s =                 since y.n = x.n#     x.n + y.s =                 since z and y are have the same tzinfo member,#                                     y.s = z.s by #2#     x.n + z.s# Plugging that back into [6] gives#     diff =#     x.n - ((x.n + z.s) - z.o) =     expanding#     x.n - x.n - z.s + z.o =         cancelling#     - z.s + z.o =                   by #2#     z.d# So diff = z.d.# If [5] is true now, diff = 0, so z.d = 0 too, and we have the standard-time# spelling we wanted in the endcase described above.  We're done.  Contrarily,# if z.d = 0, then we have a UTC equivalent, and are also done.# If [5] is not true now, diff = z.d != 0, and z.d is the offset we need to# add to z (in effect, z is in tz's standard time, and we need to shift the# local clock into tz's daylight time).# Let#     z' = z + z.d = z + diff                     [7]# and we can again ask whether#     z'.n - z'.o = x.n                           [8]# If so, we're done.  If not, the tzinfo class is insane, according to the# assumptions we've made.  This also requires a bit of proof.  As before, let's# compute the difference between the LHS and RHS of [8] (and skipping some of# the justifications for the kinds of substitutions we've done several times# already):#     diff' = x.n - (z'.n - z'.o) =           replacing z'.n via [7]#             x.n  - (z.n + diff - z'.o) =    replacing diff via [6]#             x.n - (z.n + x.n - (z.n - z.o) - z'.o) =#             x.n - z.n - x.n + z.n - z.o + z'.o =    cancel x.n#             - z.n + z.n - z.o + z'.o =              cancel z.n#             - z.o + z'.o =                      #1 twice#             -z.s - z.d + z'.s + z'.d =          z and z' have same tzinfo#             z'.d - z.d# So z' is UTC-equivalent to x iff z'.d = z.d at this point.  If they are equal,# we've found the UTC-equivalent so are done.  In fact, we stop with [7] and# return z', not bothering to compute z'.d.# How could z.d and z'd differ?  z' = z + z.d [7], so merely moving z' by# a dst() offset, and starting *from* a time already in DST (we know z.d != 0),# would have to change the result dst() returns:  we start in DST, and moving# a little further into it takes us out of DST.# There isn't a sane case where this can happen.  The closest it gets is at# the end of DST, where there's an hour in UTC with no spelling in a hybrid# tzinfo class.  In US Eastern, that's 5:MM UTC = 0:MM EST = 1:MM EDT.  During# that hour, on an Eastern clock 1:MM is taken as being in standard time (6:MM# UTC) because the docs insist on that, but 0:MM is taken as being in daylight# time (4:MM UTC).  There is no local time mapping to 5:MM UTC.  The local# clock jumps from 1:59 back to 1:00 again, and repeats the 1:MM hour in# standard time.  Since that's what the local clock *does*, we want to map both# UTC hours 5:MM and 6:MM to 1:MM Eastern.  The result is ambiguous# in local time, but so it goes -- it's the way the local clock works.# When x = 5:MM UTC is the input to this algorithm, x.o=0, y.o=-5 and y.d=0,# so z=0:MM.  z.d=60 (minutes) then, so [5] doesn't hold and we keep going.# z' = z + z.d = 1:MM then, and z'.d=0, and z'.d - z.d = -60 != 0 so [8]# (correctly) concludes that z' is not UTC-equivalent to x.# Because we know z.d said z was in daylight time (else [5] would have held and# we would have stopped then), and we know z.d != z'.d (else [8] would have held# and we have stopped then), and there are only 2 possible values dst() can# return in Eastern, it follows that z'.d must be 0 (which it is in the example,# but the reasoning doesn't depend on the example -- it depends on there being# two possible dst() outcomes, one zero and the other non-zero).  Therefore# z' must be in standard time, and is the spelling we want in this case.# Note again that z' is not UTC-equivalent as far as the hybrid tzinfo class is# concerned (because it takes z' as being in standard time rather than the# daylight time we intend here), but returning it gives the real-life "local# clock repeats an hour" behavior when mapping the "unspellable" UTC hour into# tz.# When the input is 6:MM, z=1:MM and z.d=0, and we stop at once, again with# the 1:MM standard time spelling we want.# So how can this break?  One of the assumptions must be violated.  Two# possibilities:# 1) [2] effectively says that y.s is invariant across all y belong to a given#    time zone.  This isn't true if, for political reasons or continental drift,#    a region decides to change its base offset from UTC.# 2) There may be versions of "double daylight" time where the tail end of#    the analysis gives up a step too early.  I haven't thought about that#    enough to say.# In any case, it's clear that the default fromutc() is strong enough to handle# "almost all" time zones:  so long as the standard offset is invariant, it# doesn't matter if daylight time transition points change from year to year, or# if daylight time is skipped in some years; it doesn't matter how large or# small dst() may get within its bounds; and it doesn't even matter if some# perverse time zone returns a negative dst()).  So a breaking case must be# pretty bizarre, and a tzinfo subclass can override fromutc() if it is.# Clean up unused names# XXX Since import * above excludes names that start with _,# docstring does not get overwritten. In the future, it may be# appropriate to maintain a single module level docstring and# remove the following line.b'Concrete date/time and related types.

See http://www.iana.org/time-zones/repository/tz-link.html for
time zone and DST data sources.
'u'Concrete date/time and related types.

See http://www.iana.org/time-zones/repository/tz-link.html for
time zone and DST data sources.
'b'datetime'u'datetime'b'timedelta'u'timedelta'b'timezone'u'timezone'b'MINYEAR'u'MINYEAR'b'MAXYEAR'u'MAXYEAR'b'year -> 1 if leap year, else 0.'u'year -> 1 if leap year, else 0.'b'year -> number of days before January 1st of year.'u'year -> number of days before January 1st of year.'b'year, month -> number of days in that month in that year.'u'year, month -> number of days in that month in that year.'b'year, month -> number of days in year preceding first day of month.'u'year, month -> number of days in year preceding first day of month.'b'month must be in 1..12'u'month must be in 1..12'b'year, month, day -> ordinal, considering 01-Jan-0001 as day 1.'u'year, month, day -> ordinal, considering 01-Jan-0001 as day 1.'b'day must be in 1..%d'u'day must be in 1..%d'b'ordinal -> (year, month, day), considering 01-Jan-0001 as day 1.'u'ordinal -> (year, month, day), considering 01-Jan-0001 as day 1.'b'{:02d}'u'{:02d}'b'{:02d}:{:02d}'u'{:02d}:{:02d}'b'{:02d}:{:02d}:{:02d}'u'{:02d}:{:02d}:{:02d}'b'{:02d}:{:02d}:{:02d}.{:03d}'u'{:02d}:{:02d}:{:02d}.{:03d}'b'milliseconds'u'milliseconds'b'{:02d}:{:02d}:{:02d}.{:06d}'u'{:02d}:{:02d}:{:02d}.{:06d}'b'microseconds'u'microseconds'b'Unknown timespec value'u'Unknown timespec value'b'%s%02d:%02d'u'%s%02d:%02d'b':%02d'u':%02d'b'.%06d'u'.%06d'b'%06d'u'%06d'b'utcoffset'u'utcoffset'b'%c%02d%02d%02d.%06d'u'%c%02d%02d%02d.%06d'b'%c%02d%02d%02d'u'%c%02d%02d%02d'b'%c%02d%02d'u'%c%02d%02d'b'Invalid date separator: %s'u'Invalid date separator: %s'b'Invalid date separator'u'Invalid date separator'b'Incomplete time component'u'Incomplete time component'b'Invalid time separator: %c'u'Invalid time separator: %c'b'Invalid microsecond component'u'Invalid microsecond component'b'Isoformat time too short'u'Isoformat time too short'b'Malformed time zone string'u'Malformed time zone string'b'tzinfo.tzname() must return None or string, not '%s''u'tzinfo.tzname() must return None or string, not '%s''b'dst'u'dst'b'tzinfo.%s() must return None or timedelta, not '%s''u'tzinfo.%s() must return None or timedelta, not '%s''b'%s()=%s, must be strictly between -timedelta(hours=24) and timedelta(hours=24)'u'%s()=%s, must be strictly between -timedelta(hours=24) and timedelta(hours=24)'b'year must be in %d..%d'u'year must be in %d..%d'b'hour must be in 0..23'u'hour must be in 0..23'b'minute must be in 0..59'u'minute must be in 0..59'b'second must be in 0..59'u'second must be in 0..59'b'microsecond must be in 0..999999'u'microsecond must be in 0..999999'b'fold must be either 0 or 1'u'fold must be either 0 or 1'b'tzinfo argument must be None or of a tzinfo subclass'u'tzinfo argument must be None or of a tzinfo subclass'b'can't compare '%s' to '%s''u'can't compare '%s' to '%s''b'divide a by b and round result to the nearest integer

    When the ratio is exactly half-way between two integers,
    the even integer is returned.
    'u'divide a by b and round result to the nearest integer

    When the ratio is exactly half-way between two integers,
    the even integer is returned.
    'b'Represent the difference between two datetime objects.

    Supported operators:

    - add, subtract timedelta
    - unary plus, minus, abs
    - compare to timedelta
    - multiply, divide by int

    In addition, datetime supports subtraction of two datetime objects
    returning a timedelta, and addition or subtraction of a datetime
    and a timedelta giving a datetime.

    Representation: (days, seconds, microseconds).  Why?  Because I
    felt like it.
    'u'Represent the difference between two datetime objects.

    Supported operators:

    - add, subtract timedelta
    - unary plus, minus, abs
    - compare to timedelta
    - multiply, divide by int

    In addition, datetime supports subtraction of two datetime objects
    returning a timedelta, and addition or subtraction of a datetime
    and a timedelta giving a datetime.

    Representation: (days, seconds, microseconds).  Why?  Because I
    felt like it.
    'b'_days'u'_days'b'_seconds'u'_seconds'b'_microseconds'u'_microseconds'b'_hashcode'u'_hashcode'b'timedelta # of days is too large: %d'u'timedelta # of days is too large: %d'b'days=%d'u'days=%d'b'seconds=%d'u'seconds=%d'b'microseconds=%d'u'microseconds=%d'b'%s.%s(%s)'u'%s.%s(%s)'b'%d:%02d:%02d'u'%d:%02d:%02d'b'%d day%s, 'u'%d day%s, 'b'Total seconds in the duration.'u'Total seconds in the duration.'b'days'u'days'b'Concrete date type.

    Constructors:

    __new__()
    fromtimestamp()
    today()
    fromordinal()

    Operators:

    __repr__, __str__
    __eq__, __le__, __lt__, __ge__, __gt__, __hash__
    __add__, __radd__, __sub__ (add/radd only with timedelta arg)

    Methods:

    timetuple()
    toordinal()
    weekday()
    isoweekday(), isocalendar(), isoformat()
    ctime()
    strftime()

    Properties (readonly):
    year, month, day
    'u'Concrete date type.

    Constructors:

    __new__()
    fromtimestamp()
    today()
    fromordinal()

    Operators:

    __repr__, __str__
    __eq__, __le__, __lt__, __ge__, __gt__, __hash__
    __add__, __radd__, __sub__ (add/radd only with timedelta arg)

    Methods:

    timetuple()
    toordinal()
    weekday()
    isoweekday(), isocalendar(), isoformat()
    ctime()
    strftime()

    Properties (readonly):
    year, month, day
    'b'_year'u'_year'b'_month'u'_month'b'_day'u'_day'b'Constructor.

        Arguments:

        year, month, day (required, base 1)
        'u'Constructor.

        Arguments:

        year, month, day (required, base 1)
        'b'Failed to encode latin1 string when unpickling a date object. pickle.load(data, encoding='latin1') is assumed.'u'Failed to encode latin1 string when unpickling a date object. pickle.load(data, encoding='latin1') is assumed.'b'Construct a date from a POSIX timestamp (like time.time()).'u'Construct a date from a POSIX timestamp (like time.time()).'b'Construct a date from time.time().'u'Construct a date from time.time().'b'Construct a date from a proleptic Gregorian ordinal.

        January 1 of year 1 is day 1.  Only the year, month and day are
        non-zero in the result.
        'u'Construct a date from a proleptic Gregorian ordinal.

        January 1 of year 1 is day 1.  Only the year, month and day are
        non-zero in the result.
        'b'Construct a date from the output of date.isoformat().'u'Construct a date from the output of date.isoformat().'b'fromisoformat: argument must be str'u'fromisoformat: argument must be str'b'Invalid isoformat string: 'u'Invalid isoformat string: 'b'Construct a date from the ISO year, week number and weekday.

        This is the inverse of the date.isocalendar() function'u'Construct a date from the ISO year, week number and weekday.

        This is the inverse of the date.isocalendar() function'b'Year is out of range: 'u'Year is out of range: 'b'Invalid week: 'u'Invalid week: 'b'Invalid weekday: 'u'Invalid weekday: 'b' (range is [1, 7])'u' (range is [1, 7])'b'Convert to formal string, for repr().

        >>> dt = datetime(2010, 1, 1)
        >>> repr(dt)
        'datetime.datetime(2010, 1, 1, 0, 0)'

        >>> dt = datetime(2010, 1, 1, tzinfo=timezone.utc)
        >>> repr(dt)
        'datetime.datetime(2010, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)'
        'u'Convert to formal string, for repr().

        >>> dt = datetime(2010, 1, 1)
        >>> repr(dt)
        'datetime.datetime(2010, 1, 1, 0, 0)'

        >>> dt = datetime(2010, 1, 1, tzinfo=timezone.utc)
        >>> repr(dt)
        'datetime.datetime(2010, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)'
        'b'%s.%s(%d, %d, %d)'u'%s.%s(%d, %d, %d)'b'Return ctime() style string.'u'Return ctime() style string.'b'%s %s %2d 00:00:00 %04d'u'%s %s %2d 00:00:00 %04d'b'Format using strftime().'u'Format using strftime().'b'must be str, not %s'u'must be str, not %s'b'Return the date formatted according to ISO.

        This is 'YYYY-MM-DD'.

        References:
        - http://www.w3.org/TR/NOTE-datetime
        - http://www.cl.cam.ac.uk/~mgk25/iso-time.html
        'u'Return the date formatted according to ISO.

        This is 'YYYY-MM-DD'.

        References:
        - http://www.w3.org/TR/NOTE-datetime
        - http://www.cl.cam.ac.uk/~mgk25/iso-time.html
        'b'%04d-%02d-%02d'u'%04d-%02d-%02d'b'year (1-9999)'u'year (1-9999)'b'month (1-12)'u'month (1-12)'b'day (1-31)'u'day (1-31)'b'Return local time tuple compatible with time.localtime().'u'Return local time tuple compatible with time.localtime().'b'Return proleptic Gregorian ordinal for the year, month and day.

        January 1 of year 1 is day 1.  Only the year, month and day values
        contribute to the result.
        'u'Return proleptic Gregorian ordinal for the year, month and day.

        January 1 of year 1 is day 1.  Only the year, month and day values
        contribute to the result.
        'b'Return a new date with new values for the specified fields.'u'Return a new date with new values for the specified fields.'b'Hash.'u'Hash.'b'Add a date to a timedelta.'u'Add a date to a timedelta.'b'result out of range'u'result out of range'b'Subtract two dates, or a date and a timedelta.'u'Subtract two dates, or a date and a timedelta.'b'Return day of the week, where Monday == 0 ... Sunday == 6.'u'Return day of the week, where Monday == 0 ... Sunday == 6.'b'Return day of the week, where Monday == 1 ... Sunday == 7.'u'Return day of the week, where Monday == 1 ... Sunday == 7.'b'Return a named tuple containing ISO year, week number, and weekday.

        The first ISO week of the year is the (Mon-Sun) week
        containing the year's first Thursday; everything else derives
        from that.

        The first week is 1; Monday is 1 ... Sunday is 7.

        ISO calendar algorithm taken from
        http://www.phys.uu.nl/~vgent/calendar/isocalendar.htm
        (used with permission)
        'u'Return a named tuple containing ISO year, week number, and weekday.

        The first ISO week of the year is the (Mon-Sun) week
        containing the year's first Thursday; everything else derives
        from that.

        The first week is 1; Monday is 1 ... Sunday is 7.

        ISO calendar algorithm taken from
        http://www.phys.uu.nl/~vgent/calendar/isocalendar.htm
        (used with permission)
        'b'Abstract base class for time zone info classes.

    Subclasses must override the name(), utcoffset() and dst() methods.
    'u'Abstract base class for time zone info classes.

    Subclasses must override the name(), utcoffset() and dst() methods.
    'b'datetime -> string name of time zone.'u'datetime -> string name of time zone.'b'tzinfo subclass must override tzname()'u'tzinfo subclass must override tzname()'b'datetime -> timedelta, positive for east of UTC, negative for west of UTC'u'datetime -> timedelta, positive for east of UTC, negative for west of UTC'b'tzinfo subclass must override utcoffset()'u'tzinfo subclass must override utcoffset()'b'datetime -> DST offset as timedelta, positive for east of UTC.

        Return 0 if DST not in effect.  utcoffset() must include the DST
        offset.
        'u'datetime -> DST offset as timedelta, positive for east of UTC.

        Return 0 if DST not in effect.  utcoffset() must include the DST
        offset.
        'b'tzinfo subclass must override dst()'u'tzinfo subclass must override dst()'b'datetime in UTC -> datetime in local time.'u'datetime in UTC -> datetime in local time.'b'__getinitargs__'u'__getinitargs__'b'__getstate__'u'__getstate__'b'(year='u'(year='b', week='u', week='b', weekday='u', weekday='b'Time with time zone.

    Constructors:

    __new__()

    Operators:

    __repr__, __str__
    __eq__, __le__, __lt__, __ge__, __gt__, __hash__

    Methods:

    strftime()
    isoformat()
    utcoffset()
    tzname()
    dst()

    Properties (readonly):
    hour, minute, second, microsecond, tzinfo, fold
    'u'Time with time zone.

    Constructors:

    __new__()

    Operators:

    __repr__, __str__
    __eq__, __le__, __lt__, __ge__, __gt__, __hash__

    Methods:

    strftime()
    isoformat()
    utcoffset()
    tzname()
    dst()

    Properties (readonly):
    hour, minute, second, microsecond, tzinfo, fold
    'b'_hour'u'_hour'b'_minute'u'_minute'b'_second'u'_second'b'_microsecond'u'_microsecond'b'_tzinfo'u'_tzinfo'b'_fold'u'_fold'b'Constructor.

        Arguments:

        hour, minute (required)
        second, microsecond (default to zero)
        tzinfo (default to None)
        fold (keyword only, default to zero)
        'u'Constructor.

        Arguments:

        hour, minute (required)
        second, microsecond (default to zero)
        tzinfo (default to None)
        fold (keyword only, default to zero)
        'b'Failed to encode latin1 string when unpickling a time object. pickle.load(data, encoding='latin1') is assumed.'u'Failed to encode latin1 string when unpickling a time object. pickle.load(data, encoding='latin1') is assumed.'b'hour (0-23)'u'hour (0-23)'b'minute (0-59)'u'minute (0-59)'b'second (0-59)'u'second (0-59)'b'microsecond (0-999999)'u'microsecond (0-999999)'b'timezone info object'u'timezone info object'b'cannot compare naive and aware times'u'cannot compare naive and aware times'b'whole minute'u'whole minute'b'Return formatted timezone offset (+xx:xx) or an empty string.'u'Return formatted timezone offset (+xx:xx) or an empty string.'b'Convert to formal string, for repr().'u'Convert to formal string, for repr().'b', %d, %d'u', %d, %d'b', %d'u', %d'b'%s.%s(%d, %d%s)'u'%s.%s(%d, %d%s)'b', tzinfo=%r'u', tzinfo=%r'b', fold=1)'u', fold=1)'b'Return the time formatted according to ISO.

        The full format is 'HH:MM:SS.mmmmmm+zz:zz'. By default, the fractional
        part is omitted if self.microsecond == 0.

        The optional argument timespec specifies the number of additional
        terms of the time to include. Valid options are 'auto', 'hours',
        'minutes', 'seconds', 'milliseconds' and 'microseconds'.
        'u'Return the time formatted according to ISO.

        The full format is 'HH:MM:SS.mmmmmm+zz:zz'. By default, the fractional
        part is omitted if self.microsecond == 0.

        The optional argument timespec specifies the number of additional
        terms of the time to include. Valid options are 'auto', 'hours',
        'minutes', 'seconds', 'milliseconds' and 'microseconds'.
        'b'Construct a time from the output of isoformat().'u'Construct a time from the output of isoformat().'b'Format using strftime().  The date part of the timestamp passed
        to underlying strftime should not be used.
        'u'Format using strftime().  The date part of the timestamp passed
        to underlying strftime should not be used.
        'b'Return the timezone offset as timedelta, positive east of UTC
         (negative west of UTC).'u'Return the timezone offset as timedelta, positive east of UTC
         (negative west of UTC).'b'Return the timezone name.

        Note that the name is 100% informational -- there's no requirement that
        it mean anything in particular. For example, "GMT", "UTC", "-500",
        "-5:00", "EDT", "US/Eastern", "America/New York" are all valid replies.
        'u'Return the timezone name.

        Note that the name is 100% informational -- there's no requirement that
        it mean anything in particular. For example, "GMT", "UTC", "-500",
        "-5:00", "EDT", "US/Eastern", "America/New York" are all valid replies.
        'b'Return 0 if DST is not in effect, or the DST offset (as timedelta
        positive eastward) if DST is in effect.

        This is purely informational; the DST offset has already been added to
        the UTC offset returned by utcoffset() if applicable, so there's no
        need to consult dst() unless you're interested in displaying the DST
        info.
        'u'Return 0 if DST is not in effect, or the DST offset (as timedelta
        positive eastward) if DST is in effect.

        This is purely informational; the DST offset has already been added to
        the UTC offset returned by utcoffset() if applicable, so there's no
        need to consult dst() unless you're interested in displaying the DST
        info.
        'b'Return a new time with new values for the specified fields.'u'Return a new time with new values for the specified fields.'b'bad tzinfo state arg'u'bad tzinfo state arg'b'datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])

    The year, month and day arguments are required. tzinfo may be None, or an
    instance of a tzinfo subclass. The remaining arguments may be ints.
    'u'datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])

    The year, month and day arguments are required. tzinfo may be None, or an
    instance of a tzinfo subclass. The remaining arguments may be ints.
    'b'Failed to encode latin1 string when unpickling a datetime object. pickle.load(data, encoding='latin1') is assumed.'u'Failed to encode latin1 string when unpickling a datetime object. pickle.load(data, encoding='latin1') is assumed.'b'Construct a datetime from a POSIX timestamp (like time.time()).

        A timezone info object may be passed in as well.
        'u'Construct a datetime from a POSIX timestamp (like time.time()).

        A timezone info object may be passed in as well.
        'b'Construct a naive UTC datetime from a POSIX timestamp.'u'Construct a naive UTC datetime from a POSIX timestamp.'b'Construct a datetime from time.time() and optional time zone info.'u'Construct a datetime from time.time() and optional time zone info.'b'Construct a UTC datetime from time.time().'u'Construct a UTC datetime from time.time().'b'Construct a datetime from a given date and a given time.'u'Construct a datetime from a given date and a given time.'b'date argument must be a date instance'u'date argument must be a date instance'b'time argument must be a time instance'u'time argument must be a time instance'b'Construct a datetime from the output of datetime.isoformat().'u'Construct a datetime from the output of datetime.isoformat().'b'Return integer POSIX timestamp.'u'Return integer POSIX timestamp.'b'Return POSIX timestamp as float'u'Return POSIX timestamp as float'b'Return UTC time tuple compatible with time.gmtime().'u'Return UTC time tuple compatible with time.gmtime().'b'Return the date part.'u'Return the date part.'b'Return the time part, with tzinfo None.'u'Return the time part, with tzinfo None.'b'Return the time part, with same tzinfo.'u'Return the time part, with same tzinfo.'b'Return a new datetime with new values for the specified fields.'u'Return a new datetime with new values for the specified fields.'b'tz argument must be an instance of tzinfo'u'tz argument must be an instance of tzinfo'b'%s %s %2d %02d:%02d:%02d %04d'u'%s %s %2d %02d:%02d:%02d %04d'b'Return the time formatted according to ISO.

        The full format looks like 'YYYY-MM-DD HH:MM:SS.mmmmmm'.
        By default, the fractional part is omitted if self.microsecond == 0.

        If self.tzinfo is not None, the UTC offset is also attached, giving
        giving a full format of 'YYYY-MM-DD HH:MM:SS.mmmmmm+HH:MM'.

        Optional argument sep specifies the separator between date and
        time, default 'T'.

        The optional argument timespec specifies the number of additional
        terms of the time to include. Valid options are 'auto', 'hours',
        'minutes', 'seconds', 'milliseconds' and 'microseconds'.
        'u'Return the time formatted according to ISO.

        The full format looks like 'YYYY-MM-DD HH:MM:SS.mmmmmm'.
        By default, the fractional part is omitted if self.microsecond == 0.

        If self.tzinfo is not None, the UTC offset is also attached, giving
        giving a full format of 'YYYY-MM-DD HH:MM:SS.mmmmmm+HH:MM'.

        Optional argument sep specifies the separator between date and
        time, default 'T'.

        The optional argument timespec specifies the number of additional
        terms of the time to include. Valid options are 'auto', 'hours',
        'minutes', 'seconds', 'milliseconds' and 'microseconds'.
        'b'%04d-%02d-%02d%c'u'%04d-%02d-%02d%c'b'Convert to string, for str().'u'Convert to string, for str().'b'string, format -> new datetime parsed from a string (like time.strptime()).'u'string, format -> new datetime parsed from a string (like time.strptime()).'b'Return the timezone offset as timedelta positive east of UTC (negative west of
        UTC).'u'Return the timezone offset as timedelta positive east of UTC (negative west of
        UTC).'b'cannot compare naive and aware datetimes'u'cannot compare naive and aware datetimes'b'Add a datetime and a timedelta.'u'Add a datetime and a timedelta.'b'Subtract two datetimes, or a datetime and a timedelta.'u'Subtract two datetimes, or a datetime and a timedelta.'b'cannot mix naive and timezone-aware time'u'cannot mix naive and timezone-aware time'b'_offset'u'_offset'b'_name'u'_name'b'offset must be a timedelta'u'offset must be a timedelta'b'offset must be a timedelta strictly between -timedelta(hours=24) and timedelta(hours=24).'u'offset must be a timedelta strictly between -timedelta(hours=24) and timedelta(hours=24).'b'pickle support'u'pickle support'b'Convert to formal string, for repr().

        >>> tz = timezone.utc
        >>> repr(tz)
        'datetime.timezone.utc'
        >>> tz = timezone(timedelta(hours=-5), 'EST')
        >>> repr(tz)
        "datetime.timezone(datetime.timedelta(-1, 68400), 'EST')"
        'u'Convert to formal string, for repr().

        >>> tz = timezone.utc
        >>> repr(tz)
        'datetime.timezone.utc'
        >>> tz = timezone(timedelta(hours=-5), 'EST')
        >>> repr(tz)
        "datetime.timezone(datetime.timedelta(-1, 68400), 'EST')"
        'b'datetime.timezone.utc'u'datetime.timezone.utc'b'%s.%s(%r)'u'%s.%s(%r)'b'%s.%s(%r, %r)'u'%s.%s(%r, %r)'b'utcoffset() argument must be a datetime instance or None'u'utcoffset() argument must be a datetime instance or None'b'tzname() argument must be a datetime instance or None'u'tzname() argument must be a datetime instance or None'b'dst() argument must be a datetime instance or None'u'dst() argument must be a datetime instance or None'b'fromutc: dt.tzinfo is not self'u'fromutc: dt.tzinfo is not self'b'fromutc() argument must be a datetime instance or None'u'fromutc() argument must be a datetime instance or None'DISTUTILS_DEBUG# If DISTUTILS_DEBUG is anything other than the empty string, we run in# debug mode.b'DISTUTILS_DEBUG'u'DISTUTILS_DEBUG'u'distutils.debug'_decimal_pydecimalImplementation of JSONDecoder
scannerc_scanstringFLAGSPosInfNegInfSubclass of ValueError with the following additional properties:

    msg: The unformatted error message
    doc: The JSON document being parsed
    pos: The start index of doc where parsing failed
    lineno: The line corresponding to pos
    colno: The column corresponding to pos

    colno%s: line %d column %d (char %d)_CONSTANTS(.*?)(["\\\x00-\x1f])STRINGCHUNKBACKSLASH_decode_uXXXXescInvalid \uXXXX escapepy_scanstring_b_mScan the string s for a JSON string. End is the index of the
    character in s after the quote that started the JSON string.
    Unescapes all valid JSON string escape sequences and raises ValueError
    on attempt to decode an invalid string. If strict is False then literal
    control characters are allowed in the string.

    Returns a tuple of the decoded string and the index of the character in s
    after the end quote._appendUnterminated string starting atInvalid control character {0!r} atInvalid \escape: {0!r}uni0xd8000xdbff\uuni20xdc000xdfff0x10000[ \t\n\r]*WHITESPACE 	
WHITESPACE_STRJSONObjects_and_endscan_once_wspairs_appendmemo_getExpecting property name enclosed in double quotesExpecting ':' delimiterExpecting valueExpecting ',' delimiterJSONArraySimple JSON <https://json.org> decoder

    Performs the following translations in decoding by default:

    +---------------+-------------------+
    | JSON          | Python            |
    +===============+===================+
    | object        | dict              |
    +---------------+-------------------+
    | array         | list              |
    +---------------+-------------------+
    | string        | str               |
    +---------------+-------------------+
    | number (int)  | int               |
    +---------------+-------------------+
    | number (real) | float             |
    +---------------+-------------------+
    | true          | True              |
    +---------------+-------------------+
    | false         | False             |
    +---------------+-------------------+
    | null          | None              |
    +---------------+-------------------+

    It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as
    their corresponding ``float`` values, which is outside the JSON spec.

    ``object_hook``, if specified, will be called with the result
        of every JSON object decoded and its return value will be used in
        place of the given ``dict``.  This can be used to provide custom
        deserializations (e.g. to support JSON-RPC class hinting).

        ``object_pairs_hook``, if specified will be called with the result of
        every JSON object decoded with an ordered list of pairs.  The return
        value of ``object_pairs_hook`` will be used instead of the ``dict``.
        This feature can be used to implement custom decoders.
        If ``object_hook`` is also defined, the ``object_pairs_hook`` takes
        priority.

        ``parse_float``, if specified, will be called with the string
        of every JSON float to be decoded. By default this is equivalent to
        float(num_str). This can be used to use another datatype or parser
        for JSON floats (e.g. decimal.Decimal).

        ``parse_int``, if specified, will be called with the string
        of every JSON int to be decoded. By default this is equivalent to
        int(num_str). This can be used to use another datatype or parser
        for JSON integers (e.g. float).

        ``parse_constant``, if specified, will be called with one of the
        following strings: -Infinity, Infinity, NaN.
        This can be used to raise an exception if invalid JSON numbers
        are encountered.

        If ``strict`` is false (true is the default), then control
        characters will be allowed inside strings.  Control characters in
        this context are those with character codes in the 0-31 range,
        including ``'\t'`` (tab), ``'\n'``, ``'\r'`` and ``'\0'``.
        parse_objectparse_arrayparse_stringReturn the Python representation of ``s`` (a ``str`` instance
        containing a JSON document).

        raw_decodeExtra dataDecode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.

        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.

        # Note that this exception is used from _json# Content is contains zero or more unescaped string characters# Terminator is the end of string, a literal control character,# or a backslash denoting that an escape sequence follows#msg = "Invalid control character %r at" % (terminator,)# If not a unicode escape sequence, must be in the lookup table# Use speedup if available# Use a slice to prevent IndexError from being raised, the following# check will raise a more specific ValueError if the string is empty# Normally we expect nextchar == '"'# Trivial empty object# To skip some function call overhead we optimize the fast paths where# the JSON key separator is ": " or just ":".# Look-ahead for trivial empty arrayb'Implementation of JSONDecoder
'u'Implementation of JSONDecoder
'b'Subclass of ValueError with the following additional properties:

    msg: The unformatted error message
    doc: The JSON document being parsed
    pos: The start index of doc where parsing failed
    lineno: The line corresponding to pos
    colno: The column corresponding to pos

    'u'Subclass of ValueError with the following additional properties:

    msg: The unformatted error message
    doc: The JSON document being parsed
    pos: The start index of doc where parsing failed
    lineno: The line corresponding to pos
    colno: The column corresponding to pos

    'b'%s: line %d column %d (char %d)'u'%s: line %d column %d (char %d)'b'(.*?)(["\\\x00-\x1f])'u'(.*?)(["\\\x00-\x1f])'b''u''b''u''b'Invalid \uXXXX escape'u'Invalid \uXXXX escape'b'Scan the string s for a JSON string. End is the index of the
    character in s after the quote that started the JSON string.
    Unescapes all valid JSON string escape sequences and raises ValueError
    on attempt to decode an invalid string. If strict is False then literal
    control characters are allowed in the string.

    Returns a tuple of the decoded string and the index of the character in s
    after the end quote.'u'Scan the string s for a JSON string. End is the index of the
    character in s after the quote that started the JSON string.
    Unescapes all valid JSON string escape sequences and raises ValueError
    on attempt to decode an invalid string. If strict is False then literal
    control characters are allowed in the string.

    Returns a tuple of the decoded string and the index of the character in s
    after the end quote.'b'Unterminated string starting at'u'Unterminated string starting at'b'Invalid control character {0!r} at'u'Invalid control character {0!r} at'b'Invalid \escape: {0!r}'u'Invalid \escape: {0!r}'b'\u'u'\u'b'[ \t\n\r]*'u'[ \t\n\r]*'b' 	
'u' 	
'b'Expecting property name enclosed in double quotes'u'Expecting property name enclosed in double quotes'b'Expecting ':' delimiter'u'Expecting ':' delimiter'b'Expecting value'u'Expecting value'b'Expecting ',' delimiter'u'Expecting ',' delimiter'b'Simple JSON <https://json.org> decoder

    Performs the following translations in decoding by default:

    +---------------+-------------------+
    | JSON          | Python            |
    +===============+===================+
    | object        | dict              |
    +---------------+-------------------+
    | array         | list              |
    +---------------+-------------------+
    | string        | str               |
    +---------------+-------------------+
    | number (int)  | int               |
    +---------------+-------------------+
    | number (real) | float             |
    +---------------+-------------------+
    | true          | True              |
    +---------------+-------------------+
    | false         | False             |
    +---------------+-------------------+
    | null          | None              |
    +---------------+-------------------+

    It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as
    their corresponding ``float`` values, which is outside the JSON spec.

    'u'Simple JSON <https://json.org> decoder

    Performs the following translations in decoding by default:

    +---------------+-------------------+
    | JSON          | Python            |
    +===============+===================+
    | object        | dict              |
    +---------------+-------------------+
    | array         | list              |
    +---------------+-------------------+
    | string        | str               |
    +---------------+-------------------+
    | number (int)  | int               |
    +---------------+-------------------+
    | number (real) | float             |
    +---------------+-------------------+
    | true          | True              |
    +---------------+-------------------+
    | false         | False             |
    +---------------+-------------------+
    | null          | None              |
    +---------------+-------------------+

    It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as
    their corresponding ``float`` values, which is outside the JSON spec.

    'b'``object_hook``, if specified, will be called with the result
        of every JSON object decoded and its return value will be used in
        place of the given ``dict``.  This can be used to provide custom
        deserializations (e.g. to support JSON-RPC class hinting).

        ``object_pairs_hook``, if specified will be called with the result of
        every JSON object decoded with an ordered list of pairs.  The return
        value of ``object_pairs_hook`` will be used instead of the ``dict``.
        This feature can be used to implement custom decoders.
        If ``object_hook`` is also defined, the ``object_pairs_hook`` takes
        priority.

        ``parse_float``, if specified, will be called with the string
        of every JSON float to be decoded. By default this is equivalent to
        float(num_str). This can be used to use another datatype or parser
        for JSON floats (e.g. decimal.Decimal).

        ``parse_int``, if specified, will be called with the string
        of every JSON int to be decoded. By default this is equivalent to
        int(num_str). This can be used to use another datatype or parser
        for JSON integers (e.g. float).

        ``parse_constant``, if specified, will be called with one of the
        following strings: -Infinity, Infinity, NaN.
        This can be used to raise an exception if invalid JSON numbers
        are encountered.

        If ``strict`` is false (true is the default), then control
        characters will be allowed inside strings.  Control characters in
        this context are those with character codes in the 0-31 range,
        including ``'\t'`` (tab), ``'\n'``, ``'\r'`` and ``'\0'``.
        'u'``object_hook``, if specified, will be called with the result
        of every JSON object decoded and its return value will be used in
        place of the given ``dict``.  This can be used to provide custom
        deserializations (e.g. to support JSON-RPC class hinting).

        ``object_pairs_hook``, if specified will be called with the result of
        every JSON object decoded with an ordered list of pairs.  The return
        value of ``object_pairs_hook`` will be used instead of the ``dict``.
        This feature can be used to implement custom decoders.
        If ``object_hook`` is also defined, the ``object_pairs_hook`` takes
        priority.

        ``parse_float``, if specified, will be called with the string
        of every JSON float to be decoded. By default this is equivalent to
        float(num_str). This can be used to use another datatype or parser
        for JSON floats (e.g. decimal.Decimal).

        ``parse_int``, if specified, will be called with the string
        of every JSON int to be decoded. By default this is equivalent to
        int(num_str). This can be used to use another datatype or parser
        for JSON integers (e.g. float).

        ``parse_constant``, if specified, will be called with one of the
        following strings: -Infinity, Infinity, NaN.
        This can be used to raise an exception if invalid JSON numbers
        are encountered.

        If ``strict`` is false (true is the default), then control
        characters will be allowed inside strings.  Control characters in
        this context are those with character codes in the 0-31 range,
        including ``'\t'`` (tab), ``'\n'``, ``'\r'`` and ``'\0'``.
        'b'Return the Python representation of ``s`` (a ``str`` instance
        containing a JSON document).

        'u'Return the Python representation of ``s`` (a ``str`` instance
        containing a JSON document).

        'b'Extra data'u'Extra data'b'Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.

        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.

        'u'Decode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.

        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.

        'u'json.decoder'u'decoder'distutils.dep_util

Utility functions for simple, timestamp-based dependency of files
and groups of files; also, function based entirely on such
timestamp dependency analysis.DistutilsFileErrorReturn true if 'source' exists and is more recently modified than
    'target', or if 'source' exists and 'target' doesn't.  Return false if
    both exist and 'target' is the same age or younger than 'source'.
    Raise DistutilsFileError if 'source' does not exist.
    file '%s' does not existmtime1mtime2newer_pairwiseWalk two filename lists in parallel, testing if each source is newer
    than its corresponding target.  Return a pair of lists (sources,
    targets) where source is newer than target, according to the semantics
    of 'newer()'.
    'sources' and 'targets' must be same lengthn_sourcesn_targetsReturn true if 'target' is out-of-date with respect to any file
    listed in 'sources'.  In other words, if 'target' exists and is newer
    than every file in 'sources', return false; otherwise return true.
    'missing' controls what we do when a source file is missing; the
    default ("error") is to blow up with an OSError from inside 'stat()';
    if it is "ignore", we silently drop any missing source files; if it is
    "newer", any missing source files make us assume that 'target' is
    out-of-date (this is handy in "dry-run" mode: it'll make you pretend to
    carry out commands that wouldn't work because inputs are missing, but
    that doesn't matter because you're not actually going to run the
    commands).
    target_mtime# newer ()# build a pair of lists (sources, targets) where  source is newer# newer_pairwise ()# If the target doesn't even exist, then it's definitely out-of-date.# Otherwise we have to find out the hard way: if *any* source file# is more recent than 'target', then 'target' is out-of-date and# we can immediately return true.  If we fall through to the end# of the loop, then 'target' is up-to-date and we return false.# blow up when we stat() the file# missing source dropped from#  target's dependency list# missing source means target is#  out-of-date# newer_group ()b'distutils.dep_util

Utility functions for simple, timestamp-based dependency of files
and groups of files; also, function based entirely on such
timestamp dependency analysis.'u'distutils.dep_util

Utility functions for simple, timestamp-based dependency of files
and groups of files; also, function based entirely on such
timestamp dependency analysis.'b'Return true if 'source' exists and is more recently modified than
    'target', or if 'source' exists and 'target' doesn't.  Return false if
    both exist and 'target' is the same age or younger than 'source'.
    Raise DistutilsFileError if 'source' does not exist.
    'u'Return true if 'source' exists and is more recently modified than
    'target', or if 'source' exists and 'target' doesn't.  Return false if
    both exist and 'target' is the same age or younger than 'source'.
    Raise DistutilsFileError if 'source' does not exist.
    'b'file '%s' does not exist'u'file '%s' does not exist'b'Walk two filename lists in parallel, testing if each source is newer
    than its corresponding target.  Return a pair of lists (sources,
    targets) where source is newer than target, according to the semantics
    of 'newer()'.
    'u'Walk two filename lists in parallel, testing if each source is newer
    than its corresponding target.  Return a pair of lists (sources,
    targets) where source is newer than target, according to the semantics
    of 'newer()'.
    'b''sources' and 'targets' must be same length'u''sources' and 'targets' must be same length'b'Return true if 'target' is out-of-date with respect to any file
    listed in 'sources'.  In other words, if 'target' exists and is newer
    than every file in 'sources', return false; otherwise return true.
    'missing' controls what we do when a source file is missing; the
    default ("error") is to blow up with an OSError from inside 'stat()';
    if it is "ignore", we silently drop any missing source files; if it is
    "newer", any missing source files make us assume that 'target' is
    out-of-date (this is handy in "dry-run" mode: it'll make you pretend to
    carry out commands that wouldn't work because inputs are missing, but
    that doesn't matter because you're not actually going to run the
    commands).
    'u'Return true if 'target' is out-of-date with respect to any file
    listed in 'sources'.  In other words, if 'target' exists and is newer
    than every file in 'sources', return false; otherwise return true.
    'missing' controls what we do when a source file is missing; the
    default ("error") is to blow up with an OSError from inside 'stat()';
    if it is "ignore", we silently drop any missing source files; if it is
    "newer", any missing source files make us assume that 'target' is
    out-of-date (this is handy in "dry-run" mode: it'll make you pretend to
    carry out commands that wouldn't work because inputs are missing, but
    that doesn't matter because you're not actually going to run the
    commands).
    'u'distutils.dep_util'u'dep_util'questheadDIALOG_ICON__dialog__tk_dialogFile ModifiedFile "Python.h" has been modified since the last time it was saved. Do you want to save it before exiting the application.'File "Python.h" has been modified'' since the last time it was saved.'' Do you want to save it before'' exiting the application.'Save FileDiscard ChangesReturn to EditorTestQuit# dialog.py -- Tkinter interface to the tk_dialog script.b'questhead'u'questhead'b'__dialog__'u'__dialog__'b'tk_dialog'u'tk_dialog'b'strings'u'strings'b'File Modified'u'File Modified'b'File "Python.h" has been modified since the last time it was saved. Do you want to save it before exiting the application.'u'File "Python.h" has been modified since the last time it was saved. Do you want to save it before exiting the application.'b'Save File'u'Save File'b'Discard Changes'u'Discard Changes'b'Return to Editor'u'Return to Editor'b'Test'u'Test'b'Quit'u'Quit'u'dialog'
Module difflib -- helpers for computing deltas between objects.

Function get_close_matches(word, possibilities, n=3, cutoff=0.6):
    Use SequenceMatcher to return list of the best "good enough" matches.

Function context_diff(a, b):
    For two lists of strings, return a delta in context diff format.

Function ndiff(a, b):
    Return a delta: the difference between `a` and `b` (lists of strings).

Function restore(delta, which):
    Return one of the two sequences that generated an ndiff delta.

Function unified_diff(a, b):
    For two lists of strings, return a delta in unified diff format.

Class SequenceMatcher:
    A flexible class for comparing pairs of sequences of any type.

Class Differ:
    For producing human-readable deltas from sequences of lines of text.

Class HtmlDiff:
    For producing HTML side by side comparison with change highlights.
get_close_matchesSequenceMatcherDifferIS_CHARACTER_JUNKIS_LINE_JUNKcontext_diffunified_diffdiff_bytesHtmlDiff_nlargesta b size_calculate_ratio
    SequenceMatcher is a flexible class for comparing pairs of sequences of
    any type, so long as the sequence elements are hashable.  The basic
    algorithm predates, and is a little fancier than, an algorithm
    published in the late 1980's by Ratcliff and Obershelp under the
    hyperbolic name "gestalt pattern matching".  The basic idea is to find
    the longest contiguous matching subsequence that contains no "junk"
    elements (R-O doesn't address junk).  The same idea is then applied
    recursively to the pieces of the sequences to the left and to the right
    of the matching subsequence.  This does not yield minimal edit
    sequences, but does tend to yield matches that "look right" to people.

    SequenceMatcher tries to compute a "human-friendly diff" between two
    sequences.  Unlike e.g. UNIX(tm) diff, the fundamental notion is the
    longest *contiguous* & junk-free matching subsequence.  That's what
    catches peoples' eyes.  The Windows(tm) windiff has another interesting
    notion, pairing up elements that appear uniquely in each sequence.
    That, and the method here, appear to yield more intuitive difference
    reports than does diff.  This method appears to be the least vulnerable
    to syncing up on blocks of "junk lines", though (like blank lines in
    ordinary text files, or maybe "<P>" lines in HTML files).  That may be
    because this is the only method of the 3 that has a *concept* of
    "junk" <wink>.

    Example, comparing two strings, and considering blanks to be "junk":

    >>> s = SequenceMatcher(lambda x: x == " ",
    ...                     "private Thread currentThread;",
    ...                     "private volatile Thread currentThread;")
    >>>

    .ratio() returns a float in [0, 1], measuring the "similarity" of the
    sequences.  As a rule of thumb, a .ratio() value over 0.6 means the
    sequences are close matches:

    >>> print(round(s.ratio(), 3))
    0.866
    >>>

    If you're only interested in where the sequences match,
    .get_matching_blocks() is handy:

    >>> for block in s.get_matching_blocks():
    ...     print("a[%d] and b[%d] match for %d elements" % block)
    a[0] and b[0] match for 8 elements
    a[8] and b[17] match for 21 elements
    a[29] and b[38] match for 0 elements

    Note that the last tuple returned by .get_matching_blocks() is always a
    dummy, (len(a), len(b), 0), and this is the only case in which the last
    tuple element (number of elements matched) is 0.

    If you want to know how to change the first sequence into the second,
    use .get_opcodes():

    >>> for opcode in s.get_opcodes():
    ...     print("%6s a[%d:%d] b[%d:%d]" % opcode)
     equal a[0:8] b[0:8]
    insert a[8:8] b[8:17]
     equal a[8:29] b[17:38]

    See the Differ class for a fancy human-friendly file differencer, which
    uses SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    See also function get_close_matches() in this module, which shows how
    simple code building on SequenceMatcher can be used to do useful work.

    Timing:  Basic R-O is cubic time worst case and quadratic time expected
    case.  SequenceMatcher is quadratic time for the worst case and has
    expected-case behavior dependent in a complicated way on how many
    elements the sequences have in common; best case time is linear.
    isjunkautojunkConstruct a SequenceMatcher.

        Optional arg isjunk is None (the default), or a one-argument
        function that takes a sequence element and returns true iff the
        element is junk.  None is equivalent to passing "lambda x: 0", i.e.
        no elements are considered to be junk.  For example, pass
            lambda x: x in " \t"
        if you're comparing lines as sequences of characters, and don't
        want to synch up on blanks or hard tabs.

        Optional arg a is the first of two sequences to be compared.  By
        default, an empty string.  The elements of a must be hashable.  See
        also .set_seqs() and .set_seq1().

        Optional arg b is the second of two sequences to be compared.  By
        default, an empty string.  The elements of b must be hashable. See
        also .set_seqs() and .set_seq2().

        Optional arg autojunk should be set to False to disable the
        "automatic junk heuristic" that treats popular elements as junk
        (see module documentation for more information).
        set_seqsSet the two sequences to be compared.

        >>> s = SequenceMatcher()
        >>> s.set_seqs("abcd", "bcde")
        >>> s.ratio()
        0.75
        set_seq1set_seq2Set the first sequence to be compared.

        The second sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq1("bcde")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq2().
        matching_blocksopcodesSet the second sequence to be compared.

        The first sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq2("abcd")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq1().
        fullbcount__chain_bb2jbjunkjunkbpopularpopularntestidxsfind_longest_matchaloahiblobhiFind longest matching block in a[alo:ahi] and b[blo:bhi].

        By default it will find the longest match in the entirety of a and b.

        If isjunk is not defined:

        Return (i,j,k) such that a[i:i+k] is equal to b[j:j+k], where
            alo <= i <= i+k <= ahi
            blo <= j <= j+k <= bhi
        and for all (i',j',k') meeting those conditions,
            k >= k'
            i <= i'
            and if i == i', j <= j'

        In other words, of all maximal matching blocks, return one that
        starts earliest in a, and of all those maximal matching blocks that
        start earliest in a, return the one that starts earliest in b.

        >>> s = SequenceMatcher(None, " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=0, b=4, size=5)

        If isjunk is defined, first the longest matching block is
        determined as above, but with the additional restriction that no
        junk element appears in the block.  Then that block is extended as
        far as possible by matching (only) junk elements on both sides.  So
        the resulting block never matches on junk except as identical junk
        happens to be adjacent to an "interesting" match.

        Here's the same example as before, but considering blanks to be
        junk.  That prevents " abcd" from matching the " abcd" at the tail
        end of the second sequence directly.  Instead only the "abcd" can
        match, and matches the leftmost "abcd" in the second sequence:

        >>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=1, b=0, size=4)

        If no blocks match, return (alo, blo, 0).

        >>> s = SequenceMatcher(None, "ab", "c")
        >>> s.find_longest_match(0, 2, 0, 1)
        Match(a=0, b=0, size=0)
        isbjunkbestibestjbestsizej2lennothingj2lengetnewj2lenget_matching_blocksReturn list of triples describing matching subsequences.

        Each triple is of the form (i, j, n), and means that
        a[i:i+n] == b[j:j+n].  The triples are monotonically increasing in
        i and in j.  New in Python 2.5, it's also guaranteed that if
        (i, j, n) and (i', j', n') are adjacent triples in the list, and
        the second is not the last triple in the list, then i+n != i' or
        j+n != j'.  IOW, adjacent triples never describe adjacent equal
        blocks.

        The last triple is a dummy, (len(a), len(b), 0), and is the only
        triple with n==0.

        >>> s = SequenceMatcher(None, "abxcd", "abcd")
        >>> list(s.get_matching_blocks())
        [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]
        lalbj1k1non_adjacentj2k2get_opcodesReturn list of 5-tuples describing how to turn a into b.

        Each tuple is of the form (tag, i1, i2, j1, j2).  The first tuple
        has i1 == j1 == 0, and remaining tuples have i1 == the i2 from the
        tuple preceding it, and likewise for j1 == the previous j2.

        The tags are strings, with these meanings:

        'replace':  a[i1:i2] should be replaced by b[j1:j2]
        'delete':   a[i1:i2] should be deleted.
                    Note that j1==j2 in this case.
        'insert':   b[j1:j2] should be inserted at a[i1:i1].
                    Note that i1==i2 in this case.
        'equal':    a[i1:i2] == b[j1:j2]

        >>> a = "qabxcd"
        >>> b = "abycdf"
        >>> s = SequenceMatcher(None, a, b)
        >>> for tag, i1, i2, j1, j2 in s.get_opcodes():
        ...    print(("%7s a[%d:%d] (%s) b[%d:%d] (%s)" %
        ...           (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2])))
         delete a[0:1] (q) b[0:0] ()
          equal a[1:3] (ab) b[0:2] (ab)
        replace a[3:4] (x) b[2:3] (y)
          equal a[4:6] (cd) b[3:5] (cd)
         insert a[6:6] () b[5:6] (f)
        answeraibjequalget_grouped_opcodes Isolate change clusters by eliminating ranges with no changes.

        Return a generator of groups with up to n lines of context.
        Each group is in the same format as returned by get_opcodes().

        >>> from pprint import pprint
        >>> a = list(map(str, range(1,40)))
        >>> b = a[:]
        >>> b[8:8] = ['i']     # Make an insertion
        >>> b[20] += 'x'       # Make a replacement
        >>> b[23:28] = []      # Make a deletion
        >>> b[30] += 'y'       # Make another replacement
        >>> pprint(list(SequenceMatcher(None,a,b).get_grouped_opcodes()))
        [[('equal', 5, 8, 5, 8), ('insert', 8, 8, 8, 9), ('equal', 8, 11, 9, 12)],
         [('equal', 16, 19, 17, 20),
          ('replace', 19, 20, 20, 21),
          ('equal', 20, 22, 21, 23),
          ('delete', 22, 27, 23, 23),
          ('equal', 27, 30, 23, 26)],
         [('equal', 31, 34, 27, 30),
          ('replace', 34, 35, 30, 31),
          ('equal', 35, 38, 31, 34)]]
        nnReturn a measure of the sequences' similarity (float in [0,1]).

        Where T is the total number of elements in both sequences, and
        M is the number of matches, this is 2.0*M / T.
        Note that this is 1 if the sequences are identical, and 0 if
        they have nothing in common.

        .ratio() is expensive to compute if you haven't already computed
        .get_matching_blocks() or .get_opcodes(), in which case you may
        want to try .quick_ratio() or .real_quick_ratio() first to get an
        upper bound.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.quick_ratio()
        0.75
        >>> s.real_quick_ratio()
        1.0
        triplequick_ratioReturn an upper bound on ratio() relatively quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute.
        availavailhasnumbreal_quick_ratioReturn an upper bound on ratio() very quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute than either .ratio() or .quick_ratio().
        0.6possibilitiesUse SequenceMatcher to return list of the best "good enough" matches.

    word is a sequence for which close matches are desired (typically a
    string).

    possibilities is a list of sequences against which to match word
    (typically a list of strings).

    Optional arg n (default 3) is the maximum number of close matches to
    return.  n must be > 0.

    Optional arg cutoff (default 0.6) is a float in [0, 1].  Possibilities
    that don't score at least that similar to word are ignored.

    The best (no more than n) matches among the possibilities are returned
    in a list, sorted by similarity score, most similar first.

    >>> get_close_matches("appel", ["ape", "apple", "peach", "puppy"])
    ['apple', 'ape']
    >>> import keyword as _keyword
    >>> get_close_matches("wheel", _keyword.kwlist)
    ['while']
    >>> get_close_matches("Apple", _keyword.kwlist)
    []
    >>> get_close_matches("accept", _keyword.kwlist)
    ['except']
    n must be > 0: %rcutoff must be in [0.0, 1.0]: %rscore_keep_original_wstag_sReplace whitespace with the original whitespace characters in `s`tag_c
    Differ is a class for comparing sequences of lines of text, and
    producing human-readable differences or deltas.  Differ uses
    SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    Each line of a Differ delta begins with a two-letter code:

        '- '    line unique to sequence 1
        '+ '    line unique to sequence 2
        '  '    line common to both sequences
        '? '    line not present in either input sequence

    Lines beginning with '? ' attempt to guide the eye to intraline
    differences, and were not present in either input sequence.  These lines
    can be confusing if the sequences contain tab characters.

    Note that Differ makes no claim to produce a *minimal* diff.  To the
    contrary, minimal diffs are often counter-intuitive, because they synch
    up anywhere possible, sometimes accidental matches 100 pages apart.
    Restricting synch points to contiguous matches preserves some notion of
    locality, at the occasional cost of producing a longer diff.

    Example: Comparing two texts.

    First we set up the texts, sequences of individual single-line strings
    ending with newlines (such sequences can also be obtained from the
    `readlines()` method of file-like objects):

    >>> text1 = '''  1. Beautiful is better than ugly.
    ...   2. Explicit is better than implicit.
    ...   3. Simple is better than complex.
    ...   4. Complex is better than complicated.
    ... '''.splitlines(keepends=True)
    >>> len(text1)
    4
    >>> text1[0][-1]
    '\n'
    >>> text2 = '''  1. Beautiful is better than ugly.
    ...   3.   Simple is better than complex.
    ...   4. Complicated is better than complex.
    ...   5. Flat is better than nested.
    ... '''.splitlines(keepends=True)

    Next we instantiate a Differ object:

    >>> d = Differ()

    Note that when instantiating a Differ object we may pass functions to
    filter out line and character 'junk'.  See Differ.__init__ for details.

    Finally, we compare the two:

    >>> result = list(d.compare(text1, text2))

    'result' is a list of strings, so let's pretty-print it:

    >>> from pprint import pprint as _pprint
    >>> _pprint(result)
    ['    1. Beautiful is better than ugly.\n',
     '-   2. Explicit is better than implicit.\n',
     '-   3. Simple is better than complex.\n',
     '+   3.   Simple is better than complex.\n',
     '?     ++\n',
     '-   4. Complex is better than complicated.\n',
     '?            ^                     ---- ^\n',
     '+   4. Complicated is better than complex.\n',
     '?           ++++ ^                      ^\n',
     '+   5. Flat is better than nested.\n']

    As a single multi-line string it looks like this:

    >>> print(''.join(result), end="")
        1. Beautiful is better than ugly.
    -   2. Explicit is better than implicit.
    -   3. Simple is better than complex.
    +   3.   Simple is better than complex.
    ?     ++
    -   4. Complex is better than complicated.
    ?            ^                     ---- ^
    +   4. Complicated is better than complex.
    ?           ++++ ^                      ^
    +   5. Flat is better than nested.
    linejunkcharjunk
        Construct a text differencer, with optional filters.

        The two optional keyword parameters are for filter functions:

        - `linejunk`: A function that should accept a single string argument,
          and return true iff the string is junk. The module-level function
          `IS_LINE_JUNK` may be used to filter out lines without visible
          characters, except for at most one splat ('#').  It is recommended
          to leave linejunk None; the underlying SequenceMatcher class has
          an adaptive notion of "noise" lines that's better than any static
          definition the author has ever been able to craft.

        - `charjunk`: A function that should accept a string of length 1. The
          module-level function `IS_CHARACTER_JUNK` may be used to filter out
          whitespace characters (a blank or tab; **note**: bad idea to include
          newline in this!).  Use of IS_CHARACTER_JUNK is recommended.
        
        Compare two sequences of lines; generate the resulting delta.

        Each sequence must contain individual single-line strings ending with
        newlines. Such sequences can be obtained from the `readlines()` method
        of file-like objects.  The delta generated also consists of newline-
        terminated strings, ready to be printed as-is via the writelines()
        method of a file-like object.

        Example:

        >>> print(''.join(Differ().compare('one\ntwo\nthree\n'.splitlines(True),
        ...                                'ore\ntree\nemu\n'.splitlines(True))),
        ...       end="")
        - one
        ?  ^
        + ore
        ?  ^
        - two
        - three
        ?  -
        + tree
        + emu
        cruncher_fancy_replace_dumpGenerate comparison results for a same-tagged range._plain_replace
        When replacing one block of lines with another, search the blocks
        for *similar* lines; the best-matching pair (if any) is used as a
        synch point, and intraline difference marking is done on the
        similar pair. Lots of work, but often worth it.

        Example:

        >>> d = Differ()
        >>> results = d._fancy_replace(['abcDefghiJkl\n'], 0, 1,
        ...                            ['abcdefGhijkl\n'], 0, 1)
        >>> print(''.join(results), end="")
        - abcDefghiJkl
        ?    ^  ^  ^
        + abcdefGhijkl
        ?    ^  ^  ^
        0.74best_ratioeqieqjbest_ibest_j_fancy_helperaeltbeltatagsbtagsai1ai2bj1bj2_qformatalinebline
        Format "?" output and deal with tabs.

        Example:

        >>> d = Differ()
        >>> results = d._qformat('\tabcDefghiJkl\n', '\tabcdefGhijkl\n',
        ...                      '  ^ ^  ^      ', '  ^ ^  ^      ')
        >>> for line in results: print(repr(line))
        ...
        '- \tabcDefghiJkl\n'
        '? \t ^ ^  ^\n'
        '+ \tabcdefGhijkl\n'
        '? \t ^ ^  ^\n'
        - ? + \s*(?:#\s*)?$
    Return True for ignorable line: iff `line` is blank or contains a single '#'.

    Examples:

    >>> IS_LINE_JUNK('\n')
    True
    >>> IS_LINE_JUNK('  #   \n')
    True
    >>> IS_LINE_JUNK('hello\n')
    False
    
    Return True for ignorable character: iff `ch` is a space or tab.

    Examples:

    >>> IS_CHARACTER_JUNK(' ')
    True
    >>> IS_CHARACTER_JUNK('\t')
    True
    >>> IS_CHARACTER_JUNK('\n')
    False
    >>> IS_CHARACTER_JUNK('x')
    False
    _format_range_unifiedConvert range to the "ed" formatbeginning{},{}fromfiledatetofiledatelineterm
    Compare two sequences of lines; generate the delta as a unified diff.

    Unified diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with ---, +++, or @@) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The unidiff format normally has a header for filenames and modification
    times.  Any or all of these may be specified using strings for
    'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.

    Example:

    >>> for line in unified_diff('one two three four'.split(),
    ...             'zero one tree four'.split(), 'Original', 'Current',
    ...             '2005-01-26 23:30:50', '2010-04-02 10:20:52',
    ...             lineterm=''):
    ...     print(line)                 # doctest: +NORMALIZE_WHITESPACE
    --- Original        2005-01-26 23:30:50
    +++ Current         2010-04-02 10:20:52
    @@ -1,4 +1,4 @@
    +zero
     one
    -two
    -three
    +tree
     four
    _check_types	{}fromdatetodate--- {}{}{}+++ {}{}{}file1_rangefile2_range@@ -{} +{} @@{}_format_range_context
    Compare two sequences of lines; generate the delta as a context diff.

    Context diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with *** or ---) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The context diff format normally has a header for filenames and
    modification times.  Any or all of these may be specified using
    strings for 'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.
    If not specified, the strings default to blanks.

    Example:

    >>> print(''.join(context_diff('one\ntwo\nthree\nfour\n'.splitlines(True),
    ...       'zero\none\ntree\nfour\n'.splitlines(True), 'Original', 'Current')),
    ...       end="")
    *** Original
    --- Current
    ***************
    *** 1,4 ****
      one
    ! two
    ! three
      four
    --- 1,4 ----
    + zero
      one
    ! tree
      four
    ! *** {}{}{}****************** {} ****{}--- {} ----{}lines to compare must be str, not %s (%r)all arguments must be str, not: %rdfunc
    Compare `a` and `b`, two sequences of lines represented as bytes rather
    than str. This is a wrapper for `dfunc`, which is typically either
    unified_diff() or context_diff(). Inputs are losslessly converted to
    strings so that `dfunc` only has to worry about strings, and encoded
    back to bytes on return. This is necessary to compare files with
    unknown or inconsistent encoding. All other inputs (except `n`) must be
    bytes rather than str.
    all arguments must be bytes, not %s (%r)
    Compare `a` and `b` (lists of strings); return a `Differ`-style delta.

    Optional keyword parameters `linejunk` and `charjunk` are for filter
    functions, or can be None:

    - linejunk: A function that should accept a single string argument and
      return true iff the string is junk.  The default is None, and is
      recommended; the underlying SequenceMatcher class has an adaptive
      notion of "noise" lines.

    - charjunk: A function that accepts a character (string of length
      1), and returns true iff the character is junk. The default is
      the module-level function IS_CHARACTER_JUNK, which filters out
      whitespace characters (a blank or tab; note: it's a bad idea to
      include newline in this!).

    Tools/scripts/ndiff.py is a command-line front-end to this function.

    Example:

    >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
    ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
    >>> print(''.join(diff), end="")
    - one
    ?  ^
    + ore
    ?  ^
    - two
    - three
    ?  -
    + tree
    + emu
    _mdifffromlinestolinesReturns generator yielding marked up from/to side by side differences.

    Arguments:
    fromlines -- list of text lines to compared to tolines
    tolines -- list of text lines to be compared to fromlines
    context -- number of context lines to display on each side of difference,
               if None, all from/to text lines will be generated.
    linejunk -- passed on to ndiff (see ndiff documentation)
    charjunk -- passed on to ndiff (see ndiff documentation)

    This function returns an iterator which returns a tuple:
    (from line tuple, to line tuple, boolean flag)

    from/to line tuple -- (line num, line text)
        line num -- integer or None (to indicate a context separation)
        line text -- original line text with following markers inserted:
            '\0+' -- marks start of added text
            '\0-' -- marks start of deleted text
            '\0^' -- marks start of changed text
            '\1' -- marks end of added/deleted/changed text

    boolean flag -- None indicates context separation, True indicates
        either "from" or "to" line contains a change, otherwise False.

    This function/iterator was originally developed to generate side by side
    file difference for making HTML pages (see HtmlDiff class for example
    usage).

    Note, this function utilizes the ndiff function to generate the side by
    side difference markup.  Optional ndiff arguments may be passed to this
    function and they in turn will be passed to ndiff.
    (\++|\-+|\^+)change_rediff_lines_iterator_make_lineformat_keysidenum_linesReturns line of text with user's change markup and line formatting.

        lines -- list of lines from the ndiff generator to produce a line of
                 text from.  When producing the line of text to return, the
                 lines used are removed from this list.
        format_key -- '+' return first line in list with "add" markup around
                          the entire line.
                      '-' return first line in list with "delete" markup around
                          the entire line.
                      '?' return first line in list with add/delete/change
                          intraline markup (indices obtained from second line)
                      None return first line in list with no markup
        side -- indice into the num_lines list (0=from,1=to)
        num_lines -- from/to current line number.  This is NOT intended to be a
                     passed parameter.  It is present as a keyword argument to
                     maintain memory of the current line numbers between calls
                     of this function.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        sub_inforecord_sub_infomatch_object_line_iteratorYields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from a
        differencing iterator, processes them and yields them.  When it can
        it yields both a "from" and a "to" line, otherwise it will yield one
        or the other.  In addition to yielding the lines of from/to text, a
        boolean flag is yielded to indicate if the text line(s) have
        differences in them.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        num_blanks_pendingnum_blanks_to_yield-?+?--++--?+--+from_lineto_line-+?-?++--+-_line_pair_iteratorYields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from the line
        iterator.  Its difference from that iterator is that this function
        always yields a pair of from/to text lines (with the change
        indication).  If necessary it will collect single from/to lines
        until it has a matching pair from/to pair to yield.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        line_iteratorfound_difffromDiffto_diffline_pair_iteratorlines_to_writecontextLines
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html>

<head>
    <meta http-equiv="Content-Type"
          content="text/html; charset=%(charset)s" />
    <title></title>
    <style type="text/css">%(styles)s
    </style>
</head>

<body>
    %(table)s%(legend)s
</body>

</html>_file_template
        table.diff {font-family:Courier; border:medium;}
        .diff_header {background-color:#e0e0e0}
        td.diff_header {text-align:right}
        .diff_next {background-color:#c0c0c0}
        .diff_add {background-color:#aaffaa}
        .diff_chg {background-color:#ffff77}
        .diff_sub {background-color:#ffaaaa}_styles
    <table class="diff" id="difflib_chg_%(prefi   c"    